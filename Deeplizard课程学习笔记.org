* 第2课 PyTorch Explained - Python Deep Learning Neural Network API
pytorch内置支持GPU功能，可以方便地将张量移动到GPU上。 

pytorch于2016年10月发布，在发布之前已经有torch的框架存在。torch是基于lua编程语言的机器学习框架。pytorch是用python对torch进行重写。

pytorch使用了动态计算的计算图，这意味着图形是在操作发生时动态生成的。

#+BEGIN_SRC python
> torch.cuda.is_available()
True

> torch.version.cuda
'10.0'
#+END_SRC
* 第4课 CUDA Explained - Why Deep Learning Uses GPUs
GPU适用于并行计算。 CPU通常有4个或16个核，而GPU有成千上万个核。

最适合GPU的是可以并行完成的计算，我们可以用并行编程方法和GPU完成计算。

使用并行编程方法和GPU可以加速卷积运算。

Cuda为开发者提供了使用英伟达GPU的API

pytorch自带Cudnn。我们可以用pytorch驱动cuda，不需要知道如何使用cuda的API。

下面创建张量的方式默认是在CPU上面运行的
#+BEGIN_SRC python
> t = torch.tensor([1,2,3])
> t
tensor([1, 2, 3])
#+END_SRC
下面的代码可以把张量移到GPU上
#+BEGIN_SRC python
> t = t.cuda()
> t
tensor([1, 2, 3], device='cuda:0')
#+END_SRC
* 第5课 Tensors Explained - Data Structures Of Deep Learning
张量是多维数组。张量维数没有告诉我们张量中有多少个分量。
* 第6课 Rank, Axes, And Shape Explained - Tensors For Deep Learning
#+BEGIN_SRC python
> dd = [
[1,2,3],
[4,5,6],
[7,8,9]
]
> dd[0]
[1, 2, 3]

> dd[1]
[4, 5, 6]

> dd[2]
[7, 8, 9]

> dd[0][0]
1

> dd[1][0]
4
#+END_SRC

张量的形状（shape）告诉我们每个轴的长度，即每个轴上有多少个索引。
#+BEGIN_SRC python
> dd = [
[1,2,3],
[4,5,6],
[7,8,9]
]

> t = torch.tensor(dd)
> t
tensor([
[1, 2, 3],
[4, 5, 6],
[7, 8, 9]
])

> type(t)
torch.Tensor

> t.shape
torch.Size([3,3])
#+END_SRC
在pytorch中，一个张量的大小（size）和形状（shape）是一样的。

可以用 ~reshape~ 改变张量形状
#+BEGIN_SRC python
> t = torch.tensor(dd)
> t
tensor([
[1, 2, 3],
[4, 5, 6],
[7, 8, 9]
])

> t.reshape(1,9)
tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9]])

> t.reshape(1,9).shape
torch.Size([1, 9])
#+END_SRC
* 第8集 PyTorch Tensors Explained - Neural Network Programming
pytorch的张量是类 ~torch.Tensor~ 的实例。可以用下面的方法创建一个空的张量。
#+BEGIN_SRC python
> t = torch.Tensor()
> type(t)
torch.Tensor
#+END_SRC
每个 ~torch.Tensor~ 都有三个属性：
- torch.dtype
- torch.device
- torch.layout
#+BEGIN_SRC python
> print(t.dtype)
> print(t.device)
> print(t.layout)
torch.float32
cpu
torch.strided
#+END_SRC

下面是数据类型列表，只有相同数据类型的张量才能进行运算。
| Data type                | dtype         | CPU tensor         | GPU tensor              |
|--------------------------+---------------+--------------------+-------------------------|
| 32-bit floating point    | torch.float32 | torch.FloatTensor  | torch.cuda.FloatTensor  |
| 64-bit floating point    | torch.float64 | torch.DoubleTensor | torch.cuda.DoubleTensor |
| 16-bit floating point    | torch.float16 | torch.HalfTensor   | torch.cuda.HalfTensor   |
| 8-bit integer (unsigned) | torch.uint8   | torch.ByteTensor   | torch.cuda.ByteTensor   |
| 8-bit integer (signed)   | torch.int8    | torch.CharTensor   | torch.cuda.CharTensor   |
| 16-bit integer (signed)  | torch.int16   | torch.ShortTensor  | torch.cuda.ShortTensor  |
| 32-bit integer (signed)  | torch.int32   | torch.IntTensor    | torch.cuda.IntTensor    |
| 64-bit integer (signed)  | torch.int64   | torch.LongTensor   | torch.cuda.LongTensor   |

我们可以用下面的方法创建一个设备
#+BEGIN_SRC python
> device = torch.device('cuda:0')
> device
device(type='cuda', index=0)
#+END_SRC
~cuda~ 表示GPU的意思。如果我们将索引设置为3或4，而我们系统中并没有3到4个gpu时，当我们给该设备分配张量时，将会报错。
使用多设备时，张量之间的操作必须与存在于同一设备上的张量发生。

布局表示张量在内存中的存储方式。
** 使用数据创建张量的方式
- torch.Tensor(data)
- torch.tensor(data)
- torch.as_tensor(data)
- torch.from_numpy(data)
#+BEGIN_SRC python
> data = np.array([1,2,3])
> type(data)
numpy.ndarray

> o1 = torch.Tensor(data)  //这个是类构造函数，注意它的输出将整数变成了浮点数
> o2 = torch.tensor(data)  //这个和下面两个都是所谓的工厂函数，工厂函数接受参数输入并返回特定类型对象
> o3 = torch.as_tensor(data)
> o4 = torch.from_numpy(data)

> print(o1)
> print(o2)
> print(o3)
> print(o4)
tensor([1., 2., 3.])
tensor([1, 2, 3], dtype=torch.int32)
tensor([1, 2, 3], dtype=torch.int32)
tensor([1, 2, 3], dtype=torch.int32)
#+END_SRC
** 特殊张量的创建
#+BEGIN_SRC bash
>torch.eye(2)
tensor([
    [1., 0.],
    [0., 1.]
])
>torch.zeros([2,2])
tensor([
    [0., 0.],
    [0., 0.]
])
>torch.ones([2,2])
tensor([
    [1., 1.],
    [1., 1.]
])
>torch.rand([2,2])
tensor([
    [0.0465, 0.4557],
    [0.6596, 0.0941]
])
#+END_SRC
* 第9课 Creating PyTorch Tensors For Deep Learning - Best Options
所有的工厂函数都有更好的文档和更多的配置参数。

构造函数在构造一个张量时使用全局缺省值，而工厂函数则根据输入推断数据类型。

我们可以用 ~torch.get_default_dtype()~ 参看 ~dtype~ 的缺省值
#+BEGIN_SRC bash
> torch.get_default_dtype()
torch.float32
#+END_SRC

我们也可以为工厂函数指定数据类型
#+BEGIN_SRC bash
>torch.tensor(np.array([1,2,3]),dtype=torch.float64)
tensor([1.,2.,3.],dtype=torch.float64)
#+END_SRC

#+BEGIN_SRC python
> data = np.array([1,2,3])
> data
array([1,2,3])

> t1 = torch.Tensor(data) 
> t2 = torch.tensor(data) 
> t3 = torch.as_tensor(data)
> t4 = torch.from_numpy(data)

>data[0]=0
>data[1]=0
>data[2]=0

> print(t1)
tensor([1., 2., 3.])
> print(t2)
tensor([1, 2, 3], dtype=torch.int32)

//t3和t4会随着data的改变而改变
> print(t3)
tensor([0, 0, 0], dtype=torch.int32)
> print(t4)
tensor([0, 0, 0], dtype=torch.int32)
#+END_SRC

copy vs share，共享数据比复制数据更有效，使用更少的内存
| Share Data         | Copy Data      |
|--------------------+----------------|
| torch.as_tensor()  | torch.tensor() |
| torch.from_numpy() | torch.Tensor() |

~torch.tensor()~ 是最常使用的，当需要对性能优化时，可以使用数据共享的方法。 ~torch.as_tensor()~ 比 ~torch.from_numpy()~ 更常用，因为 ~torch.as_tensor()~ 可以接受任何像python这样的数组，而 ~torch.from_numpy()~ 只接受numpy数组。

#+BEGIN_QUOTE
Some things to keep in mind about memory sharing (it works where it can):
1. Since ~numpy.ndarray~ objects are allocated on the CPU, the ~as_tensor()~ function must copy the data from the CPU to the GPU when a GPU is being used.
2. The memory sharing of ~as_tensor()~ doesn’t work with built-in Python data structures like lists.
3. The ~as_tensor()~ call requires developer knowledge of the sharing feature. This is necessary so we don’t inadvertently make an unwanted change in the underlying data without realizing the change impacts multiple objects.
4. The ~as_tensor()~ performance improvement will be greater if there are a lot of back and forth operations between ~numpy.ndarray~ objects and tensor objects. However, if there is just a single load operation, there shouldn’t be much impact from a performance perspective.
#+END_QUOTE
* 第10课 Flatten, Reshape, And Squeeze Explained - Tensors For Deep Learning With PyTorch
Reshaping operations
Element-wise operations
Reduction operations
Access operations

** Reshaping operations
#+BEGIN_SRC bash
> t = torch.tensor([
    [1,1,1,1],
    [2,2,2,2],
    [3,3,3,3]
], dtype=torch.float32)

> t.size()
torch.Size([3, 4])

> t.shape
torch.Size([3, 4])

//获取秩
> len(t.shape)  
2
#+END_SRC
下面两种方法可以得到张量的元素总个数
#+BEGIN_SRC bash
> torch.tensor(t.shape).prod()
tensor(12)
> t.numel()
12
#+END_SRC
在使用 ~reshape~ 时必须保证元素总个数相等

~squeeze~ 可以移除（压缩）所有长度为1的轴，而 ~unsqueeze~ 可以增加一个长度为1的维度
#+BEGIN_SRC bash
> print(t.reshape([1,12]))
> print(t.reshape([1,12]).shape)
tensor([[1., 1., 1., 1., 2., 2., 2., 2., 3., 3., 3., 3.]])
torch.Size([1, 12])

> print(t.reshape([1,12]).squeeze())
> print(t.reshape([1,12]).squeeze().shape)
tensor([1., 1., 1., 1., 2., 2., 2., 2., 3., 3., 3., 3.])
torch.Size([12])

> print(t.reshape([1,12]).squeeze().unsqueeze(dim=0))
> print(t.reshape([1,12]).squeeze().unsqueeze(dim=0).shape)
tensor([[1., 1., 1., 1., 2., 2., 2., 2., 3., 3., 3., 3.]])
torch.Size([1, 12])
#+END_SRC

我们可以写一个展平（flatten）函数将一个张量变成一维数组
#+BEGIN_SRC python
def flatten(t):
    t = t.reshape(1, -1)
    t = t.squeeze()
    return t
#+END_SRC
#+BEGIN_SRC bash
> t = torch.ones(4, 3)
> t
tensor([[1., 1., 1.],
    [1., 1., 1.],
    [1., 1., 1.],
    [1., 1., 1.]])

> flatten(t)
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])
#+END_SRC

** 张量拼接
使用 ~cat~ 并指定在哪个维度进行拼接即可
#+BEGIN_SRC bash
> t1 = torch.tensor([
    [1,2],
    [3,4]
])
> t2 = torch.tensor([
    [5,6],
    [7,8]
])

> torch.cat((t1, t2), dim=0)
tensor([[1, 2],
        [3, 4],
        [5, 6],
        [7, 8]])

> torch.cat((t1, t2), dim=1)
tensor([[1, 2, 5, 6],
        [3, 4, 7, 8]])

> torch.cat((t1, t2), dim=0).shape
torch.Size([4, 2])

> torch.cat((t1, t2), dim=1).shape
torch.Size([2, 4])
#+END_SRC
* 第11课 CNN Flatten Operation Visualized - Tensor Batch Processing For Deep Learning
~stack~ 可以创建训练批（batch）
#+BEGIN_SRC python
t1 = torch.tensor([
    [1,1,1,1],
    [1,1,1,1],
    [1,1,1,1],
    [1,1,1,1]
])

t2 = torch.tensor([
    [2,2,2,2],
    [2,2,2,2],
    [2,2,2,2],
    [2,2,2,2]
])

t3 = torch.tensor([
    [3,3,3,3],
    [3,3,3,3],
    [3,3,3,3],
    [3,3,3,3]
])

> t = torch.stack((t1, t2, t3))
> t.shape
torch.Size([3, 4, 4])
> t
tensor([[[1, 1, 1, 1],
         [1, 1, 1, 1],
         [1, 1, 1, 1],
         [1, 1, 1, 1]],

        [[2, 2, 2, 2],
         [2, 2, 2, 2],
         [2, 2, 2, 2],
         [2, 2, 2, 2]],

        [[3, 3, 3, 3],
         [3, 3, 3, 3],
         [3, 3, 3, 3],
         [3, 3, 3, 3]]])
#+END_SRC

由于cnn需要的输入需要3个rgb维度，所以我们可以用 ~reshape~ 将张量变成4个维度的。
#+BEGIN_SRC python
> t = t.reshape(3,1,4,4)
> t
tensor([[[[1, 1, 1, 1],
          [1, 1, 1, 1],
          [1, 1, 1, 1],
          [1, 1, 1, 1]]],
        [[[2, 2, 2, 2],
          [2, 2, 2, 2],
          [2, 2, 2, 2],
          [2, 2, 2, 2]]],
        [[[3, 3, 3, 3],
          [3, 3, 3, 3],
          [3, 3, 3, 3],
          [3, 3, 3, 3]]]])
#+END_SRC

下面几种方法都可以将张量展开（faltten）
#+BEGIN_SRC python
> t.reshape(1,-1)[0] # Thank you Mick!
tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])

> t.reshape(-1) # Thank you Aamir!
tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])

> t.view(t.numel()) # Thank you Ulm!
tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])

> t.flatten() # Thank you PyTorch!
tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])
#+END_SRC

我们可以用 ~flatten~ 对某一个特定的轴进行展开. ~start_dim~ 指定从哪个轴开始进行展开
#+BEGIN_SRC python
> t.flatten(start_dim=1).shape
torch.Size([3, 16])

> t.flatten(start_dim=1)
tensor(
[
    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
    [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],
    [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]
]
)
#+END_SRC
~t.reshape(-1,16)~ 也可以达到同样的效果
* 第12课 Tensors For Deep Learning - Broadcasting And Element-Wise Operations With PyTorch
** 张量广播  
进行操作的两个张量必须有相同的形状（shape），即轴的数量相等并且轴的长度相等。
#+BEGIN_SRC python
> t1 = torch.tensor([
    [1,2],
    [3,4]
], dtype=torch.float32)

> t2 = torch.tensor([
    [9,8],
    [7,6]
], dtype=torch.float32)
> t1 + t2
tensor([[10., 10.],
        [10., 10.]])
#+END_SRC

张量广播定义了在元素操作过程中如何处理不同形状的张量。
#+BEGIN_SRC python
> print(t + 2)
tensor([[3., 4.],
        [5., 6.]])

> print(t - 2)
tensor([[-1.,  0.],
        [ 1.,  2.]])

> print(t * 2)
tensor([[2., 4.],
        [6., 8.]])

> print(t / 2)
tensor([[0.5000, 1.0000],
        [1.5000, 2.0000]])

## or equivalently, (2) these built-in tensor object methods:
> print(t1.add(2))
tensor([[3., 4.],
        [5., 6.]])

> print(t1.sub(2))
tensor([[-1.,  0.],
        [ 1.,  2.]])

> print(t1.mul(2))
tensor([[2., 4.],
        [6., 8.]])

> print(t1.div(2))
tensor([[0.5000, 1.0000],
        [1.5000, 2.0000]])
#+END_SRC

我们可以用 ~broadcast_to()~ 来检查广播后的张量形状
#+BEGIN_SRC python
> np.broadcast_to(2, t1.shape)
array([[2, 2],
        [2, 2]])
> t1 + 2
tensor([[3., 4.],
        [5., 6.]])
#+END_SRC

当两个不同形状的张量进行操作时，会应用张量广播将两个张量转化为相同的形状。同样的，我们也可以用 ~broadcast_to()~ 检查广播后的转换结果
#+BEGIN_SRC python
>t1 = torch.tensor([
    [1,1],
    [1,1]
], dtype=torch.float32)

>t2 = torch.tensor([2,4], dtype=torch.float32)

> t1.shape
torch.Size([2, 2])

> t2.shape
torch.Size([2])

> np.broadcast_to(t2.numpy(), t1.shape)
array([[2., 4.],
        [2., 4.]], dtype=float32)

> t1 + t2
tensor([[3., 5.],
        [3., 5.]])
#+END_SRC
** 比较运算
#+BEGIN_SRC python
> t = torch.tensor([
    [0,5,0],
    [6,0,7],
    [0,8,0]
], dtype=torch.float32)

> t.eq(0)
tensor([[True, False, True],
        [False, True, False],
        [True, False, True]])


> t.ge(0)
tensor([[True, True, True],
        [True, True, True],
        [True, True, True]])


> t.gt(0)
tensor([[False, True, False],
        [True, False, True],
        [False, True, False]])


> t.lt(0)
tensor([[False, False, False],
        [False, False, False],
        [False, False, False]])

> t.le(7)
tensor([[True, True, True],
        [True, True, True],
        [True, False, True]])
#+END_SRC
** Element-Wise Operations Using Functions
#+BEGIN_SRC python
> t.abs() 
tensor([[0., 5., 0.],
        [6., 0., 7.],
        [0., 8., 0.]])


> t.sqrt()
tensor([[0.0000, 2.2361, 0.0000],
        [2.4495, 0.0000, 2.6458],
        [0.0000, 2.8284, 0.0000]])

> t.neg()
tensor([[-0., -5., -0.],
        [-6., -0., -7.],
        [-0., -8., -0.]])

> t.neg().abs()
tensor([[0., 5., 0.],
        [6., 0., 7.],
        [0., 8., 0.]])
#+END_SRC
* 第13课 Code For Deep Learning - ArgMax And Reduction Tensor Ops
** Reduction Operation Example
下面的方法在所有张量元素上操作，将张量减少为单个元素标量张量
#+BEGIN_SRC python
> t = torch.tensor([
    [0,1,0],
    [2,0,2],
    [0,3,0]
], dtype=torch.float32)

> t.sum()
tensor(8.)
> t.prod()
tensor(0.)
> t.mean()
tensor(.8889)
> t.std()
tensor(1.1667)
#+END_SRC

我们可以指定要压缩的维度
#+BEGIN_SRC python
> t = torch.tensor([
    [1,1,1,1],
    [2,2,2,2],
    [3,3,3,3]
], dtype=torch.float32)

> t.sum(dim=0)
tensor([6., 6., 6., 6.])

> t.sum(dim=1)
tensor([ 4.,  8., 12.])
#+END_SRC

~argmax~ 返回最大值的索引
#+BEGIN_SRC python
> t = torch.tensor([
    [1,0,0,2],
    [0,3,3,0],
    [4,0,0,5]
], dtype=torch.float32)
> t.max()
tensor(5.)
> t.argmax()
tensor(11)

> t.flatten()
tensor([1., 0., 0., 2., 0., 3., 3., 0., 4., 0., 0., 5.])
#+END_SRC
可以指定轴进行操作，注意 ~max~ 返回最大值和索引：（最大值，索引值）
#+BEGIN_SRC python
> t.max(dim=0)  #因为我们是对第0维度进行求最大值，所以索引值告诉我们的是第0维度的索引，即分别是在第2，1，1，2个数组取到最大值
(tensor([4., 3., 3., 5.]), tensor([2, 1, 1, 2]))

> t.argmax(dim=0)
tensor([2, 1, 1, 2])

> t.max(dim=1)
(tensor([2., 3., 5.]), tensor([3, 1, 3]))

> t.argmax(dim=1)
tensor([3, 1, 3])
#+END_SRC
** Accessing Elements Inside Tensors
注意 ~item~ 方法只能作用于标量型张量
#+BEGIN_SRC python
> t = torch.tensor([
    [1,2,3],
    [4,5,6],
    [7,8,9]
], dtype=torch.float32)

> t.mean()
tensor(5.)

> t.mean().item()
5.0
#+END_SRC
可以指定维度进行操作
#+BEGIN_SRC python
> t = torch.tensor([
    [1,2,3],
    [4,5,6],
    [7,8,9]
], dtype=torch.float32)
> t.mean(dim=0)
tensor([4., 5., 6.])
> t.mean(dim=0).tolist()
[4.0, 5.0, 6.0]

> t.mean(dim=0).numpy()
array([4., 5., 6.], dtype=float32)
#+END_SRC
* 第14课 Data In Deep Learning (Important) - Fashion MNIST For Artificial Intelligence
** MNIST Dataset?
What Is The MNIST Dataset?NIST stands for National Institute of Standards and Technology.The M in MNIST stands for modified, and this is because there was an original NIST dataset of digits that was modified to give us MNIST.

The dataset consists of 70,000 images of hand written digits with the following split:
- 60,000 training images
- 10,000 testing images

** Fashion-MNIST
Fashion-MNIST as the name suggests is a dataset of fashion items. Specifically, the dataset has the following ten classes of fashion items:
| Index | Label       |
|-------+-------------|
|     0 | T-shirt/top |
|     1 | Trouser     |
|     2 | Pullover    |
|     3 | Dress       |
|     4 | Coat        |
|     5 | Sandal      |
|     6 | Shirt       |
|     7 | Sneaker     |
|     8 | Bag         |
|     9 | Ankle boot  |

* 第15课 CNN Image Preparation Code Project - Learn To Extract, Transform, Load (ETL)
** Preparing Our Data Using PyTorch
Our ultimate goal when preparing our data is to do the following (ETL):

- Extract – Get the Fashion-MNIST image data from the source.
- Transform – Put our data into tensor form.
- Load – Put our data into an object to make it easily accessible.

For these purposes, PyTorch provides us with two classes:
| Class                       | Description                                                 |
|-----------------------------+-------------------------------------------------------------|
| torch.utils.data.Dataset    | An abstract class for representing a dataset.               |
| torch.utils.data.DataLoader | Wraps a dataset and provides access to the underlying data. |

#+BEGIN_EXAMPLE
All subclasses of the Dataset class must override __len__, that provides the size of the dataset, and __getitem__, supporting integer indexing in range from 0 to len(self) exclusive.
#+END_EXAMPLE
** PyTorch Torchvision Package
The ~torchvision~ package, gives us access to the following resources:

- Datasets (like MNIST and Fashion-MNIST)
- Models (like VGG16)
- Transforms
- Utils

The PyTorch FashionMNIST dataset simply extends the MNIST dataset and overrides the urls.

创建Fashion-MNIST数据集实例

To get an instance of the FashionMNIST dataset using torchvision, we just create one like so:
#+BEGIN_SRC python
import torch
import torchvision
import torchvision.transforms as transforms

train_set = torchvision.datasets.FashionMNIST(
    root='./data'  #表示数据集下载位置
    ,train=True    #这个表示我们希望数据集是用于训练集的，FashionMNIST数据集中有6万张用作训练数据，1万张用于测试数据
    ,download=True #这个表示如果下载位置没有数据集，则下载数据集
    ,transform=transforms.Compose([  #这个使用了内置的 ToTensor 表换来转换图像
        transforms.ToTensor()
    ])
)
#+END_SRC

将数据集打包或加载到数据加载器中：
#+BEGIN_SRC python
train_loader = torch.utils.data.DataLoader(train_set
    ,batch_size=1000
    ,shuffle=True
)
#+END_SRC

* 第16课 PyTorch Datasets And DataLoaders - Training Set Exploration For Deep Learning And AI
** Exploring The Data
#+BEGIN_SRC python
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F

import torchvision
import torchvision.transforms as transforms

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.metrics import confusion_matrix
#from plotcm import plot_confusion_matrix

import pdb

train_set = torchvision.datasets.FashionMNIST(
    root='./data'  #表示数据集下载位置
    ,train=True    #这个表示我们希望使用训练训练集的数据，FashionMNIST数据集中有6万张用作训练数据，1万张用于测试数据
    ,download=True #这个表示如果下载位置没有数据集，则下载数据集
    ,transform=transforms.Compose([  #这个使用了内置的 ToTensor 表换来转换图像
        transforms.ToTensor()
    ])
)
train_loader = torch.utils.data.DataLoader(train_set
    ,batch_size=10
)

torch.set_printoptions(linewidth=120) #这个是为了设置打印行宽
#+END_SRC
#+BEGIN_SRC bash
> len(train_set)  #fashionmnist数据集中有6万张用作训练数据
60000
> train_set.train_labels #这个提供了数据集的标签张量
tensor([9, 0, 0, ..., 3, 0, 5])
# Starting with torchvision 0.2.2
> train_set.targets
tensor([9, 0, 0, ..., 3, 0, 5])
#+END_SRC

If we want to see how many of each label exists in the dataset, we can use the PyTorch bincount() function like so:
#+BEGIN_SRC bash
# Before torchvision 0.2.2
> train_set.train_labels.bincount()
tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
# Before torchvision 0.2.2
> train_set.targets.bincount()
tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
#+END_SRC

** Accessing Data In The Training Set
To access an individual element from the training set, we first pass the ~train_set~ object to Python’s ~iter()~ built-in function, which returns an object representing a stream of data.With the stream of data, we can use Python built-in ~next()~ function to get the next data element in the stream of data. 
#+BEGIN_SRC bash
> sample = next(iter(train_set))
> len(sample)  #训练集中的每个样本都包含图像数据张量，以及相应的标签张量，sample[0]为图像，sample[1]为标签
2

> type(image)
torch.Tensor

# Before torchvision 0.2.2
> type(label)
torch.Tensor
# Starting at torchvision 0.2.2
> type(label)
int

>image,label=sample #可以用这种方式分配图像和标签

> image.shape
torch.Size([1, 28, 28]) 

> torch.tensor(label).shape
torch.Size([])

> image.squeeze().shape
torch.Size([28, 28])

> plt.imshow(image.squeeze(), cmap="gray")
> torch.tensor(label)
tensor(9)

#+END_SRC
下面是进行一批图像的展示：
#+BEGIN_SRC bash
> batch = next(iter(train_loader))

> print('len:', len(batch))
len: 2

> images, labels = batch

> print('types:', type(images), type(labels))
> print('shapes:', images.shape, labels.shape)
types: <class 'torch.Tensor'> <class 'torch.Tensor'>
shapes: torch.Size([10, 1, 28, 28]) torch.Size([10])

#用下面的方法可以画出一批图像
> grid = torchvision.utils.make_grid(images, nrow=10)  #创建一个网格，nrow 指定每行的图像数量

> plt.figure(figsize=(15,15))
> plt.imshow(np.transpose(grid, (1,2,0)))

> print('labels:', labels)
labels: tensor([9, 0, 0, 3, 0, 2, 7, 2, 5, 5])
#+END_SRC

** How To Plot Images Using PyTorch DataLoader
Here is another was to plot the images using the PyTorch DataLoader. 
#+BEGIN_SRC python
how_many_to_plot = 20

train_loader = torch.utils.data.DataLoader(
    train_set, batch_size=1, shuffle=True
)

plt.figure(figsize=(50,50))
for i, batch in enumerate(train_loader, start=1):
    image, label = batch
    plt.subplot(10,10,i)
    plt.imshow(image.reshape(28,28), cmap='gray')
    plt.axis('off')
    plt.title(train_set.classes[label.item()], fontsize=28)
    if (i >= how_many_to_plot): break
plt.show()
#+END_SRC

#+DOWNLOADED: file:F:/org/图片/fashion mnist grid sample 2.png @ 2020-07-04 22:18:24
[[file:第16课/2020-07-04_22-18-24_fashion mnist grid sample 2.png]]

* 第17课 Build PyTorch CNN - Object Oriented Neural Networks
** Building A Neural Network In PyTorch
We now have enough information to provide an outline for building neural networks in PyTorch. The steps are as follows:
1. Create a neural network class that extends the ~nn.Module~ base class.
2. In the class constructor, define the network’s layers as class attributes using pre-built layers from ~torch.nn~.
3. Use the network’s layer attributes as well as operations from the ~nn.functional~ API to define the network’s forward pass.

let’s create a simple class to represent a neural network:
#+BEGIN_SRC python
class Network:
    def __init__(self):
        self.layer = None

    def forward(self, t):
        t = self.layer(t)
        return t
#+END_SRC
This is a good start, but the class hasn’t yet extended the ~nn.Module~ class. To make our ~Network~ class extend ~nn.Module~, we must do two additional things:
1. Specify the ~nn.Module~ class in parentheses on line 1.
2. Insert a call to the super class constructor on line 3 inside the constructor.

This gives us:
#+BEGIN_SRC python
class Network(nn.Module): # line 1
    def __init__(self):
        #super(Network,self).__init__ 这是python2的写法
        super().__init__() # line 3
        self.layer = None

    def forward(self, t):
        t = self.layer(t)
        return t
#+END_SRC
These changes transform our simple neural network into a PyTorch neural network because we are now extending PyTorch's ~nn.Module~ base class.

With this, we are done! Now we have a Network class that has all of the functionality of the PyTorch ~nn.Module~ class.
** Define The Network’s Layers As Class Attributes
#+BEGIN_SRC python
class Network(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)
        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)
        
        self.fc1 = nn.Linear(in_features=12 * 4 * 4, out_features=120)
        self.fc2 = nn.Linear(in_features=120, out_features=60)
        self.out = nn.Linear(in_features=60, out_features=10)
        
    def forward(self, t):
        # implement the forward pass
        return t
#+END_SRC
#+BEGIN_SRC bash
>network=Network()
>network
Network(
  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))
  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=192, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=60, bias=True)
  (out): Linear(in_features=60, out_features=10, bias=True)
)
#+END_SRC
* 第18课 CNN Layers - PyTorch Deep Neural Network Architecture
** Parameter Vs Argument
We often hear the words parameter and argument, but what's the difference between these two?

We'll parameters are used in function definitions as place-holders while arguments are the actual values that are passed to the function. The parameters can be thought of as local variables that live inside a function.

parameter 在函数定义中使用，可以把parameter看做占位符。argument是函数被调用时传递给函数的实际值。
** Two Types Of Parameters
To better understand the argument values for these parameters, let's consider two categories or types of parameters that we used when constructing our layers.

- Hyperparameters
- Data dependent hyperparameters

In general, hyperparameters are parameters whose values are chosen manually and arbitrarily.
| Parameter    | Description                                                            |
|--------------+------------------------------------------------------------------------|
| kernel_size  | Sets the filter size. The words kernel and filter are interchangeable. |
| out_channels | Sets the number of filters. One filter produces one output channel.    |
| out_features | Sets the size of the output tensor.                                    |

Data dependent hyperparameters are parameters whose values are dependent on data. The first two data dependent hyperparameters that stick out are the ~in_channels~ of the first convolutional layer, and the ~out_features~ of the output layer.

You see, the ~in_channels~ of the first convolutional layer depend on the number of color channels present inside the images that make up the training set. Since we are dealing with grayscale images, we know that this value should be a 1.

The ~out_features~ for the output layer depend on the number of classes that are present inside our training set. Since we have 10 classes of clothing inside the Fashion-MNIST dataset, we know that we need 10 output features.
* 第19课 CNN Weights - Learnable Parameters In PyTorch Neural Networks
~Model~ 类中的 ~__repr__(self)~ 可以重写python的默认字符串表示，即调用 ~print~ 时要输出的内容。

我们也可以自定义重写 ~__repr__(self)~ 
#+BEGIN_SRC python
class Network(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)
        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)

        self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)
        self.fc2 = nn.Linear(in_features=120, out_features=60)
        self.out = nn.Linear(in_features=60, out_features=10)

    def forward(self, t):
        # implement the forward pass
        return t

    def __repr__(self):
    return "lizardnet"
#+END_SRC
#+BEGIN_SRC bash
>network=Network()
>print(network)
lizardnet
#+END_SRC

在python中，所有特殊的oop方法通常都有前双划线和后双划线。

我们用点符号访问对象中的属性和方法
#+BEGIN_SRC bash
> network.conv1
Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))

> network.conv2
Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))

> network.fc1
Linear(in_features=192, out_features=120, bias=True)

> network.fc2                                    
Linear(in_features=120, out_features=60, bias=True)

> network.out
Linear(in_features=60, out_features=10, bias=True)
#+END_SRC

可以用下面的方式访问层中的权重：
#+BEGIN_SRC bash
> network.conv1.weight
Parameter containing:
tensor([[[[ 0.0692,  0.1029, -0.1793,  0.0495,  0.0619],
            [ 0.1860,  0.0503, -0.1270, -0.1240, -0.0872],
            [-0.1924, -0.0684, -0.0028,  0.1031, -0.1053],
            [-0.0607,  0.1332,  0.0191,  0.1069, -0.0977],
            [ 0.0095, -0.1570,  0.1730,  0.0674, -0.1589]]],

        [[[-0.1392,  0.1141, -0.0658,  0.1015,  0.0060],
            [-0.0519,  0.0341,  0.1161,  0.1492, -0.0370],
            [ 0.1077,  0.1146,  0.0707,  0.0927,  0.0192],
            [-0.0656,  0.0929, -0.1735,  0.1019, -0.0546],
            [ 0.0647, -0.0521, -0.0687,  0.1053, -0.0613]]],

        [[[-0.1066, -0.0885,  0.1483, -0.0563,  0.0517],
            [ 0.0266,  0.0752, -0.1901, -0.0931, -0.0657],
            [ 0.0502, -0.0652,  0.0523, -0.0789, -0.0471],
            [-0.0800,  0.1297, -0.0205,  0.0450, -0.1029],
            [-0.1542,  0.1634, -0.0448,  0.0998, -0.1385]]],

        [[[-0.0943,  0.0256,  0.1632, -0.0361, -0.0557],
            [ 0.1083, -0.1647,  0.0846, -0.0163,  0.0068],
            [-0.1241,  0.1761,  0.1914,  0.1492,  0.1270],
            [ 0.1583,  0.0905,  0.1406,  0.1439,  0.1804],
            [-0.1651,  0.1374,  0.0018,  0.0846, -0.1203]]],

        [[[ 0.1786, -0.0800, -0.0995,  0.1690, -0.0529],
            [ 0.0685,  0.1399,  0.0270,  0.1684,  0.1544],
            [ 0.1581, -0.0099, -0.0796,  0.0823, -0.1598],
            [ 0.1534, -0.1373, -0.0740, -0.0897,  0.1325],
            [ 0.1487, -0.0583, -0.0900,  0.1606,  0.0140]]],

        [[[ 0.0919,  0.0575,  0.0830, -0.1042, -0.1347],
            [-0.1615,  0.0451,  0.1563, -0.0577, -0.1096],
            [-0.0667, -0.1979,  0.0458,  0.1971, -0.1380],
            [-0.1279,  0.1753, -0.1063,  0.1230, -0.0475],
            [-0.0608, -0.0046, -0.0043, -0.1543,  0.1919]]]], 
            requires_grad=True
)
#+END_SRC

为了跟踪网络中的所有权重张量，pytorch 有一个名为 ~parameter~ 的特殊类。 ~parameter~ 类扩张了张量类。每一层的权重就是 ~parameter~ 类的实例。

下面的两种方法可以同时获得网络的权重参数形状：
#+BEGIN_SRC bash
>for param in network.parameters():
    print(param.shape)

torch.Size([6, 1, 5, 5])
torch.Size([6])
torch.Size([12, 6, 5, 5])
torch.Size([12])
torch.Size([120, 192])
torch.Size([120])
torch.Size([60, 120])
torch.Size([60])
torch.Size([10, 60])
torch.Size([10])

>for name, param in network.named_parameters():
    print(name, '\t\t', param.shape)

conv1.weight 		 torch.Size([6, 1, 5, 5])
conv1.bias 		 torch.Size([6])
conv2.weight 		 torch.Size([12, 6, 5, 5])
conv2.bias 		 torch.Size([12])
fc1.weight 		 torch.Size([120, 192])
fc1.bias 		 torch.Size([120])
fc2.weight 		 torch.Size([60, 120])
fc2.bias 		 torch.Size([60])
out.weight 		 torch.Size([10, 60])
out.bias 		 torch.Size([10])
#+END_SRC
* 第20课 Callable Neural Networks - Linear Layers In Depth
#+BEGIN_SRC bash
>in_features = torch.tensor([1,2,3,4], dtype=torch.float32)

>weight_matrix = torch.tensor([
    [1,2,3,4],
    [2,3,4,5],
    [3,4,5,6]
], dtype=torch.float32)

> weight_matrix.matmul(in_features)
tensor([30., 40., 50.])

>fc = nn.Linear(in_features=4, out_features=3, bias=False) #pytorch 将数值4和3传递给构造函数，以创建一个3x4的权重矩阵
#+END_SRC

Let's see how we can call our layer now by passing the in_features tensor.
#+BEGIN_SRC bash
> fc(in_features)
tensor([-0.8877,  1.4250,  0.8370], grad_fn=<SqueezeBackward3>) #权重矩阵是随机初试化的
#+END_SRC
We can call the object instance like this because PyTorch neural network modules are ~callable Python objects~. 

我们也可以自己制定权重矩阵：
#+BEGIN_SRC bash
> fc.weight = nn.Parameter(weight_matrix)  
> fc(in_features)
tensor([30.0261, 40.1404, 49.7643], grad_fn=<AddBackward0>) #可以看到这里的结果接近于上面的例子，由于线性层自动添加了偏置，所以会有差异
#+END_SRC
当我们去掉偏置时，结果就一样了：
#+BEGIN_SRC bash
> fc = nn.Linear(in_features=4, out_features=3, bias=False)
> fc.weight = nn.Parameter(weight_matrix)
> fc(in_features)  #我们并不直接调用forward方法，而是通过pytorch内置的 __call__ 去调用forward
tensor([30., 40., 50.], grad_fn=<SqueezeBackward3>)
#+END_SRC
* 第21课 CNN Forward Method - PyTorch Deep Learning Implementation
** Implementing The ~forward()~ Method
#+BEGIN_SRC python
class Network(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)
        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)

        self.fc1 = nn.Linear(in_features=12 * 4 * 4, out_features=120)
        self.fc2 = nn.Linear(in_features=120, out_features=60)
        self.out = nn.Linear(in_features=60, out_features=10)

    def forward(self, t):
        # (1) input layer
        t = t

        # (2) hidden conv layer
        t = self.conv1(t)
        t = F.relu(t)
        t = F.max_pool2d(t, kernel_size=2, stride=2)

        # (3) hidden conv layer
        t = self.conv2(t)
        t = F.relu(t)
        t = F.max_pool2d(t, kernel_size=2, stride=2)

        # (4) hidden linear layer
        t = t.reshape(-1, 12 * 4 * 4)  #数组新的shape属性应该要与原来的配套，如果等于-1的话，那么Numpy会根据剩下的维度计算出数组的另外一个shape属性值。
        t = self.fc1(t)
        t = F.relu(t)

        # (5) hidden linear layer
        t = self.fc2(t)
        t = F.relu(t)

        # (6) output layer
        t = self.out(t)
        #t = F.softmax(t, dim=1)   #However, in our case, we won't use softmax() because the loss function that we'll use, F.cross_entropy(), implicitly performs the softmax() operation on its input, so we'll just return the result of the last linear transformation.

        return t
        
#+END_SRC
* 第22课 CNN Image Prediction With PyTorch - Forward Propagation Explained
pytorch是动态计算的，我们可以关闭这个功能来减少内存消耗（此时这个图没有存储在内存中）：
#+BEGIN_SRC python
torch.set_grad_enabled(False)
#+END_SRC
** Passing A Single Image To The Network
#+BEGIN_SRC bash
> network = Network()
> sample = next(iter(train_set)) 
> image, label = sample 
> image.shape 
torch.Size([1, 28, 28])
> image.unsqueeze(0).shape
torch.Size([1, 1, 28, 28])

> pred = network(image.unsqueeze(0)) # image shape needs to be (batch_size × in_channels × H × W)
> pred
tensor([[0.0991, 0.0916, 0.0907, 0.0949, 0.1013, 0.0922, 0.0990, 0.1130, 0.1107, 0.1074]])
> pred.shape
torch.Size([1, 10])
> label
9
> pred.argmax(dim=1)  #这里由于只是前向传播，没有训练网络，所以预测了7，但实际值应该为9，所以网络这里预测错误
tensor([7])

> F.softmax(pred, dim=1)  #也可以用softmax来对所有类的概率进行归一化
tensor([[0.1096, 0.1018, 0.0867, 0.0936, 0.1102, 0.0929, 0.1083, 0.0998, 0.0943, 0.1030]])
> F.softmax(pred, dim=1).sum()
tensor(1.)
#+END_SRC
* 第23课 Neural Network Batch Processing - Pass Image Batch To PyTorch CNN
下面是进行批处理的代码：
#+BEGIN_SRC bash
> network=Network()
> data_loader=torch.utils.data.DataLoader(train_set,batch_size=10) #与单个图像的不同就在于多了这一行代码
> batch=next(iter(data_loader))
> images,labels=batch
> images.shape
torch.Size([10, 1, 28, 28])
> labes.shape
torch.Size([10])
> preds=network(images)
> preds.shape
torch.Size([10, 10])
> preds
tensor([[-0.0939, -0.0701, -0.1039, -0.0429, -0.0485,  0.1127, -0.0217,  0.1144,
         -0.0583,  0.0962],
        [-0.0903, -0.0716, -0.0986, -0.0350, -0.0625,  0.1070, -0.0222,  0.1121,
         -0.0665,  0.0947],
        [-0.0969, -0.0732, -0.0954, -0.0223, -0.0632,  0.1114, -0.0306,  0.1066,
         -0.0685,  0.0969],
        [-0.0964, -0.0757, -0.0994, -0.0219, -0.0633,  0.1086, -0.0302,  0.1073,
         -0.0679,  0.0994],
        [-0.0965, -0.0741, -0.0973, -0.0243, -0.0649,  0.1091, -0.0300,  0.0996,
         -0.0664,  0.0946],
        [-0.0909, -0.0734, -0.0997, -0.0330, -0.0605,  0.1038, -0.0228,  0.1105,
         -0.0672,  0.0962],
        [-0.0942, -0.0715, -0.1013, -0.0376, -0.0533,  0.1124, -0.0292,  0.1054,
         -0.0637,  0.0948],
        [-0.0922, -0.0765, -0.1023, -0.0333, -0.0606,  0.1053, -0.0168,  0.1156,
         -0.0627,  0.1014],
        [-0.0993, -0.0709, -0.0952, -0.0297, -0.0588,  0.1225, -0.0284,  0.1175,
         -0.0641,  0.1043],
        [-0.0931, -0.0636, -0.0966, -0.0426, -0.0502,  0.1173, -0.0184,  0.1162,
         -0.0677,  0.0980]])
> preds.argmax(dim=1)
tensor([7, 7, 5, 5, 5, 7, 5, 7, 5, 5])
> labels
tensor([9, 0, 0, 3, 0, 2, 7, 2, 5, 5])
> preds.argmax(dim=1).eq(labels)
tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=torch.uint8)
#+END_SRC
* 第24集 CNN Output Size Formula - Bonus Neural Network Debugging Session
- Suppose we have an nxn input.
- Suppose we have an fxf filter.
- Suppose we have a padding of p and a stride of s.

卷积层输出大小等于：（n-f+2p）/s +1
* 第25课 CNN Training With Code Example - Neural Network Programming Course
我们可以选择打开或关闭梯度追踪功能
#+BEGIN_SRC 
> torch.set_grad_enabled(True)  #打开梯度追踪，默认是打开的
<torch.autograd.grad_mode.set_grad_enabled at 0x15b22d012b0>
#+END_SRC

#+BEGIN_SRC bash
> network=Network()

> train_loader=torch.utils.data.DataLoader(train_set,batch_size=100)
> batch=next(iter(train_loader))
> images,labels=batch

> preds=network(images)
> loss=F.cross_entropy(preds,labels)
> loss.item()
2.312843084335327

> network.conv1.weight.grad  #可以看到现在还没有梯度
None 
> loss.backward() # Calculating the gradients
> network.conv1.weight.grad.shape #现在有梯度了
torch.Size([6, 1, 5, 5])
#+END_SRC

Updating The Weights:To the Adam class constructor, we pass the network parameters (this is how the optimizer is able to access the gradients), and we pass the learning rate .
#+BEGIN_SRC bash
> optimizer = optim.Adam(network.parameters(), lr=0.01)
> optimizer.step() # Updating the weights

> preds = network(images)
> loss.item()

> loss = F.cross_entropy(preds, labels)
2.262690782546997   #可以看到损失减小了
#+END_SRC

下面是单批次训练的代码总结：
#+BEGIN_SRC python
network = Network()

train_loader = torch.utils.data.DataLoader(train_set, batch_size=100)
optimizer = optim.Adam(network.parameters(), lr=0.01)

batch = next(iter(train_loader)) # Get Batch
images, labels = batch

preds = network(images) # Pass Batch
loss = F.cross_entropy(preds, labels) # Calculate Loss

loss.backward() # Calculate Gradients
optimizer.step() # Update Weights

print('loss1:', loss.item())
preds = network(images)
loss = F.cross_entropy(preds, labels)
print('loss2:', loss.item())
#+END_SRC
* 第26课 CNN Training Loop Explained - Neural Network Code Project
** Training With All Batches (Single Epoch)
下面是对所有批次进行训练的代码:
#+BEGIN_SRC python 
network = Network()

train_loader = torch.utils.data.DataLoader(train_set, batch_size=100)
optimizer = optim.Adam(network.parameters(), lr=0.01)

total_loss = 0
total_correct = 0

for batch in train_loader: # Get Batch
    images, labels = batch 

    preds = network(images) # Pass Batch
    loss = F.cross_entropy(preds, labels) # Calculate Loss

    optimizer.zero_grad()  #注意这里要对梯度清零，因为pytorch会积累（累加）梯度
    loss.backward() # Calculate Gradients
    optimizer.step() # Update Weights

    total_loss += loss.item()
    total_correct += get_num_correct(preds, labels)

print( 
    "epoch:", 0, 
    "total_correct:", total_correct, 
    "loss:", total_loss
) # epoch: 0 total_correct: 42104 loss: 476.6809593439102
#+END_SRC

We get the results, and we can see that the total number correct out of 60,000 was 42,104.
#+BEGIN_SRC bash
> total_correct / len(train_set)
0.7017333333333333
#+END_SRC
** Training With Multiple Epochs
To do multiple epochs, all we have to do is put this code into a for loop. We'll also add the epoch number to the print statement.
#+BEGIN_SRC python
network = Network()

train_loader = torch.utils.data.DataLoader(train_set, batch_size=100)
optimizer = optim.Adam(network.parameters(), lr=0.01)

for epoch in range(10):

    total_loss = 0
    total_correct = 0

    for batch in train_loader: # Get Batch
        images, labels = batch 

        preds = network(images) # Pass Batch
        loss = F.cross_entropy(preds, labels) # Calculate Loss

        optimizer.zero_grad()
        loss.backward() # Calculate Gradients
        optimizer.step() # Update Weights

        total_loss += loss.item()
        total_correct += get_num_correct(preds, labels)

    print(
        "epoch", epoch, 
        "total_correct:", total_correct, 
        "loss:", total_loss
    )
#+END_SRC
* 第27课 CNN Confusion Matrix With PyTorch - Neural Network Programming
#+BEGIN_SRC bash
> len(train_set)
60000
> len(train_set.targets)
60000
#+END_SRC
** Getting prediction for the entire training set_grad_enabled
在训练过程中，我们不会得到任何张量的梯度值，直到我们对张量进行方向调用。
#+begin_src bash
> def get_all_preds(model, loader):
    all_preds = torch.tensor([])
    for batch in loader:
        images, labels = batch

        preds = model(images)
        all_preds = torch.cat(
            (all_preds, preds)
            ,dim=0
        )
    return all_preds
> prediction_loader=torch.utils.data.DataLoader(train_set,batch_size =1000)
> train_preds=get_all_preds(network,prediction_loader)
> train_preds.shape
torch.Size([60000,10])
> print(train_preds.requires_grad)
True
> train_preds.grad #这里不会显示任何东西，因为我们没有做反向传播
> train_preds.grad_fn 

#下面这个表示所有计算都不用追踪梯度，这是一种局部关闭梯度追踪的方法
> with torch.no_grad():
     prediction_loader = torch.utils.data.DataLoader(train_set, batch_size=10000)
     train_preds = get_all_preds(network, prediction_loader)

> print(train_preds.requires_grad) #false,因为创建这个张量时关闭了梯度跟踪

> train_preds.grad #这里不会显示任何东西，因为我们没有做反向传播
> train_preds.grad_fn 

> preds_correct = get_num_correct(train_preds, train_set.targets)
> print('total correct:', preds_correct)
> print('accuracy:', preds_correct / len(train_set))
total correct: 53578
accuracy: 0.8929666666666667

#+END_SRC

关闭梯度跟踪的另一个方法就是用下面的修饰 ~torch.no_grad~ 来注释函数.这意味着无论何时调用这个函数，它的梯度跟踪在该函数的上下门中被局部调用
#+BEGIN_SRC python
@torch.no_grad()
def get_all_preds(model, loader):
    all_preds = torch.tensor([])
    for batch in loader:
        images, labels = batch

        preds = model(images)
        all_preds = torch.cat(
            (all_preds, preds)
            ,dim=0
        )
    return all_preds
#+END_SRC
#+BEGIN_EXAMPLE
Note at the top, we have annotated the function using the @torch.no_grad() PyTorch decoration. This is because we want this functions execution to omit gradient tracking.

This is because gradient tracking uses memory, and during inference (getting predictions while not training) there is no need to keep track of the computational graph. The decoration is one way of locally turning off the gradient tracking feature while executing specific functions.
#+END_EXAMPLE

** Building The Confusion Matrix
To do this, we need to have the targets tensor and the predicted label from the train_preds tensor.
#+BEGIN_SRC bash
> train_set.targets
tensor([9, 0, 0,  ..., 3, 0, 5])

> train_preds.argmax(dim=1)
tensor([9, 0, 0,  ..., 3, 0, 5])

> stacked = torch.stack(
    (
        train_set.targets
        ,train_preds.argmax(dim=1)
    )
    ,dim=1
)

> stacked.shape
torch.Size([60000, 2])

> stacked
tensor([
    [9, 9],
    [0, 0],
    [0, 0],
    ...,
    [3, 3],
    [0, 0],
    [5, 5]
])

> stacked[0].tolist()
[9, 9]

> cmt = torch.zeros(10,10, dtype=torch.int64)
> cmt
tensor([
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
])
> for p in stacked:
     tl, pl = p.tolist()
     cmt[tl, pl] = cmt[tl, pl] + 1

> cmt
tensor([
    [5637,    3,   96,   75,   20,   10,   86,    0,   73,    0],
    [  40, 5843,    3,   75,   16,    8,    5,    0,   10,    0],
    [  87,    4, 4500,   70, 1069,    8,  156,    0,  106,    0],
    [ 339,   61,   19, 5269,  203,   10,   72,    2,   25,    0],
    [  23,    9,  263,  209, 5217,    2,  238,    0,   39,    0],
    [   0,    0,    0,    1,    0, 5604,    0,  333,   13,   49],
    [1827,    7,  716,  104,  792,    3, 2370,    0,  181,    0],
    [   0,    0,    0,    0,    0,   22,    0, 5867,    4,  107],
    [  32,    1,   13,   15,   19,    5,   17,   11, 5887,    0],
    [   0,    0,    0,    0,    0,   28,    0,  234,    6, 5732]
])
#+END_SRC

** Plotting The Confusion Matrix
To generate the actual confusion matrix as a ~numpy.ndarray~, we use the ~confusion_matrix()~ function from the ~sklearn.metrics~ library. Let's get this imported along with our other needed imports.
#+BEGIN_SRC bash
> import matplotlib.pyplot as plt

> from sklearn.metrics import confusion_matrix
> from resources.plotcm import plot_confusion_matrix

> cm = confusion_matrix(train_set.targets, train_preds.argmax(dim=1))
> print(type(cm))
> cm
<class 'numpy.ndarray'>
Out[74]:
array([[5431,   14,   88,  145,   26,    7,  241,    0,   48,    0],
        [   4, 5896,    6,   75,    8,    0,    8,    0,    3,    0],
        [  92,    6, 5002,   76,  565,    1,  232,    1,   25,    0],
        [ 191,   49,   23, 5504,  162,    1,   61,    0,    7,    2],
        [  15,   12,  267,  213, 5305,    1,  168,    0,   19,    0],
        [   0,    0,    0,    0,    0, 5847,    0,  112,    3,   38],
        [1159,   16,  523,  189,  676,    0, 3396,    0,   41,    0],
        [   0,    0,    0,    0,    0,   99,    0, 5540,    0,  361],
        [  28,    6,   29,   15,   32,   23,   26,   14, 5827,    0],
        [   0,    0,    0,    0,    1,   61,    0,  107,    1, 5830]],
        dtype=int64)

> plt.figure(figsize=(10,10))
> plot_confusion_matrix(cm, train_set.classes)

Confusion matrix, without normalization
[[5431   14   88  145   26    7  241    0   48    0]
[   4 5896    6   75    8    0    8    0    3    0]
[  92    6 5002   76  565    1  232    1   25    0]
[ 191   49   23 5504  162    1   61    0    7    2]
[  15   12  267  213 5305    1  168    0   19    0]
[   0    0    0    0    0 5847    0  112    3   38]
[1159   16  523  189  676    0 3396    0   41    0]
[   0    0    0    0    0   99    0 5540    0  361]
[  28    6   29   15   32   23   26   14 5827    0]
[   0    0    0    0    1   61    0  107    1 5830]]
#+END_SRC

下面是 ~plotcm.py~ 的内容,可以自己安装 ~resources~ 库，或者把下面用到的函数直接复制使用即可:
#+BEGIN_SRC python
import itertools
import numpy as np
import matplotlib.pyplot as plt

def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    print(cm)
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment="center", color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')
#+END_SRC


下面是完整的代码：
#+BEGIN_SRC python
import matplotlib.pyplot as plt
import itertools
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
from resources.plotcm import plot_confusion_matrix

def get_all_preds(model, loader):
    all_preds = torch.tensor([])
    for batch in loader:
        images, labels = batch

        preds = model(images)
        all_preds = torch.cat(
            (all_preds, preds)
            ,dim=0
        )
    return all_preds

with torch.no_grad():
     prediction_loader = torch.utils.data.DataLoader(train_set, batch_size=10000)
     train_preds = get_all_preds(network, prediction_loader)

cm = confusion_matrix(train_set.targets, train_preds.argmax(dim=1))
plt.figure(figsize=(10,10))
plot_confusion_matrix(cm, train_set.classes)
#+END_SRC
* 第28集 Stack Vs Concat In PyTorch, TensorFlow & NumPy - Deep Learning Tensor Ops
The difference between stacking and concatenating tensors can be described in a single sentence, so here goes.
#+BEGIN_EXAMPLE
Concatenating joins a sequence of tensors along an existing axis, and stacking joins a sequence of tensors along a new axis.
#+END_EXAMPLE

下表是拼接操作在不同库里的名称，而堆叠的名称都是一样的，用 ~stack~ 。
| Library    | Function Name |
|------------+---------------|
| PyTorch    | cat()         |
| TensorFlow | concat()      |
| NumPy      | concatenate() |

使用 ~??toech.stack~ 可以查看帮助

** How To Add Or Insert An Axis Into A Tensor 
#+BEGIN_SRC bash
> import torch
> t1 = torch.tensor([1,1,1])
> t1.unsqueeze(dim=0) #相当于t1.unsqueeze(0)
tensor([[1, 1, 1]])
> t1.unsqueeze(dim=1) #相当于t1.unsqueeze(1)
tensor([[1],
        [1],
        [1]])
> print(t1.shape)
> print(t1.unsqueeze(dim=0).shape)
> print(t1.unsqueeze(dim=1).shape)
torch.Size([3])
torch.Size([1, 3])
torch.Size([3, 1])
#+END_SRC
** Stack Vs Cat In PyTorch
#+BEGIN_SRC bash
import torch

> t1 = torch.tensor([1,1,1])
> t2 = torch.tensor([2,2,2])
> t3 = torch.tensor([3,3,3])

> torch.cat(
    (t1,t2,t3)
    ,dim=0
  )
tensor([1, 1, 1, 2, 2, 2, 3, 3, 3])

> torch.stack(
    (t1,t2,t3)
    ,dim=0
  )
tensor([[1, 1, 1],
        [2, 2, 2],
        [3, 3, 3]])

> torch.cat((t1.unsqueeze(0),t2.unsqueeze(0),t3.unsqueeze(0)),dim=0)    #注意这种方式和stack是一样的，因为这里用unsqueeze(0)新建了一个新的维度了
tensor([[1, 1, 1],
        [2, 2, 2],
        [3, 3, 3]])
#+END_SRC
由于 ~t1,t2,t3~ 没有第2个维度，所以是没有办法对第二个维度进行 ~cat~ 操作的，所以我们只能用stack
#+BEGIN_SRC bash
> torch.stack(   
    (t1,t2,t3)
    ,dim=1
)
tensor([[1, 2, 3],
        [1, 2, 3],
        [1, 2, 3]])
> t1.unsqueeze(1)  #注意给t1添加第2个维度的结果是这样的
tensor([[1],
        [1],
        [1]])
> torch.cat(
    (
         t1.unsqueeze(1)
        ,t2.unsqueeze(1)
        ,t3.unsqueeze(1)
    )
    ,dim=1
)
tensor([[1, 2, 3],
        [1, 2, 3],
        [1, 2, 3]])
#+END_SRC
从上面的例子可以看出： ~stack~ 就是相当于用 ~unsqueeze(dim)~ 创建了新的维度，然后用 ~cat~ 的方式拼接起来。

当需要把很多3维图像转化成果一批图像时，可以用stack；当需要把两批图像结合成一批图像时，可以用cat.
** Stack Vs Concat In TensorFlow
#+BEGIN_SRC bash
> import tensorflow as tf

> t1 = tf.constant([1,1,1])
> t2 = tf.constant([2,2,2])
> t3 = tf.constant([3,3,3])

> tf.concat(
    (t1,t2,t3)
    ,axis=0
)
tf.Tensor: id=4, shape=(9,), dtype=int32, numpy=array([1, 1, 1, 2, 2, 2, 3, 3, 3])

> tf.stack(
    (t1,t2,t3)
    ,axis=0
)
tf.Tensor: id=6, shape=(3, 3), dtype=int32, numpy=
array([[1, 1, 1],
       [2, 2, 2],
       [3, 3, 3]])

> tf.concat(
    (
         tf.expand_dims(t1, 0)  #相当于unsqueeze
        ,tf.expand_dims(t2, 0)
        ,tf.expand_dims(t3, 0)
    )    
    ,axis=0
)
tf.Tensor: id=15, shape=(3, 3), dtype=int32, numpy=
array([[1, 1, 1],
       [2, 2, 2],
       [3, 3, 3]])
#+END_SRC
同样的， ~concat~ 只能对已经有的维度使用，当维度不存在时，只能用 ~stack~
#+BEGIN_SRC bash
> tf.stack(
    (t1,t2,t3)
    ,axis=1
)
tf.Tensor: id=17, shape=(3, 3), dtype=int32, numpy=
array([[1, 2, 3],
       [1, 2, 3],
       [1, 2, 3]])

> tf.concat(
    (
         tf.expand_dims(t1, 1)
        ,tf.expand_dims(t2, 1)
        ,tf.expand_dims(t3, 1)
    )
    ,axis=1
)
tf.Tensor: id=26, shape=(3, 3), dtype=int32, numpy=
array([[1, 2, 3],
       [1, 2, 3],
       [1, 2, 3]])

#+END_SRC
** Stack Vs Concatenate In NumPy
#+BEGIN_SRC bash
> import numpy as np

> t1 = np.array([1,1,1])
> t2 = np.array([2,2,2])
> t3 = np.array([3,3,3])

> np.concatenate(
    (t1,t2,t3)
    ,axis=0
  )
array([1, 1, 1, 2, 2, 2, 3, 3, 3])
> np.stack(
    (t1,t2,t3)
    ,axis=0
  )
array([[1, 1, 1],
       [2, 2, 2],
       [3, 3, 3]])

> np.concatenate(
    (
         np.expand_dims(t1, 0)
        ,np.expand_dims(t2, 0)
        ,np.expand_dims(t3, 0)
    )
    ,axis=0
)
array([[1, 1, 1],
       [2, 2, 2],
       [3, 3, 3]])
#+END_SRC
同样的，只能对已经有的维度使用 ~stack~
#+BEGIN_SRC bash
> np.stack(  
    (t1,t2,t3)
    ,axis=1
)  
array([[1, 2, 3],
       [1, 2, 3],
       [1, 2, 3]])

> np.concatenate(
    (
         np.expand_dims(t1, 1)
        ,np.expand_dims(t2, 1)
        ,np.expand_dims(t3, 1)
    )
    ,axis=1
)
array([[1, 2, 3],
       [1, 2, 3],
       [1, 2, 3]])
#+END_SRC

可以用下面的方式查看 ~stack~ 的函数定义
#+BEGIN_SRC bash
> import numpy
> ??numpy.stack
#+END_SRC
* 第29集 TensorBoard With PyTorch - Visualize Deep Learning Metrics
** TensorBoard: TensorFlow's Visualization Toolkit
=TensorBoard= provides the visualization and tooling needed for machine learning experimentation:

- Tracking and visualizing metrics such as loss and accuracy
- Visualizing the model graph (ops and layers)
- Viewing histograms of weights, biases, or other tensors as they change over time
- Projecting embeddings to a lower dimensional space
- Displaying images, text, and audio data
- Profiling TensorFlow programs
- And much more

As of PyTorch version =1.1.0=, PyTorch has added a =tensorboard= utility package that enables us to use TensorBoard with PyTorch.

~tensorboard~ 必须另外安装才能使用。
** Getting Started With TensorBoard For PyTorch
To make this easy for us, PyTorch has created a utility class called ~SummaryWriter~. To get access to this class we use the following import:
#+BEGIN_SRC python
from torch.utils.tensorboard import SummaryWriter
#+END_SRC
*** Network Graph And Training Set Image
#+BEGIN_SRC python
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim

import torchvision
import torchvision.transforms as transforms

torch.set_printoptions(linewidth=120)

from torch.utils.tensorboard import SummaryWriter

def get_num_correct(preds,labels):
    return preds.argmax(dim=1).eq(labels).sum().item()

class Network(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)
        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)

        self.fc1 = nn.Linear(in_features=12 * 4 * 4, out_features=120)
        self.fc2 = nn.Linear(in_features=120, out_features=60)
        self.out = nn.Linear(in_features=60, out_features=10)

    def forward(self, t):
        # (1) input layer
        t = t

        # (2) hidden conv layer
        t = self.conv1(t)
        t = F.relu(t)
        t = F.max_pool2d(t, kernel_size=2, stride=2)

        # (3) hidden conv layer
        t = self.conv2(t)
        t = F.relu(t)
        t = F.max_pool2d(t, kernel_size=2, stride=2)

        # (4) hidden linear layer
        t = t.reshape(-1, 12 * 4 * 4)
        t = self.fc1(t)
        t = F.relu(t)

        # (5) hidden linear layer
        t = self.fc2(t)
        t = F.relu(t)

        # (6) output layer
        t = self.out(t)
        #t = F.softmax(t, dim=1)   
        return t

train_set = torchvision.datasets.FashionMNIST(
    root='./data'  #表示数据集下载位置
    ,train=True    #这个表示我们希望使用训练训练集的数据，FashionMNIST数据集中有6万张用作训练数据，1万张用于测试数据
    ,download=True #这个表示如果下载位置没有数据集，则下载数据集
    ,transform=transforms.Compose([  #这个使用了内置的 ToTensor 表换来转换图像
        transforms.ToTensor()
    ])
)

train_loader=torch.utils.data.DataLoader(train_set,batch_size=100,shuffle=True)
#+END_SRC
#+BEGIN_SRC python
tb = SummaryWriter()

network = Network()
images, labels = next(iter(train_loader))
grid = torchvision.utils.make_grid(images)  #这个是制作网格的函数，这个创造出一组图像网格

tb.add_image('images', grid) #传递标签和数据
tb.add_graph(network, images)#这个的结果是能够看到一个图形或者一个网络的可视化在tensorboard中
tb.close()  #关闭summarywriter
#+END_SRC
运行之后会在当前工作目录下生成名为 ~runs~ 的文件夹，里面保存着tensorboard的显示数据
** Running TensorBoard
To launch TensorBoard, we need to run the tensorboard command at our terminal. This will launch a local server that will serve the TensorBoard UI and the the data our SummaryWriter wrote to disk.

By default, the PyTorch SummaryWriter object writes the data to disk in a directory called ~./runs~ that is created in the current working directory.

When we run the tensorboard command, we pass an argument that tells tensorboard where the data is. So it's like this:
（在终端输入命令） 
#+BEGIN_SRC bash
tensorboard --logdir=runs  #TensorBoard 2.2.1 at http://localhost:6006/ (Press CTRL+C to quit)
#+END_SRC
The TensorBoard server will launch and be listening for ~http~ requests on port ~6006~. These details will be displayed in the console.

Access the TensorBoard UI by browsing to:
#+BEGIN_SRC bash
http://localhost:6006 #在浏览器输入该地址就可以开启tensorboard
#+END_SRC
** TensorBoard Histograms And Scalars
To add scalars and histograms we use the corresponding methods provided by the PyTorch ~SummaryWriter~ class.

Here is an example of the calls:
#+BEGIN_SRC python
tb.add_scalar('Loss', total_loss, epoch)
tb.add_scalar('Number Correct', total_correct, epoch)
tb.add_scalar('Accuracy', total_correct / len(train_set), epoch)

tb.add_histogram('conv1.bias', network.conv1.bias, epoch)
tb.add_histogram('conv1.weight', network.conv1.weight, epoch)
tb.add_histogram('conv1.weight.grad', network.conv1.weight.grad, epoch)
#+END_SRC
And here is an example of where we would place these calls inside our training loop:
#+BEGIN_SRC python
network = Network()
train_loader = torch.utils.data.DataLoader(train_set, batch_size=100)
optimizer = optim.Adam(network.parameters(), lr=0.01)

images, labels = next(iter(train_loader))
grid = torchvision.utils.make_grid(images)

tb = SummaryWriter()
tb.add_image('images', grid)
tb.add_graph(network, images)

for epoch in range(10):

    total_loss = 0
    total_correct = 0

    for batch in train_loader: # Get Batch
        images, labels = batch 

        preds = network(images) # Pass Batch
        loss = F.cross_entropy(preds, labels) # Calculate Loss

        optimizer.zero_grad()
        loss.backward() # Calculate Gradients
        optimizer.step() # Update Weights

        total_loss += loss.item()
        total_correct += get_num_correct(preds, labels)

    tb.add_scalar('Loss', total_loss, epoch)
    tb.add_scalar('Number Correct', total_correct, epoch)
    tb.add_scalar('Accuracy', total_correct / len(train_set), epoch)

    tb.add_histogram('conv1.bias', network.conv1.bias, epoch)
    tb.add_histogram('conv1.weight', network.conv1.weight, epoch)
    tb.add_histogram('conv1.weight.grad',network.conv1.weight.grad,epoch)

    print(
        "epoch", epoch, 
        "total_correct:", total_correct, 
        "loss:", total_loss
    )

tb.close()
#+END_SRC
频率分布图会随着直方图一起出现。
* 第30集 Hyperparameter Tuning And Experimenting - Training Deep Neural Networks
** Naming The Training Runs For TensorBoard 
To take advantage of TensorBoard comparison capabilities, we need to do multiple runs and name each run in such a way that we can identify it uniquely.

With PyTorch's ~SummaryWriter~, a run starts when the writer object instance is created and ends when the writer instance is closed or goes out of scope.

To uniquely identify each run, we can either set the file name of the run directly, or pass a comment string to the constructor that will be appended to the auto-generated file name.

At the time of the creation of this post, the name of the run is contained inside the ~SummaryWriter~ in an attribute called ~log_dir~. It is created like this:
#+BEGIN_SRC python
# PyTorch version 1.1.0 SummaryWriter class
if not log_dir:
    import socket
    from datetime import datetime
    current_time = datetime.now().strftime('%b%d_%H-%M-%S')
    log_dir = os.path.join(
        'runs', 
        current_time + '_' + socket.gethostname() + comment
    )
self.log_dir = log_dir
#+END_SRC
Here, we can see that the ~log_dir~ attribute, which corresponds to the location on disk and the name of the run, is set to ~runs + time + host + comment~. This is of course assuming that the ~log_dir~ parameter doesn't have a value that was passed in. Hence, this is the default behavior.
*** Choosing A Name For The Run

One way to name the run is to add the parameter names and values as a comment for the run. This will allow us to see how each parameter value stacks up with the others later when we are reviewing the runs inside TensorBoard.

We'll see that this is how we set the comment up later:
#+BEGIN_SRC python
tb = SummaryWriter(comment=f' batch_size={batch_size} lr={lr}')
#+END_SRC

** Creating Variables For Our Hyperparameters
To make the experimentation easy, we will pull out our hard-coded values and turn them into variables.

This is the hard-coded way:
#+BEGIN_SRC python
network = Network()
train_loader = torch.utils.data.DataLoader(
    train_set, batch_size=100
)
optimizer = optim.Adam(
    network.parameters(), lr=0.01
)
#+END_SRC
Notice how the ~batch_size~ and ~lr~ parameter values are hard-coded.

This is what we change it to (now our values are set using variables):
#+BEGIN_SRC python
batch_size = 100
lr = 0.01

network = Network()
train_loader = torch.utils.data.DataLoader(
    train_set, batch_size=batch_size
)
optimizer = optim.Adam(
    network.parameters(), lr=lr
)
#+END_SRC
This will allow us to change the values in a single place and have them propagate through our code.

Now, we will create the value for our comment parameter using the variables like so:
#+BEGIN_SRC python
tb = SummaryWriter(comment=f' batch_size={batch_size} lr={lr}')
#+END_SRC
With this setup, we can change the value of our hyperparameters and our runs will be automatically tracked and identifiable in TensorBoard.

#+BEGIN_SRC bash
> for name, weight in network.named_parameters():
     print(name,weight.size())
conv1.weight torch.Size([6, 1, 5, 5])
conv1.bias torch.Size([6])
conv2.weight torch.Size([12, 6, 5, 5])
conv2.bias torch.Size([12])
fc1.weight torch.Size([120, 192])
fc1.bias torch.Size([120])
fc2.weight torch.Size([60, 120])
fc2.bias torch.Size([60])
out.weight torch.Size([10, 60])
out.bias torch.Size([10])

> for name, weight in network.named_parameters():
    print(f'{name}.grad',weight.grad.size())   #f的作用其实相当于字符串链接
conv1.weight.grad torch.Size([6, 1, 5, 5])
conv1.bias.grad torch.Size([6])
conv2.weight.grad torch.Size([12, 6, 5, 5])
conv2.bias.grad torch.Size([12])
fc1.weight.grad torch.Size([120, 192])
fc1.bias.grad torch.Size([120])
fc2.weight.grad torch.Size([60, 120])
fc2.bias.grad torch.Size([60])
out.weight.grad torch.Size([10, 60])
out.bias.grad torch.Size([10])
#+END_SRC
** Calculate Loss With Different Batch Sizes
Since we'll be varying our batch sizes now, we'll need to make a change to the way we are calculating and accumulating the loss. Instead of just summing the loss returned by the loss function. We'll adjust it to account for the batch size.
#+BEGIN_SRC python
total_loss += loss.item() * batch_size
#+END_SRC
Why do this? We'll the ~cross_entropy~ loss function averages the loss values that are produced by the batch and then returns this average loss. This is why we need to account for the batch size.

There is a parameter that the ~cross_entropy~ function accepts called ~reduction~ that we could also use.

The reduction parameter optionally accepts a string as an argument. This parameter specifies the reduction to apply to the output of the loss function.
1. ~'none'~ - no reduction will be applied.
2. ~'mean'~ - the sum of the output will be divided by the number of elements in the output.
3. ~'sum'~ - the output will be summed.
Note that the default is ~'mean'~. This is why ~loss.item() * batch_size~ works.
** Experimenting With Hyperparameter Values
Now that we have this setup, we can do more!

All we need to do is create some lists and some loops, and we can run the code and sit back and wait for all the combinations to run.

Here is an example of what we mean:

Parameter Lists
#+BEGIN_SRC python
batch_size_list = [100, 1000, 10000]
lr_list = [.01, .001, .0001, .00001]
#+END_SRC
Nested Iteration
#+BEGIN_SRC python
for batch_size in batch_size_list:
    for lr in lr_list:
        network = Network()

        train_loader = torch.utils.data.DataLoader(
            train_set, batch_size=batch_size
        )
        optimizer = optim.Adam(
            network.parameters(), lr=lr
        )

        images, labels = next(iter(train_loader))
        grid = torchvision.utils.make_grid(images)

        comment=f' batch_size={batch_size} lr={lr}'
        tb = SummaryWriter(comment=comment)
        tb.add_image('images', grid)
        tb.add_graph(network, images)

        for epoch in range(5):
            total_loss = 0
            total_correct = 0
            for batch in train_loader:
                images, labels = batch # Get Batch
                preds = network(images) # Pass Batch
                loss = F.cross_entropy(preds, labels) # Calculate Loss
                optimizer.zero_grad() # Zero Gradients
                loss.backward() # Calculate Gradients
                optimizer.step() # Update Weights

                total_loss += loss.item() * batch_size
                total_correct += get_num_correct(preds, labels)

            tb.add_scalar(
                'Loss', total_loss, epoch
            )
            tb.add_scalar(
                'Number Correct', total_correct, epoch
            )
            tb.add_scalar(
                'Accuracy', total_correct / len(train_set), epoch
            )

            for name, param in network.named_parameters():
                tb.add_histogram(name, param, epoch)
                tb.add_histogram(f'{name}.grad', param.grad, epoch)

            print(
                "epoch", epoch
                ,"total_correct:", total_correct
                ,"loss:", total_loss
            )  
        tb.close()
#+END_SRC
Once this code completes we run TensorBoard and all the runs will be displayed graphically and easily comparable.
#+BEGIN_SRC bash
tensorboard --logdir runs
#+END_SRC
*** Batch Size Vs Training Set Size
When the training set size is not divisible by the batch size, the last batch of data will contain fewer samples than the other batches.

One simple way to deal with this discrepancy is to drop the last batch. The PyTorch ~DataLoader~ class gives us the ability to do this by setting ~drop_last=True~. By default the ~drop_last~ parameter value is set to ~False~.

Let's consider how including a batch with fewer samples than our batch size affects our ~total_loss~ calculation in the code above.

For every batch, we are using the ~batch_size~ variable to update the ~total_loss~ value. We are scaling up the average loss value of the samples in the batch by the ~batch_size~ value. However, as we have just discussed, sometimes the last batch will contain fewer samples. Thus, scaling by the predefined ~batch_size~ value is inaccurate.

The code can be updated to be more accurate by dynamically accessing the number of samples for each batch.

Currently, we have the following:
#+BEGIN_SRC python
total_loss += loss.item() * batch_size
#+END_SRC
Using the updated code below, we can achieve a more accurate ~total_loss~ value:
#+BEGIN_SRC python
total_loss += loss.item() * images.shape[0]
#+END_SRC
Note that these two lines of code give us the same ~total_loss~ value when the training set size is divisible by the batch size. Thank you to Alireza Abedin Varamin for pointing this out in a comment on YouTube.
** Adding Network Parameters & Gradients To TensorBoard
Note that in the last episode, we added the following values to TensorBoard:
- conv1.weight
- conv1.bias
- conv1.weight.grad
We did this using the code below:
#+BEGIN_SRC python
tb.add_histogram('conv1.bias', network.conv1.bias, epoch)
tb.add_histogram('conv1.weight', network.conv1.weight, epoch)
tb.add_histogram('conv1.weight.grad', network.conv1.weight.grad, epoch)
#+END_SRC
Now, we've enhanced this by adding these values for all of our layers using the loop below:
#+BEGIN_SRC python
for name, weight in network.named_parameters():
    tb.add_histogram(name, weight, epoch)
    tb.add_histogram(f'{name}.grad', weight.grad, epoch)
#+END_SRC
This works because the PyTorch ~nn.Module~ method called ~named_parameters()~ gives us the name and value of all the parameters inside the network.
** Adding More Hyperparameters Without Nesting
This is cool. However, what if we want to add a third or even a forth parameter to iterate on? We'll, this is going to get messy with many nested for-loops.

There is a solution. We can create a set of parameters for each run, and package all of them up in a single iterable. Here's how we do it.

If we have a list of parameters, we can package them up into a set for each of our runs using the ~Cartesian product~. For this we'll use the product function from the ~itertools~ library.
#+BEGIN_SRC python
from itertools import product
#+END_SRC
#+BEGIN_SRC bash
Init signature: product(*args, **kwargs)
Docstring:     
"""
product(*iterables, repeat=1) --> product object
Cartesian product of input iterables.  Equivalent to nested for-loops.
"""
#+END_SRC
Next, we define a dictionary that contains parameters as keys and parameter values we want to use as values.
#+BEGIN_SRC python
parameters = dict(
    lr = [.01, .001]
    ,batch_size = [100, 1000]
    ,shuffle = [True, False]
)
#+END_SRC
Next, we'll create a list of iterables that we can pass to the ~product~ functions.
#+BEGIN_SRC python
param_values = [v for v in parameters.values()]
param_values

[[0.01, 0.001], [10,100, 1000], [True, False]]
#+END_SRC
Now, we have three lists of parameter values. After we take the Cartesian product of these three lists, we'll have a set of parameter values for each of our runs. Note that this is equivalent to nested for-loops, as the doc string of the ~product~ function indicates. 
#+BEGIN_SRC bash
> for lr, batch_size, shuffle in product(*param_values):  #这里的 * 告诉product()把列表中的每个值作为参数，而不是把列表本身当做参数来对待
      print (lr, batch_size, shuffle)

0.01 10 True
0.01 10 False
0.01 100 True
0.01 100 False
0.01 1000 True
0.01 1000 False
0.001 10 True
0.001 10 False
0.001 100 True
0.001 100 False
0.001 1000 True
0.001 1000 False
#+END_SRC
Alright, now we can iterate over each set of parameters using a single for-loop. All we have to do is unpack the set using sequence unpacking. It looks like this.
#+BEGIN_SRC python
for lr, batch_size, shuffle in product(*param_values): 
    comment = f' batch_size={batch_size} lr={lr} shuffle={shuffle}'

    train_loader = torch.utils.data.DataLoader(
        train_set
        ,batch_size=batch_size
        ,shuffle=shuffle 
    )

    optimizer = optim.Adam(
        network.parameters(), lr=lr
    )

    # Rest of training process given the set of parameters
#+END_SRC
Note the way we build our comment string to identify the run. We just plug in the values. Also, notice the ~*~ operator. This is a special way in Python to unpack a list into a set of arguments. Thus, in this situation, we have passing three individual unpacked arguments to the ~product~ function opposed to the single list.

Here are two references for the *, asterisk, splat, spread operator. These are all common names for this one.
- [[https://docs.python.org/3/tutorial/controlflow.html#unpacking-argument-lists][Python doc: More Control Flow Tools]]
- [[https://www.python.org/dev/peps/pep-0448/][PEP 448 -- Additional Unpacking Generalizations]]

** 总代码
#+BEGIN_SRC python
parameters = dict(
    lr = [.01, .001]
    ,batch_size = [100, 1000]
    ,shuffle = [True, False]
)
param_values = [v for v in parameters.values()]
for lr, batch_size, shuffle in product(*param_values): 
    network = Network()
    train_loader = torch.utils.data.DataLoader(
        train_set
        ,batch_size=batch_size
        ,shuffle=shuffle 
    )
    optimizer = optim.Adam(
        network.parameters(), lr=lr
    )

    images, labels = next(iter(train_loader))
    grid = torchvision.utils.make_grid(images)

    comment = f' batch_size={batch_size} lr={lr} shuffle={shuffle}'
    tb = SummaryWriter(comment=comment)
    tb.add_image('images', grid)
    tb.add_graph(network, images)

    for epoch in range(5):

        total_loss = 0
        total_correct = 0

        for batch in train_loader: # Get Batch
            images, labels = batch 

            preds = network(images) # Pass Batch
            loss = F.cross_entropy(preds, labels) # Calculate Loss

            optimizer.zero_grad()
            loss.backward() # Calculate Gradients
            optimizer.step() # Update Weights

            total_loss += loss.item()*batch_size
            total_correct += get_num_correct(preds, labels)

        tb.add_scalar('Loss', total_loss, epoch)
        tb.add_scalar('Number Correct', total_correct, epoch)
        tb.add_scalar('Accuracy', total_correct / len(train_set), epoch)

        tb.add_histogram('conv1.bias', network.conv1.bias, epoch)
        tb.add_histogram('conv1.weight', network.conv1.weight, epoch)
        tb.add_histogram('conv1.weight.grad',network.conv1.weight.grad,epoch)

        print(
            "epoch", epoch, 
            "total_correct:", total_correct, 
            "loss:", total_loss
        )

    tb.close()
#+END_SRC
* 第31集 Training Loop Run Builder - Neural Network Experimentation Code
#+BEGIN_SRC python
from collections import OrderedDict
from collections import namedtuple
from itertools import product

class RunBuilder():
    @staticmethod
    def get_runs(params):

        Run = namedtuple('Run', params.keys())

        runs = []
        for v in product(*params.values()):
            runs.append(Run(*v))

        return runs
#+END_SRC
The main thing to note about using this class is that it has a static method called get_runs(). This method will get the runs for us that it builds based on the parameters we pass in.
#+BEGIN_SRC python
params = OrderedDict(
    lr = [.01, .001]
    ,batch_size = [1000, 10000]
)
#+END_SRC
#+BEGIN_SRC bash
> runs = RunBuilder.get_runs(params)
> runs

[
    Run(lr=0.01, batch_size=1000),
    Run(lr=0.01, batch_size=10000),
    Run(lr=0.001, batch_size=1000),
    Run(lr=0.001, batch_size=10000)
]
#+END_SRC
We can access an individual run by indexing into the list like so:
#+BEGIN_SRC bash
> run = runs[0]
> run

Run(lr=0.01, batch_size=1000)
#+END_SRC
Additionally, because the run is object is a tuple with named attributes, we can access the values using dot notation like so:
#+BEGIN_SRC bash
> print(run.lr, run.batch_size)

0.01 1000
#+END_SRC
Finally, since the list of runs is a Python iterable, we can iterate over the runs cleanly like so:
#+BEGIN_SRC bash
> for run in runs:
      print(run, run.lr, run.batch_size)
Run(lr=0.01, batch_size=1000) 0.01 1000
Run(lr=0.01, batch_size=10000) 0.01 10000
Run(lr=0.001, batch_size=1000) 0.001 1000
Run(lr=0.001, batch_size=10000) 0.001 10000
#+END_SRC
** Coding The RunBuilder Class
Let’s sees how to build this ~RunBuilder~ class.

The first thing we need to have is a dictionary of parameters and values we’d like to try.

#+BEGIN_SRC python
params = OrderedDict(
    lr = [.01, .001]
    ,batch_size = [1000, 10000]
)
#+END_SRC
Next, we get a list of keys from the dictionary.
#+BEGIN_SRC bash
> params.keys()
odict_keys(['lr', 'batch_size'])
#+END_SRC
Then, we get a list of values from the dictionary.
#+BEGIN_SRC bash
> params.values()
odict_values([[0.01, 0.001], [1000, 10000]])
#+END_SRC
Once we have both of these, we just make sure we understand both of them by inspecting their output. Once we do, we use these keys and values for what comes next. We’ll start with the keys.
#+BEGIN_SRC python
Run = namedtuple('Run', params.keys())
#+END_SRC
This line creates a new tuple subclass called Run that has named fields. This Run class is used to encapsulate the data for each of our runs. The field names of this class are set by the list of names passed to the constructor. First, we are passing the class name. Then, we are passing the field names, and in our case, we are passing the list of keys from our dictionary.

Now that we have a class for our runs, we are ready to create some.
#+BEGIN_SRC python
runs = []
for v in product(*params.values()):
    runs.append(Run(*v))
#+END_SRC
First we create a list called ~runs~. Then, we use the ~product()~ function from ~itertools~ to create the Cartesian product using the values for each parameter inside our dictionary. This gives us a set of ordered pairs that define our runs. We iterate over these adding a run to the ~runs~ list for each one.

For each value in the Cartesian product we have an ordered tuples. The Cartesian product gives us every ordered pair so we have all possible order pairs of learning rates and batch sizes. When we pass the ~tuple~ to the ~Run~ constructor, we use the ~*~ operator to tell the constructor to accept the ~tuple~ values as arguments opposed to the tuple itself.
#+BEGIN_SRC bash
> runs
[
    Run(lr=0.01, batch_size=1000),
    Run(lr=0.01, batch_size=10000),
    Run(lr=0.001, batch_size=1000),
    Run(lr=0.001, batch_size=10000)
]
#+END_SRC
Finally, we wrap this code in our RunBuilder class.
#+BEGIN_SRC python
class RunBuilder(): 
    @staticmethod   #静态方法意味着我们不需要类的实例来调用该方法
    def get_runs(params):

        Run = namedtuple('Run', params.keys())

        runs = []
        for v in product(*params.values()):
        runs.append(Run(*v))

        return runs
#+END_SRC
Since the get_runs() method is static, we can call it using the class itself. We don’t need an instance of the class.

Now, this allow us to update our training code in the following way:

Before:
#+BEGIN_SRC python
for lr, batch_size, shuffle in product(*param_values):
    comment = f' batch_size={batch_size} lr={lr} shuffle={shuffle}'

    # Training process given the set of parameters
#+END_SRC
After:
#+BEGIN_SRC python
for run in RunBuilder.get_runs(params):
    comment = f'-{run}'

    # Training process given the set of parameters
#+END_SRC
** What Is A Cartesian Product?
#+BEGIN_SRC python
X = {1,2,3}
Y = {1,2,3}

{ (x,y) for x in X for y in Y }
#Output:
#{(1, 1), (1, 2), (1, 3), (2, 1), (2, 2), (2, 3), (3, 1), (3, 2), (3, 3)}
#+END_SRC
Notice how powerful the mathematical code is. It covers all cases. Maybe you noticed that this can be achieved using for-loop iteration like so:
#+BEGIN_SRC python
X = {1,2,3}
Y = {1,2,3}
cartesian_product = set()
for x in X:
    for y in Y:
        cartesian_product.add((x,y))
cartesian_product
#Output:
#{(1, 1), (1, 2), (1, 3), (2, 1), (2, 2), (2, 3), (3, 1), (3, 2), (3, 3)}
#+END_SRC
* 第32集 CNN Training Loop Refactoring - Simultaneous Hyperparameter Testing
** Cleaning Up The Training Loop And Extracting Classes
Our goal is to be able to add parameters and values at the top, and have all the values tested or tried during multiple training runs.

For example, in this case, we are saying that we want to use two parameters, lr and batch_size, and for the batch_size we want to try two different values. This gives us a total of two training runs. Both runs will have the same learning rate while the batch size varies.
#+BEGIN_SRC python
params = OrderedDict(
    lr = [.01]
    ,batch_size = [1000, 2000]
)
#+END_SRC
For the results, we'd like to see and be able to compare the both runs.
| run | epoch |  loss | accuracy | epoch duration | run duration |   lr | batch_size |
|-----+-------+-------+----------+----------------+--------------+------+------------|
|   1 |     1 | 0.983 |    0.618 |         48.697 |       50.563 | 0.01 |       1000 |
|   1 |     2 | 0.572 |    0.777 |         19.165 |       69.794 | 0.01 |       1000 |
|   1 |     3 | 0.468 |    0.827 |         19.366 |       89.252 | 0.01 |       1000 |
|   1 |     4 | 0.428 |    0.843 |         18.840 |      108.176 | 0.01 |       1000 |
|   1 |     5 | 0.389 |    0.857 |         19.082 |      127.320 | 0.01 |       1000 |
|   2 |     1 | 1.271 |    0.528 |         18.558 |       19.627 | 0.01 |       2000 |
|   2 |     2 | 0.623 |    0.757 |         19.822 |       39.520 | 0.01 |       2000 |
|   2 |     3 | 0.526 |    0.791 |         21.101 |       60.694 | 0.01 |       2000 |
|   2 |     4 | 0.478 |    0.814 |         20.332 |       81.110 | 0.01 |       2000 |
|   2 |     5 | 0.440 |    0.835 |         20.413 |      101.600 | 0.01 |       2000 |
*** The Two Classes We Will Build
To do this, we need to build two new classes. We built the first class called ~RunBuilder~ in the last episode. It's being called at the top.
#+BEGIN_SRC python
for run in RunBuilder.get_runs(params):
#+END_SRC
Now, we need to build this ~RunManager~ class that will allow us to manage each run inside our run loop. The ~RunManager~ instance will allow us to pull out a lot of the tedious TensorBoard calls and allow us to add additional functionality as well.

We'll see that as our number of parameters and runs get larger, TensorBoard will start to breakdown as a viable solution for reviewing our results.

The ~RunManager~ will be invoked at different stages inside each of our runs. We'll have calls at the start and end of both the run and the epoch phases. We'll also have calls to track the loss and the number of correct predictions inside each epoch. Finally, at the end, we'll save the run results to disk.

Let's see how to build this ~RunManager~ class.
** Building The RunManger For Training Loop Runs
Let's kick things off with our imports:
#+BEGIN_SRC python
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import torchvision
import torchvision.transforms as transforms

from torch.utils.data import DataLoader
from torch.utils.tensorboard import SummaryWriter
from IPython.display import display, clear_output
import pandas as pd
import time
import json

from itertools import product
from collections import namedtuple
from collections import OrderedDict
#+END_SRC
#+BEGIN_SRC python
class RunManager():
    def __init__(self):

        self.epoch_count = 0
        self.epoch_loss = 0
        self.epoch_num_correct = 0
        self.epoch_start_time = None

        self.run_params = None
        self.run_count = 0
        self.run_data = []
        self.run_start_time = None

        self.network = None
        self.loader = None 
        self.tb = None  #保存tensorboard的数据
#+END_SRC
For now, we'll take no arguments in the constructor, and we'll just define some attributes that will enable us to keep track of data across runs and across epochs.

We'll track the following:
- The number of epochs.
- The running loss for an epoch.
- The number of correct predictions for an epoch.
- The start time of the epoch.
Remember we saw that the ~RunManager~ class has two methods with epoch in the name. We have ~begin_epoch()~ and ~end_epoch()~. These two methods will allow us to manage these values across the epoch lifecycle.

Now, next we have some attributes for the runs. We have an attribute called ~run_params~. This is the run definition in terms for the run parameters. It's value will be one of the runs returned by the ~RunBuilder~ class.

Next, we have attributes to track the ~run_count~, and the ~run_data~. The ~run_count~ gives us the run number and the ~run_data~ is a list we'll use to keep track of the parameter values and the results of each epoch for each run, and so we'll see that we add a value to this list for each epoch. Then, we have the run start time which will be used to calculate the run duration.

Alright, next we will save the network and the data loader that are being used for the run, as well as a ~SummaryWriter~ that we can use to save data for TensorBoard.
*** What Are Code Smells?
Do you smell that? There's something that doesn't smell right about this code. Have you heard of code smells before? Have you smelled them? A code smell is a term used to describe a condition where something about the code in front of our eyes doesn't seem right. It's like a gut feeling for software developers.

A code smell doesn't mean that something is definitely wrong. A code smell does not mean the code is incorrect. It just means that there is likely a better way. In this case, the code smell is the fact that we have several variable names that have a prefix. The use of the prefix here indicates that the variables somehow belong together.

Anytime we see this, we need to be thinking about removing these prefixes. Data that belongs together should be together. This is done by encapsulating the data inside of a class. After all, if the data belongs together, object oriented languages give us the ability to express this fact using classes.
*** Refactoring By Extracting A Class
It's fine to leave this code in now, but later we might want to refactor this code by doing what is referred to as extracting a class. This is a refactoring technique where we remove these prefixes and create a class called ~Epoch~, that has these attributes, ~count~, ~loss~, ~num_correct~, and ~start_time~.
#+BEGIN_SRC python
class Epoch():
    def __init__(self):
        self.count = 0
        self.loss = 0
        self.num_correct = 0
        self.start_time = None 
#+END_SRC
Then, we'll replace these class variable with an instance of the ~Epoch~ class. We might even change the count variable to have a more intuitive name, like say ~number~ or ~id~. The reason we can leave this now is because refactoring is an iterative process, and this is our first iteration.
*** Beginning A Training Loop Run
Anyway, let's look at the first method of this class which extracts the code needed to begin a run.
#+BEGIN_SRC python
def begin_run(self, run, network, loader):

    self.run_start_time = time.time()

    self.run_params = run
    self.run_count += 1

    self.network = network
    self.loader = loader
    self.tb = SummaryWriter(comment=f'-{run}')

    images, labels = next(iter(self.loader))
    grid = torchvision.utils.make_grid(images)

    self.tb.add_image('images', grid)
    self.tb.add_graph(self.network, images)
#+END_SRC
First, we capture the start time for the run. Then, we save the passed in run parameters and increment the run count by one. After this, we save our network and our data loader, and then, we initialize a ~SummaryWriter~ for TensorBoard. Notice how we are passing our run as the comment argument. This will allow us to uniquely identify our run inside TensorBoard.

Alright, next we just have some TensorBoard calls that we made in our training loop before. These calls add our network and a batch of images to TensorBoard.

When we end a run, all we have to do is close the TensorBoard handle and set the epoch count back to zero to be ready for the next run.
#+BEGIN_SRC python
def end_run(self):
    self.tb.close()
    self.epoch_count = 0
#+END_SRC
For starting an epoch, we first save the start time. Then, we increment the epoch_count by one and set the epoch_loss and epoch_number_correct to zero.
#+BEGIN_SRC python
def begin_epoch(self):
    self.epoch_start_time = time.time()

    self.epoch_count += 1
    self.epoch_loss = 0
    self.epoch_num_correct = 0
#+END_SRC
Now, let's look at where the bulk of the action occurs which is ending an epoch.
#+BEGIN_SRC python
def end_epoch(self):

    epoch_duration = time.time() - self.epoch_start_time
    run_duration = time.time() - self.run_start_time

    loss = self.epoch_loss / len(self.loader.dataset)
    accuracy = self.epoch_num_correct / len(self.loader.dataset)

    self.tb.add_scalar('Loss', loss, self.epoch_count)
    self.tb.add_scalar('Accuracy', accuracy, self.epoch_count)

    for name, param in self.network.named_parameters():
        self.tb.add_histogram(name, param, self.epoch_count)
        self.tb.add_histogram(f'{name}.grad', param.grad, self.epoch_count)

    ...
#+END_SRC
We start by calculating the epoch duration and the run duration. Since we are at the end of an epoch, the epoch duration is final, but the run duration here represents the running time of the current run. The value will keep running until the run ends. However, we'll still save it with each epoch.

Next, we compute the ~epoch_loss~ and ~accuracy~, and we do it relative to the size of the training set. This gives us the average loss per sample. Then, we pass both of these values to TensorBoard.

Next, we pass our network's weights and gradient values to TensorBoard like we did before.
*** Tracking Our Training Loop Performance
We're ready now for whats new in this processing. This is the part that we are adding to give us additional insight when we preform large numbers of runs. We're going to save all of the data ourselves so we can analyze it outsize of TensorBoard.
#+BEGIN_SRC python
def end_epoch(self):
    ...

    results = OrderedDict()
    results["run"] = self.run_count
    results["epoch"] = self.epoch_count
    results['loss'] = loss
    results["accuracy"] = accuracy
    results['epoch duration'] = epoch_duration
    results['run duration'] = run_duration
    for k,v in self.run_params._asdict().items(): results[k] = v
    self.run_data.append(results)

    df = pd.DataFrame.from_dict(self.run_data, orient='columns')

    ...
#+END_SRC
Here, we are building a dictionary that contains the keys and values we care about for our run. We add in the ~run_count~, the ~epoch_count~, the ~loss~, the ~accuracy~, the ~epoch_duration~, and the ~run_duration~.

Then, we iterate over the keys and values inside our run parameters adding them to the results dictionary. This will allow us to see the parameters that are associated with the performance results.

Finally, we append the results to the ~run_data~ list.

Once the data is added to the list, we turn the data list into a ~pandas~ data frame so we can have formatted output.

The next two lines are specific to Jupyter notebook. We clear the current output and display the new data frame.
#+BEGIN_SRC python
clear_output(wait=True)
display(df)
#+END_SRC
Alright, that ends an epoch. One thing you may be wondering is how the ~epoch_loss~ and ~epoch_num_correct~ values were tracked. We'll we have two methods just below for that.
#+BEGIN_SRC python
def track_loss(self, loss):
    self.epoch_loss += loss.item() * self.loader.batch_size

def track_num_correct(self, preds, labels):
    self.epoch_num_correct += self.get_num_correct(preds, labels)
#+END_SRC
We have a method called ~track_loss()~ and a method called ~track_num_correct()~. These methods are called inside the training loop after each batch. The loss is passed into the ~track_loss()~ method and the predictions and labels are passed into the ~track_num_correct()~ method.

To calculate the number of correct predictions, we are using the same ~get_num_correct()~ function that we defined in previous episodes. The difference here is that the function is now encapsulated inside our ~RunManager~ class.
#+BEGIN_SRC python
@torch.no_rrad()
def _get_num_correct(self, preds, labels): #函数名前的下划线表示它有点像私有方法，不打算被外部调用者使用。下划线并不能阻止外部调用者的调用，但它确实向调用者发出了信号，即该方法主要在内部使用
    return preds.argmax(dim=1).eq(labels).sum().item()
#+END_SRC
Lastly, we have a method called ~save()~ that saves the run_data in two formats, json and csv. This output goes to disk and makes it available for other apps to consume. For example, we can open the csv file in excel or we can even build our own even better TensorBoard with the data.
#+BEGIN_SRC python
def save(self, fileName):

    pd.DataFrame.from_dict(
        self.run_data, orient='columns'
    ).to_csv(f'{fileName}.csv')

    with open(f'{fileName}.json', 'w', encoding='utf-8') as f:
        json.dump(self.run_data, f, ensure_ascii=False, indent=4)
#+END_SRC
That's it. Now, we can use this ~RunManager~ class inside our training loop.

If we use the following parameters below:
#+BEGIN_SRC python
params = OrderedDict(
    lr = [.01]
    ,batch_size = [1000, 2000]
    ,shuffle = [True, False]
)
#+END_SRC
These are the results we get:
| run | epoch |  loss | accuracy | epoch duration | run duration |   lr | batch_size | shuffle |
|-----+-------+-------+----------+----------------+--------------+------+------------+---------|
|   1 |     1 | 0.979 |    0.624 |         20.056 |       22.935 | 0.01 |       1000 | True    |
|   1 |     2 | 0.514 |    0.805 |         19.786 |       43.141 | 0.01 |       1000 | True    |
|   1 |     3 | 0.425 |    0.843 |         20.117 |       63.342 | 0.01 |       1000 | True    |
|   1 |     4 | 0.378 |    0.861 |         19.556 |       82.969 | 0.01 |       1000 | True    |
|   1 |     5 | 0.342 |    0.872 |         18.706 |      101.752 | 0.01 |       1000 | True    |
|   2 |     1 | 0.965 |    0.632 |         18.846 |       19.390 | 0.01 |       1000 | False   |
|   2 |     2 | 0.503 |    0.806 |         20.276 |       39.758 | 0.01 |       1000 | False   |
|   2 |     3 | 0.409 |    0.849 |         19.741 |       59.579 | 0.01 |       1000 | False   |
|   2 |     4 | 0.360 |    0.866 |         19.358 |       79.015 | 0.01 |       1000 | False   |
|   2 |     5 | 0.330 |    0.877 |         19.523 |       98.616 | 0.01 |       1000 | False   |
|   3 |     1 | 1.298 |    0.513 |         18.831 |       20.039 | 0.01 |       2000 | True    |
|   3 |     2 | 0.665 |    0.745 |         18.872 |       38.988 | 0.01 |       2000 | True    |
|   3 |     3 | 0.548 |    0.789 |         18.947 |       58.012 | 0.01 |       2000 | True    |
|   3 |     4 | 0.485 |    0.819 |         19.325 |       77.416 | 0.01 |       2000 | True    |
|   3 |     5 | 0.443 |    0.838 |         19.629 |       97.121 | 0.01 |       2000 | True    |
|   4 |     1 | 1.305 |    0.497 |         19.242 |       20.465 | 0.01 |       2000 | False   |
|   4 |     2 | 0.693 |    0.727 |         18.858 |       39.406 | 0.01 |       2000 | False   |
|   4 |     3 | 0.572 |    0.777 |         18.839 |       58.321 | 0.01 |       2000 | False   |
|   4 |     4 | 0.503 |    0.809 |         18.774 |       77.168 | 0.01 |       2000 | False   |
|   4 |     5 | 0.462 |    0.831 |         19.028 |       96.274 | 0.01 |       2000 | False   |
** 总代码
未简化前的代码：
#+BEGIN_SRC python
parameters = dict(
    lr = [.01, .001]
    ,batch_size = [10,100, 1000]
    ,shuffle = [True, False]
)
param_values = [v for v in parameters.values()]

for lr,batch_size,shuffle in product(*param_values):
    comment=f` batch_size={batch_size} lr={lr} shuffle={shuffle}`
    network = Network()
    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,shuffle=shuffle)
    optimizer = optim.Adam(network.parameters(), lr=lr)

    images, labels = next(iter(train_loader))
    grid = torchvision.utils.make_grid(images)

    tb = SummaryWriter(comment=comment)
    tb.add_image('images', grid)
    tb.add_graph(network, images)

    for epoch in range(5):

        total_loss = 0
        total_correct = 0

        for batch in train_loader: # Get Batch
            images, labels = batch 

            preds = network(images) # Pass Batch
            loss = F.cross_entropy(preds, labels) # Calculate Loss

            optimizer.zero_grad()
            loss.backward() # Calculate Gradients
            optimizer.step() # Update Weights

            total_loss += loss.item()*batch_size
            total_correct += get_num_correct(preds, labels)

        tb.add_scalar('Loss', total_loss, epoch)
        tb.add_scalar('Number Correct', total_correct, epoch)
        tb.add_scalar('Accuracy', total_correct / len(train_set), epoch)

        tb.add_histogram('conv1.bias', network.conv1.bias, epoch)
        tb.add_histogram('conv1.weight', network.conv1.weight, epoch)
        tb.add_histogram('conv1.weight.grad',network.conv1.weight.grad,epoch)

        print(
            "epoch", epoch, 
            "total_correct:", total_correct, 
            "loss:", total_loss
        )

    tb.close()
#+END_SRC
简化后的代码：
#+BEGIN_SRC python
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import torchvision
import torchvision.transforms as transforms

from torch.utils.data import DataLoader
from torch.utils.tensorboard import SummaryWriter
from IPython.display import display, clear_output
import pandas as pd
import time
import json

from itertools import product
from collections import namedtuple
from collections import OrderedDict

class RunBuilder():
    @staticmethod
    def get_runs(params):

        Run = namedtuple('Run', params.keys())

        runs = []
        for v in product(*params.values()):
            runs.append(Run(*v))

        return runs
    
class RunManager():
    def __init__(self):

        self.epoch_count = 0
        self.epoch_loss = 0
        self.epoch_num_correct = 0
        self.epoch_start_time = None

        self.run_params = None
        self.run_count = 0
        self.run_data = []
        self.run_start_time = None

        self.network = None
        self.loader = None 
        self.tb = None  #保存tensorboard的数据

    def begin_run(self, run, network, loader):

        self.run_start_time = time.time()

        self.run_params = run
        self.run_count += 1

        self.network = network
        self.loader = loader
        self.tb = SummaryWriter(comment=f'-{run}')

        images, labels = next(iter(self.loader))
        grid = torchvision.utils.make_grid(images)

        self.tb.add_image('images', grid)
        self.tb.add_graph(self.network, images)
    def end_run(self):
        self.tb.close()
        self.epoch_count = 0
    
    def begin_epoch(self):
        self.epoch_start_time = time.time()

        self.epoch_count += 1
        self.epoch_loss = 0
        self.epoch_num_correct = 0

    def end_epoch(self):

        epoch_duration = time.time() - self.epoch_start_time
        run_duration = time.time() - self.run_start_time

        loss = self.epoch_loss / len(self.loader.dataset)
        accuracy = self.epoch_num_correct / len(self.loader.dataset)

        self.tb.add_scalar('Loss', loss, self.epoch_count)
        self.tb.add_scalar('Accuracy', accuracy, self.epoch_count)

        for name, param in self.network.named_parameters():
            self.tb.add_histogram(name, param, self.epoch_count)
            self.tb.add_histogram(f'{name}.grad', param.grad, self.epoch_count)
            results = OrderedDict()
        results["run"] = self.run_count
        results["epoch"] = self.epoch_count
        results['loss'] = loss
        results["accuracy"] = accuracy
        results['epoch duration'] = epoch_duration
        results['run duration'] = run_duration
        for k,v in self.run_params._asdict().items(): results[k] = v
        self.run_data.append(results)

        df = pd.DataFrame.from_dict(self.run_data, orient='columns')
        clear_output(wait=True)
        display(df)
    def track_loss(self, loss):
        self.epoch_loss += loss.item() * self.loader.batch_size

    def track_num_correct(self, preds, labels):
        self.epoch_num_correct += self._get_num_correct(preds, labels)

#    @torch.no_rrad()
    def _get_num_correct(self, preds, labels): #函数名前的下划线表示它有点像私有方法，不打算被外部调用者使用。下划线并不能阻止外部调用者的调用，但它确实向调用者发出了信号，即该方法主要在内部使用
        return preds.argmax(dim=1).eq(labels).sum().item()

    def save(self, fileName):
        pd.DataFrame.from_dict(
            self.run_data, orient='columns'
        ).to_csv(f'{fileName}.csv')

        with open(f'{fileName}.json', 'w', encoding='utf-8') as f:
            json.dump(self.run_data, f, ensure_ascii=False, indent=4)

class Network(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)
        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)

        self.fc1 = nn.Linear(in_features=12 * 4 * 4, out_features=120)
        self.fc2 = nn.Linear(in_features=120, out_features=60)
        self.out = nn.Linear(in_features=60, out_features=10)

    def forward(self, t):
        # (1) input layer
        t = t

        # (2) hidden conv layer
        t = self.conv1(t)
        t = F.relu(t)
        t = F.max_pool2d(t, kernel_size=2, stride=2)

        # (3) hidden conv layer
        t = self.conv2(t)
        t = F.relu(t)
        t = F.max_pool2d(t, kernel_size=2, stride=2)

        # (4) hidden linear layer
        t = t.reshape(-1, 12 * 4 * 4)  
        t = self.fc1(t)
        t = F.relu(t)

        # (5) hidden linear layer
        t = self.fc2(t)
        t = F.relu(t)

        # (6) output layer
        t = self.out(t)
        #t = F.softmax(t, dim=1)   
        return t

train_set = torchvision.datasets.FashionMNIST(
    root='./data'  #表示数据集下载位置
    ,train=True    #这个表示我们希望使用训练训练集的数据，FashionMNIST数据集中有6万张用作训练数据，1万张用于测试数据
    ,download=True #这个表示如果下载位置没有数据集，则下载数据集
    ,transform=transforms.Compose([  #这个使用了内置的 ToTensor 表换来转换图像
        transforms.ToTensor()
    ])
)

params = OrderedDict(
    lr = [.01]
    ,batch_size = [1000, 2000]
)

m=RunManager()
for run in RunBuilder.get_runs(params):
    network=Network()
    loader=DataLoader(train_set,batch_size=run.batch_size)
    optimizer=optim.Adam(network.parameters(),lr=run.lr)

    m.begin_run(run,network,loader)
    for epoch in range(5):
        m.begin_epoch()
        for batch in loader:
            images,labels=batch
            preds= network(images) #Pass Batch
            loss= F.cross_entropy(preds,labels) # Calculate Loss
            optimizer.zero_grad()  #Zero Gradients
            loss.backward() # Calculate Gradients
            optimizer.step() # Update Weights
            
            m.track_loss(loss)
            m.track_num_correct(preds,labels)
        m.end_epoch()
    m.end_run()
m.save('results')
#+END_SRC
** csv文件
csv文件可以在excel中打开。json文件中有各种网络参数。
* 第33集 PyTorch DataLoader Num_workers - Deep Learning Speed Limit Increase
** Speeding Up The Training Process
In this episode, we will see how we can speed up the neural network training process by utilizing the multiple process capabilities of the PyTorch DataLoader class.

To speed up the training process, we will make use of the ~num_workers~ optional attribute of the ~DataLoader~ class.

The ~num_workers~ attribute tells the data loader instance how many sub-processes to use for data loading. By default, the ~num_workers~ value is set to zero, and a value of zero tells the loader to load the data inside the main process.

This means that the training process will work sequentially inside the main process. After a batch is used during the training process and another one is needed, we read the batch data from disk.

Now, if we have a worker process, we can make use of the fact that our machine has multiple cores. This means that the next batch can already be loaded and ready to go by the time the main process is ready for another batch. This is where the speed up comes from. The batches are loaded using additional worker processes and are queued up in memory.
** Testing Values For The num_workers Attribute
#+BEGIN_SRC python
params = OrderedDict(
    lr = [.01]
    ,batch_size = [100,1000, 10000]
    ,num_workers=[0,1,2,4,8,16]  #这里添加
)

m=RunManager()
for run in RunBuilder.get_runs(params):
    network=Network()
    loader=DataLoader(train_set,batch_size=run.batch_size,num_workers=run.num_workers)  #这里也要添加参数
    optimizer=optim.Adam(network.parameters(),lr=run.lr)

    m.begin_run(run,network,loader)
    for epoch in range(1):
        m.begin_epoch()
        for batch in loader:
            images,labels=batch
            preds= network(images) #Pass Batch
            loss= F.cross_entropy(preds,labels) # Calculate Loss
            optimizer.zero_grad()  #Zero Gradients
            loss.backward() # Calculate Gradients
            optimizer.step() # Update Weights
            
            m.track_loss(loss)
            m.track_num_correct(preds,labels)
        m.end_epoch()
    m.end_run()
m.save('results')
#+END_SRC
Alright, let's see what we get.
** Different num_workers Values: Results
将num_workers设置为cpu的核数，获得的加速效果最好，超过cpu核数反而无法提升太多速度。

Alright, we can see down below that we have the results. We completed a total of eighteen runs. We have three groups of differing batch sizes, and inside each of these groups, we varied the number of worker processes.
| run | epoch |     loss | accuracy | epoch duration | run duration |   lr | batch_size | num_workers |
|-----+-------+----------+----------+----------------+--------------+------+------------+-------------|
|   1 |     1 | 0.566253 | 0.782583 |      23.281029 |    23.374832 | 0.01 |        100 |           0 |
|   2 |     1 | 0.573350 | 0.783917 |      18.125359 |    18.965940 | 0.01 |        100 |           1 |
|   3 |     1 | 0.574852 | 0.782133 |      18.161020 |    19.037995 | 0.01 |        100 |           2 |
|   4 |     1 | 0.593246 | 0.775067 |      18.637056 |    19.669869 | 0.01 |        100 |           4 |
|   5 |     1 | 0.587598 | 0.777500 |      18.631994 |    20.123626 | 0.01 |        100 |           8 |
|   6 |     1 | 0.596401 | 0.775983 |      20.110439 |    22.930428 | 0.01 |        100 |          16 |
|   7 |     1 | 1.105825 | 0.577500 |      21.254815 |    21.941008 | 0.01 |       1000 |           0 |
|   8 |     1 | 1.013017 | 0.612267 |      15.961835 |    17.457127 | 0.01 |       1000 |           1 |
|   9 |     1 | 0.881558 | 0.666200 |      16.060656 |    17.614599 | 0.01 |       1000 |           2 |
|  10 |     1 | 1.034153 | 0.606767 |      16.206196 |    17.883490 | 0.01 |       1000 |           4 |
|  11 |     1 | 0.963817 | 0.626400 |      16.700765 |    18.882340 | 0.01 |       1000 |           8 |
|  12 |     1 | 1.046822 | 0.601683 |      17.912993 |    21.747298 | 0.01 |       1000 |          16 |
|  13 |     1 | 2.173913 | 0.265983 |      22.219368 |    27.145123 | 0.01 |      10000 |           0 |
|  14 |     1 | 2.156031 | 0.191167 |      16.563987 |    23.368729 | 0.01 |      10000 |           1 |
|  15 |     1 | 2.182048 | 0.210250 |      16.128202 |    23.030015 | 0.01 |      10000 |           2 |
|  16 |     1 | 2.245768 | 0.200683 |      16.248334 |    22.108252 | 0.01 |      10000 |           4 |
|  17 |     1 | 2.177970 | 0.206483 |      16.921782 |    23.897321 | 0.01 |      10000 |           8 |
|  18 |     1 | 2.153342 | 0.208017 |      18.555999 |    26.654219 | 0.01 |      10000 |          16 |
*** Innnnnterpreting The Results
The twenty percent speed up that we see after adding a single worker process makes sense because the main process had less work to do.

While the main process is busy performing the forward and backward passes, the worker process is loading the next batch. By the time the main process is ready for another batch, the worker process already has it queued up in memory.
 
As a result, the main process doesn't have to read the data from disk. Instead, the data is already in memory, and this gives us the twenty percent speed up.

Now, why are we not seeing additional speed ups after adding more workers?

We'll if one worker is enough to keep the queue full of data for the main process, then adding more batches of data to the queue isn't going to do anything. This is what I think we are seeing here.

Just because we are adding more batches to the queue doesn't mean the batches are being processes faster. Thus, we are bounded by the time it takes to forward and backward propagate a given batch.

We can even see that things start bogging as we get to 16 workers.
* 第34集 PyTorch On The GPU - Training Neural Networks With CUDA
** Using A GPU For Deep Learning
For now, we're going to hit the ground running with a PyTorch GPU example.
*** PyTorch GPU Example
PyTorch allows us to seamlessly move data to and from our GPU as we preform computations inside our programs.

When we go to the GPU, we can use the ~cuda()~ method, and when we go to the CPU, we can use the ~cpu()~ method.

We can also use the ~to()~ method. To go to the GPU, we write ~to('cuda')~ and to go to the CPU, we write ~to('cpu')~. The ~to()~ method is the preferred way mainly because it is more flexible. We'll see one example using using the first two, and then we'll default to always using the ~to()~ variant.
| CPU       | GPU        |
|-----------+------------|
| cpu()     | cuda()     |
| to('cpu') | to('cuda') |

To make use of our GPU during the training process, there are two essential requirements. These requirements are as follows, the data must be moved to the GPU, and the network must be moved to the GPU.

1. Data on the GPU
2. Network on the GPU

By default, when a PyTorch tensor or a PyTorch neural network module is created, the corresponding data is initialized on the CPU. Specifically, the data exists inside the CPU's memory.

Now, let's create a tensor and a network, and see how we make the move from CPU to GPU.

Here, we create a tensor and a network:
#+BEGIN_SRC python
t = torch.ones(1,1,28,28)
network = Network()
#+END_SRC
Now, we call the cuda() method and reassign the tensor and network to returned values that have been copied onto the GPU:
#+BEGIN_SRC python
t = t.cuda()
network = network.cuda()
#+END_SRC
Next, we can get a prediction from the network and see that the prediction tensor's device attribute confirms that the data is on cuda, which is the GPU:

#+BEGIN_SRC bash
> gpu_pred = network(t)
> gpu_pred.device
device(type='cuda', index=0)
#+END_SRC

Likewise, we can go in the opposite way:
#+BEGIN_SRC bash
> t = t.cpu()
> network = network.cpu()

> cpu_pred = network(t)
> cpu_pred.device
device(type='cpu')
#+END_SRC
This is, in a nutshell, how we can utilize the GPU capabilities of PyTorch. What we should turn to now are some important details that are lurking beneath the surface of the code we've just seen.

For example, although we've used the ~cuda()~ and ~cpu()~ methods, they actually aren't our best options. Furthermore, what's the difference with the methods between the network instance and the tensor instance? These after all are different objects types, which means the two methods are different. Finally, we want to integrate this code into a working example and do a performance test.
** PyTorch Tensor Computations On A GPU
We'll start by creating two tensors:
#+BEGIN_SRC python
t1 = torch.tensor([
    [1,2],
    [3,4]
])

t2 = torch.tensor([
    [5,6],
    [7,8]
])
#+END_SRC
Now, we'll check which device these tensors were initialized on by inspecting the device attribute:
#+BEGIN_SRC bash
> t1.device, t2.device
(device(type='cpu'), device(type='cpu'))
#+END_SRC
As we'd expect, we see that, indeed, both tensors are on the same device, which is the CPU. Let's move the first tensor t1 to the GPU.
#+BEGIN_SRC bash
> t1 = t1.to('cuda')
> t1.device
device(type='cuda', index=0)
#+END_SRC
We can see that this tensor's device has been changed to cuda, the GPU. Note the use of the to() method here. Instead of calling a particular method to move to a device, we call the same method and pass an argument that specifies the device. Using the to() method is the preferred way of moving data to and from devices.

Also, note the reassignment. The operation is not in-place, and so the reassignment is required.
 
Let's try an experiment. I'd like to test what we discussed earlier by attempting to perform a computation on these two tensors, t1 and t2, that we now know to be on different devices.

Since we expect an error, we'll wrap the call in a try and catch the exception:
#+BEGIN_SRC python
try: 
    t1 + t2
except Exception as e:
    print(e)

expected device cuda:0 but got device cpu
#+END_SRC
By reversing the order of the operation, we can see that the error also changes:
#+BEGIN_SRC python
try: 
    t2 + t1
except Exception as e: 
    print(e)

expected device cpu but got device cuda:0
#+END_SRC
Both of these errors are telling us that the binary plus operation expects the second argument to have the same device as the first argument. Understanding the meaning of this error can help when debugging these types of device mismatches.

Finally, for completion, let's move the second tensor to the cuda device to see the operation succeed.
#+BEGIN_SRC bash
> t2 = t2.to('cuda')
> t1 + t2

tensor([[ 6,  8],
        [10, 12]], device='cuda:0')
#+END_SRC
** PyTorch nn.Module Computations On A GPU
Network里面的参数默认都是在cpu上，当把整个网络移动到GPU时，实际上是把所有参数都移动到GPU上。

We've just seen how tensors can be moved to and from devices. Now, let's see how this is done with PyTorch ~nn.Module~ instances.

More generally, we are interested in understanding how and what it means for a network to be on a device like a GPU or CPU. PyTorch aside, this is the essential issue.

We put a network on a device by moving the network's parameters to that said device. Let's create a network and take a look at what we mean.
#+BEGIN_SRC python
network = Network()
#+END_SRC
Now, let's look at the network's parameters:
#+BEGIN_SRC python
for name, param in network.named_parameters():
    print(name, '\t\t', param.shape)

conv1.weight        torch.Size([6, 1, 5, 5])
conv1.bias          torch.Size([6])
conv2.weight        torch.Size([12, 6, 5, 5])
conv2.bias          torch.Size([12])
fc1.weight          torch.Size([120, 192])
fc1.bias            torch.Size([120])
fc2.weight          torch.Size([60, 120])
fc2.bias            torch.Size([60])
out.weight          torch.Size([10, 60])
out.bias            torch.Size([10])
#+END_SRC
Here, we've created a PyTorch network, and we've iterated through the network's parameters. As we can see, the network's parameters are the weights and biases inside the network.

In other words, these are simply tensors that live on a device like we have already seen. Let's verify this by checking the device of each of the parameters.
#+BEGIN_SRC python
for n, p in network.named_parameters():
    print(p.device, '', n)

cpu  conv1.weight
cpu  conv1.bias
cpu  conv2.weight
cpu  conv2.bias
cpu  fc1.weight
cpu  fc1.bias
cpu  fc2.weight
cpu  fc2.bias
cpu  out.weight
cpu  out.bias
#+END_SRC
This shows us that all the parameters inside the network are, by default, initialized on the CPU.

An important consideration of this is that it explains why ~nn.Module~ instances like networks don't actually have a device. It's not the network that lives on a device, but the tensors inside the network that live on a device.

Let's see what happens when we ask a network to be moved to() the GPU:
#+BEGIN_SRC bash
> network.to('cuda')
Network(
    (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))
    (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))
    (fc1): Linear(in_features=192, out_features=120, bias=True)
    (fc2): Linear(in_features=120, out_features=60, bias=True)
    (out): Linear(in_features=60, out_features=10, bias=True)
)
#+END_SRC
Note here that a reassignment was not required. This is because the operation is in-place as far as the network instance is concerned. However, this operation can be used as a reassignment operation. This is preferred for consistency between ~nn.Module~ instances and PyTorch tensors.

Here, we can see that now, all the network parameters are have a device of cuda:
#+BEGIN_SRC python
for n, p in network.named_parameters():
    print(p.device, '', n)

cuda:0  conv1.weight
cuda:0  conv1.bias
cuda:0  conv2.weight
cuda:0  conv2.bias
cuda:0  fc1.weight
cuda:0  fc1.bias
cuda:0  fc2.weight
cuda:0  fc2.bias
cuda:0  out.weight
cuda:0  out.bias
#+END_SRC

*** Passing A Sample To The Network
将一个在cpu上的张量传入一个在GPU上的网络时，会发生错误。

Let's round off this demonstration by passing a sample to the network.
#+BEGIN_SRC python
> sample = torch.ones(1,1,28,28)
> sample.shape

torch.Size([1, 1, 28, 28])
#+END_SRC
This gives us a sample tensor we can pass like so:
#+BEGIN_SRC bash
> try:
      network(sample)
  except Exception as e: 
      print(e)

Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _thnn_conv2d_forward
#+END_SRC
Since our network is on the GPU and this newly created sample is on the CPU by default, we are getting an error. The error is telling us that the CPU tensor was expected to be a GPU tensor when calling the forward method of the first convolutional layer. This is precisely what we saw before when adding two tensors directly.

We can fix this issue by sending our sample to the GPU like so:
#+BEGIN_SRC bash
> try:
      pred = network(sample.to('cuda'))
      print(pred)
  except Exception as e:
      print(e)

tensor([[-0.0685,  0.0201,  0.1223,  0.1075,  0.0810,  0.0686, -0.0336, -0.1088, -0.0995,  0.0639]]
, device='cuda:0'
, grad_fn=<AddmmBackward>
)
#+END_SRC
Finally, everything works as expected, and we get a prediction.
** PyTorch GPU Training Performance Test
*** Refactoring The RunManager Class
Before we update the training loop, we need to update the RunManager class. Inside the ~begin_run()~ method we need to modify the ~device~ of the ~images~ tensor that is passed to ~add_graph~ method.

It should look like this:
#+BEGIN_SRC python
def begin_run(self, run, network, loader):

    self.run_start_time = time.time()

    self.run_params = run
    self.run_count += 1

    self.network = network
    self.loader = loader
    self.tb = SummaryWriter(comment=f'-{run}')

    images, labels = next(iter(self.loader))
    grid = torchvision.utils.make_grid(images)

    self.tb.add_image('images', grid)
    self.tb.add_graph(    #修改了这里
            self.network
        ,images.to(getattr(run, 'device', 'cpu'))
    )
#+END_SRC
Here, we are using the ~getattr()~ built in function to get the value of the ~device~ on the ~run~ object. If the ~run~ object doesn't have a ~device~, then ~cpu~ is returned. This makes the code backward compatible. It will still work if we don't specify a ~device~ for our ~run~.

Note that the network doesn't need to be moved to a device because it's device was set before being passed in. However, the images tensor is obtained from the loader.
总代码：
#+BEGIN_SRC python
class RunBuilder():
    @staticmethod
    def get_runs(params):

        Run = namedtuple('Run', params.keys())

        runs = []
        for v in product(*params.values()):
            runs.append(Run(*v))

        return runs
    
class RunManager():
    def __init__(self):

        self.epoch_count = 0
        self.epoch_loss = 0
        self.epoch_num_correct = 0
        self.epoch_start_time = None

        self.run_params = None
        self.run_count = 0
        self.run_data = []
        self.run_start_time = None

        self.network = None
        self.loader = None 
        self.tb = None  #保存tensorboard的数据

    def begin_run(self, run, network, loader):

        self.run_start_time = time.time()

        self.run_params = run
        self.run_count += 1

        self.network = network
        self.loader = loader
        self.tb = SummaryWriter(comment=f'-{run}')

        images, labels = next(iter(self.loader))
        grid = torchvision.utils.make_grid(images)

        self.tb.add_image('images', grid)
        self.tb.add_graph(
            self.network
        ,images.to(getattr(run, 'device', 'cpu'))
    )
    def end_run(self):
        self.tb.close()
        self.epoch_count = 0
    
    def begin_epoch(self):
        self.epoch_start_time = time.time()

        self.epoch_count += 1
        self.epoch_loss = 0
        self.epoch_num_correct = 0

    def end_epoch(self):

        epoch_duration = time.time() - self.epoch_start_time
        run_duration = time.time() - self.run_start_time

        loss = self.epoch_loss / len(self.loader.dataset)
        accuracy = self.epoch_num_correct / len(self.loader.dataset)

        self.tb.add_scalar('Loss', loss, self.epoch_count)
        self.tb.add_scalar('Accuracy', accuracy, self.epoch_count)

        for name, param in self.network.named_parameters():
            self.tb.add_histogram(name, param, self.epoch_count)
            self.tb.add_histogram(f'{name}.grad', param.grad, self.epoch_count)
            results = OrderedDict()
        results["run"] = self.run_count
        results["epoch"] = self.epoch_count
        results['loss'] = loss
        results["accuracy"] = accuracy
        results['epoch duration'] = epoch_duration
        results['run duration'] = run_duration
        for k,v in self.run_params._asdict().items(): results[k] = v
        self.run_data.append(results)

        df = pd.DataFrame.from_dict(self.run_data, orient='columns')
        clear_output(wait=True)
        display(df)
    def track_loss(self, loss):
        self.epoch_loss += loss.item() * self.loader.batch_size

    def track_num_correct(self, preds, labels):
        self.epoch_num_correct += self._get_num_correct(preds, labels)

#    @torch.no_rrad()
    def _get_num_correct(self, preds, labels): #函数名前的下划线表示它有点像私有方法，不打算被外部调用者使用。下划线并不能阻止外部调用者的调用，但它确实向调用者发出了信号，即该方法主要在内部使用
        return preds.argmax(dim=1).eq(labels).sum().item()

    def save(self, fileName):
        pd.DataFrame.from_dict(
            self.run_data, orient='columns'
        ).to_csv(f'{fileName}.csv')

        with open(f'{fileName}.json', 'w', encoding='utf-8') as f:
            json.dump(self.run_data, f, ensure_ascii=False, indent=4)
#+END_SRC
*** Refactoring The Training Loop
#+BEGIN_SRC python
params = OrderedDict(
    lr = [.01]
    ,batch_size = [1000, 2000]
    ,num_worker=[0,1]          #这里修改
    ,device=['cuda','cpu']
)

m=RunManager()
for run in RunBuilder.get_runs(params):

    device=torch.device(run.device) #这两行修改
    network=Network().to(device)

    loader=DataLoader(train_set,batch_size=run.batch_size,num_workers=run.num_workers)
    optimizer=optim.Adam(network.parameters(),lr=run.lr)

    m.begin_run(run,network,loader)
    for epoch in range(5):
        m.begin_epoch()
        for batch in loader:

            images=batch[0].to(device)  #这里修改两行
            labels=batch[1].to(divice)

            preds= network(images) #Pass Batch
            loss= F.cross_entropy(preds,labels) # Calculate Loss
            optimizer.zero_grad()  #Zero Gradients
            loss.backward() # Calculate Gradients
            optimizer.step() # Update Weights
            
            m.track_loss(loss)
            m.track_num_correct(preds,labels)
        m.end_epoch()
    m.end_run()
m.save('results')
#+END_SRC
| run | epoch | loss | accuracy | epoch duration | run duration |   lr | batch_size | num_workers | device |
|-----+-------+------+----------+----------------+--------------+------+------------+-------------+--------|
|   1 |     1 | 1.08 |     0.59 |           7.50 |         9.67 | 0.01 |       1000 |           0 | cuda   |
|   2 |     1 | 1.04 |     0.60 |          20.83 |        21.88 | 0.01 |       1000 |           0 | cpu    |
|   3 |     1 | 1.03 |     0.61 |           7.84 |        10.69 | 0.01 |       1000 |           1 | cuda   |
|   4 |     1 | 1.02 |     0.61 |          16.49 |        19.21 | 0.01 |       1000 |           1 | cpu    |
|   5 |     1 | 2.10 |     0.24 |           7.69 |        12.30 | 0.01 |      10000 |           0 | cuda   |
|   6 |     1 | 2.09 |     0.24 |          19.89 |        28.85 | 0.01 |      10000 |           0 | cpu    |
|   7 |     1 | 2.11 |     0.25 |           8.05 |        15.21 | 0.01 |      10000 |           1 | cuda   |
|   8 |     1 | 2.17 |     0.20 |          17.09 |        28.68 | 0.01 |      10000 |           1 | cpu    |
|   9 |     1 | 2.28 |     0.21 |           9.65 |        17.56 | 0.01 |      20000 |           0 | cuda   |
|  10 |     1 | 2.29 |     0.10 |          19.63 |        36.19 | 0.01 |      20000 |           0 | cpu    |
|  11 |     1 | 2.29 |     0.14 |           8.18 |        19.59 | 0.01 |      20000 |           1 | cuda   |
|  12 |     1 | 2.29 |     0.12 |          17.68 |        38.08 | 0.01 |      20000 |           1 | cpu    |
我们可以按运行时间排序：
#+BEGIN_SRC bash
> pd.DataFrame.from_dict(m.run_data,orient='columns').sort_values('epoch duration')
#+END_SRC
* 第35集 PyTorch Dataset Normalization - Torchvision.Transforms.Normalize()
标准化：z=(x-mean)/std

mean表示均值，std表示标准差
** Normalize A Dataset In Code
Let's jump into a code example. The first step is to initialize our dataset, so in this example we'll use the Fashion MNIST dataset that we've been working with up to this point in the series.
#+BEGIN_SRC python
train_set = torchvision.datasets.FashionMNIST(
    root='./data'
    ,train=True
    ,download=True
    ,transform=transforms.Compose([
        transforms.ToTensor()
    ])
)

#+END_SRC
PyTorch allows us to normalize our dataset using the standardization process we've just seen by passing in the mean and standard deviation values for each color channel to the ~Normalize()~ transform.
#+BEGIN_SRC python
torchvision.transforms.Normalize(
      [meanOfChannel1, meanOfChannel2, meanOfChannel3] 
    , [stdOfChannel1, stdOfChannel2, stdOfChannel3] 
)
#+END_SRC
Since the images inside our dataset only have a single channel, we only need to pass in solo mean and standard deviation values. In order to do this we need to first calculate these values. Sometimes the values might be posted online somewhere, so we can get them that way. However, when in doubt, we can just calculate the manually.

There are two ways it can be done. The easy way, and the harder way. The easy way can be achieved if the dataset is small enough to fit into memory all at once. Otherwise, we have to iterate over the data which is slightly harder.
*** Calculating mean And std The Easy Way
The easy way is easy. All we have to do is load the dataset using the data loader and get a single batch tensor that contains all the data. To do this we set the batch size to be equal to the training set length.
#+BEGIN_SRC python
> loader = DataLoader(train_set, batch_size=len(train_set), num_workers=1)
> data = next(iter(loader))
> data[0].mean(), data[0].std()

(tensor(0.2860), tensor(0.3530))
#+END_SRC
Here, we can obtain the mean and standard deviation values by simply using the corresponding PyTorch tensor methods.
*** Calculating mean And std The Hard Way
#+BEGIN_SRC python
loader = DataLoader(train_set, batch_size=1000, num_workers=1)
num_of_pixels = len(train_set) * 28 * 28

total_sum = 0
for batch in loader: total_sum += batch[0].sum()  #batch[0]是图像，batch[1]是标签
mean = total_sum / num_of_pixels

sum_of_squared_error = 0
for batch in loader: 
    sum_of_squared_error += ((batch[0] - mean).pow(2)).sum()
std = torch.sqrt(sum_of_squared_error / num_of_pixels)
#+END_SRC
This gives us:
#+BEGIN_SRC bash
> mean, std
(tensor(0.2860), tensor(0.3530))
#+END_SRC
*** Using The mean And std Values
#+BEGIN_SRC python
> train_set_normal = torchvision.datasets.FashionMNIST(
    root='./data'
    ,train=True
    ,download=True
    ,transform=transforms.Compose([
          transforms.ToTensor()
        , transforms.Normalize(mean, std)
    ])
)

> loader = DataLoader(
      train_set_normal
    , batch_size=len(train_set)
    , num_workers=1
)
> data = next(iter(loader))
> data[0].mean(), data[0].std()

(tensor(1.2368e-05), tensor(1.0000))
#+END_SRC
Our mean value is not  while the standard deviation value is .
** Training With Normalized Data
Let's create a dictionary of training sets that we can use to run the test in the framework that we've been building throughout the course.
#+BEGIN_SRC python
trainsets = {
    'not_normal': train_set
    ,'normal': train_set_normal
}
#+END_SRC
Now, we can add these two train_sets to our configuration and access the values inside our runs loop.
#+BEGIN_SRC python
params = OrderedDict(
      lr = [.01]
    , batch_size = [1000]
    , num_workers = [1]
    , device = ['cuda']
    , trainset = ['not_normal', 'normal']  #这里改变
)
m = RunManager()
for run in RunBuilder.get_runs(params):

    device = torch.device(run.device)
    network = Network().to(device)
    loader = DataLoader(
          trainsets[run.trainset]       #这里改变
        , batch_size=run.batch_size
        , num_workers=run.num_workers
    )
    optimizer = optim.Adam(network.parameters(), lr=run.lr)

    m.begin_run(run, network, loader)
    for epoch in range(20):
        m.begin_epoch()
        for batch in loader:

            images = batch[0].to(device)
            labels = batch[1].to(device)
            preds = network(images) # Pass Batch
            loss = F.cross_entropy(preds, labels) # Calculate Loss
            optimizer.zero_grad() # Zero Gradients
            loss.backward() # Calculate Gradients
            optimizer.step() # Update Weights

            m.track_loss(loss, batch)
            m.track_num_correct(preds, labels)
        m.end_epoch()
    m.end_run()
m.save('results')
#+END_SRC
* 第37集 PyTorch Sequential Models - Neural Networks Made Easy
** Building PyTorch Sequential Networks
There are three ways to create a Sequential model. Let's see them in action.
*** Code Setup
Firstly, we handle our imports.
#+BEGIN_SRC python
import torch
import torch.nn as nn
import torch.nn.functional as F

import torchvision
import torchvision.transforms as transforms

import matplotlib.pyplot as plt
import math

from collections import OrderedDict

torch.set_printoptions(linewidth=150)
#+END_SRC
Then, we need to create a dataset that we can use for the purposes of passing a sample to the networks we will be building.
#+BEGIN_SRC python
train_set = torchvision.datasets.FashionMNIST(
    root='./data'
    ,train=True
    ,download=True
    ,transform=transforms.Compose([
        transforms.ToTensor()
    ])
)
#+END_SRC
Now, we'll grab a sample image from the FashionMNIST dataset instance.
#+BEGIN_SRC python
> image, label = train_set[0]
> image.shape

torch.Size([1, 28, 28])
#+END_SRC
