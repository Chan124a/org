<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2020-01-02 周四 14:46 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>&lrm;</title>
<meta name="generator" content="Org mode" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2019 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org014647f">1. caffe支持的数据格式</a></li>
</ul>
</div>
</div>
<p>
一般把数据源放在 $CAFFE<sub>ROOT</sub>/data 文件夹下面。
处理后的数据和模型文件等放在 $CAFFE<sub>ROOT</sub>/examples文件夹下。（$CAFFE<sub>ROOT</sub> 表示你电脑上的caffe代码路径。）
</p>

<div id="outline-container-org014647f" class="outline-2">
<h2 id="org014647f"><span class="section-number-2">1</span> caffe支持的数据格式</h2>
<div class="outline-text-2" id="text-1">
<ul class="org-ul">
<li>数据库格式 （LEVELDB or LMDB） $CAFFEROOT/build/tools/convert<sub>imageset</sub> 可以用来做把原始图片转换为LevelDB或者 Lmdb格式。</li>
</ul>
<blockquote>
<p>
Image Data - read raw images.
</p>

<p>
Database - read data from LEVELDB or LMDB.
</p>

<p>
HDF5 Input - read HDF5 data, allows data of arbitrary dimensions.
</p>

<p>
HDF5 Output - write data as HDF5.
</p>

<p>
Input - typically used for networks that are being deployed.
</p>

<p>
Window Data - read window data file.
</p>

<p>
Memory Data - read data directly from memory.
</p>

<p>
Dummy Data - for static data and debugging.
</p>
</blockquote>


<p>
## 准备数据
</p>

<p>
MNIST数据： $CAFFE<sub>ROOT</sub>/data/mnist/get<sub>mnist.sh</sub> 
运行这个脚本就可以帮我们下载MNIST数据。
</p>

<p>
```bash
cd $CAFFE<sub>ROOT</sub>
./data/mnist/get<sub>mnist.sh</sub> #得到MNIST数据
```
</p>

<p>
运行成功后，在 `data/mnist/` 目录下有四个文件：
![在这里插入图片描述](<a href="https://img-blog.csdnimg.cn/20191224154902223.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxMTIwNjMzMjY5,size_16,color_FFFFFF,t_70">https://img-blog.csdnimg.cn/20191224154902223.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxMTIwNjMzMjY5,size_16,color_FFFFFF,t_70</a>)
但是这些数据不能在 Caffe 中直接使用，需要转换成 LMDB 数据
</p>

<p>
```
./examples/mnist/create<sub>mnist.sh</sub> #官方给出的专门转换MNIST数据格式的脚本
#这条命令必须从$CAFFE<sub>ROOT这个目录下执行</sub>，否则会出现找不到文件的错误：build/examples/mnist/convert<sub>mnist</sub><sub>data.bin</sub>: not found
```
</p>

<p>
如果想运行 leveldb 数据，请运行 examples/siamese/ 文件夹下面的程序。 examples/mnist/ 文件夹是运行 lmdb 数据
转换成功后，会在 `examples/mnist/` 目录下，生成两个文件夹
![在这里插入图片描述](<img src="https://img-blog.csdnimg.cn/20191224094839543.png" alt="20191224094839543.png" />)
</p>

<p>
## 配置网络结构
</p>

<p>
官网提供了定义好的网络文件 $CAFFE<sub>ROOT</sub>/examples/mnist/lenet<sub>train</sub><sub>test.prototxt</sub> 
内容如下：
</p>

<p>
```python
name: "LeNet"
layer {
  name: "mnist"
  type: "Data" #数据层
  top: "data" 
  top: "label"
  include {
    phase: TRAIN #训练时才加载
  }
  transform<sub>param</sub> {
    scale: 0.00390625 #每个像素乘以改值做归一化（1/255 = 0.00390625）
  }
  data<sub>param</sub> {
    source: "examples/mnist/mnist<sub>train</sub><sub>lmdb</sub>" #前面生成的训练数据集
    batch<sub>size</sub>: 64 # 每一批训练集大小
    backend: LMDB #数据格式
  }
}
layer {
  name: "mnist"
  type: "Data" #数据层
  top: "data"
  top: "label"
  include {
    phase: TEST #测试时才加载
  }
  transform<sub>param</sub> {
    scale: 0.00390625
  }
  data<sub>param</sub> {
    source: "examples/mnist/mnist<sub>test</sub><sub>lmdb</sub>" #前面生成的测试数据集
    batch<sub>size</sub>: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution" #卷积层
  bottom: "data"
  top: "conv1"
  param {
    lr<sub>mult</sub>: 1 #weights学习率
  }
  param {
    lr<sub>mult</sub>: 2 #bias学习率
  }
  convolution<sub>param</sub> {
    num<sub>output</sub>: 20 #输出多少个特征图（对应卷积核数量）
    kernel<sub>size</sub>: 5 #卷积核大小
    stride: 1 #步长
    weight<sub>filler</sub> {
      type: "xavier" #权重初始化算法
    }
    bias<sub>filler</sub> {
      type: "constant" #基值初始化算法
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling" #池化层
  bottom: "conv1" 
  top: "pool1"
  pooling<sub>param</sub> {
    pool: MAX #池化方法
    kernel<sub>size</sub>: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr<sub>mult</sub>: 1
  }
  param {
    lr<sub>mult</sub>: 2
  }
  convolution<sub>param</sub> {
    num<sub>output</sub>: 50
    kernel<sub>size</sub>: 5
    stride: 1
    weight<sub>filler</sub> {
      type: "xavier"
    }
    bias<sub>filler</sub> {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling<sub>param</sub> {
    pool: MAX
    kernel<sub>size</sub>: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct" #全链接层
  bottom: "pool2"
  top: "ip1"
  param {
    lr<sub>mult</sub>: 1 #weights学习率
  }
  param {
    lr<sub>mult</sub>: 2 #bias学习率
  }
  inner<sub>product</sub><sub>param</sub> {
    num<sub>output</sub>: 500
    weight<sub>filler</sub> {
      type: "xavier"
    }
    bias<sub>filler</sub> {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU" #relu层
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr<sub>mult</sub>: 1
  }
  param {
    lr<sub>mult</sub>: 2
  }
  inner<sub>product</sub><sub>param</sub> {
    num<sub>output</sub>: 10
    weight<sub>filler</sub> {
      type: "xavier"
    }
    bias<sub>filler</sub> {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy" #输出精度
  bottom: "ip2"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss" 
  type: "SoftmaxWithLoss" #输出损失
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
```
</p>

<p>
可以用 官方自带的python绘图工具绘制出网络图：
</p>

<p>
```
~/caffe/python/draw<sub>net.py</sub> ~/caffe/examples/mnist/lenet<sub>train</sub><sub>test.prototxt</sub> ~/lenet<sub>train</sub><sub>test.png</sub>
#最后一个参数是输出图片的路径
```
</p>

<p>
## 配置网络求解文件
</p>

<p>
官网给出了一个求解文件：$CAFFE<sub>ROOT</sub>/examples/mnist/lenet<sub>solver.prototxt</sub>:
</p>

<p>
```python
</p>

<p>
net: "examples/mnist/lenet<sub>train</sub><sub>test.prototxt</sub>"
</p>

<p>
test<sub>iter</sub>: 100
</p>

<p>
test<sub>interval</sub>: 500
</p>

<p>
base<sub>lr</sub>: 0.01
momentum: 0.9
weight<sub>decay</sub>: 0.0005
</p>

<p>
lr<sub>policy</sub>: "inv"
gamma: 0.0001
power: 0.75
</p>

<p>
display: 100
</p>

<p>
max<sub>iter</sub>: 10000
</p>

<p>
snapshot: 5000
snapshot<sub>prefix</sub>: "examples/mnist/lenet" 
</p>

<p>
solver<sub>mode</sub>: GPU
```
</p>

<p>
## 训练
</p>

<p>
```bash
cd $CAFFE<sub>ROOT</sub>
./examples/mnist/train<sub>lenet.sh</sub>
```
</p>

<p>
其内容如下：
`#!/usr/bin/env sh
set -e
</p>

<p>
./build/tools/caffe train &#x2013;solver=examples/mnist/lenet<sub>solver.prototxt</sub> $@`
可见只是调用命令行接口。
然后得到一堆的输出信息：
</p>

<p>
```bash
#solver文件设置每100次迭代训练显示当前状态 lr loss
I1203 solver.cpp:204] Iteration 100, lr = 0.00992565  #学习率
I1203 solver.cpp:66] Iteration 100, loss = 0.26044 #损失
&#x2026;
#solver文件设置每500次测试一下网络 精度 损失
I1203 solver.cpp:84] Testing net
I1203 solver.cpp:111] Test score #0: 0.9785 #精度
I1203 solver.cpp:111] Test score #1: 0.0606671 #损失
```
</p>

<p>
训练结束后，输出信息可以看到最终的精度和损失。 在 $CAFFE<sub>ROOT</sub>/examples/mnist 文件夹下可以看到 如下文件。 迭代5000次的中间状态快照 （.solverstate文件，可用于恢复网络训练）和模型 （.caffemodel文件，可用于下一步测试），迭代10000次的中间状态快照和模型![在这里插入图片描述](<img src="https://img-blog.csdnimg.cn/20191224101300626.png" alt="20191224101300626.png" />)
备注：由于我们在solver中设置了每500做一下测试。所以实际上上面 ./build/tools/caffe train &#x2013;solver=examples/mnist/lenet<sub>solver.prototxt</sub> 的过程包含了训练和间隔测试。这样做有助于我们对网络训练的中间过程有直观感受。
</p>

<p>
## 测试
</p>

<p>
参数包括：
网络结构模型文件(.prototxt 注意不是求解文件solover) 训练好的模型参数（.caffemodel） 迭代测试100次（前面训练和间隔测试时是在solver文件中定义的 此处则用命令行写明）
</p>

<p>
```bash
cd $CAFFE<sub>ROOT</sub>
build/tools/caffe test -model examples/mnist/lenet<sub>train</sub><sub>test.prototxt</sub> -weights examples/mnist/lenet<sub>iter</sub><sub>10000.caffemodel</sub>  -iterations 100
```
</p>

<p>
## 准备数据
</p>

<p>
cifar10 数据训练样本50000张，测试样本10000张，每张为32*32的彩色三通道图片，共分为10类。
下载数据：
</p>

<p>
```bash
sh data/cifar10/get<sub>cifar10.sh</sub>
```
</p>

<p>
运行成功后，会在 `data/cifar10/` 文件夹下生成一堆 bin 文件
转换数据格式为 lmdb：
</p>

<p>
```bash
sh examples/cifar10/create<sub>cifar10.sh</sub>
```
</p>

<p>
注意：这些命令必须在caffe 主目录下执行，否则会报错
转换成功后，会在 `examples/cifar10/` 文件夹下生成两个文件夹，`cifar10<sub>train</sub><sub>lmdb</sub>` 和 `cifar10<sub>test</sub><sub>lmdb</sub>` 里面的文件就是我们需要的文件。
</p>

<p>
为了节省时间，我们进行快速训练 (train<sub>quick</sub>)，训练分为两个阶段，第一个阶段（迭代4000次）调用配置文件 `cifar10<sub>quick</sub><sub>solver.prototxt</sub>`, 学习率 (base<sub>lr</sub>) 为0.001。第二阶段（迭代1000次）调用配置文件 `cifar10<sub>quick</sub><sub>solver</sub><sub>lr1.prototxt</sub>`, 学习率 (base<sub>lr</sub>) 为0.0001。
</p>

<p>
前后两个配置文件就是学习率 (base<sub>lr</sub>) 和最大迭代次数 (max<sub>iter</sub>) 不一样，其它都是一样。如果你对配置文件比较熟悉以后，实际上是可以将两个配置文件合二为一的，设置 `lr<sub>policy</sub> 为 multistep` 就可以了。
</p>

<p>
```bash
base<sub>lr</sub>: 0.001
momentum: 0.9
weight<sub>decay</sub>: 0.004
lr<sub>policy</sub>: "multistep"
gamma: 0.1
stepvalue: 4000
stepvalue: 5000
```
</p>

<p>
运行例子：
</p>

<p>
```bash
sh examples/cifar10/train<sub>quick.sh</sub>
```
</p>

<p>
```bash
net: "examples/mnist/lenet<sub>train</sub><sub>test.prototxt</sub>"  
test<sub>iter</sub>: 100  
test<sub>interval</sub>: 500  
base<sub>lr</sub>: 0.01  
momentum: 0.9  
type: SGD  
weight<sub>decay</sub>: 0.0005  
lr<sub>policy</sub>: "inv"  
gamma: 0.0001  
power: 0.75  
display: 100  
max<sub>iter</sub>: 20000  
snapshot: 5000  
snapshot<sub>prefix</sub>: "examples/mnist/lenet"  
solver<sub>mode</sub>: CPU  
```
</p>

<p>
```bash
net: "examples/mnist/lenet<sub>train</sub><sub>test.prototxt</sub>" 
```
</p>

<p>
设置网络模型。每一个模型就是一个net，需要在一个专门的配置文件中对net进行配置，每个net由许多的layer所组成。
需要注意的是：文件的路径要从caffe的根目录开始，其它的所有配置都是这样。
</p>

<p>
```bash
test<sub>iter</sub>: 100
```
</p>

<p>
测试集迭代次数。
这个要与`test layer`中的`batch<sub>size</sub>`结合起来理解。mnist数据中测试样本总数为10000，一次性执行全部数据效率很低，因此我们将测试数据分成几个批次来执行，每个批次的数量就是`batch<sub>size</sub>`。假设我们设置`batch<sub>size</sub>`为100，则需要迭代100次才能将10000个数据全部执行完。因此`test<sub>iter</sub>`设置为100。执行完一次全部数据，称之为一个`epoch`。
</p>

<p>
```bash
test<sub>interval</sub>: 500
```
</p>

<p>
测试间隔。也就是每训练500次，才进行一次测试。
</p>

<p>
```bash
base<sub>lr</sub>: 0.01  
lr<sub>policy</sub>: "inv"  
gamma: 0.0001  
power: 0.75  
```
</p>

<p>
这四行可以放在一起理解，用于学习率的设置。只要是梯度下降法来求解优化，都会有一个学习率，也叫步长。
`base<sub>lr</sub>`用于设置基础学习率
`lr<sub>policy</sub>`设置学习率的调整策略。
`lr<sub>policy</sub>`可以设置为下面这些值，相应的学习率的计算为：
</p>

<ul class="org-ul">
<li>fixed:　　 保持base<sub>lr不变</sub>.</li>
<li>step: 　　 如果设置为step,则还需要设置一个stepsize, 返回 base<sub>lr</sub> * gamma ^ (floor(iter / stepsize)),其中iter表示当前的迭代次数</li>
<li>exp: 　　返回base<sub>lr</sub> * gamma ^ iter， iter为当前迭代次数</li>
<li>inv:　　 如果设置为inv,还需要设置一个power, 返回base<sub>lr</sub> * (1 + gamma * iter) ^ (- power)</li>
<li>multistep: 如果设置为multistep,则还需要设置一个stepvalue。这个参数和step很相似，step是均匀等间隔变化，而multistep则是根据 stepvalue值变化</li>
<li>poly: 　　 学习率进行多项式误差, 返回 base<sub>lr</sub> (1 - iter/max<sub>iter</sub>) ^ (power)</li>
<li>sigmoid:　学习率进行sigmod衰减，返回 base<sub>lr</sub> ( 1/(1 + exp(-gamma * (iter - stepsize))))</li>
</ul>

<p>
multistep示例：
</p>

<p>
```bash
base<sub>lr</sub>: 0.01  
momentum: 0.9  
weight<sub>decay</sub>: 0.0005  
</p>

<p>
lr<sub>policy</sub>: "multistep"  
gamma: 0.9  
stepvalue: 5000  
stepvalue: 7000  
stepvalue: 8000  
stepvalue: 9000  
stepvalue: 9500  
```
</p>

<p>
接下来的参数：
</p>

<p>
```bash
momentum ：0.9  
```
</p>

<p>
指上一次梯度更新的权重
</p>

<p>
```bash
type: SGD  
```
</p>

<p>
优化算法选择。这一行可以省掉，因为默认值就是SGD。
caffe提供了六种优化算法来求解最优参数，在solver配置文件中，通过设置`type`类型来选择
</p>

<ul class="org-ul">
<li>Stochastic Gradient Descent (type:”SGD”),</li>
<li>AdaDelta (type:”AdaDelta”),</li>
<li>Adaptive Gradient (type:”AdaGrad”),</li>
<li>Adam (type: “Adam”),</li>
<li>Nesterov’s Accelerated Gradient (type: “Nesterov”) and</li>
<li>RMSprop (type:”RMSProp”)</li>
</ul>

<p>
```bash
weight<sub>decay</sub>: 0.0005  
```
</p>

<p>
权重衰减项，防止过拟合的一个参数。
</p>

<p>
```bash
display: 100  
```
</p>

<p>
每训练100次，在屏幕上显示一次。如果设置为0，则不显示。
</p>

<p>
```bash
max<sub>iter</sub>: 20000 
```
</p>

<p>
最大迭代次数。这个数设置太小，会导致没有收敛，精确度很低。设置太大，会导致震荡，浪费时间
</p>

<p>
```bash
snapshot: 5000  
snapshot<sub>prefix</sub>: "examples/mnist/lenet"  
```
</p>

<p>
快照。将训练出来的model和solver状态进行保存，`snapshot`用于设置训练多少次后进行保存，默认为0，不保存。
`snapshot<sub>prefix</sub>`设置保存路径。
还可以设置`snapshot<sub>diff</sub>`，是否保存梯度值，默认为`false`,不保存。
也可以设置`snapshot<sub>format</sub>`，保存的类型。有两种选择：`HDF5` 和`BINARYPROTO` ，默认为`BINARYPROTO`
</p>

<p>
```bash
solver<sub>mode</sub>: CPU  
```
</p>

<p>
设置运行模式。默认为GPU,如果你没有GPU,则需要改成CPU,否则会出错。
</p>

<p>
注意：以上的所有参数都是可选参数，都有默认值。根据solver方法（type)的不同，还有一些其它的参数，在此不一一列举。
</p>

<p>
Caffe的 C++ 主程序（caffe.cpp) 放在根目录下的 tools 文件夹内, 当然还有一些其它的功能文件，如：`convert<sub>imageset.cpp</sub>`, `train<sub>net.cpp</sub>`, `test<sub>net.cpp</sub>` 等也放在这个文件夹内。经过编译后，这些文件都被编译成了可执行文件，放在了 `./build/tools/` 文件夹内。因此我们要执行caffe程序，都需要加 `./build/tools/` 前缀。
如：`sh ./build/tools/caffe train &#x2013;solver=examples/mnist/train<sub>lenet.sh</sub>`
</p>

<p>
## Caffe 程序的命令行执行格式
</p>

<p>
### 命令格式
</p>

<p>
```bash
caffe &lt;command&gt; &lt;args&gt;
```
</p>

<p>
![在这里插入图片描述](<a href="https://img-blog.csdnimg.cn/20191224160503182.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxMTIwNjMzMjY5,size_16,color_FFFFFF,t_70">https://img-blog.csdnimg.cn/20191224160503182.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxMTIwNjMzMjY5,size_16,color_FFFFFF,t_70</a>)
![在这里插入图片描述](<a href="https://img-blog.csdnimg.cn/20191224160343273.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxMTIwNjMzMjY5,size_16,color_FFFFFF,t_70">https://img-blog.csdnimg.cn/20191224160343273.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxMTIwNjMzMjY5,size_16,color_FFFFFF,t_70</a>)
</p>


<p>
### 操作例子
</p>

<ol class="org-ol">
<li>-solver：一个 protocol buffer 类型的文件，即模型的配置文件。
`./build/tools/caffe train -solver examples/mnist/lenet<sub>solver.prototxt</sub>`</li>
<li>-gpu: 该参数用来指定用哪一块 GPU 运行，根据 GPU 的 ID 进行选择，如果设置为 -gpu all 则使用所有的 GPU 运行。如使用第二块 GPU 运行：`./build/tools/caffe train -solver examples/mnist/lenet<sub>solver.prototxt</sub> -gpu 1`</li>
<li>-snapshot: 该参数用来从快照 (snapshot)中恢复训练。可以在 solver 配置文件设置快照，保存 solverstate。如：`./build/tools/caffe train -solver examples/mnist/lenet<sub>solver.prototxt</sub> -snapshot examples/mnist/lenet<sub>iter</sub><sub>5000.solverstate</sub>`</li>
<li>-weights: 用预先训练好的权重来 fine-tuning 模型，需要一个 caffemodel，不能和 -snapshot 同时使用。如：`./build/tools/caffe train -solver examples/finetuning<sub>on</sub><sub>flickr</sub><sub>style</sub>/solver.prototxt -weights models/bvlc<sub>reference</sub><sub>caffenet</sub>/bvlc<sub>reference</sub><sub>caffenet.caffemodel</sub>`</li>
<li>-iterations: 指定迭代次数，默认为50。如果在配置文件文件中没有设定迭代次数，则默认迭代50次。</li>
<li>-model: 指定 protocol buffer 文件中的模型。也可以在 solver 配置文件中指定。</li>
<li>-sighup<sub>effect</sub>：用来设定当程序发生挂起事件时，执行的操作，可以设置为 snapshot, stop 或 none, 默认为 snapshot</li>
<li>-sigint<sub>effect</sub>: 用来设定当程序发生键盘中止事件时 (Ctrl + C), 执行的操作，可以设置为 snapshot, stop 或 none, 默认为 stop</li>
</ol>

<p>
刚才举例了一些 `train` 参数的例子，现在我们来看看其它三个`&lt;command&gt;`：
</p>

<ol class="org-ol">
<li>test
`test` 参数用在测试阶段，用于最终结果的输出，要模型配置文件中我们可以设定需要输入 accuracy 还是 loss. 假设我们要在验证集中验证已经训练好的模型，就可以这样写</li>
</ol>

<p>
```bash
./build/tools/caffe test -model examples/mnist/lenet<sub>train</sub><sub>test.prototxt</sub> -weights examples/mnist/lenet<sub>iter</sub><sub>10000.caffemodel</sub> -gpu 0 -iterations 100
```
</p>

<p>
这个例子比较长，不仅用到了 test 参数，还用到了-model, -weights, -gpu 和 -iterations 四个参数。意思是利用训练好了的权重 (-weight)，输入到测试模型中 (-model)，用编号为0的 gpu (-gpu) 测试100次 (-iteration)。
</p>

<ol class="org-ol">
<li>time
time 参数用来在屏幕上显示程序运行时间。如</li>
</ol>

<p>
```bash
./build/tools/caffe time -model examples/mnist/lenet<sub>train</sub><sub>test.prototxt</sub> -iterations 10
#这个例子用来在屏幕上显示 lenet 模型迭代10次所使用的时间。包括每次迭代的 forward 和 backward 所用的时间，也包括每层 forward 和 backward 所用的平均时间。
</p>

<p>
./build/tools/caffe time -model examples/mnist/lenet<sub>train</sub><sub>test.prototxt</sub> -gpu 0
#这个例子用来在屏幕上显示 lenet 模型用 gpu 迭代50次所使用的时间。
</p>

<p>
./build/tools/caffe time -model examples/mnist/lenet<sub>train</sub><sub>test.prototxt</sub> -weights examples/mnist/lenet<sub>iter</sub><sub>10000.caffemodel</sub> -gpu 0 -iterations 10
#利用给定的权重，利用第一块 gpu，迭代10次 lenet 模型所用的时间。
```
</p>

<ol class="org-ol">
<li>device<sub>query</sub> 
device<sub>query</sub> 参数用来诊断 gpu 信息。</li>
</ol>

<p>
```bash
./build/tools/caffe device<sub>query</sub> -gpu 0
```
</p>

<ol class="org-ol">
<li>关于GPU的例子</li>
</ol>

<p>
```bash
./build/tools/caffe train -solver examples/mnist/lenet<sub>solver.prototxt</sub> -gpu 0,1
./build/tools/caffe train -solver examples/mnist/lenet<sub>solver.prototxt</sub> -gpu all
```
</p>

<p>
这两个例子表示： 用两块或多块 GPU 来平行运算，这样速度会快很多。但是如果你只有一块或没有 GPU, 就不要加 -gpu 参数了，加了反而慢。
最后，在 linux 下，本身就有一个 time 命令，因此可以结合进来使用，因此我们运行mnist例子的最终命令是(一块 gpu )：
</p>

<p>
```bash
time ./build/toos/caffe train -solver examples/mnist/lenet<sub>solver.prototxt</sub>
```
</p>

<p>
在 Caffe 中，作者为我们提供了这样一个文件：`convert<sub>imageset.cpp</sub>`，存放在根目录下的 `tools` 文件夹下。编译之后，生成对应的可执行文件放在 `buile/tools/` 下面，这个文件的作用就是用于将图片文件转换成 Caffe 框架中能直接使用的 db 文件。
</p>

<p>
```bash
convert<sub>imageset</sub> [FLAGS] ROOTFOLDER/ LISTFILE DB<sub>NAME</sub>
```
</p>

<p>
需要带四个参数：
</p>

<ul class="org-ul">
<li>FLAGS: 图片参数组</li>
<li>ROOTFOLDER/: 图片存放的绝对路径，从 linux 系统根目录开始</li>
<li>LISTFILE: 图片文件列表清单，一般为一个 txt 文件，一行一张图片</li>
<li>DB<sub>NAME</sub>: 最终生成的 db 文件存放目录
如果图片已经下载到本地电脑上了，那么我们首先需要创建一个图片列表清单，保存为 txt。本文以 Caffe 程序中自带的图片为例，进行讲解，图片目录是 `example/images/`, 两张图片，一张为 `cat.jpg`, 另一张为 `fish<sub>bike.jpg</sub>`，表示两个类别。</li>
</ul>

<p>
我们创建一个 sh 脚本文件，调用 linux 命令来生成图片清单： 
</p>

<p>
```bash
vim examples/images/create<sub>filelist.sh</sub>
```
</p>

<p>
编辑这个文件,输入下面的代码并保存
</p>

<p>
```bash
</p>

<p>
DATA=examples/images
echo "Create train.txt&#x2026;"
rm -rf $DATA/train.txt
find $DATA -name *cat.jpg | cut -d '<i>' -f3 | sed "s/$</i> 1/" &gt;&gt; $DATA/train.txt
find $DATA -name *bike.jpg | cut -d '<i>' -f3 | sed "s/$</i> 2/" &gt;&gt; $DATA/tmp.txt
cat $DATA/tmp.txt &gt;&gt; $DATA/train.txt
rm -rf $DATA/tmp.txt
echo "Done.."
```
</p>

<p>
这个脚本文件中，用到了 `rm, find, cut, sed, cat`等 linux 命令。
</p>

<ul class="org-ul">
<li>rm: 删除文件</li>
<li>find: 寻找文件</li>
<li>cut: 截取路径</li>
<li>sed: 在每行的最后面加上标注。本例中将找到的 *cat.jpg 文件加入标注为1，找到的 *bike.jpg 文件加入标注为2</li>
<li>cat: 将两个类别合并在一个文件里。</li>
</ul>

<p>
最终生成如下的一个 train.txt 文件：
</p>

<p>
```bash
cat.jpg 1
fish-bike.jpg 2
```
</p>

<p>
当然，图片很少的时候，手动编写这个列表清单文件就行了。但图片很多的情况，就需要用脚本文件来自动生成了。在以后的实际应用中，还需要生成相应的 `val.txt` 和 `test.txt` 文件，方法是一样的。生成的这个 `train.txt` 文件，就可以作为第三个参数，直接使用了。
接下来，我们来了解一下 `FLAGS` 这个参数组，有些什么内容：
</p>

<ul class="org-ul">
<li>-gray: 是否以灰度图的方式打开图片。程序调用 opencv 库中的 imread() 函数来打开图片，默认为 false</li>
<li>-shuffle: 是否随机打乱图片顺序。默认为 false</li>
<li>-backend: 需要转换成的 db 文件格式，可选为 leveldb 或 lmdb,默认为 lmdb</li>
<li>-resize<sub>width</sub>/resize<sub>height</sub>: 改变图片的大小。在运行中，要求所有图片的尺寸一致，因此需要改变图片大小。 程序调用 opencv 库的 resize() 函数来对图片放大缩小，默认为0，不改变</li>
<li>-check<sub>size</sub>: 检查所有的数据是否有相同的尺寸。默认为 false, 不检查</li>
<li>-encoded: 是否将原图片编码放入最终的数据中，默认为false</li>
<li>-encode<sub>type</sub>: 与前一个参数对应，将图片编码为哪一个格式：‘png’, ‘jpg’……</li>
</ul>

<p>
知道这些参数后，我们就可以调用命令来生成最终的 lmdb 格式数据了。由于参数比较多，因此我们可以编写一个 sh 脚本来执行命令：
首先，创建 sh 脚本文件：
</p>

<p>
```bash
vim examples/images/create<sub>lmdb.sh</sub>
```
</p>

<p>
编辑，输入下面的代码并保存
</p>

<p>
```bash
#!/usr/bin/en sh
DATA=examples/images
rm -rf $DATA/img<sub>train</sub><sub>lmdb</sub>
build/tools/convert<sub>imageset</sub> &#x2013;shuffle \
&#x2013;resize<sub>height</sub>=256 &#x2013;resize<sub>width</sub>=256 \
$CAFFE<sub>ROOT</sub>/examples/images/ $DATA/train.txt  $DATA/img<sub>train</sub><sub>lmdb</sub>
```
</p>

<p>
设置参数 `-shuffle`,打乱图片顺序。设置参数 `-resize<sub>height</sub>`和 `-resize<sub>width</sub>`将所有图片尺寸都变为256*256。`$CAFFE<sub>ROOT</sub>/examples/images/` 为图片保存的绝对路径（$CAFFE<sub>ROOT</sub> 是 Caffe 工程的根目录）。
最后，运行这个脚本文件
</p>

<p>
```bash
sh examples/images/create<sub>lmdb.sh</sub>
```
</p>

<p>
就会在 `examples/images/` 目录下生成一个名为 `img<sub>train</sub><sub>lmdb</sub>` 的文件夹，里面的文件就是我们需要的 db 文件了。
</p>

<p>
Caffe 程序是由 C++ 语言写的，本身是不带数据可视化功能的。只能借助其它的库或接口，如 opencv, python 或 matlab。大部分人使用 python 接口来进行可视化，因为 python 出了个比较强大的东西：`ipython notebook`, 现在的最新版本改名叫 `jupyter notebook`，它能将python代码搬到浏览器上去执行，以富文本方式显示，使得整个工作可以以笔记的形式展现、存储，对于交互编程、学习非常方便。
</p>

<p>
图片减去均值后，再进行训练和测试，会提高速度和精度。因此，一般在各种模型中都会有这个操作。这个均值实际上就是计算所有训练样本的平均值，计算出来后，保存为一个均值文件，在以后的测试中，就可以直接使用这个均值来相减，而不需要对测试图片重新计算。
</p>

<p>
## 1、二进制格式的均值计算
</p>

<p>
Caffe 中使用的均值数据格式是 `binaryproto`, 作者为我们提供了一个计算均值的文件 `compute<sub>image</sub><sub>mean.cpp</sub>`，放在 Caffe 根目录下的 `tools` 文件夹里面。编译后的可执行体放在 `build/tools/` 下面，我们直接调用就可以了。
</p>

<p>
```bash
./build/tools/compute<sub>image</sub><sub>mean</sub> examples/mnist/mnist<sub>train</sub><sub>lmdb</sub> examples/mnist/mean.binaryproto
```
</p>

<p>
参数解释：
</p>

<ul class="org-ul">
<li>第一个参数：examples/mnist/mnist<sub>train</sub><sub>lmdb</sub>， 表示需要计算均值的数据，格式为lmdb的训练数据。</li>
<li>第二个参数：examples/mnist/mean.binaryproto，计算出来的结果保存文件。</li>
</ul>

<p>
## 2、python 格式的均值计算
</p>

<p>
如果我们要使用 python 接口，或者我们要进行特征可视化，可能就要用到 python 格式的均值文件了。首先，我们用 lmdb 格式的数据，计算出二进制格式的均值，然后，再转换成 python 格式的均值。
我们可以编写一个 python 脚本来实现：
</p>

<p>
```python
#!/usr/bin/env python
import numpy as np
import sys,caffe
if len(sys.argv)!=3:
    print "Usage: python convert<sub>mean.py</sub> mean.binaryproto mean.npy"
    sys.exit()
blob = caffe.proto.caffe<sub>pb2.BlobProto</sub>()
bin<sub>mean</sub> = open( sys.argv[1] , 'rb' ).read()
blob.ParseFromString(bin<sub>mean</sub>)
arr = np.array( caffe.io.blobproto<sub>to</sub><sub>array</sub>(blob) )
npy<sub>mean</sub> = arr[0]
np.save( sys.argv[2] , npy<sub>mean</sub> )
```
</p>

<p>
将这个脚本保存为 convert<sub>mean.py</sub>。调用格式为：
</p>

<p>
```bash
python convert<sub>mean.py</sub> mean.binaryproto mean.npy
```
</p>

<p>
其中的 `mean.binaryproto` 就是经过前面步骤计算出来的二进制均值。`mean.npy` 就是我们需要的python格式的均值。
</p>

<p>
通过前面的学习，我们已经能够正常训练各种数据了。设置好 `solver.prototxt` 后，我们可以把训练好的模型保存起来，如 `lenet<sub>iter</sub><sub>10000.caffemodel</sub>`。训练多少次就自动保存一下，这个是通过 `snapshot` 进行设置的，保存文件的路径及文件名前缀是由 `snapshot<sub>prefix</sub>` 来设定的。
  `*.caffemodel` 文件里面存放的就是各层的参数，即 `net.params`，里面没有数据 `net.blobs`。
  顺带还生成了一个相应的 `*.solverstate` 文件，这个和 `*.caffemodel` 差不多，但它多了一些数据，如模型名称、当前迭代次数等。两者的功能不一样，训练完后保存起来的 `*.caffemodel`，是在测试阶段用来分类的，而 `.*solverstate` 是用来恢复训练的，防止意外终止而保存的快照。
</p>

<p>
  既然我们知道了 `*.caffemodel` 里面保存的就是模型各层的参数，因此我们可以把这些参数提取出来，进行可视化，看一看究竟长什么样。
  参数有两种类型：权值参数和偏置项，分别用 params["conv1"][0] 和 params["conv1"][1] 表示。
</p>

<p>
## 1、绘制网络模型
</p>

<p>
  `python/draw<sub>net.py</sub>` 这个文件，就是用来绘制网络模型的，也就是将网络模型由 prototxt 变成一张图片。
draw<sub>net.py</sub> 执行的时候带三个参数
</p>

<ul class="org-ul">
<li>第一个参数：网络模型的 prototxt 文件</li>
<li>第二个参数：保存的图片路径及名字</li>
<li>第二个参数：–rankdir=x , x 有四种选项，分别是 LR, RL, TB, BT 。用来表示网络的方向，分别是从左到右，从右到左，从上到小，从下到上。默认为LＲ。</li>
</ul>

<p>
## 2、绘制 loss 和 accuracy 曲线
</p>

<p>
[绘制 loss 和 accuracy 曲线](<a href="http://blog.leanote.com/post/braveapple/Caffe-%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7">http://blog.leanote.com/post/braveapple/Caffe-使用技巧</a>)
</p>

<ol class="org-ol">
<li>下载caffemodel文件
可以手动下载，也可以使用脚本下载</li>
</ol>

<p>
```bash
./scripts/download<sub>model</sub><sub>binary.py</sub> models/bvlc<sub>reference</sub><sub>caffenet</sub>
```
</p>

<ol class="org-ol">
<li>下载均值文件
有了 caffemodel 文件，就需要对应的均值文件，在测试阶段，需要把测试数据减去均值。这个文件我们用脚本来下载，在 caffe 根目录下执行：</li>
</ol>

<p>
```bash
sh ./data/ilsvrc12/get<sub>ilsvrc</sub><sub>aux.sh</sub>
```
</p>

<p>
执行并下载后，均值文件放在 data/ilsvrc12/ 文件夹里。
</p>

<ol class="org-ol">
<li>synset<sub>words.txt</sub> 文件
在调用脚本文件下载均值的时候，这个文件也一并下载好了。里面放的是1000个类的名称。数据准备好了，我们就可以开始分类了。这里提供两个版本的分类方法：
3.1 C++ 方法
在 Caffe 根目录下的 `examples/cpp-classification/` 文件夹下面，有个 `classification.cpp`文件，就是用来分类的。当然编译后，放在 `/build/examples/cpp<sub>classification</sub>/` 下面。</li>
</ol>

<p>
  我们就直接运行命令：
</p>


<p>
```bash
./build/examples/cpp<sub>classification</sub>/classification.bin \
  models/bvlc<sub>reference</sub><sub>caffenet</sub>/deploy.prototxt \
  models/bvlc<sub>reference</sub><sub>caffenet</sub>/bvlc<sub>reference</sub><sub>caffenet.caffemodel</sub> \
  data/ilsvrc12/imagenet<sub>mean.binaryproto</sub> \
  data/ilsvrc12/synset<sub>words.txt</sub> \
  examples/images/cat.jpg
```
</p>

<p>
命令很长，用了很多的 \ 符号来换行。可以看出，从第二行开始就是参数，每行一个，共需要4个参数运行成功后，输出 top-5 结果：
</p>

<p>
```bash
-----&#x2013;&#x2014; Prediction for examples/images/cat.jpg -----&#x2013;&#x2014;
0.3134 - "n02123045 tabby, tabby cat"
0.2380 - "n02123159 tiger cat"
0.1235 - "n02124075 Egyptian cat"
0.1003 - "n02119022 red fox, Vulpes vulpes"
0.0715 - "n02127052 lynx, catamount"
```
</p>

<p>
即有0.3134的概率为 `tabby cat`, 有0.2380的概率为 `tiger cat`。
3.2、python 方法
python 接口可以使用 jupyter notebook 来进行可视化操作，因此推荐使用这种方法。编写一个 py 文件，命名为 py-classify.py
</p>

<p>
```python
#coding=utf-8
#加载必要的库
import numpy as np
import sys,os
#设置当前目录
caffe<sub>root</sub> = '<i>home/xxx/caffe</i>' 
sys.path.insert(0, caffe<sub>root</sub> + 'python')
import caffe
os.chdir(caffe<sub>root</sub>)
net<sub>file</sub>=caffe<sub>root</sub> + 'models/bvlc<sub>reference</sub><sub>caffenet</sub>/deploy.prototxt'
caffe<sub>model</sub>=caffe<sub>root</sub> + 'models/bvlc<sub>reference</sub><sub>caffenet</sub>/bvlc<sub>reference</sub><sub>caffenet.caffemodel</sub>'
mean<sub>file</sub>=caffe<sub>root</sub> + 'python/caffe/imagenet/ilsvrc<sub>2012</sub><sub>mean.npy</sub>'
net = caffe.Net(net<sub>file,caffe</sub><sub>model,caffe.TEST</sub>)
transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})
transformer.set<sub>transpose</sub>('data', (2,0,1))
transformer.set<sub>mean</sub>('data', np.load(mean<sub>file</sub>).mean(1).mean(1))
transformer.set<sub>raw</sub><sub>scale</sub>('data', 255) 
transformer.set<sub>channel</sub><sub>swap</sub>('data', (2,1,0))
im=caffe.io.load<sub>image</sub>(caffe<sub>root</sub>+'examples/images/cat.jpg')
net.blobs['data'].data[&#x2026;] = transformer.preprocess('data',im)
out = net.forward()
imagenet<sub>labels</sub><sub>filename</sub> = caffe<sub>root</sub> + 'data/ilsvrc12/synset<sub>words.txt</sub>'
labels = np.loadtxt(imagenet<sub>labels</sub><sub>filename</sub>, str, delimiter='\t')
top<sub>k</sub> = net.blobs['prob'].data[0].flatten().argsort()[-1:-6:-1]
for i in np.arange(top<sub>k.size</sub>):
    print top<sub>k</sub>[i], labels[top<sub>k</sub>[i]]
```
</p>

<p>
执行这个文件，输出：
</p>

<p>
```bash
281 n02123045 tabby, tabby cat
282 n02123159 tiger cat
285 n02124075 Egyptian cat
277 n02119022 red fox, Vulpes vulpes
287 n02127052 lynx, catamount
```
</p>

<p>
 Caffe开发团队实际上也编写了一个 python 版本的分类文件，路径为 `python/classify.py`。运行这个文件必需两个参数，一个输入图片文件，一个输出结果文件。而且运行必须在 `python` 目录下。假设当前目录是 caffe 根目录，则运行：
 
</p>

<p>
```bash
cd python
python classify.py ../examples/images/cat.jpg result.npy
```
</p>

<p>
分类的结果保存为当前目录下的 `result.npy`文件里面，是看不见的。而且这个文件有错误，运行的时候，会提示 `Mean shape incompatible with input shape`的错误。因此，要使用这个文件，我们还得进行修改：
</p>

<ul class="org-ul">
<li>修改均值计算：
定位到</li>
</ul>

<p>
```bash
mean = np.load(args.mean<sub>file</sub>)
```
</p>

<p>
这一行，在下面加上一行：
</p>

<p>
```bash
mean=mean.mean(1).mean(1)
```
</p>

<p>
则可以解决报错的问题。
</p>

<ul class="org-ul">
<li>修改文件，使得结果显示在命令行下：
定位到</li>
</ul>

<p>
```python
</p>

<p>
    start = time.time()
    predictions = classifier.predict(inputs, not args.center<sub>only</sub>)
    print("Done in %.2f s." % (time.time() - start))
```
</p>

<p>
这个地方，在后面加上几行，如下所示：
</p>

<p>
```python
</p>

<p>
    start = time.time()
    predictions = classifier.predict(inputs, not args.center<sub>only</sub>)
    print("Done in %.2f s." % (time.time() - start))
    imagenet<sub>labels</sub><sub>filename</sub> = '../data/ilsvrc12/synset<sub>words.txt</sub>'
    labels = np.loadtxt(imagenet<sub>labels</sub><sub>filename</sub>, str, delimiter='\t')
    top<sub>k</sub> = predictions.flatten().argsort()[-1:-6:-1]
    for i in np.arange(top<sub>k.size</sub>):
        print top<sub>k</sub>[i], labels[top<sub>k</sub>[i]]
```
</p>

<p>
就样就可以了。运行不会报错，而且结果会显示在命令行下面。
</p>

<p>
我们把最后一层的输出类别改一下，然后把层的名称改一下,最后用别人的参数、修改后的 network 和我们自己的数据，再进行训练，使得参数适应我们的数据，这样一个过程，通常称之为微调 (fine tuning)
</p>

<ol class="org-ol">
<li>下载`.caffemodel`文件</li>
<li>准备数据</li>
</ol>

<p>
&gt; 这些数据共有500张图片，分为大巴车、恐龙、大象、鲜花和马五个类，每个类100张。编号分别以0,1,2,3,4开头，各为一类。我从其中每类选出20张作为测试，其余80张作为训练。因此最终训练图片400张（放在 train 文件夹内，每个类一个子文件夹），测试图片100张（放在 test 文件夹内，每个类一个子文件夹）。
</p>

<p>
caffenet的网络配置文件，放在 caffe/models/bvlc<sub>reference</sub><sub>caffenet</sub>/ 这个文件夹里面，名字叫 train<sub>val.prototxt</sub>。
</p>

<p>
修改 train 阶段的 data 层为：
</p>

<p>
```c
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform<sub>param</sub> {
    mean<sub>file</sub>: "examples/finetune/mean.binaryproto"
    mirror: true
    crop<sub>size</sub>: 227
  }
  data<sub>param</sub> {
    source: "examples/finetune/finetune<sub>train</sub><sub>lmdb</sub>"
    batch<sub>size</sub>: 100
    backend: LMDB
  }
}
```
</p>

<p>
把均值文件（mean<sub>file</sub>)、数据源文件 (source)、批次大小 (batch<sub>size</sub>)和数据源格式 (backend) 这四项作相应的修改。
修改 test 阶段的 data 层：
</p>

<p>
```c
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform<sub>param</sub> {
    mean<sub>file</sub>: "examples/finetune/mean.binaryproto"
    mirror: false
    crop<sub>size</sub>: 227
  }
   data<sub>param</sub> {
    source: "examples/finetune/finetune<sub>test</sub><sub>lmdb</sub>"
    batch<sub>size</sub>: 100
    backend: LMDB
  }
}
```
</p>

<p>
修改最后一个全连接层 (fc8)：
</p>

<p>
```c
layer {
  name: "fc8-my"               #原来为"fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr<sub>mult</sub>: 1.0
    decay<sub>mult</sub>: 1.0
  }
  param {
    lr<sub>mult</sub>: 2.0
    decay<sub>mult</sub>: 0.0
  }
  inner<sub>product</sub><sub>param</sub> {
    num<sub>output</sub>: 5        #原来为"1000"
    weight<sub>filler</sub> {
      type: "gaussian"
      std: 0.01
    }
    bias<sub>filler</sub> {
      type: "constant"
      value: 0.0
    }
  }
}
```
</p>

<p>
看注释的地方，就只有两个地方修改，其它不变。设置好后，就可以开始微调了(fine tuning)。训练结果就是一个新的 model，可以用来单张图片和多张图片测试。
</p>

<p>
[Caffe 使用教程](<a href="http://blog.leanote.com/post/braveapple/Caffe-%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7">http://blog.leanote.com/post/braveapple/Caffe-使用技巧</a>)
[caffe学习系列：训练自己的图片集](<a href="https://blog.csdn.net/qq_27923041/article/details/54139887">https://blog.csdn.net/qq_27923041/article/details/54139887</a>)
[caffe 有关prototxt文件的设置解读](<a href="https://blog.csdn.net/greenlight_74110/article/details/78640916">https://blog.csdn.net/greenlight_74110/article/details/78640916</a>)
</p>

<p>
我用的模型是[deploy<sub>resnet10</sub>-1x32d.prototxt](<a href="https://github.com/soeaver/caffe-model/tree/master/cls/resnet">https://github.com/soeaver/caffe-model/tree/master/cls/resnet</a>)
这个模型的输入数据格式为
</p>

<p>
```bash
input<sub>shape</sub> {
  dim: 1
  dim: 3
  dim: 224
  dim: 224
}
```
</p>

<p>
我用的数据集合是[这个](<a href="https://pan.baidu.com/s/1nuqlTnN">https://pan.baidu.com/s/1nuqlTnN</a>)
这个数据集有500张图片，分为大巴车、恐龙、大象、鲜花和马五个类，每个类100张。
编号分别以3，4，5，6，7开头，各为一类。我从其中每类选出20张作为测试，其余80张作为训练。因此最终训练图片400张，测试图片100张，共5类。
首先在examples下面创建一个myfile的文件夹，来用存放配置文件和脚本文件。
我将图片放在`/root/caffe/examples/myfile/re`下。即训练图片目录：`/root/caffe/examples/myfile/re/train/`，测试图片目录：`/root/caffe/examples/myfile/re/test/`
然后编写一个脚本create<sub>filelist.sh</sub>，用来生成train.txt和test.txt清单文件
编辑create<sub>filelist.sh文件</sub>，并写入如下代码，并保存
</p>

<p>
```bash
#!/usr/bin/env sh
DATA=/root/caffe/examples/myfile/re
MY=/root/caffe/examples/myfile
</p>

<p>
echo "Create train.txt&#x2026;"
rm -rf $MY/train.txt
for i in 3 4 5 6 7
do
j=`expr $i - 3`
find $DATA/train -name $i*.jpg | cut -d '<i>' -f7-8 | sed "s/$</i> $j/"&gt;&gt;$MY/train.txt
done
echo "Create test.txt&#x2026;"
rm -rf $MY/test.txt
for i in 3 4 5 6 7
do
j=`expr $i - 3`
find $DATA/test -name $i*.jpg | cut -d '<i>' -f7-8 | sed "s/$</i> $j/"&gt;&gt;$MY/test.txt
done
```
</p>

<p>
  然后，运行此脚本
在这个脚本里，我们通过查找替换功能，将train.txt文件和test.txt文件里面的图片编号依次由3,4,5，6,7改为0,1,2,3,4。之所以要改编号的原因是，编号从3~7会影响训练精度。修改完后，train.txt内容如下图所示
打开train.txt可以看到如下内容，同样test.txt文件里面的内容也是如此，二者仅数量不同。
![在这里插入图片描述](<img src="https://img-blog.csdnimg.cn/20191224203626639.png" alt="20191224203626639.png" />)
接着再编写一个脚本文件create<sub>lmdb.sh</sub>，调用convert<sub>imageset命令来转换数据格式</sub>
</p>

<p>
```bash
#!/usr/bin/en sh
My=/root/caffe/examples/myfile
echo "Create train lmdb.."
rm -rf $My/img<sub>train</sub><sub>lmdb</sub>
/root/caffe/build/tools/convert<sub>imageset</sub> &#x2013;shuffle \
&#x2013;resize<sub>height</sub>=256 &#x2013;resize<sub>width</sub>=256 \
$My/re/train/ $My/train.txt  $My/img<sub>train</sub><sub>lmdb</sub>
</p>

<p>
echo "Create test lmdb.."
rm -rf $My/img<sub>test</sub><sub>lmdb</sub>
/root/caffe/build/tools/convert<sub>imageset</sub> &#x2013;shuffle \
&#x2013;resize<sub>height</sub>=256 &#x2013;resize<sub>width</sub>=256 \
$My/re/test/ $My/test.txt  $My/img<sub>test</sub><sub>lmdb</sub>
</p>

<p>
echo "All Done"
```
</p>

<p>
代码中的shuffle为，打乱图片顺序。`/root/caffe/examples/myfile/re`为下载的图像数据保存的绝对路径。
执行该脚本即可。运行成功后，会在`examples/myfile`下面生成两个`img<sub>test</sub><sub>lmdb</sub>`和`img<sub>train</sub><sub>lmdb</sub>`，分别用于保存图片转换后的lmdb文件。
</p>

<p>
图片减去均值再训练，会提高训练速度和精度。因此，一般都会有这个操作。
caffe程序提供了一个计算均值的文件`compute<sub>image</sub><sub>mean.cpp</sub>`，我们直接使用就可以了。
</p>

<p>
```bash
/root/caffe/build/tools/compute<sub>image</sub><sub>mean</sub> /root/caffe/examples/myfile/img<sub>train</sub><sub>lmdb</sub> /root/caffe/examples/myfile/mean.binaryproto
```
</p>

<p>
第一个参数为上一步得到的`img<sub>train</sub><sub>lmdb</sub>`,第二个参数为转换后的文件保存位置。
</p>

<p>
这一步我失败了
</p>

<p>
创建模型并编写配置文件
配置文件`solver.prototxt`的内容为
</p>

<p>
```bash
net: "/root/caffe/examples/myfile/deploy<sub>resnet10</sub>-1x32d.prototxt"
test<sub>iter</sub>: 2
test<sub>interval</sub>: 50
base<sub>lr</sub>: 0.01
lr<sub>policy</sub>: "step"
gamma: 0.1
stepsize: 100
display: 20
max<sub>iter</sub>: 500
momentum: 0.9
weight<sub>decay</sub>: 0.0005
solver<sub>mode</sub>: GPU
```
</p>

<p>
100个测试数据，batch<sub>size为50</sub>，因此test<sub>iter设置为2</sub>，就能全覆盖了。在训练过程中，调整学习率，逐步变小。</p>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="date">Created: 2020-01-02 周四 14:46</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
