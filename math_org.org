#+title: My favorite math

#+latex_header: \usepackage[UTF8]{ctex}
#+latex_header: \usepackage{amsthm}
#+latex_header: \newtheorem{definition}{Definition}[section]
#+latex_header: \newtheorem{axiom}{å…¬ç†}[section]
#+latex_header: \newtheorem{theorem}{Theorem}[section]
#+latex_header: \usepackage{enumerate}

* å®åˆ†æ
** å…¬ç†
*** 0 æ˜¯ä¸€ä¸ªè‡ªç„¶æ•°.
\label{axiom1}
*** è‹¥n æ˜¯è‡ªç„¶æ•°, åˆ™n++ ä¹Ÿæ˜¯è‡ªç„¶æ•°.
\label{axiom2}
*** 0ä¸æ˜¯ä»»ä½•è‡ªç„¶æ•°çš„åç»§,å³å¯¹äºæ¯ä¸ªè‡ªç„¶æ•°n,éƒ½æœ‰ $n++ \ne 0$
\label{axiom3}
*** ä¸åŒçš„è‡ªç„¶æ•°å¿…å®šæœ‰ä¸åŒçš„åç»§è€…
\label{axiom4}
ä¹Ÿå°±æ˜¯è¯´,è‹¥n,mæ˜¯è‡ªç„¶æ•°ä¸”$n \ne m$,åˆ™$n++\ne m++$.ç­‰ä»·åœ°è¯´,è‹¥n++=m++,åˆ™å¿…æœ‰n=m.
*** æ•°å­¦å½’çº³åŸç†
\label{axiom5}
è®¾$P(n)$æ˜¯å…³äºè‡ªç„¶æ•°çš„ä¸€ä¸ªæ€§è´¨.å‡è®¾$P(0)$æ˜¯çœŸçš„,å¹¶ä¸”åªè¦$P(n)$ä¸ºçœŸå¯ä»¥æ¨å¯¼å‡º$P(n++)$ä¸ºçœŸ,é‚£ä¹ˆå¯¹äºæ¯ä¸ªè‡ªç„¶æ•°$n$,$P(n)$éƒ½æ˜¯çœŸçš„.

** å®šä¹‰
*** å®šä¹‰1æ˜¯æ•°0++,2æ•°æ•°(0++)++,3æ˜¯æ•°((0++)++)++,ç­‰ç­‰.

*** å­˜åœ¨ä¸€ä¸ªæ•°ç³»$N$,ç§°å…¶å…ƒç´ ä¸ºè‡ªç„¶æ•°,å…¬ç†\ref{axiom1} ~ \ref{axiom5} å¯¹æ­¤æ•°ç³»æˆç«‹.

*** è‡ªç„¶æ•°çš„åŠ æ³•
è®¾mæ˜¯è‡ªç„¶æ•°.æˆ‘ä»¬å®šä¹‰$0+m:=m$.ç°åœ¨å½’çº³å‡å®šå·²å®šä¹‰å¥½å¦‚ä½•ä½¿måŠ ä¸Šn,é‚£ä¹ˆæŠŠmåŠ äºn++å®šä¹‰ä¸º$(n++)+m:=(n+m)++$.

*** æ­£è‡ªç„¶æ•°
ä¸ªè‡ªç„¶æ•°å«åšæ­£çš„,å½“ä¸”ä»…å½“å®ƒä¸ç­‰äº0.

*** è‡ªç„¶æ•°çš„æ’åº
è®¾nå’Œmæ˜¯è‡ªç„¶æ•°.æˆ‘ä»¬è¯´nå¤§äºç­‰äºm,è®°ä½œ$n \geq m$æˆ–$m \leq n$,å½“ä¸”
  ä»…å½“å¯¹äºæŸè‡ªç„¶æ•°a,æˆç«‹n=m+a.æˆ‘ä»¬è¯´nä¸¥æ ¼å¤§äºm,è®°ä½œ$n>m$æˆ–$m<n$,å½“ä¸”ä»…å½“$n\geq m
  $å¹¶ä¸”$n \ne m$.

*** è‡ªç„¶æ•°çš„ä¹˜æ³•
è®¾mæ˜¯è‡ªç„¶æ•°.æˆ‘ä»¬å®šä¹‰$0 \times  m:=0$.è®¾å·²å®šä¹‰äº†å¦‚ä½•æŠŠnä¹˜åˆ°mä¸Š,é‚£ä¹ˆå½’çº³åœ°,æˆ‘ä»¬å®šä¹‰æŠŠn++ä¹˜åˆ°mä¸Šæ˜¯(n++) $ \times $ m:=(n $ \times $ m)+m.


** å®šç†

*** è®¾å¯¹äºæ¯ä¸ªè‡ªç„¶æ•°n,éƒ½æœ‰æŸä¸ªå‡½æ•° $f_n:N->N$ æŠŠè‡ªç„¶æ•°æ˜ æˆè‡ªç„¶æ•°.è®¾cæ˜¯ä¸€ä¸ªè‡ªç„¶æ•°,é‚£ä¹ˆå¯ä»¥å¯¹äºæ¯ä¸ªè‡ªç„¶æ•°næŒ‡å®šå”¯ä¸€ä¸€ä¸ªè‡ªç„¶æ•° $a_n$ ,ä½¿å¾— $a_0=c$ ä¸” $a_{n++}=f_n(a_n)$ .


***   å¯¹äºä»»ä½•è‡ªç„¶æ•°n,$n+0=n$.

***   å¯¹äºä»»ä½•è‡ªç„¶æ•°nå’Œm,$n+(m++)=(n+m)++$.

*** åŠ æ³•æ˜¯äº¤æ¢çš„
  å¯¹äºä»»ä½•è‡ªç„¶æ•°nå’Œm,n+m=m+n.


*** åŠ æ³•æ˜¯ç»“åˆçš„
å¯¹äºä»»ä½•è‡ªç„¶æ•°a,b,c,$(a+b)+c=a+(b+c)$.


*** æ¶ˆå»å¾‹
  è®¾a,b,cæ˜¯è‡ªç„¶æ•°,æ»¡è¶³a+b=a+c,æˆ‘ä»¬æœ‰b=c.


*** è‹¥aæ˜¯æ­£çš„è€Œbæ˜¯è‡ªç„¶æ•°,åˆ™a+bæ˜¯æ­£çš„.


*** å¦‚æœaå’Œbæ˜¯è‡ªç„¶æ•°,æ»¡è¶³a+b=0,é‚£ä¹ˆa=0ä¸”b=0.

*** è®¾aæ˜¯æ­£æ•°,é‚£ä¹ˆæ°å­˜åœ¨ä¸€ä¸ªè‡ªç„¶æ•°b,ä½¿å¾—b++=a.

*** è‡ªç„¶æ•°çš„åºçš„åŸºæœ¬æ€§è´¨
è®¾a,b,cæ˜¯è‡ªç„¶æ•°.é‚£ä¹ˆ
\begin{enumerate}[(a)]
\item (åºæ˜¯è‡ªåçš„)$a\geq a$
\item (åºæ˜¯ä¼ é€’çš„)è‹¥$a \geq b$ä¸”$b \geq c$,é‚£ä¹ˆ$a \geq c$.
\item (åºæ˜¯åå¯¹ç§°çš„)è‹¥$a \geq b$ä¸”$b \geq a$,é‚£ä¹ˆ$a \eq b$.
\item (åŠ æ³•ä¿åº)$a \geq b$å½“ä¸”ä»…å½“$a+c \geq b+c$
\item $a < b $å½“ä¸”ä»…å½“$a++ \leq b$
\item $a < b $å½“ä¸”ä»…å½“å¯¹äºæŸæ­£æ•°d,$b=a+d$
\end{enumerate}
\end{theorem}

*** è‡ªç„¶æ•°çš„åºçš„ä¸‰æ­§æ€§
è®¾aå’Œ
  bæ˜¯è‡ªç„¶æ•°,é‚£ä¹ˆä¸‹è¿°ä¸‰å‘½é¢˜ä¸­æ°æœ‰ä¸€ä¸ªæ˜¯çœŸçš„:
  $$a<b,a=b,a>b$$


*** å¼ºå½’çº³æ³•åŸç†
è®¾ $m_0$ æ˜¯ä¸€ä¸ªè‡ªç„¶æ•°,è€Œ $P(m)$ æ˜¯ä¸€ä¸ªä¾èµ–äºä»»æ„è‡ªç„¶æ•°mçš„æ€§è´¨.è®¾å¯¹äºæ¯
ä¸ª $m \geq m_0$ éƒ½æœ‰ä¸‹è¿°è•´å«å…³ç³»:å¦‚æœ $P(m^')$ å¯¹äºä¸€åˆ‡æ»¡è¶³ $m_0 \leq m^{'}  < m$ çš„è‡ªç„¶
æ•° $m^'$ éƒ½æˆç«‹,é‚£ä¹ˆ $P(m
)$ ä¹Ÿæˆç«‹(ç‰¹åˆ«åœ°,è¿™æ„å‘³ç€ $P(m_0)$ æˆç«‹,å› ä¸ºåœ¨ $m=m_0$ çš„æƒ…å†µä¸‹,å‡å®šçš„æ¡ä»¶ $P(m^')$ æ˜¯
ç©ºçš„),é‚£ä¹ˆ,æˆ‘ä»¬å¯ä»¥æ–­å®š $P(m)$ å¯¹äºä¸€åˆ‡è‡ªç„¶æ•° $m \geq m_0$ éƒ½æˆç«‹.

* å¾®ç§¯åˆ†
** å®šç†
*** integrate of $e^{-x^2}$}
å‚
è€ƒ
:[[https://math.stackexchange.com/questions/154968/is-there-really-no-way-to-integrate-e-x2][calculus - Is there really no way to integrate $e^{-x^2}$? - Mathematics Stack Exchange]]

Let $I=\int_{-\infty}^\infty e^{-x^2} dx$.

Then,

\begin{align}
I^2 &= \left(\int_{-\infty}^\infty e^{-x^2} dx\right) \times \left(\int_{-\infty}^{\infty} e^{-y^2}dy\right) \\
&=\int_{-\infty}^\infty\left(\int_{-\infty}^\infty e^{-(x^2+y^2)} dx\right)dy \\
\end{align}
Next we change to polar form: $dx\,dy=dA=r\,d\theta\,dr$.

Therefore
\begin{align}
I^2 &= \iint e^{-(r^2)}r\,d\theta\,dr \\
&=\int_0^{2\pi}\left(\int_0^\infty re^{-r^2}dr\right)d\theta \\
&=2\pi\int_0^\infty re^{-r^2}dr
\end{align}

Next, let's change variables so that $u=r^2,du=2rdr$. Therefore,
\begin{align}
2I^2 &=2\pi\int_{r=0}^\infty 2re^{-r^2}dr \\
&= 2\pi \int_{u=0}^\infty e^{-u} du \\
&= 2\pi \left(-e^{-\infty}+e^0\right) \\
&= 2\pi \left(-0+1\right) \\
&= 2\pi
\end{align}

Therefore, $I=\sqrt{\pi}$.
** å¯å¾®
*** å®šä¹‰
In mathematics, a differentiable function of one real variable is a function whose derivative exists at each point in its domain.
**** Differentiability of real functions of one variable

A function $f:U\to \mathbb {R}$ , defined on an open set $U\subset \mathbb {R}$ , is said to be differentiable at $a\in U$ if the derivative
$f'(a)=\lim _{h\to 0}{\frac {f(a+h)-f(a)}{h}}$ exists.

This implies that the function is continuous at a.

This function f is said to be differentiable on U if it is differentiable at every point of U. In this case, the derivative of f is thus a function from U into $\mathbb {R}$ .

A continuous function is not necessarily differentiable, but a differentiable function is necessarily continuous (at every point where it is differentiable) as being shown below (in the section Differentiability and continuity). A function is said to be continuously differentiable if its derivative is also a continuous function; there exist functions that are differentiable but not continuously differentiable (an example is given in the section Differentiability classes).
**** class $C^n$

Similarly to how continuous functions are said to be of class $C^{0}$ ,continuously differentiable functions are sometimes said to be of class $C^{1}$ . A function is of class $C^{2}$ if the first and second derivative of the function both exist and are continuous. More generally, a function is said to be of class $C^{k}$ if the first k derivatives $f^{\prime }(x),f^{\prime \prime }(x),\ldots ,f^{(k)}(x)$ all exist and are continuous. If derivatives $f^{(n)}$ exist for all positive integers n , the function is smooth or equivalently, of class $C^{\infty$ .
**** Jacobian matrix

Suppose
$\mathebf{f}:\mathbf{R}^n \to \mathbf{R}^m$
is a function such that each of its first-order partial derivatives exist on
$\mathbf{R}^n$ .
This function takes a point
$\mathbf{x}\in\mathbf{R}^n$
as input and produces the vector
$\mathbf{f\(\mathbf{x}\)}\in\mathbf{R}^m$
as output. Then the Jacobian matrix of
$\mathbf{f}$
is defined to be an mÃ—n matrix, denoted by
$\mathbf{J}$ , whose (i,j)th entry is
$\mathbf {J} _{ij}={\frac {\partial f_{i}}{\partial x_{j}}}$
, or explicitly
$\mathbf {J} ={\begin{bmatrix}{\dfrac {\partial \mathbf {f} }{\partial x_{1}}}&\cdots &{\dfrac {\partial \mathbf {f} }{\partial x_{n}}}\end{bmatrix}}={\begin{bmatrix}\nabla ^{\mathrm {T} }f_{1}\\\vdots \\\nabla ^{\mathrm {T} }f_{m}\end{bmatrix}}={\begin{bmatrix}{\dfrac {\partial f_{1}}{\partial x_{1}}}&\cdots &{\dfrac {\partial f_{1}}{\partial x_{n}}}\\\vdots &\ddots &\vdots \\{\dfrac {\partial f_{m}}{\partial x_{1}}}&\cdots &{\dfrac {\partial f_{m}}{\partial x_{n}}}\end{bmatrix}}$
where $\nabla ^{\mathrm {T} }f_{i}$ is the transpose (row vector) of the gradient of the $i$-th component.

The Jacobian matrix, whose entries are functions of $\mathbf{x}$ , is denoted in various ways; common notations include $\mathbf{D}\mathbf{f}$ , $\mathbf{J}\mathbf{f}$ , $\nabla \mathbf{f}$, and $\frac{\partial(f_1,..,f_m)}{\partial(x_1, ..,x_n)}$.
Some authors define the Jacobian as the transpose of the form given above.

The Jacobian matrix Matrix_(mathematics)#Linear_transformations|represents]] the [[total derivative|differential]] of $\mathbf{f}$  at every point where $\mathbf{f}$  is differentiable. In detail, if $\mathbf{h}$  is a [[displacement vector]] represented by a [[column matrix]], the [[matrix product]] $\mathbf{J'''('''x''') â‹… '''h}$  is another displacement vector, that is the best linear approximation of the change of $\mathbf{f}$  in a [[neighborhood (mathematics)|neighborhood]] of $\mathbf{x}$ , if $\mathbf{f'''('''x''')}} is [[Differentiable function|differentiable]] at $\mathbf{x}$ .{{efn|Differentiability at $\mathbf{x}$  implies, but is not implied by, the existence of all first-order partial derivatives at $\mathbf{x}$ , and hence is a stronger condition.}} This means that the function that maps $\mathbf{y}$  to $\mathbf{f'''('''x''') + '''J'''('''x''') â‹… ('''y''' â€“ '''x''')}} is the best [[linear approximation]] of $\mathbf{f'''('''y''')}} for all points $\mathbf{y}$  close to $\mathbf{x}$ . The [[linear map]] $\mathbf{h''' â†’ '''J'''('''x''') â‹… '''h}$  is known as the ''derivative'' or the [[total derivative|''differential'']] of $\mathbf{f}$  at $\mathbf{x}$ .

When {{math|1=''m'' = ''n''}}, the Jacobian matrix is square, so its [[determinant]] is a well-defined function of $\mathbf{x}$ , known as the '''Jacobian determinant''' of $\mathbf{f}$ . It carries important information about the local behavior of $\mathbf{f}$ . In particular, the function $\mathbf{f}$  has a differentiable [[inverse function]] in a neighborhood of a point $\mathbf{x}$  if and only if the Jacobian determinant is nonzero at $\mathbf{x}$  (see [[Jacobian conjecture]] for a related problem of ''global'' invertibility). The Jacobian determinant also appears when changing the variables in [[multiple integral]]s (see [[Integration_by_substitution#Substitution_for_multiple_variables|substitution rule for multiple variables]]).

When {{math|1=''m'' = 1}}, that is when {{math|''f'' : '''R'''<sup>''n''</sup> â†’ '''R}$  is a [[scalar field|scalar-valued function]], the Jacobian matrix reduces to the [[row vector]] $\nabla^{\mathrm T} f$; this row vector of all first-order partial derivatives of {{math|''f''}} is the transpose of the [[gradient]] of {{math|''f''}}, i.e.
$ \mathbf{J}_{f} = \nabla^T f $.  Specializing further, when {{math|1=''m'' = ''n'' = 1}}, that is when {{math|''f'' : '''R''' â†’ '''R}$  is a [[scalar field|scalar-valued function]] of a single variable, the Jacobian matrix has a single entry; this entry is the derivative of the function {{math|''f''}}.

These concepts are named after the [[mathematician]] [[Carl Gustav Jacob Jacobi]] (1804â€“1851).






The Jacobian matrix, whose entries are functions of x, is denoted in various ways; common notations include $D\mathbf{f}, \mathbf{J}_f, \nabla \mathbf {f}$, and $\frac {\partial (f_{1},..,f_{m})}{\partial (x_{1},..,x_{n})}$ . Some authors define the Jacobian as the transpose of the form given above.

The Jacobian matrix represents the differential of f at every point where f is differentiable. In detail, if h is a displacement vector represented by a column matrix, the matrix product J(x) â‹… h is another displacement vector, that is the best linear approximation of the change of f in a neighborhood of x, if f(x) is differentiable at x.[a] This means that the function that maps y to f(x) + J(x) â‹… (y â€“ x) is the best linear approximation of f(y) for all points y close to x. The linear map h â†’ J(x) â‹… h is known as the derivative or the differential of f at x.

When m = n, the Jacobian matrix is square, so its determinant is a well-defined function of x, known as the Jacobian determinant of f. It carries important information about the local behavior of f. In particular, the function f has a differentiable inverse function in a neighborhood of a point x if and only if the Jacobian determinant is nonzero at x (see Jacobian conjecture for a related problem of global invertibility). The Jacobian determinant also appears when changing the variables in multiple integrals (see substitution rule for multiple variables).

When m = 1, that is when f : Rn â†’ R is a scalar-valued function, the Jacobian matrix reduces to the row vector 
âˆ‡
T
ğ‘“
{\displaystyle \nabla ^{\mathrm {T} }f}; this row vector of all first-order partial derivatives of f is the transpose of the gradient of f, i.e. 
ğ½
ğ‘“
=
âˆ‡
ğ‘‡
ğ‘“
{\displaystyle \mathbf {J} _{f}=\nabla ^{T}f}. Specializing further, when m = n = 1, that is when f : R â†’ R is a scalar-valued function of a single variable, the Jacobian matrix has a single entry; this entry is the derivative of the function f.

These concepts are named after the mathematician Carl Gustav Jacob Jacobi (1804â€“1851).
**** Differentiability in higher dimensions

A function of several real variables $\mathbf{f}{:}\mathbf{R}^{m}\to\mathbf{R}^{n}$ is said to be differentiable at a point $\mathbf{x}_0$ if there exists a linear map $\mathbf{J}{:}\mathbf{R}^{m}\to\mathbf{R}^{n}$ such that
\begin{align}
\lim\limits_{\mathbf{h}\to\mathbf{0}} \frac{\|\mathbf{f(x_{0}+h)-f(x_{0})-J(h)}\|_{{\mathbf{R}^{n}}}}{\|\mathbf{h}\|_{{\mathbf{R}^{m}}}}=0
\end{align}

If a function is differentiable at $\mathx0, then all of the partial derivatives exist at $\mathbf{x}_0$ , and the linear map $\mathbf{J}$ is given by the Jacobian matrix, an $\text{n x m}$ matrix in this case. A similar formulation of the higher-dimensional derivative is provided by the fundamental increment lemma found in single-variable calculus.

If all the partial derivatives of a function exist in a neighborhood of a point $\mathbf{x}_0$ and are continuous at the point $\mathbf{x}_0$ , then the function is differentiable at that point $\mathbf{x}_0$ .

However, the existence of the partial derivatives (or even of all the directional derivatives) does not guarantee that a function is differentiable at a point. For example, the function $f{:}\mathbf{R}^{2}\to\mathbf{R}$ defined by $f(x,y)={\begin{cases}x&{\text{if }}y\neq x^{2}\\0&{\text{if }}y=x^{2}\end{cases}}$ is not differentiable at (0, 0), but all of the partial derivatives and directional derivatives exist at this point. For a continuous example, the function $f(x,y)={\begin{cases}y^{3}/(x^{2}+y^{2})&{\text{if }}(x,y)\neq (0,0)\\0&{\text{if }}(x,y)=(0,0)\end{cases}}$ is not differentiable at (0, 0), but again all of the partial derivatives and directional derivatives exist.


** å¤šé‡ç§¯åˆ†
*** å®šä¹‰
å¤šé‡ç§¯åˆ†ï¼ˆè‹±è¯­ï¼šMultiple integralï¼‰æ˜¯å®šç§¯åˆ†çš„ä¸€ç±»ï¼Œå®ƒå°†å®šç§¯åˆ†æ‰©å±•åˆ°å¤šå…ƒå‡½æ•°ï¼ˆå¤š
å˜é‡çš„å‡½æ•°ï¼‰ï¼Œä¾‹å¦‚æ±‚$f(x,y)$æˆ–è€…$f(x,y,z)$ç±»å‹çš„å¤šå…ƒå‡½æ•°çš„ç§¯åˆ†.

æ­£å¦‚å•å˜é‡çš„æ­£å‡½æ•°çš„å®šç§¯åˆ†ä»£è¡¨å‡½æ•°å›¾åƒå’Œ x è½´ä¹‹é—´åŒºåŸŸçš„é¢ç§¯ä¸€æ ·ï¼Œæ­£çš„åŒå˜é‡å‡½æ•°çš„
åŒé‡ç§¯åˆ†ä»£è¡¨å‡½æ•°æ‰€å®šä¹‰çš„æ›²é¢å’ŒåŒ…å«å‡½æ•°å®šä¹‰åŸŸçš„å¹³é¢ä¹‹é—´æ‰€å¤¹çš„åŒºåŸŸçš„ä½“ç§¯ã€‚ï¼ˆæ³¨æ„åŒ
æ ·çš„ä½“ç§¯ä¹Ÿå¯ä»¥é€šè¿‡ä¸‰å˜é‡å¸¸å‡½æ•° $f(x,y,z)=1$ åœ¨ä¸Šè¿°æ›²é¢å’Œå¹³é¢ä¹‹é—´çš„åŒºåŸŸä¸­çš„ä¸‰é‡ç§¯åˆ†å¾—åˆ°ã€‚è‹¥æœ‰æ›´å¤šå˜é‡ï¼Œåˆ™å¤šå…ƒå‡½æ•°çš„å¤šé‡ç§¯åˆ†ç»™å‡ºè¶…ä½“ç§¯ã€‚

n å…ƒå‡½æ•°$f(x_1,x_2,...,x_n)$åœ¨å®šä¹‰åŸŸ D ä¸Šçš„å¤šé‡ç§¯åˆ†é€šå¸¸ç”¨åµŒå¥—çš„ç§¯åˆ†å·æŒ‰ç…§æ¼”ç®—çš„é€†åº
æ ‡è¯†ï¼ˆæœ€å·¦è¾¹çš„ç§¯åˆ†å·æœ€åè®¡ç®—ï¼‰ï¼Œåé¢è·Ÿç€è¢«ç§¯å‡½æ•°å’Œæ­£å¸¸æ¬¡åºçš„ç§¯åˆ†å˜é‡ï¼ˆæœ€å³è¾¹çš„å˜
é‡æœ€åä½¿ç”¨ï¼‰ã€‚ç§¯åˆ†åŸŸæˆ–è€…å¯¹æ¯ä¸ªç§¯åˆ†å˜é‡åœ¨æ¯ä¸ªç§¯åˆ†å·ä¸‹æ ‡è¯†ï¼Œæˆ–è€…ç”¨ä¸€ä¸ªå˜é‡æ ‡åœ¨æœ€å³
è¾¹çš„ç§¯åˆ†å·ä¸‹ï¼š

$\int\ldots\int_{\mathbf{D}} f(x_{1},x_{2},\ldots,x_{n}) \mathrm{d}x_{1}\ldots\mathrm{d}x_{n}$

å› ä¸ºä¸å¯èƒ½è®¡ç®—å¤šäºä¸€ä¸ªè‡ªå˜é‡çš„å‡½æ•°çš„ä¸å®šç§¯åˆ†ï¼Œâ€œä¸å®šâ€å¤šé‡ç§¯åˆ†æ˜¯ä¸å­˜åœ¨çš„ã€‚å› æ­¤æ‰€æœ‰å¤šé‡ç§¯åˆ†éƒ½æ˜¯â€œå®šâ€ç§¯åˆ†ã€‚

é€šå¸¸åœ¨åæ ‡ç³»ä¸­ï¼Œå¤šé‡ç§¯åˆ†éƒ½åˆ©ç”¨åµŒå¥—çš„ç´¯æ¬¡ç§¯åˆ†è®¡ç®—ã€‚è€Œç´¯æ¬¡ç§¯åˆ†ä¸ºäº†ç®€ä¾¿å¯è®°ä¸ºï¼š

$\int_{\varphi_{1}}^{\psi_{1}}\mathrm{d}x_{1}\int_{\varphi_{1}(x_{1})}^{\psi_{2}(x_{1})}\mathrm{d}x_{2}\ldots\int_{\varphi_{n}(x_{1},x_{2},\ldots,x_{n-1})}^{\psi_{n}(x_{1},x_{2},\ldots,x_{n-1})}f(x_{1},x_{2},\ldots,x_{n})\mathrm{d}x_{n}$

å…¶ä¸­ç§¯åˆ†åŸŸä¸ºï¼š

$D=\{(x_1,x_2,\ldots,x_n)|\varphi_1\leq
x_1\leq\dot{\varphi}_1,\varphi_2(x_1)\leq
x_2\leq\dot{\varphi}_2(x_1),\ldots,\varphi_n(x_1,x_2,\ldots,x_{n-1})\leq
x_n\leq\psi_n(x_1,x_2,\ldots,x_{n-1})\}$
æ³¨æ„çš„æ˜¯ï¼Œè¯¥å¼ä¸€èˆ¬æƒ…å†µä¸‹å¹¶ä¸è¡¨ç¤ºå¤šä¸ªå®šç§¯åˆ†çš„ç§¯ï¼Œåœ¨å®é™…è®¡ç®—ä¸­ä»æœ€å³ä¾§ç§¯åˆ†å˜é‡å¼€å§‹ç§¯åˆ†ï¼Œå…¶ç»“æœä¼šä½œä¸ºå¤–ä¸€å±‚ç§¯åˆ†çš„è¢«ç§¯å‡½æ•°ã€‚

*** ç§¯åˆ†æ–¹æ³•
å¤šé‡ç§¯åˆ†é—®é¢˜çš„è§£å†³åœ¨å¤šæ•°æƒ…å†µä¸‹ä¾èµ–äºå°†å¤šé‡ç§¯åˆ†è½¬åŒ–ä¸ºä¸€ç³»åˆ—å•å˜é‡ç§¯åˆ†ï¼Œè€Œå…¶ä¸­æ¯ä¸ªå•å˜é‡ç§¯åˆ†éƒ½æ˜¯ç›´æ¥å¯è§£çš„ã€‚

**** ç›´æ¥æ£€éªŒ
æœ‰æ—¶å¯ä»¥ç›´æ¥è·å¾—ç§¯åˆ†çš„ç»“æœï¼Œè€Œæ— éœ€ä»»ä½•ç›´æ¥è®¡ç®—ã€‚

**** å¸¸æ•°
åœ¨å¸¸å‡½æ•°çš„æƒ…å†µä¸­ï¼Œç»“æœå¾ˆç›´æ¥ï¼šåªè¦å°†å¸¸å‡½æ•° c ä¹˜ä»¥æµ‹åº¦å°±å¯ä»¥äº†ã€‚å¦‚æœ c = 1ï¼Œè€Œä¸”æ˜¯åœ¨$R^2$çš„å­é›†ä¸­ç§¯åˆ†ï¼Œåˆ™ä¹˜ç§¯å°±æ˜¯åŒºåŸŸé¢ç§¯ï¼Œè€Œåœ¨$R^3$ä¸­ï¼Œå®ƒå°±æ˜¯åŒºåŸŸçš„ä½“ç§¯ã€‚

ä¾‹å¦‚ï¼š
$D = \{ (x,y) \in \mathbb{R}^2 \ : \ 2 \le x \le 4 \ ; \ 3 \le y \le 6 \}$ and $f(x,y) = 2$

åœ¨ D ä¸Šç§¯åˆ† fï¼š
$\int_3^6 \int_2^4 \ 2 \ \mathrm{d}x\, \mathrm{d}y = \mbox{area}(D) \cdot 2 = (2 \cdot 3) \cdot 2 = 12$
**** åˆ©ç”¨å¯èƒ½çš„å¯¹ç§°æ€§
å¦‚æœå®šä¹‰åŸŸå­˜åœ¨æ²¿ç€æŸæ¡è½´çš„å¯¹ç§°æ€§è€Œä¸”å‡½æ•°å¯¹äºé‚£ä¸ªå˜é‡æ˜¯å¥‡å‡½æ•°ï¼Œåˆ™ç§¯åˆ†ä¸º 0ï¼ˆå› ä¸ºç›¸åçš„ä¸¤éƒ¨åˆ†åŠ èµ·æ¥ä¸º 0ï¼‰ã€‚

å¯¹äº$R^n$ä¸­çš„å‡½æ•°ï¼Œåªè¦ç›¸å…³å˜é‡å¯¹äºå½¢æˆå¯¹ç§°çš„è½´æ˜¯å¥‡å˜é‡å°±å¯ä»¥äº†ã€‚

ä¾‹ä¸€:
ç»™å®š$f(x,y) = 2 \sin(x)-3y^3+5$ä»¥åŠ$T=\left \{ ( x,y) \in \mathbf{R}^2 \ : \ x^2+y^2\le 1 \right \}$ä¸ºç§¯åˆ†åŒºåŸŸï¼ˆåŠå¾„ä¸º 1 çš„åœ†ç›˜ï¼ŒåŒ…å«è¾¹ç•Œï¼‰ã€‚

åˆ©ç”¨çº¿æ€§æ€§è´¨ï¼Œç§¯åˆ†å¯ä»¥åˆ†è§£ä¸ºä¸‰éƒ¨åˆ†ï¼š

$\iint_T (2\sin x - 3y^3 + 5) \, \mathrm{d}x \, \mathrm{d}y = \iint_T 2 \sin x \, \mathrm{d}x \, \mathrm{d}y - \iint_T 3y^3 \, \mathrm{d}x \, \mathrm{d}y + \iint_T 5 \, \mathrm{d}x \, \mathrm{d}y$

$2\sin(x)$ å’Œ $3y^3$ éƒ½æ˜¯å¥‡å‡½æ•°ï¼Œè€Œä¸”æ˜¾ç„¶ T å¯¹äº x å’Œ y è½´éƒ½æ˜¯å¯¹ç§°çš„ï¼›å› æ­¤å”¯ä¸€æœ‰è´¡çŒ®çš„éƒ¨åˆ†æ˜¯å¸¸å‡½æ•° 5,å› ä¸ºå…¶å®ƒä¸¤ä¸ªéƒ½è´¡çŒ® 0.

ä¾‹äºŒï¼š
è€ƒè™‘å‡½æ•°$f(x,y,z)=x \exp(y^2+z^2)$ä»¥åŠåœ†å¿ƒåœ¨åŸç‚¹çš„åŠå¾„ä¸º 2 çš„çƒ
$T = \left \{ ( x,y, z) \in \mathbf{R}^3 \ : \ x^2+y^2+z^2 \le 4 \right \}$
è¯¥çƒæ˜¾ç„¶æ˜¯å¯¹äºä¸‰æ¡è½´éƒ½å¯¹ç§°ï¼Œä½†æ˜¯åªè¦å¯¹äº x è½´ç§¯åˆ†å°±å¯ä»¥çœ‹å‡ºç»“æœæ˜¯ 0ï¼Œå› ä¸º f å¯¹äºè¯¥å˜é‡æ˜¯å¥‡å‡½æ•°ã€‚

**** ç®€åŒ–å…¬å¼
ç®€åŒ–å…¬å¼åŸºäºç®€å•ç§¯åˆ†åŒºåŸŸæ¥å°†å¤šé‡ç§¯åˆ†è½¬åŒ–ä¸ºå•å˜é‡ç§¯åˆ†çš„åºåˆ—ã€‚å®ƒä»¬å¿…é¡»ä»å³è‡³å·¦è®¡ç®—ï¼Œè¿‡ç¨‹ä¸­å°†å…¶å®ƒå˜é‡æš‚æ—¶è§†ä¸ºå¸¸æ•°ï¼ˆå’Œåå¯¼æ•°çš„è®¡ç®—ç±»ä¼¼ï¼‰ã€‚

***** $R^2$ä¸­çš„å¸¸è§„åŒºåŸŸ
æ­¤ç§æ–¹æ³•é€‚ç”¨äºæ»¡è¶³ä¸‹è¿°æ¡ä»¶çš„ä»»ä½•å®šä¹‰åŸŸ D:
1. D æŠ•å½±åˆ° x è½´æˆ– y è½´ä»»ä¸€è½´ï¼Œå½¢æˆä¸€ä¸ªæœ‰è¾¹ç•Œçš„èŒƒå›´, ä»¥ a, b ä»£è¡¨è¾¹ç•Œå€¼ã€‚
2. é€šè¿‡ a, b ä¸¤ç‚¹å¹¶ä¸$\overline {ab}$ å‚ç›´çš„ç›´çº¿ä¸ D ç›¸äº¤åçš„ä¸¤ä¸ªç«¯ç‚¹ï¼Œå¯ä»¥ç”¨ 2 ä¸ªå‡½æ•°$\alpha , \beta $.

X è½´:å°† D å¯¹ x è½´åšå‚ç›´æŠ•å½±ï¼Œå‡½æ•¸$f: D \longrightarrow \mathbb{R}$æ˜¯è¿ç»­å‡½æ•°ï¼Œå¹¶ä¸” D å¯ä»¥è§†ä¸ºï¼ˆå®šä¹‰åœ¨[a,b]åŒºé—´ä¸Šçš„ï¼‰Î±(x)å’ŒÎ²(x)ä¹‹é—´çš„åŒºåŸŸã€‚åˆ™

$\iint_D f(x,y)\ \mathrm{d}x\, \mathrm{d}y = \int_a^b \mathrm{d}x \int_{ \alpha (x)}^{ \beta (x)} f(x,y)\, \mathrm{d}y$

y:
å°† D å¯¹ y è½´åšå‚ç›´æŠ•å½±ï¼Œå‡½æ•¸$f: D \longrightarrow \mathbb{R}$æ˜¯è¿ç»­å‡½æ•°ï¼Œå¹¶ä¸” D å¯ä»¥è§†ä¸ºï¼ˆå®šä¹‰åœ¨[a,b]åŒºé—´ä¸Šçš„ï¼‰Î±(y)å’ŒÎ²(y)ä¹‹é—´çš„åŒºåŸŸã€‚åˆ™

$\iint_D f(x,y)\ \mathrm{d}x\, \mathrm{d}y = \int_a^b \mathrm{d}y \int_{ \alpha (y)}^{ \beta (y)} f(x,y)\, \mathrm{d}x$

èŒƒä¾‹:
è€ƒè™‘åŒºåŸŸï¼š$D = \{ (x,y) \ : \ x \ge 0, y \le 1, y \ge x^2 \}$ï¼ˆå‚çœ‹é™„å›¾ï¼‰ã€‚è®¡ç®—

$\iint_D (x+y) \, \mathrm{d}x \, \mathrm{d}y$

è¯¥åŒºåŸŸå¯ä»¥æ²¿ x æˆ–è€… y è½´åˆ†è§£ã€‚è¦é‡‡ç”¨å…¬å¼ï¼Œå¿…é¡»å…ˆæ‰¾åˆ°é™åˆ¶''D''çš„ä¸¤ä¸ªå‡½æ•°å’Œå®šä¹‰åŒºé—´ã€‚
è¿™ä¸ªä¾‹å­ä¸­ï¼Œè¿™ä¸¤ä¸ªå‡½æ•°ä¸ºï¼š

$\alpha (x) = x^2\,\!$ å’Œ $\beta (x) = 1\,\!$

è€ŒåŒºé—´ä¸º$[a,b] = [0,1]\,\!$ï¼ˆè¿™é‡Œä¸ºäº†ç›´è§‚èµ·è§é‡‡ç”¨æ²¿ x è½´åˆ†è§£ï¼‰ã€‚

åº”ç”¨ç®€åŒ–å…¬å¼ï¼Œå¾—åˆ°ï¼š

$\iint_D (x+y) \, \mathrm{d}x \, \mathrm{d}y = \int_0^1 \mathrm{d}x \int_{x^2}^1 (x+y) \, \mathrm{d}y = \int_0^1 \mathrm{d}x \ \left[xy \ + \ \frac{y^2}{2} \ \right]^1_{x^2}$

ï¼ˆé¦–å…ˆï¼Œç¬¬äºŒä¸ªç§¯åˆ†å°† x ä½œä¸ºå¸¸æ•°ï¼‰ã€‚ç„¶åå°±æ˜¯ç”¨ç§¯åˆ†çš„åŸºæœ¬æŠ€æœ¯ï¼š

$\int_0^1 \left[xy \ + \ \frac{y^2}{2} \ \right]^1_{x^2} \, \mathrm{d}x = \int_0^1 \left(x + \frac{1}{2} - x^3 - \frac{x^4}{2} \right) \mathrm{d}x = \cdots = \frac{13}{20}$

å¦‚æœæ²¿ç€ y è½´åˆ†è§£ï¼Œå¯ä»¥è®¡ç®—
$\int_0^1 \mathrm{d}y \int_0^{\sqrt{y}} (x+y) \, \mathrm{d}x$

å¹¶å¾—åˆ°åŒæ ·çš„ç»“æœã€‚
***** $R^3$ä¸­çš„å¸¸è§„åŒºåŸŸ
è¿™äº›å…¬å¼å¯ä»¥æ¨å¹¿åˆ°ä¸‰é‡ç§¯åˆ†ï¼š

T æ˜¯ä¸€ä¸ªå¯ä»¥æŠ•å½±åˆ° xy å¹³é¢çš„ä½“ï¼Œå®ƒå¤¹åœ¨Î±(x,y)å’ŒÎ²(x,y)ä¸¤ä¸ªå‡½æ•°ä¹‹é—´ã€‚é‚£ä¹ˆï¼š

$\iiint_T f(x,y,z) \ \mathrm{d}x\, \mathrm{d}y\, \mathrm{d}z = \iint_D \mathrm{d}x\, \mathrm{d}y \int_{\alpha (x,y)}^{\beta (x,y)} f(x,y,z) \, \mathrm{d}z$

ï¼ˆæ­¤å®šä¹‰å’Œå…¶å®ƒ$R^3$$ä¸­çš„åˆ†è§£ç±»ä¼¼ï¼‰ã€‚

***** å˜é‡æ›¿æ¢
ç§¯åˆ†çš„æé™å¸¸å¸¸ä¸æ˜“äº¤æ¢ï¼ˆåŒºåŸŸæ— æ³•åˆ†è§£æˆ–è€…å…¬å¼å¾ˆå¤æ‚ï¼‰ï¼Œè¿™æ—¶å¯ä»¥é‡‡ç”¨å˜é‡æ›¿æ¢æ¥é‡å†™ç§¯åˆ†ï¼Œä»¤åŒºåŸŸæ›´åŠ ç®€æ˜“ï¼Œä»è€Œå¯ä»¥ç”¨æ›´ç®€å•çš„å…¬å¼è¡¨è¾¾ã€‚ä¸ºæ­¤ï¼Œå‡½æ•°å¿…é¡»å˜æ¢åˆ°æ–°åæ ‡ç³»ä¸‹ã€‚

å‡½æ•°ä¸º$f(x, y) = (x-1)^2 +\sqrt y$;

è‹¥é‡‡ç”¨æ›¿æ¢$x' = x-1, \ y'= y $åˆ™$x = x' + 1, \ y=y' $

å¯ä»¥å¾—åˆ°æ–°å‡½æ•°$f_2(x,y) = (x')^2 +\sqrt y$.

å¯¹äºå®šä¹‰åŸŸè¦è¿›è¡Œç±»ä¼¼å¤„ç†ï¼Œå› ä¸ºåŸæ¥æ˜¯é‡‡ç”¨å˜æ¢å‰çš„å˜é‡è¡¨è¾¾çš„ï¼ˆæœ¬ä¾‹ä¸­çš„ x å’Œ yï¼‰

å¾®åˆ† dx å’Œ dy è¦é€šè¿‡åŒ…å«è¢«æ›¿æ¢çš„å˜é‡å¯¹äºæ–°å˜é‡çš„åå¾®åˆ†çš„é›…å…‹æ¯”è¡Œåˆ—å¼æ¥å˜æ¢ã€‚ï¼ˆè­¬å¦‚ï¼Œæåæ ‡çš„å¾®åˆ†å˜æ¢ï¼‰ã€‚

å¸¸ç”¨çš„å˜é‡æ›¿æ¢æœ‰ä¸‰ç§ï¼ˆ$R^2$ä¸­ä¸€ç§ï¼Œ$R^3$ä¸­ä¸¤ç§ï¼‰ï¼›ä½†æ˜¯ï¼Œæ›´æ™®éçš„å˜æ¢å¯ä»¥ç”¨åŒæ ·çš„åŸç†æ¥å‘ç°ã€‚

***** æåæ ‡
åœ¨$R^2$ä¸­ï¼Œè‹¥å®šä¹‰åŸŸæœ‰æŸç§åœ†å½¢å¯¹ç§°æ€§è€Œå‡½æ•°ä¹Ÿæœ‰æŸç§ç‰¹å¾ï¼Œåˆ™å¯ä»¥é‡‡ç”¨æåæ ‡å˜æ¢ï¼ˆå‚çœ‹å›¾ä¸­çš„ä¾‹å­ï¼‰ï¼Œä¹Ÿå°±æ˜¯è¯´å°†ç‚¹$P(x,y)$ä»ç¬›å¡å°”åæ ‡å˜æ¢åˆ°ç›¸åº”çš„æåæ ‡ä¸­ã€‚è¿™ä½¿å¾—å®šä¹‰åŸŸçš„å½¢çŠ¶æ”¹å˜ï¼Œä»è€Œç®€åŒ–è¿ç®—ã€‚

è¯¥å˜æ¢çš„åŸºæœ¬å…³ç³»å¦‚ä¸‹ï¼š

$f(x,y) \rightarrow f(\rho \ \cos \phi,\rho \ \sin \phi )$ã€‚

ä¾‹å­ 1,
å‡½æ•°ä¸º$f(x,y) = x + y$

åº”ç”¨è¯¥å˜æ¢å¾—åˆ°$f(\rho, \phi) = \rho \cos \phi + \rho \sin \phi = \rho \ (\cos \phi + \sin \phi )$ã€‚

ä¾‹å­ 2,
å‡½æ•°ä¸º$f(x,y) = x^2 + y^2$
åº”ç”¨è¯¥å˜æ¢åˆ°å¾—$f(\rho, \phi) = \rho^2 (\cos^2 \phi + \sin^2 \phi) = \rho^2\$

è¿™é‡Œä½¿ç”¨äº†å‹¾è‚¡å®šç†ï¼ˆåœ¨ç®€åŒ–æ“ä½œæ—¶å¾ˆæœ‰ç”¨ï¼‰ã€‚

å®šä¹‰åŸŸçš„å˜æ¢æ˜¯æ ¹æ® x å’Œ y é€šè¿‡ç¯åšå’Œè§’åº¦çš„å¹…åº¦æ¥é™å®šÏ, Ï†çš„åŒºé—´ã€‚

ä¾‹å­ 3,
åŒºåŸŸä¸º$D = x^2 + y^2 \le 4$,åœ†å‘¨åŠå¾„ 2ï¼›å¾ˆæ˜æ˜¾ï¼Œè¿™ä¸ªåŒºåŸŸæ‰€è¦†ç›–çš„è§’åº¦æ˜¯æ•´ä¸ªåœ†å‘¨è§’ï¼Œæ‰€ä»¥Ï†ä» 0 å˜åŒ–åˆ° 2Ï€ï¼Œè€Œç¯åŠå¾„ä» 0 å˜åŒ–åˆ° 2ï¼ˆå†…ç¯ä¸º 0 çš„ç¯å½¢å°±æ˜¯åœ†ï¼‰ã€‚

ä¾‹å­ 3,
åŒºåŸŸä¸º $D = \{ x^2 + y^2 \le 9, \ x^2 + y^2 \ge 4, \ y \ge 0 \}$ï¼Œè¿™æ˜¯åœ¨æ­£ y åŠå¹³é¢ä¸­çš„åœ†ç¯ï¼ˆå‚çœ‹ç¤ºæ„å›¾ï¼‰ï¼›æ³¨æ„Ï†è¡¨ç¤ºå¹³é¢è§’è€ŒÏä» 2 å˜åŒ–åˆ° 3ã€‚å› æ­¤å˜æ¢å‡ºæ¥çš„åŒºåŸŸä¸ºçŸ©å½¢ï¼š$T = \{ 2 \le \rho \le 3, \ 0 \le \phi \le \pi \}$

è¯¥å˜æ¢çš„é›…å¯æ¯”è¡Œåˆ—å¼ä¸ºï¼š
$\frac{\partial (x,y)}{\partial (\rho, \phi)} =
\begin{vmatrix}
\cos \phi & - \rho \sin \phi \\
\sin \phi & \rho \cos \phi
\end{vmatrix} = \rho$

è¿™å¯ä»¥é€šè¿‡å°† x = Ï cos(Ï†),y = Ï sin(Ï†)ä»£å…¥å…³äºÏçš„ç¬¬ä¸€è¡Œå’Œå…³äºÏ†çš„ç¬¬äºŒè¡Œçš„åå¾®åˆ†ä¸­å¾—åˆ°ï¼Œæ‰€ä»¥å¾®åˆ† dx dy å˜æ¢ä¸ºÏ dÏ dÏ†.

ä¸€æ—¦å‡½æ•°å’ŒåŒºåŸŸçš„å˜æ¢å®Œæˆåï¼Œå¯ä»¥å®šä¹‰æåæ ‡ä¸­çš„å˜é‡å˜æ¢å…¬å¼ï¼š

$\iint_D f(x,y) \ \mathrm{d}x\, \mathrm{d}y = \iint_T f(\rho \cos \phi, \rho \sin \phi) \rho \, \mathrm{d} \rho\, \mathrm{d} \phi$ã€‚

æ³¨æ„Ï†åœ¨[0, 2Ï€]åŒºé—´ä¸­æœ‰æ•ˆï¼Œè€ŒÏæµ‹é‡é•¿åº¦ï¼Œå› æ­¤åªèƒ½å–éè´Ÿå€¼ã€‚

æ­¤å¤–ï¼Œåº”ç”¨å˜é‡å˜æ¢å…¬å¼çš„å‰ææ˜¯ï¼Œé›…å¯æ¯”è¡Œåˆ—å¼çš„å€¼åœ¨å˜æ¢åçš„ç§¯åˆ†å˜é‡(å¦‚æ­¤ä¾‹ä¸­çš„Ïå’ŒÏ†)ç»„æˆçš„æœ‰ç•Œé—­åŒºåŸŸ(å¦‚æ­¤ä¾‹ä¸­Ï†å’ŒÏæ„æˆçš„äºŒç»´åŸŸ)ä¸Šæ’ä¸ä¸ºé›¶ã€‚ä½†æ˜¯åœ¨æåæ ‡ä¸­å½“ä¸”ä»…å½“Ïä¸ºé›¶æ—¶ï¼Œæ‰æœ‰é›…å¯æ¯”è¡Œåˆ—å¼ä¸ºé›¶ï¼Œæ•…å¯è¯æ˜è¯¥å˜é‡å˜æ¢å…¬å¼æˆç«‹ã€‚

ä¾‹å­ 4,
å‡½æ•°ä¸º f(x,y) = x åŒºåŸŸå’Œä¾‹ 2-d ç›¸åŒã€‚
:ä»å‰é¢å¯¹''D''çš„åˆ†æï¼Œæˆ‘ä»¬çŸ¥é“Ïçš„åŒºé—´ä¸º[2,3]ï¼Œè€ŒÏ†çš„ä¸º[0,Ï€].å‡½æ•°å˜æ¢ä¸ºï¼š

$f(x,y) = x \longrightarrow f(\rho,\phi) = \rho \ \cos \phi$ã€‚

æœ€åï¼Œåº”ç”¨ç§¯åˆ†å…¬å¼ï¼š

$\iint_D x \, \mathrm{d}x\, \mathrm{d}y = \iint_T \rho \cos \phi \ \rho \, \mathrm{d}\rho\, \mathrm{d}\phi$ã€‚

:ä¸€æ—¦åŒºé—´ç»™å®šï¼Œå°±å¯ä»¥å¾—åˆ°

$\int_0^{\pi} \int_2^3 \rho^2 \cos \phi \ \mathrm{d} \rho \ \mathrm{d} \phi = \int_0^{\pi} \cos \phi \ \mathrm{d} \phi \left[ \frac{\rho^3}{3} \right]_2^3 = \left[ \sin \phi \right]_0^{\pi} \ \left(9 - \frac{8}{3} \right) = 0$ã€‚

***** æŸ±æåæ ‡
$R^3$ä¸­ï¼Œåœ¨æœ‰åœ†å½¢åº•é¢çš„å®šä¹‰åŸŸä¸Šçš„ç§¯åˆ†å¯ä»¥é€šè¿‡å˜æ¢åˆ°æŸ±æåæ ‡ç³»æ¥å®Œæˆï¼›å‡½æ•°çš„å˜æ¢ç”¨å¦‚ä¸‹çš„å…³ç³»è¿›è¡Œï¼š
$f(x,y,z) \rightarrow f(\rho \cos \phi, \rho \sin \phi, z)$

åŒºåŸŸçš„å˜æ¢å¯ä»¥ä»å›¾å½¢ä¸­å¾—åˆ°ï¼Œå› ä¸ºåº•é¢çš„å½¢çŠ¶å¯èƒ½ä¸åŒï¼Œè€Œé«˜éµå¾ªåˆå§‹åŒºåŸŸçš„å½¢çŠ¶ã€‚

ä¾‹å­ 1,
åŒºåŸŸä¸º$D = \{ x^2 + y^2 \le 9, \ x^2 + y^2 \ge 4, \ 0 \le z \le 5 \}$ï¼›å¦‚æœé‡‡ç”¨å˜æ¢ï¼Œå¯ä»¥å¾—åˆ°åŒºåŸŸ$T = \{ 2 \le \rho \le 3, \ 0 \le \phi \le \pi, \ 0 \le z \le 5 \}$ï¼ˆè¿™æ˜¯ä¸€ä¸ªåº•é¢ä¸ºä¾‹ 2-d ä¸­çš„çŸ©å½¢è€Œé«˜ä¸º 5 çš„é•¿æ–¹ä½“ï¼‰ã€‚

å› ä¸º z åˆ†é‡æ²¡æœ‰å˜åŒ–ï¼Œdx dy dz å’Œåœ¨æåæ ‡ä¸­ä¸€æ ·å˜åŒ–ï¼šå˜Ï dÏ dÏ† dzã€‚

æœ€åï¼Œå˜æ¢åˆ°æŸ±æåæ ‡çš„æœ€åå…¬å¼ä¸ºï¼š

$\iiint_D f(x,y,z) \, \mathrm{d}x\, \mathrm{d}y\, \mathrm{d}z = \iiint_T f(\rho \cos \phi, \rho \sin \phi, z) \rho \, \mathrm{d}\rho\, \mathrm{d}\phi\, \mathrm{d}z$ã€‚

è¿™ä¸ªæ–¹æ³•åœ¨æŸ±å½¢æˆ–è€…é”¥å½¢åŒºåŸŸçš„æƒ…å†µè¾ƒä¸ºé€‚ç”¨ï¼Œä¹Ÿé€‚ç”¨äºå®¹æ˜“åˆ†è¾¨''z''åŒºé—´å’Œå˜æ¢åœ†å½¢åº•é¢å’Œå‡½æ•°çš„å…¶å®ƒæƒ…å†µã€‚

ä¾‹å­ 2,
å‡½æ•°ä¸º$f(x,y,z) = x^2 + y^2 + z$è€Œç§¯åˆ†åŒºåŸŸä¸ºåœ†æŸ±$D = \{ x^2 + y^2 \le 9, \ -5 \le z \le 5 \}$$.
å°† D å˜æ¢åˆ°æŸ±æåæ ‡å¦‚ä¸‹ï¼š

$T = \{ 0 \le \rho \le 3, \ 0 \le \phi \le 2 \pi, \ -5 \le z \le 5 \}$ã€‚

å‡½æ•°å˜ä¸º

$f(\rho \cos \phi, \rho \sin \phi, z) = \rho^2 + z$

æœ€æœ‰åº”ç”¨ç§¯åˆ†å…¬å¼ï¼š

$\iiint_D (x^2 + y^2 +z) \, \mathrm{d}x\, \mathrm{d}y\, \mathrm{d}z = \iiint_T ( \rho^2 + z) \rho \, \mathrm{d}\rho\, \mathrm{d}\phi\, \mathrm{d}z$;

æ¨æ¼”ä¸€ä¸‹å…¬å¼ï¼Œå¾—åˆ°

$\int_{-5}^5 \mathrm{d}z \int_0^{2 \pi} \mathrm{d}\phi \int_0^3 ( \rho^3 + \rho z )\, \mathrm{d}\rho = 2 \pi \int_{-5}^5 \left[ \frac{\rho^4}{4} + \frac{\rho^2 z}{2} \right]_0^3 \, \mathrm{d}z = 2 \pi \int_{-5}^5 \left( \frac{81}{4} + \frac{9}{2} z\right)\, \mathrm{d}z = \cdots = 405 \pi$

***** çƒæåæ ‡
$R^3$ä¸­ï¼Œæœ‰äº›åŒºåŸŸæœ‰çƒå½¢å¯¹ç§°æ€§ï¼Œæ‰€ä»¥å°†ç§¯åˆ†åŒºåŸŸçš„æ¯ç‚¹ç”¨ä¸¤ä¸ªè§’åº¦å’Œä¸€ä¸ªè·ç¦»æ ‡è¯†è¾ƒä¸ºåˆé€‚ã€‚å› æ­¤å¯ä»¥é‡‡ç”¨å˜æ¢åˆ°çƒæåæ ‡ç³»ï¼›å‡½æ•°å˜æ¢ç”±å¦‚ä¸‹å…³ç³»äº§ç”Ÿï¼š
$f(x,y,z) \longrightarrow f(\rho \cos \theta \sin \phi, \rho \sin \theta \sin \phi, \rho \cos \phi)$

æ³¨æ„ z è½´ä¸Šçš„ç‚¹æ²¡æœ‰å”¯ä¸€è¡¨ç¤ºï¼Œ$\theta$å¯ä»¥åœ¨ 0 åˆ° 2Ï€é—´å˜åŒ–ã€‚

è¿™ä¸ªæ–¹æ³•æœ€ä¸ºé€‚ç”¨çš„åŒºåŸŸæ˜¾ç„¶æ˜¯çƒã€‚

ä¾‹å­ 1,
åŒºåŸŸä¸º$D = x^2 + y^2 + z^2 \le 16$ï¼ˆçƒå¿ƒåœ¨åŸç‚¹åŠå¾„ä¸º 4 çš„çƒï¼‰ï¼›åº”ç”¨å˜æ¢åå¾—åˆ°ï¼š$T = \{ 0 \le \rho \le 4, \ 0 \le \phi \le \pi, \ 0 \le \theta \le 2 \pi \}$ã€‚

åæ ‡å˜æ¢çš„é›…å¯æ¯”è¡Œåˆ—å¼ä¸ºï¼š

$\frac{\partial (x,y,z)}{\partial (\rho, \theta, \phi)} =
\begin{vmatrix}
\cos \theta \sin \phi & - \rho \sin \theta \sin \phi & \rho \cos \theta \cos \phi \\
\sin \theta \sin \phi & \rho \cos \theta \sin \phi & \rho \sin \theta \cos \phi \\
\cos \phi & 0 & - \rho \sin \phi
\end{vmatrix} = -\rho^2 \sin \phi$

:å› æ­¤<math> \mathrm{d}x\, \mathrm{d}y\, \mathrm{d}z </math>å˜æ¢ä¸º<math> \rho^2 \sin \phi \, \mathrm{d}\rho\, \mathrm{d}\theta\, \mathrm{d}\phi$.

å¾—åˆ°æœ€åå…¬å¼:

$\iiint_D f(x,y,z) \, \mathrm{d}x\, \mathrm{d}y\, \mathrm{d}z = \iiint_T f(\rho \sin \theta \cos \phi, \rho \sin \theta \sin \phi, \rho \cos \theta) \rho^2 \sin \phi \, \mathrm{d}\rho\, \mathrm{d}\theta\, \mathrm{d}\phi$

åº”å½“åœ¨ç§¯åˆ†åŒºåŸŸä¸ºçƒå½¢å¯¹ç§°å¹¶ä¸”å‡½æ•°å¾ˆå®¹æ˜“é€šè¿‡åŸºæœ¬ä¸‰è§’å…¬å¼ç®€åŒ–çš„æ—¶å€™æ‰ä½¿ç”¨è¿™ä¸ªæ–¹æ³•ã€‚ï¼ˆå‚çœ‹ä¾‹ 4-bï¼‰ï¼›å…¶å®ƒæƒ…å†µä¸‹ï¼Œå¯èƒ½ä½¿ç”¨æŸ±æåæ ‡æ›´ä¸ºåˆé€‚ï¼ˆå‚çœ‹ä¾‹ 4-cï¼‰ã€‚

:<math>\iiint_T f(a,b,c) \rho^2 \sin \phi \, \mathrm{d}\rho\, \mathrm{d}\theta\, \mathrm{d}\phi</math>ã€‚

æ³¨æ„ä»é›…å¯æ¯”è¡Œåˆ—å¼æ¥çš„<math>\rho^2</math>å’Œ<math>\sin \phi</math>å› å­ã€‚

æ³¨æ„ä¸‹é¢ä¾‹å­ä¸­ï¼ŒÏ†å’ŒÎ¸çš„ä½œç”¨åè¿‡æ¥äº†ã€‚

<blockquote>
<u>ä¾‹ï¼ˆ4-bï¼‰</u>:<br />
:''D''å’Œä¾‹ 4-a ç›¸åŒï¼Œè€Œ<math>f(x,y,z) = x^2 + y^2 + z^2\,\!</math>æ˜¯è¢«ç§¯å‡½æ•°ã€‚

:å¾ˆå®¹æ˜“å˜æ¢ä¸ºï¼š

::<math>f(\rho \sin \theta \cos \phi, \rho \sin \theta \sin \phi, \rho \cos \theta) = \rho^2,</math>ï¼Œ

:è€Œä»''D''åˆ°''T''çš„å˜æ¢æ˜¯å·²çŸ¥çš„ï¼š

::<math>(0 \le \rho \le 4, \ 0 \le \phi \le 2 \pi, \ 0 \le \theta \le \pi)</math>ã€‚

:åº”ç”¨ç§¯åˆ†å…¬å¼ï¼š

::<math>\iiint_D (x^2 + y^2 +z^2) \, \mathrm{d}x\, \mathrm{d}y\, \mathrm{d}z = \iiint_T \rho^2 \ \rho^2 \sin \theta \, \mathrm{d}\rho\, \mathrm{d}\theta\, \mathrm{d}\phi,</math>

:å¹¶å±•å¼€ï¼š

::<math>\iiint_T \rho^4 \sin \theta \, \mathrm{d}\rho\, \mathrm{d}\theta\, \mathrm{d}\phi = \int_0^{\pi} \sin \theta \,\mathrm{d}\theta \int_0^4 \rho^4 \mathrm{d} \rho \int_0^{2 \pi} \mathrm{d}\phi = 2 \pi \int_0^{\pi} \sin \theta \left[ \frac{\rho^5}{5} \right]_0^4 \, \mathrm{d} \theta</math>

::<math>= 2 \pi \left[ \frac{\rho^5}{5} \right]_0^4 \left[- \cos \theta \right]_0^{\pi} = 4 \pi \cdot \frac{1024}{5} = \frac{4096 \pi}{5}</math>ã€‚

<u>ä¾‹ï¼ˆ4-cï¼‰</u>:
:åŒºåŸŸ''D''æ˜¯çƒå¿ƒåœ¨åŸç‚¹åŠå¾„ä¸º''3a''çš„çƒï¼ˆ<math>D = x^2 + y^2 + z^2 \le 9a^2 \,\!</math>ï¼‰è€Œ<math>f(x,y,z) = x^2 + y^2\,\!</math>æ˜¯è¢«ç§¯å‡½æ•°ã€‚

:çœ‹èµ·æ¥é‡‡ç”¨çƒæåæ ‡å˜æ¢è¾ƒä¸ºåˆé€‚ï¼Œä½†æ˜¯äº‹å®ä¸Šï¼Œé™å®šæ–°åŒºåŸŸ''T''çš„å˜é‡å¾ˆæ˜æ˜¾åº”è¯¥æ˜¯ï¼š

::<math>0 \le \rho \le 3a, \ 0 \le \phi \le 2 \pi, \ 0 \le \theta \le \pi</math>ã€‚

:ä½†æ˜¯é‡‡ç”¨è¿™ä¸ªå˜æ¢å°±æœ‰

::<math>f(x,y,z) = x^2 + y^2 \longrightarrow \rho^2 \sin^2 \theta \cos^2 \phi + \rho^2 \sin^2 \theta \sin^2 \phi = \rho^2 \sin^2 \theta</math>.

:åº”ç”¨ç§¯åˆ†å…¬å¼å¾—åˆ°ï¼š

::<math>\iiint_T \rho^2 \sin^2 \theta \rho^2 \sin \theta \, \mathrm{d}\rho\, \mathrm{d}\theta\, \mathrm{d}\phi = \iiint_T \rho^4 \sin^3 \theta \, \mathrm{d}\rho\, \mathrm{d}\theta\, \mathrm{d}\phi</math>

:è¿™å¾ˆéš¾æ±‚è§£ã€‚è€Œå¦‚æœé‡‡ç”¨æŸ±æåæ ‡ï¼Œæ–°çš„''T''åŒºé—´ä¸ºï¼š

::<math>0 \le \rho \le 3a, \ 0 \le \phi \le 2 \pi, \ - \sqrt{9a^2 - \rho^2} \le z \le \sqrt{9a^2 - \rho^2};</math>

:''z''åŒºé—´å¯ä»¥é€šè¿‡å°†çƒåˆ‡æˆä¸¤ä¸ªåŠçƒå¹¶æ±‚è§£ä»''D''çš„å…¬å¼æ¥çš„ä¸ç­‰å¼å¾—åˆ°ï¼ˆç„¶åç›´æ¥å˜æ¢''x<sup>2</sup> + y<sup>2</sup>''åˆ°''Ï<sup>2</sup>''ï¼‰ã€‚æ–°å‡½æ•°å°±æ˜¯''Ï<sup>2</sup>''.é‡‡ç”¨ç§¯åˆ†å…¬å¼

::<math>\iiint_T \rho^2 \rho \ \mathrm{d} \rho \mathrm{d} \phi \mathrm{d}z</math>.

:å¾—åˆ°

::<math>\int_0^{2 \pi} \mathrm{d}\phi \int_0^{3a} \rho^3 \mathrm{d}\rho \int_{- \sqrt{9a^2 - \rho^2} }^{\sqrt{9 a^2 - \rho^2} }\, \mathrm{d}z = 2 \pi \int_0^{3a} 2 \rho^3 \sqrt{9 a^2 - \rho^2} \, \mathrm{d}\rho</math>ã€‚

:ç„¶ååº”ç”¨å˜æ¢

::<math>9 a^2 - \rho^2 = t\,\! \longrightarrow \mathrm{d}t = -2 \rho\, \mathrm{d}\rho \longrightarrow \mathrm{d}\rho = \frac{\mathrm{d} t}{- 2 \rho}\,\!</math>

:(æ–°åŒºé—´å˜ä¸º<math>0, 3a \longrightarrow 9 a^2, 0</math>)ã€‚å¾—åˆ°

::<math>- 2 \pi \int_{9 a^2}^{0} \rho^2 \sqrt{t}\, \mathrm{d}t</math>

:å› ä¸º<math>\rho^2 = 9 a^2 - t\,\!</math>ï¼Œæ‰€ä»¥

::<math>-2 \pi \int_{9 a^2}^0 (9 a^2 - t) \sqrt{t}\, \mathrm{d}t,</math>

:å°†ç§¯åˆ†é™åè¿‡æ¥ï¼Œç„¶ååˆ†é…æ‹¬å·ä¸­çš„é¡¹ï¼Œå¾ˆå®¹æ˜“å°†ç§¯åˆ†åˆ†è§£ä¸ºå¯ä»¥ç›´æ¥ç§¯åˆ†çš„ä¸¤éƒ¨åˆ†ï¼š

::<math>2 \pi \left[ \int_0^{9 a^2} 9 a^2 \sqrt{t} \, \mathrm{d}t - \int_0^{9 a^2} t \sqrt{t} \, \mathrm{d}t\right] = 2 \pi \left[9 a^2 \frac{2}{3} t^{ \frac{3}{2} } - \frac{2}{5} t^{ \frac{5}{2}} \right]_0^{9 a^2}</math>

::<math>= 2 \cdot 27 \pi a^5 \left ( 6 - \frac{18}{5} \right ) = \frac{648 \pi}{5} a^5.</math>

:ç”±äºé‡‡ç”¨æŸ±æåæ ‡ï¼Œå¾ˆå®¹æ˜“å°±å°†è¿™ä¸ªä¸‰é‡ç§¯åˆ†å˜æ¢ä¸ºç®€å•çš„å•å˜é‡ç§¯åˆ†ã€‚</blockquote>

å‚çœ‹æŸ±æå’Œçƒæåæ ‡ä¸‹çš„âˆ‡ä¸­è®¨è®ºçš„ä¸åŒçš„ä½“ç§¯å…ƒã€‚

* çº¿æ€§ä»£æ•°

** å…¬ç†
** å®šä¹‰
*** dot product
the dot product or inner product of $\mathbf{v}
=(v_1,v_2)$and$\mathbf{w}=(w_1,w_2)$is the number $\mathbf{v} \cdot \mathbf{w} = v_1w_1+v_2w_2$.
*** cross product(external product)
The cross product is defined by the formula: $\mathbf{a} \times \mathbf{b} = \| \mathbf{a} \| \| \mathbf{b} \| \sin(\theta) \, \mathbf{n}$

** å®šç†

*** ç‚¹ç§¯ä¸ºé›¶è¡¨ç¤ºä¸¤ä¸ªå‘é‡å‚ç›´.
\begin{proof}
  \begin{figure}[H] %Hä¸ºå½“å‰ä½ç½®ï¼Œ!htbä¸ºå¿½ç•¥ç¾å­¦æ ‡å‡†ï¼Œhtbpä¸ºæµ®åŠ¨å›¾å½¢
    \centering %å›¾ç‰‡å±…ä¸­
    \includegraphics[width=0.7\textwidth]{images/math/1.jpg} %æ’å…¥å›¾ç‰‡ï¼Œ[]ä¸­è®¾ç½®å›¾ç‰‡å¤§å°ï¼Œ{}ä¸­æ˜¯å›¾ç‰‡æ–‡ä»¶å
    % \caption{Main name 2} %æœ€ç»ˆæ–‡æ¡£ä¸­å¸Œæœ›æ˜¾ç¤ºçš„å›¾ç‰‡æ ‡é¢˜
    % \label{Fig.main2} %ç”¨äºæ–‡å†…å¼•ç”¨çš„æ ‡ç­¾
  \end{figure}
  ç”±äºä¸¤ä¸ªå‘é‡ç»„æˆäº†ç›´è§’ä¸‰è§’å½¢,ç”±å‹¾è‚¡å®šç†å¯çŸ¥æ–œè¾¹é•¿çš„å¹³æ–¹
  ä¸º$v_1^2+v_2^2+w_1^2+w_2^2$. ç”±äºçŸ©å½¢çš„ä¸¤ä¸ªå¯¹è§’çº¿ç›¸ç­‰,æ‰€ä»¥è¯¥æ–œè¾¹é•¿ç­‰äºå¦ä¸€ä¸ªå¯¹è§’
  çº¿çš„é•¿åº¦. å¦ä¸€ä¸ªå¯¹è§’çº¿çš„ç»ˆç‚¹åæ ‡
  ä¸º$(v_1+w_1,v_2+w_2)$,æ‰€ä»¥$v_1^2+v_2^2+w_1^2+w_2^2=(v_1+w_1)^2+(v_2+w_2)^2$,åŒ–ç®€
  å³å¯å¾—$v_1w_1+v_2w_2=0$. $v_1$	
\end{proof}

* æ¦‚ç‡è®º
** å…¬ç†
** å®šä¹‰
** å®šç†
*** æ ·æœ¬å‡å€¼çš„æœŸæœ›ç­‰äºæ€»ä½“çš„æœŸæœ›.
\begin{proof}
$x_1,x_2,x_3,...,x_n$ ä¸æ€»ä½“Xæ˜¯åŒåˆ†å¸ƒçš„ï¼Œæ‰€ä»¥å„æ ·æœ¬çš„æœŸæœ›å‡ä¸ºæ€»ä½“æœŸæœ›ã€‚

$E(\bar{X})=E(\frac{1}{n}\sum_{i=1}^{n}x_{i})=\frac{1}{n}\sum_{i=1}^{n}E(x_{i})=\frac{1}{n}\cdot n\cdot E(X)=\mu $
\end{proof}
*** $S^2=\frac{1}{n-1}\sum_{i=1}^n(X_i-\overline{X})^2$ æ˜¯æ ·æœ¬æ–¹å·®çš„æ— åä¼°è®¡.

\begin{proof}
æ–¹å·®æ— åä¼°è®¡çš„æ¨ç®—:

\begin{aligned}
\operatorname{E}[S^{2}]& =\mathrm{E}\left[\frac{1}{n}\sum_{i=1}^{n}\left(X_{i}-\overline{X}\right)^{2}\right]=\mathrm{E}\left[\frac{1}{n}\sum_{i=1}^{n}\left((X_{i}-\mu)-(\overline{X}-\mu)\right)^{2}\right] \\
&=\mathrm{E}\left[\frac{1}{n}\sum_{i=1}^{n}\left((X_{i}-\mu)^{2}-2(\overline{X}-\mu)(X_{i}-\mu)+(\overline{X}-\mu)^{2}\right)\right] \\
&=\mathrm{E}\left[\frac{1}{n}\sum_{i=1}^{n}(X_{i}-\mu)^{2}-\frac{2}{n}(\overline{X}-\mu)\sum_{i=1}^{n}(X_{i}-\mu)+\frac{1}{n}(\overline{X}-\mu)^{2}\sum_{i=1}^{n}1\right] \\
&=\mathrm{E}\left[\frac{1}{n}\sum_{i=1}^{n}(X_{i}-\mu)^{2}-\frac{2}{n}(\overline{X}-\mu)\sum_{i=1}^{n}(X_{i}-\mu)+\frac{1}{n}(\overline{X}-\mu)^{2}\cdot n\right] \\
&=\mathrm{E}\left[\frac{1}{n}\sum_{i=1}^{n}(X_{i}-\mu)^{2}-\frac{2}{n}(\overline{X}-\mu)\sum_{i=1}^{n}(X_{i}-\mu)+(\overline{X}-\mu)^{2}\right] \\
&=\mathrm{E}\left[\frac1n\sum_{i=1}^n(X_i-\mu)^2-\frac2n(\overline{X}-\mu)\cdot n\cdot(\overline{X}-\mu)+(\overline{X}-\mu)^2\right] \\
&=\mathrm{E}\left[\frac{1}{n}\sum_{i=1}^{n}(X_{i}-\mu)^{2}-2(\overline{X}-\mu)^{2}+(\overline{X}-\mu)^{2}\right] \\
&=\operatorname{E}\left[\frac1n\sum_{i=1}^n(X_i-\mu)^2-(\overline{X}-\mu)^2\right] \\
&=\operatorname{E}\left[\frac1n\sum_{i=1}^n(X_i-\mu)^2\right]-\operatorname{E}\left[(\overline{X}-\mu)^2\right] \\
&=\sigma^2-\mathrm{E}\Big[(\overline{X}-\mu)^2\Big]
\end{aligned}

\begin{aligned}
E(\bar{X}-\mu)^2& =E(\bar{X}-E[\bar{X}])^2=var(\bar{X}) \\
&=var\left(\frac{\sum_{i=1}^nX_i}n\right) \\
&=\frac1{n^2}var\left(\sum_{i=1}^nX_i\right) \\
&=\frac1{n^2}\sum_{i=1}^nvar\left(X_i\right) \\
&=\frac{n\sigma^2}{n^2} \\
&=\frac{\sigma^2}n
\end{aligned}

$E[\frac{1}{n}\sum_{i=1}^n(X_i-\overline{X})^2]=\sigma^2-\frac{1}{n}\sigma^2=\frac{n-1}{n}\sigma^2$
\end{proof}

å³ä¸‹å¼æ˜¯å¯¹æ–¹å·®çš„æ— åä¼°è®¡:

$\mathrm{E}\left[\frac{1}{n-1}\sum_{i=1}^{n}\left(X_{i}-\overline{X}\right)^{2}\right]
=\mathrm{E}\left[\frac{n}{n-1}\frac{1}{n}\sum_{i=1}^{n}\left(X_{i}-\overline{X}\right)^{2}\right]
=\frac{n}{n-1}\frac{n-1}{n}\sigma^2
=\sigma^2$

** æ­£æ€åˆ†å¸ƒ

*** æ¨å¯¼
å‚è€ƒ:[[https://math.stackexchange.com/questions/384893/how-was-the-normal-distribution-derived][statistics - How was the normal distribution derived? - Mathematics Stack Exchange]]

Theorem: **Two identically distributed independent random variables** follow a distribution, called the *normal distribution,* given that their probability density functions (PDFs) are known to be continuous and differentiable, symmetric about a mean, and decrease towards zero away from the mean. 

Proof: Let $X$ and $Y$ be identically distributed independent random variables with continuous and differentiable PDFs. It is assumed that the PDFs are even functions, for example $f_X(x) = f_X(-x)$, and $f_X(x) \rightarrow 0 \text{ as } x\rightarrow \pm \infty$.  

Their joint PDF, because of their independence, is $f_{XY}(x,y) = f_X(x)f_Y(y)$. Because they are identically distributed and symmetric, only the *norm* or magnitude of the two variables is unique - that is, $x$ and $y$ can be interchanged with no effect on the final probability. They are identically distributed and symmetric, figuratively related to a circle, as opposed to the unequally distributed oval. Therefore, there must exist a function $g(r)$ such that
$$ f_{XY}(x,y) = g(\sqrt{x^2 + y^2}) $$
Which, because $g$ is not yet determined, is equivalent to
$$ f_{XY}(x,y) = g(x^2 + y^2). $$

From the definition of the joint distribution,
$$ f_X(x)f_Y(y) = g(x^2 + y^2). $$
Which, for $y=0$, gives
$$ f_X(x) \propto g(x^2). $$
Assuming $f_Y(0)$ is a constant. Similar argument gives
$$ f_Y(y) \propto g(y^2). $$
These last two results are significant, because substitution shows that the product of $g(x^2)g(y^2)$ is proportional to the sum $g(x^2 + y^2)$:
$$ g(x^2)g(y^2) \propto g(x^2 + y^2) $$
And it is known from algebra that the only function to have this property is the exponential function (and the natural logarithm). 

This is to say, $g(r)$ will be some type of exponential, 
$$ g(r) = Ae^{Br} .$$
Where $A$ and $B$ are constants yet to be determined. We assume, now, that wherever the expected value is, the probability of error away from this expected value will decrease. That is to say, we expect that the chance of error should be minimum near the expected value, and decrease to zero away from this value. Another way of saying this is that the mean must be the maximum of $g(r)$, and yet another way of saying this is that $g(r)$ must approach $0$ as $r\rightarrow \pm \infty$. In any case, we need the argument to the exponential to be negative. 
$$ g(r) = Ae^{-Br} $$

Now if we return to our joint PDF, 
$$ f_{XY}(x,y) = f_X(x)f_Y(y) = g(x^2 + y^2) $$
Here again, we can investigate the PDF of $f_X(x)$ alone by setting $y=0$,
$$ f_X(x) \propto g(x^2) = A e^{-Bx^2} $$
Note that the mean of this distribution is $0$. In order to give a mean of $\mu$, this distribution becomes
$$ f_X(x) \propto A e^{-B(x-\mu)^2} .$$

The constants are determined from the fact that the integral of the PDF $f_{X}(x)$ must be equal to 1 for the entire domain. That is, the cumulative distribution function (CDF) must approach 1 at the upper limit (probability cannot be >100%). 
$$ \int_{0}^{\infty} f_{X}(x) dx = 1 $$
The integral of $e^{-Bx^2}$ is $\sqrt{\frac{\pi}{B}}$, thus
$$ A \int_0^\infty e^{-Bx^2} dx = A \sqrt{\frac{\pi}{B}} = 1$$
$$ A = \sqrt{\frac{B}{\pi}} $$
The constant $B$ is, for convenience, substituted by $\sigma^2 = \frac{1}{2B}$, so that $A = \frac{1}{\sqrt{2\pi\sigma^2}}$ and
$$ f_X(x) = \frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{(x-\mu)^2}{2\sigma^2}} .$$
Which is, of course, the common form of what is known as the Normal distribution. Note that the proportional symbol became an equals sign, which is necessary from the assumption that $X$ is a random variable, and all random variables have a PDF which integrates to $1$. This proves the theorem.

One will find that $\sigma^2$ is called the variation, and $\sigma$ is the standard deviation. The parameters $\sigma^2$ and $\mu$, that is, the variation and the mean, may be chosen arbitrarily, and uniquely define the distribution. 
