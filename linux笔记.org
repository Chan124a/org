* apt
** 查看已安装软件
apt-get 命令 没有类似列出已安装软件包的简单的选项，但是 apt 有一个这样的命令：
#+begin_src bash
apt list --installed
#+END_SRC
这个会显示使用 apt 命令安装的所有的软件包。同时也会包含由于依赖而被安装的软件包。也就是说不仅会包含你曾经安装的程序，而且会包含大量库文件和间接安装的软件包。

apt 和 apt-get 命令都是基于 dpkg。也就是说用 dpkg 命令可以列出 Debian 系统的所有已经安装的软件包。
#+begin_src bash
dpkg-query -l
#+END_SRC
*** 参考文章
[[https://zhuanlan.zhihu.com/p/57472336][https://zhuanlan.zhihu.com/p/57472336]]
** apt-cache
1.apt-cache showpkg
显示软件包的一些常规信息
例: apt-cache showpkg openssh

2.apt-cache stats
显示相关的统计信息顯示相關的統計資訊

3.apt-cache dump
显示缓存中的每个软件包的简要描述信息

4.apt-cache unmet
显示不符合一致性的依赖关系

5.apt-cache show
显示指定软件包的记录信息。类似于rpm -qi

6.apt-cache search
查找软件包，类似于rpm -qa|grep package_name
例: apt-cache search openssh

7.apt-cache depends
显示软件包的依赖性关系

8.apt-cache pkgnames
列出所有的软件包

** 查看软件所有版本
这个方法还是比较多的，基本上都可以列举出软件的所有版本号。不过列举出来的都是在当前系统版本下可以安装的版本，比如适用于 Ubuntu 16.04 LTS 的软件版本就不会出现在 Ubuntu 18.04 LTS 的查询结果中。

1、使用 madison 命令

apt-cache madison <<package name>>
将列出所有来源的版本。如下输出所示：

apt-cache madison vim
   vim | 2:7.3.547-1 | http://debian.mirrors.tds.net/debian/ unstable/main amd64 Packages
   vim | 2:7.3.429-2 | http://debian.mirrors.tds.net/debian/ testing/main amd64 Packages
   vim | 2:7.3.429-2 | http://http.us.debian.org/debian/ testing/main amd64 Packages
   vim | 2:7.3.429-2 | http://debian.mirrors.tds.net/debian/ testing/main Sources
   vim | 2:7.3.547-1 | http://debian.mirrors.tds.net/debian/ unstable/main Sources
madison 是一个 apt-cache 子命令，可以通过 man apt-cache 查询更多用法。

2、使用 policy 命令

apt-cache policy <<package name>>
将列出所有来源的版本。信息会比上面详细一点，如下输出所示：

apt-cache policy gdb
gdb:
  Installed: 7.7.1-0ubuntu5~14.04.2
  Candidate: 7.7.1-0ubuntu5~14.04.2
  Version table:
 *** 7.7.1-0ubuntu5~14.04.2 0
        500 http://fr.archive.ubuntu.com/ubuntu/ trusty-updates/main amd64 Packages
        100 /var/lib/dpkg/status
     7.7-0ubuntu3 0
        500 http://fr.archive.ubuntu.com/ubuntu/ trusty/main amd64 Packages
        500 http://archive.ubuntu.com/ubuntu/ trusty/main amd64 Packages
policy 是一个 apt-cache 子命令，可以通过 man apt-cache 查询更多用法。

3、使用 showpkg 命令

apt-cache showpkg <<package name>>
4、使用 install 命令

apt-get install -s <<package-name>>
说明：这个命令只是模拟安装时会安装哪些软件列表，但不会例举出每个软件有多少个版本

5、使用 aptitude 命令

以上基本都是使用的 apt-cache 的子命令，下面介绍点别的，比如这个使用 aptitude 命令的。

aptitude versions <<package name>>
参考：https://manpages.debian.org/unstable/aptitude/aptitude.8.en.html

6、使用 apt-show-versions 命令

apt-show-versions -a <<package name>>
说明：列举出所有版本，且能查看是否已经安装。还可以通过 apt-show-versions -u <<package name>> 来查询是否有升级版本。

参考：http://manpages.ubuntu.com/manpages/trusty/man1/apt-show-versions.1p.html

7、使用 whohas 命令

whohas -d Debian,Ubuntu <<package name>> | tr -s ' ' '\t' | cut -f 1-3 | column -t
8、使用 rmadison 命令

rmadison -u debian,ubuntu,bpo <<package name>> | cut -d "|" -f 1-3
*** 参考文章
[[https://oldtang.com/4014.html][Ubuntu 查看软件所有版本以及安装时指定软件版本]]
** apt-get
-y：yes，在命令行交互提示中，直接输入 yes
**** 修改源
1、原文件备份

sudo cp /etc/apt/sources.list /etc/apt/sources.list.bak

2、编辑源列表文件

sudo vim /etc/apt/sources.list

3、将原来的列表删除，添加如下内容

阿里云源
#+BEGIN_EXAMPLE
deb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse
deb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse
deb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse
deb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse
deb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse
#+END_EXAMPLE
清华源 ubuntu18.04
#+BEGIN_EXAMPLE
# 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释
# 若出现no longer has a Release file错误，把https该成http即可
deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic main restricted universe multiverse
# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic main restricted universe multiverse
deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-updates main restricted universe multiverse
# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-updates main restricted universe multiverse
deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-backports main restricted universe multiverse
# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-backports main restricted universe multiverse
deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-security main restricted universe multiverse
# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-security main restricted universe multiverse
#+END_EXAMPLE
清华源 ubuntu 20.04 LTS
#+BEGIN_EXAMPLE
# 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释
deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiverse
# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiverse
deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiverse
# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiverse
deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiverse
# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiverse
deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted universe multiverse
# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted universe multiverse

# 预发布软件源，不建议启用
# deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-proposed main restricted universe multiverse
# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-proposed main restricted universe multiverse
#+END_EXAMPLE
清华源 ubuntu 22.04
#+BEGIN_EXAMPLE
# 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释
deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy main restricted universe multiverse
# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy main restricted universe multiverse
deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-updates main restricted universe multiverse
# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-updates main restricted universe multiverse
deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-backports main restricted universe multiverse
# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-backports main restricted universe multiverse
deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-security main restricted universe multiverse
# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-security main restricted universe multiverse

# 预发布软件源，不建议启用
# deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-proposed main restricted universe multiverse
# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-proposed main restricted universe multiverse
#+END_EXAMPLE
4、更新源

更新软件包列表
sudo apt-get update
**** no longer has a Release file错误的解决方法
 把软件源里的https改成http就行了

 今天我sudo apt-get update遇到了一个
 #+BEGIN_SRC bash
 Hit:1 http://packages.microsoft.com/repos/code stable InRelease
 Ign:2 http://mirrors.tuna.tsinghua.edu.cn/ros/ubuntu bionic InRelease          
 Ign:3 https://mirrors.tuna.tsinghua.edu.cn/ubuntu bionic InRelease             
 Hit:4 http://mirrors.tuna.tsinghua.edu.cn/ros/ubuntu bionic Release            
 Hit:5 http://dl.google.com/linux/chrome/deb stable InRelease                   
 Ign:6 https://mirrors.tuna.tsinghua.edu.cn/ubuntu bionic-updates InRelease     
 Ign:8 https://mirrors.tuna.tsinghua.edu.cn/ubuntu bionic-backports InRelease   
 Ign:9 https://mirrors.tuna.tsinghua.edu.cn/ubuntu bionic-security InRelease    
 Err:10 https://mirrors.tuna.tsinghua.edu.cn/ubuntu bionic Release              
   Certificate verification failed: The certificate is NOT trusted. The certificate chain uses expired certificate.  Could not handshake: Error in the certificate verification. [IP: 101.6.15.130 443]
 Err:11 https://mirrors.tuna.tsinghua.edu.cn/ubuntu bionic-updates Release  
   Certificate verification failed: The certificate is NOT trusted. The certificate chain uses expired certificate.  Could not handshake: Error in the certificate verification. [IP: 101.6.15.130 443]
 Hit:12 http://archive.ubuntu.com/ubuntu bionic InRelease
 Hit:13 http://ppa.launchpad.net/videolan/master-daily/ubuntu bionic InRelease  
 Err:14 https://mirrors.tuna.tsinghua.edu.cn/ubuntu bionic-backports Release    
   Certificate verification failed: The certificate is NOT trusted. The certificate chain uses expired certificate.  Could not handshake: Error in the certificate verification. [IP: 101.6.15.130 443]
 Err:15 https://mirrors.tuna.tsinghua.edu.cn/ubuntu bionic-security Release     
   Certificate verification failed: The certificate is NOT trusted. The certificate chain uses expired certificate.  Could not handshake: Error in the certificate verification. [IP: 101.6.15.130 443]
 Reading package lists... Done                                
 E: The repository 'https://mirrors.tuna.tsinghua.edu.cn/ubuntu bionic Release' no longer has a Release file.
 N: Updating from such a repository can't be done securely, and is therefore disabled by default.
 N: See apt-secure(8) manpage for repository creation and user configuration details.
 E: The repository 'https://mirrors.tuna.tsinghua.edu.cn/ubuntu bionic-updates Release' no longer has a Release file.
 N: Updating from such a repository can't be done securely, and is therefore disabled by default.
 N: See apt-secure(8) manpage for repository creation and user configuration details.
 E: The repository 'https://mirrors.tuna.tsinghua.edu.cn/ubuntu bionic-backports Release' no longer has a Release file.
 N: Updating from such a repository can't be done securely, and is therefore disabled by default.
 N: See apt-secure(8) manpage for repository creation and user configuration details.
 E: The repository 'https://mirrors.tuna.tsinghua.edu.cn/ubuntu bionic-security Release' no longer has a Release file.
 N: Updating from such a repository can't be done securely, and is therefore disabled by default.
 N: See apt-secure(8) manpage for repository creation and user configuration details.
 #+END_SRC
**** Ubuntu换源后，更新提示GPG error缺少公钥
#+BEGIN_EXAMPLE
W: GPG error: http://mirrors.aliyun.com trusty-security InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 40976EAF437D05B5 NO_PUBKEY 3B4FE6ACC0B21F32
W: GPG error: http://mirrors.aliyun.com trusty-updates InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 40976EAF437D05B5 NO_PUBKEY 3B4FE6ACC0B21F32
W: GPG error: http://mirrors.aliyun.com trusty-proposed InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 40976EAF437D05B5 NO_PUBKEY 3B4FE6ACC0B21F32
W: GPG error: http://mirrors.aliyun.com trusty-backports InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 40976EAF437D05B5 NO_PUBKEY 3B4FE6ACC0B21F32
W: GPG error: http://mirrors.aliyun.com trusty Release: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 40976EAF437D05B5 NO_PUBKEY 3B4FE6ACC0B21F32
#+END_EXAMPLE
Solution
#+begin_src bash
apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 3B4FE6ACC0B21F32
#+END_SRC
**** ubuntu-ports focal 证书过期
解决方法：[[https://github.com/tuna/issues/issues/1342]]、[[https://letsencrypt.org/docs/dst-root-ca-x3-expiration-september-2021/]]

先使用 http 源，然后再执行 apt upgrade 更新 ca-certificates 即可解决。
**** apt-get彻底卸载软件包
apt-get的卸载相关的命令有remove/purge/autoremove/clean/autoclean等。具体来说：

apt-get purge / apt-get --purge remove
删除已安装包（不保留配置文件)。
如软件包a，依赖软件包b，则执行该命令会删除a，而且不保留配置文件

apt-get autoremove
删除为了满足依赖而安装的，但现在不再需要的软件包（包括已安装包），保留配置文件。

apt-get remove
删除已安装的软件包（保留配置文件），不会删除依赖软件包，且保留配置文件。

apt-get autoclean
APT的底层包是dpkg, 而dpkg 安装Package时, 会将 *.deb 放在 /var/cache/apt/archives/中，apt-get autoclean 只会删除 /var/cache/apt/archives/ 已经过期的deb。

apt-get clean
使用 apt-get clean 会将 /var/cache/apt/archives/ 的 所有 deb 删掉，可以理解为 rm /var/cache/apt/archives/*.deb。

那么如何彻底卸载软件呢？

具体来说可以运行如下命令：
#+begin_src bash
# 删除软件及其配置文件
apt-get --purge remove <package>
# 删除没用的依赖包
apt-get autoremove <package>
# 此时dpkg的列表中有“rc”状态的软件包，可以执行如下命令做最后清理：
dpkg -l |grep ^rc|awk '{print $2}' |sudo xargs dpkg -P
#+END_SRC
***** 参考文章
[[https://blog.csdn.net/get_set/article/details/51276609][Ubuntu apt-get彻底卸载软件包]]
** apt-key
apt-key命令用于管理Debian Linux系统中的软件包密钥。

每个发布的deb包，都是通过密钥认证的，apt-key用来管理密钥。

用法：apt-key [--keyring file] [command] [arguments]

参数：
- apt-key add <file>          - 把下载的key添加到本地trusted数据库中
- apt-key del <keyid>         - 从本地trusted数据库通过keyid删除key
- apt-key export <keyid>      - 通过keyid导出key
- apt-key exportall           - 导出本地trusted数据库中的所有key
- apt-key update              - 通过key包来更新key,更新本地trusted数据库，删除过期没用的key
- apt-key net-update          - 通过网络更新key
- apt-key list                - 列出已保存在系统中key
- apt-key finger              - 列出所有验证指纹
- apt-key adv                 - 设置key的高级配置, Pass advanced options to gpg
** The following signatures were invalid
To find any expired repository keys and their IDs, use apt-key as follows:

  apt-key list | grep expired

You will get a result similar to the following:

  pub   4096R/BE1DB1F1 2011-03-29 [expired: 2014-03-28]

The key ID is the bit after the / i.e. BE1DB1F1 in this case.

To update the key, run

  sudo apt-key adv --recv-keys --keyserver keys.gnupg.net BE1DB1F1
*** 参考文章
1. [[https://stackoverflow.com/questions/29070471/gpg-error-http-archive-debian-org-lenny-updates-release-the-following-signat#][GPG error: http://archive.debian.org lenny/updates Release: The following signatures were invalid: KEYEXPIRED 1356982504]]
2. [[https://blog.csdn.net/qq_41538587/article/details/90260913][apt-get update报错：Release: The following signatures were invalid: KEYEXPIRED 1544811256]]

* Anaconda
Anaconda（官方网站）就是可以便捷获取包且对包能够进行管理，同时对环境可以统一管理的发行版本。Anaconda包含了conda、Python在内的超过180个科学包及其依赖项。如果日常工作或学习并不必要使用1,000多个库，那么可以考虑安装Miniconda
** Anaconda、conda、pip、virtualenv的区别
*** Anaconda
Anaconda是一个包含180+的科学包及其依赖项的发行版本。其包含的科学包包括：conda, numpy, scipy, ipython notebook等。
*** conda
conda是包及其依赖项和环境的管理工具。

- 适用语言：Python, R, Ruby, Lua, Scala, Java, JavaScript, C/C++, FORTRAN。

- 适用平台：Windows, macOS, Linux

- 用途：

(1)快速安装、运行和升级包及其依赖项。

(2)在计算机中便捷地创建、保存、加载和切换环境。

如果你需要的包要求不同版本的Python，你无需切换到不同的环境，因为conda同样是一个环境管理器。仅需要几条命令，你可以创建一个完全独立的环境来运行不同的Python版本，同时继续在你常规的环境中使用你常用的Python版本。——Conda官方网站
▪ conda为Python项目而创造，但可适用于上述的多种语言。

▪ conda包和环境管理器包含于Anaconda的所有版本当中。

** conda
Python的版本比较多，并且它的库也非常广泛，同时库和库之间存在很多依赖关系，所以在库的安装和版本的管理上很麻烦。Conda是一个管理版本和Python环境的工具.
*** 源（channels）管理
**** 显示所有channel
#+BEGIN_SRC bash
conda config --show #显示出所有conda的config信息。
conda config --show channels #只看channels的信息
#+END_SRC
**** 增加源
#+BEGIN_SRC bash
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/
conda config --set show_channel_urls yes  # 设置搜索时显示通道地址，这样就可以知道包的安装来源了。
#+END_SRC
添加完后，找到 .condarc 文件，删除里面的 defaults，这样能快点。当第一次执行 ~conda config~ 时，会生成配置文件.condarc


1、切换为清华源
#+BEGIN_SRC python
conda config --add channels http://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/   
conda config --add channels http://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge 
conda config --add channels http://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/
conda config --add channels http://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/ 
# 设置搜索时显示通道地址
conda config --set show_channel_urls yes
#+END_SRC
镜像源地址由https改为http可以避免一些安装库时发生的错误
2、切换为中科大源
#+BEGIN_SRC python
conda config --add channels https://mirrors.ustc.edu.cn/anaconda/pkgs/main/
conda config --add channels https://mirrors.ustc.edu.cn/anaconda/pkgs/free/
conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/conda-forge/
conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/msys2/
conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/bioconda/
conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/menpo/
conda config --set show_channel_urls yes
#+END_SRC
3、切换回默认源
#+BEGIN_SRC python
conda config --remove-key channels
#+END_SRC
**** 移除镜像
#+BEGIN_SRC bash
conda config --remove channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/  #这个命令是为了移除之前conda config --show channels显示的清华源。
#+END_SRC
*** Conda的环境管理
**** 创建环境
 #+BEGIN_SRC bash
 #创建一个名为py35的环境，指定Python版本是3.5（不用管是3.5.x，conda会为我们自动寻找3.５.x中的最新版本）
 conda create --name py35 python=3.5
 #+END_SRC

**** 激活环境
 #+BEGIN_SRC bash
 # 安装好后，使用activate激活某个环境
 activate py35 # for Windows
 source activate py35 # for Linux & Mac
 (py35) user@user-XPS-8920:~$
 #激活后，会发现terminal输入的地方多了py35的字样，实际上，此时系统做的事情就是把默认2.7环境从PATH中去除，再把3.4对应的命令加入PATH
 #+END_SRC

**** 返回主环境
 #+BEGIN_SRC bash
 # 如果想返回默认的python 2.7环境，运行
 deactivate py35 # for Windows
 source deactivate py35 # for Linux & Mac
 #+END_SRC

**** 删除环境
 #+BEGIN_SRC bash
 # 删除一个已有的环境
 conda remove --name py35 --all
 #+END_SRC
删除后将目录 anaconda3/envs下的环境文件夹删除
**** 复制（克隆）环境
conda本身的命令里是有移植这个选项的。 

假如前提是，在本地的conda里已经有一个AAA的环境，我想创建一个新环境跟它一模一样的叫BBB，那么这样一句就搞定了：

~conda create -n BBB --clone AAA~

但是如果是跨计算机呢。其实是一样的。

查询conda create命令的原来说明，是这样的：
#+BEGIN_EXAMPLE
–clone ENV 
Path to (or name of) existing local environment.
#+END_EXAMPLE
–clone这个参数后面的不仅可以是环境的名字，也可以是环境的路径。
**** 查看系统中的所有环境
 用户安装的不同Python环境会放在~/anaconda/envs目录下。

 查看当前系统中已经安装了哪些环境，使用:
 #+BEGIN_SRC bash
 conda info -e
 #+END_SRC
*** Conda的包管理
**** 安装库
 为当前环境安装库
 #+BEGIN_SRC bash
 conda install numpy
 # conda会从从远程搜索numpy的相关信息和依赖项目
 #+END_SRC
**** 查看已经安装的库
 #+BEGIN_SRC bash
 # 查看已经安装的packages
 conda list
 # 最新版的conda是从site-packages文件夹中搜索已经安装的包，可以显示出通过各种方式安装的包
 #+END_SRC
**** 查看某个环境的已安装包
 #+BEGIN_SRC bash
 # 查看某个指定环境的已安装包
 conda list -n py35
 #+END_SRC
**** 搜索package的信息
 #+BEGIN_SRC bash
 # 查找package信息
 conda search numpy
 #+END_SRC
**** 安装package到指定的环境
 #+BEGIN_SRC bash
 # 安装package
 conda install -n py35 numpy
 # 如果不用-n指定环境名称，则被安装在当前活跃环境
 # 也可以通过-c指定通过某个channel安装
 #+END_SRC
**** 更新package
 #+BEGIN_SRC bash
 # 更新package
 conda update -n py35 numpy
 #+END_SRC
**** 删除package
#+BEGIN_SRC bash
# 删除package
conda uninstall xxx   #卸载xxx文件包
#+END_SRC
**** 删除没用的包
#+BEGIN_SRC python
conda clean [-h] [-a] [-i] [-p] [-t] [-f]
                   [-c TEMPFILES [TEMPFILES ...]] [-d] [--json] [-q] [-v] [-y]
#+END_SRC
***** Removal Targets
-a, --all
Remove index cache, lock files, unused cache packages, and tarballs.

-i, --index-cache
Remove index cache.

-p, --packages
Remove unused packages from writable package caches. WARNING: This does not check for packages installed using symlinks back to the package cache.

-t, --tarballs
Remove cached package tarballs.

-f, --force-pkgs-dirs
Remove all writable package caches. This option is not included with the --all flag. WARNING: This will break environments with packages installed using symlinks back to the package cache.

-c, --tempfiles
Remove temporary files that could not be deleted earlier due to being in-use. Argument is path(s) to prefix(es) where files should be found and removed.
***** Output, Prompt, and Flow Control Options
-d, --dry-run
Only display what would have been done.

--json
Report all output as json. Suitable for using conda programmatically.

-q, --quiet
Do not display progress bar.

-v, --verbose
Can be used multiple times. Once for INFO, twice for DEBUG, three times for TRACE.

-y, --yes
Do not ask for confirmation.

Examples:

conda clean --tarballs
**** 更新conda
#+BEGIN_SRC bash
# 更新conda，保持conda最新
conda update conda
#+END_SRC
**** 更新anaconda
#+BEGIN_SRC bash
# 更新anaconda
conda update anaconda
#+END_SRC
**** 更新python
 #+BEGIN_SRC bash
 #假设当前环境是python 3.5, conda会将python升级为3.5.x系列的当前最新版本
 conda update python
 #+END_SRC
**** 批量导出、安装库
conda批量导出包含环境中所有组件的requirements.txt文件
#+BEGIN_SRC python
conda list -e > requirements.txt
#+END_SRC
conda批量安装requirements.txt文件中包含的组件依赖
#+BEGIN_SRC python
conda install --yes --file requirements.txt
#+END_SRC

*** 安装requirement.txt指定的依赖包
1. 生成requirement.txt文件
#+begin_src python
pip freeze > requirements.txt
#+END_SRC
安装requirement.txt文件依赖
#+begin_src python
pip install -r requirements.txt
#+END_SRC
2. 除了使用pip命令来生成及安装requirement.txt文件以外，也可以使用conda命令来安装。
#+begin_src python
conda install --yes --file requirements.txt
#+END_SRC
但是这里存在一个问题，如果requirements.txt中的包不可用，则会抛出“无包错误”。

使用下面这个命令可以解决这个问题
#+begin_src bash
$ while read requirement; do conda install --yes $requirement; done < requirements.txt
#+END_SRC
如果想要在conda命令无效时使用pip命令来代替，那么使用如下命令：
#+begin_src bash
$ while read requirement; do conda install --yes $requirement || pip install $requirement; done < requirements.txt
#+END_SRC

**** 参考文章
[[https://blog.csdn.net/Mao_Jonah/article/details/89502380][使用conda安装requirement.txt指定的依赖包]]
** 使用国内镜像源安装pytorch
先设置镜像源，如清华的conda镜像
#+BEGIN_SRC python
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge 
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/
conda config --set show_channel_urls yes
#+END_SRC
官方安装的命令是(版本1.6 CPU)：
#+BEGIN_SRC bash
conda install pytorch torchvision cpuonly -c pytorch
#+END_SRC
但要用国内源，我发现不能用-c这一段，直接用
#+BEGIN_SRC bash
conda install pytorch torchvision cpuonly
#+END_SRC

** 卸载Anaconda要点
1. 安装 Anaconda-Clean package
打开 Anaconda Prompt， 输入如下命令：

conda install anaconda-clean

2. 输入如下命令卸载

anaconda-clean --yes

3. 删除整个anaconda目录：
由于Anaconda的安装文件都包含在一个目录中，所以直接将该目录删除即可。到包含整个anaconda目录的文件夹下，删除整个Anaconda目录：
rm -rf anaconda文件夹名

4. 建议——清理下.bashrc中的Anaconda路径：
#+BEGIN_EXAMPLE
1.到根目录下，打开终端并输入：
sudo gedit ~/.bashrc
2.在.bashrc文件末尾用#号注释掉之前添加的路径(或直接删除)：
#export PATH=/home/lq/anaconda3/bin:$PATH
保存并关闭文件
3.使其立即生效，在终端执行：
source ~/.bashrc
#+END_EXAMPLE


5. 关闭终端，然后再重启一个新的终端，这一步很重要，不然在原终端上还是绑定有anaconda.


** 解决 conda install failed: conda.core.subdir_data.Response304ContentUnchanged
问题产生：

在install pkgs时，报错

Collecting package metadata (current_repodata.json): failed

具体为：

conda.core.subdir_data.Response304ContentUnchanged

 

解决：
works for me.
#+BEGIN_SRC bash
conda clean -i
#+END_SRC


清空cache后重新安装

suggestion from Github
#+BEGIN_SRC bash
conda config --remove channels conda-forge
#+END_SRC

疑似 forge 源出了问题
* awk
** 简介
awk是一个强大的文本分析工具，相对于grep的查找，sed的编辑，awk在其对数据分析并生成报告时，显得尤为强大。
简单来说awk就是把文件逐行的读入，以空格为默认分隔符将每行切片，切开的部分再进行各种分析处理。

awk有3个不同版本: awk、nawk和gawk，未作特别说明，一般指gawk，gawk 是 AWK 的 GNU 版本。

awk其名称得自于它的创始人 Alfred Aho 、Peter Weinberger 和 Brian Kernighan 姓氏的首个字母。实际上 AWK 的确拥有自己的语言： AWK 程序设计语言 ， 三位创建者已将它正式定义为“样式扫描和处理语言”。它允许您创建简短的程序，这些程序读取输入文件、为数据排序、处理数据、对输入执行计算以及生成报表，还有无数其他的功能。
** 使用方法
awk 'BEGIN{ print "start" } pattern{ commands } END{ print "end" }' file
一个awk脚本通常由：BEGIN语句块、能够使用模式匹配的通用语句块、END语句块3部分组成，这三个部分是可选的。
任意一个部分都可以不出现在脚本中，脚本通常放在单引号 中，例如：
#+begin_src bash
awk 'BEGIN{ i=0 } { i++ } END{ print i }' filename
#+END_SRC
*** awk工作流程
#+begin_src bash
awk 'BEGIN{ commands } pattern{ commands } END{ commands }'

#+END_SRC
第一步：执行BEGIN{ commands }语句块中的语句；

第二步：从文件或标准输入(stdin)读取一行，然后执行pattern{ commands }语句块，它逐行扫描文件，从第一行到最后一行重复这个过程，直到文件全部被读取完毕。

第三步：当读至输入流末尾时，执行END{ commands }语句块。

BEGIN语句块 在awk开始从输入流中读取行 之前 被执行，这是一个可选的语句块，比如变量初始化、打印输出表格的表头等语句通常可以写在BEGIN语句块中。

END语句块 在awk从输入流中读取完所有的行 之后 即被执行，比如打印所有行的分析结果这类信息汇总都是在END语句块中完成，它也是一个可选语句块。

pattern语句块 中的通用命令是最重要的部分，它也是可选的。如果没有提供pattern语句块，则默认执行{ print }，即打印每一个读取到的行，awk读取的每一行都会执行该语句块。

** 选项
- -F fs 指定行中划分数据字段的字段分隔符
- -f file 从指定的文件中读取程序
- -v var=value 定义gawk程序中的一个变量及其默认值
- -mf N 指定要处理的数据文件中的最大字段数
- -mr N 指定数据文件中的最大数据行数
- -W keyword 指定gawk的兼容模式或警告等级
** 模式
模式可以是以下任意一个：
- 正则表达式：使用通配符的扩展集,注意:正则表达式要放在两个/里面
- 关系表达式：使用运算符进行操作，可以是字符串或数字的比较测试。
- 模式匹配表达式：用运算符~（匹配）和!~（不匹配）。
- BEGIN语句块、pattern语句块、END语句块：参见awk的工作原理
** 三种调用方式
1. 命令行方式
dawk [-F  field-separator]  'commands'  input-file(s)

其中，commands 是真正awk命令，[-F域分隔符]是可选的。 input-file(s) 是待处理的文件。

在awk中，文件的每一行中，由域分隔符分开的每一项称为一个域。通常，在不指名-F域分隔符的情况下，默认的域分隔符是空格。

2. shell脚本方式
将所有的awk命令插入一个文件，并使awk程序可执行，然后awk命令解释器作为脚本的首行，一遍通过键入脚本名称来调用。

相当于shell脚本首行的：#!/bin/sh

可以换成：#!/bin/awk

3. 将所有的awk命令插入一个单独文件，然后调用：

awk -f awk-script-file input-file(s)

其中，-f选项加载awk-script-file中的awk脚本，input-file(s)跟上面的是一样的。
** 内置变量
| 属性        | 说明                                |
|-------------+-------------------------------------|
| $0          | 当前记录（作为单个变量）            |
| $1~$n       | 当前记录的第n个字段，字段间由FS分隔 |
| FS          | 输入字段分隔符 默认是空格           |
| NF          | 当前记录中的字段个数，就是有多少列  |
| NR          | 已经读出的记录数，就是行号，从1开始 |
| RS          | 输入的记录他隔符默 认为换行符       |
| OFS         | 输出字段分隔符 默认也是空格         |
| ORS         | 输出的记录分隔符，默认为换行符      |
| ARGC        | 命令行参数个数                      |
| ARGV        | 命令行参数数组                      |
| FILENAME    | 当前输入文件的名字                  |
| IGNORECASE  | 如果为真，则进行忽略大小写的匹配    |
| ARGIND      | 当前被处理文件的ARGV标志符          |
| CONVFMT     | 数字转换格式 %.6g                   |
| ENVIRON     | UNIX环境变量                        |
| ERRNO       | UNIX系统错误消息                    |
| FIELDWIDTHS | 输入字段宽度的空白分隔字符串        |
| FNR         | 当前记录数                          |
| OFMT        | 数字的输出格式 %.6g                 |
| RSTART      | 被匹配函数匹配的字符串首            |
| RLENGTH     | 被匹配函数匹配的字符串长度          |
| SUBSEP      | \034                                |

*** 示例
使用print $NF可以打印出一行中的最后一个字段，使用$(NF-1)则是打印倒数第二个字段，其他以此类推：
#+begin_src bash
echo -e "line1 f2 f3\n line2 f4 f5" | awk '{print $NF}'
f3
f5
echo -e "line1 f2 f3\n line2 f4 f5" | awk '{print $(NF-1)}'
f2
f4
#+END_SRC

**** 打印每一行的第二和第三个字段：
#+begin_src bash
awk '{ print $2,$3 }' filename
#+END_SRC

**** 统计文件中的行数：
#+begin_src bash
awk 'END{ print NR }' filename
#+END_SRC
以上命令只使用了END语句块，在读入每一行的时，awk会将NR更新为对应的行号，当到达最后一行NR的值就是最后一行的行号，所以END语句块中的NR就是文件的行数。

**** 一个每一行中第一个字段值累加的例子：
#+begin_src bash
seq 5 | awk 'BEGIN{ sum=0; print "总和：" } { print $1"+"; sum+=$1 } END{ print "等于"; print sum }' 
总和：
1+
2+
3+
4+
5+
等于
15
#+END_SRC
** 转义序列
#+begin_example
\\ \自身
\$ 转义$
\t 制表符
\b 退格符
\r 回车符
\n 换行符
\c 取消换行
#+end_example
** BEGIN关键字
默认情况下，gawk会从输入中读取一行文本，然后针对该行的数据执行程序脚本。
有时可能需要在处理数据前运行脚本，比如为报告创建标题。
BEGIN关键字就是用来做这个的。它会强制gawk在读取数据前执行BEGIN关键字后指定的程序脚本。
#+begin_src bash
$ cat data3.txt
Line 1
Line 2
Line 3

$ gawk 'BEGIN {print "The data3 File Contents:"}
> {print $0}' data3.txt
The data3 File Contents:
Line 1
Line 2
Line 3
#+END_SRC

** END关键字
与BEGIN关键字类似，END关键字允许你指定一个程序脚本，gawk会在读完数据后执行它。
#+begin_src bash
$ gawk 'BEGIN {print "The data3 File Contents:"}
> {print $0}
> END {print "End of File"}' data3.txt
The data3 File Contents:
Line 1
Line 2
Line 3
End of File
#+END_SRC

** print
当使用不带参数的print时，它就打印当前行.
#+begin_src bash
echo -e "A line 1\nA line 2" | awk 'BEGIN{ print "Start" } { print } END{ print "End" }'
Start
A line 1
A line 2
End
#+END_SRC
当print的参数是以逗号进行分隔时，打印时则以空格作为定界符。
#+begin_src bash
echo | awk '{ var1="v1"; var2="v2"; var3="v3"; print var1,var2,var3; }' 
v1 v2 v3
#+END_SRC
在awk的print语句块中双引号是被当作拼接符使用，例如：
#+begin_src bash
echo | awk '{ var1="v1"; var2="v2"; var3="v3"; print var1"="var2"="var3; }'
v1=v2=v3

#+END_SRC

** 将外部变量值传递给awk
借助 -v选项 ，可以将外部值（并非来自stdin）传递给awk：
#+begin_src bash
VAR=10000
echo | awk -v VARIABLE=$VAR '{ print VARIABLE }'

#+END_SRC
另一种传递外部变量方法：
#+begin_src bash
var1="aaa"
var2="bbb"
echo | awk '{ print v1,v2 }' v1=$var1 v2=$var2

#+END_SRC
当输入来自于文件时使用：
#+begin_src bash
awk '{ print v1,v2 }' v1=$var1 v2=$var2 filename
#+END_SRC
以上方法中，变量之间用空格分隔作为awk的命令行参数跟随在BEGIN、{}和END语句块之后。

** awk运算与判断
awk支持多种运算，这些运算与C语言提供的基本相同。
awk还提供了一系列内置的运算函数（如log、sqr、cos、sin等）和一些用于对字符串进行操作（运算）的函数（如length、substr等等）。
awk也支持条件转移和关系判断.
作为样式匹配，awk还提供了模式匹配表达式~（匹配）和!~（不匹配）。

*** 算术运算符
#+begin_example
运算符	描述
+ -	加，减
\* / &	乘，除与求余
+ - !	一元加，减和逻辑非
^ ***	求幂
++ --	增加或减少，作为前缀或后缀
#+end_example>
例：
#+begin_src bash
awk 'BEGIN{a="b";print a++,++a;}'
0 2
#+END_SRC
注意：所有用作算术运算符进行操作，操作数自动转为数值，所有非数值都变为0
*** 赋值运算符
= += -= *= /= %= ^= **=	赋值语句
例：
#+begin_src bash
a+=5; 等价于：a=a+5; 其它同类
#+END_SRC
*** 逻辑运算符
||	逻辑或
&&	逻辑与

例：
#+begin_src bash
awk 'BEGIN{a=1;b=2;print (a>5 && b<=2),(a>5 || b<=2);}'
0 1

#+END_SRC
*** 正则运算符
~ !~	匹配正则表达式和不匹配正则表达式
^ 行首
$ 行尾
. 除了换行符以外的任意单个字符
\* 前导字符的零个或多个
.* 所有字符
[] 字符组内的任一字符
[^]对字符组内的每个字符取反(不匹配字符组内的每个字符)
^[^] 非字符组内的字符开头的行
[a-z] 小写字母
[A-Z] 大写字母
[a-Z] 小写和大写字母
[0-9] 数字
\< 单词头单词一般以空格或特殊字符做分隔,连续的字符串被当做单词
\> 单词尾
正则需要用 /正则/ 包围住

例：
#+begin_src bash
awk 'BEGIN{a="100testa";if(a ~ /^100*/){print "ok";}}'
ok
#+END_SRC
*** 关系运算符
< <= > >= != ==	关系运算符

例：
#+begin_src bash
awk 'BEGIN{a=11;if(a >= 9){print "ok";}}'
ok
#+END_SRC
注意：> < 可以作为字符串比较，也可以用作数值比较，关键看操作数如果是字符串就会转换为字符串比较。两个都为数字才转为数值比较。字符串比较：按照ASCII码顺序比较。
*** 其它运算符
运算符	描述
$	字段引用
空格	字符串连接符
?:	C条件表达式
in	数组中是否存在某键值

例：
#+begin_src bash
awk 'BEGIN{a="b";print a=="b"?"ok":"err";}'
ok
awk 'BEGIN{a="b";arr[0]="b";arr[1]="c";print (a in arr);}'
0
awk 'BEGIN{a="b";arr[0]="b";arr["b"]="c";print (a in arr);}'
1
#+END_SRC

** 流程控制语句

在linux awk的while、do-while和for语句中允许使用break,continue语句来控制流程走向，也允许使用exit这样的语句来退出。
awk中，流程控制语句，语法结构，与c语言类型。
- break 当 break 语句用于 while 或 for 语句时，导致退出程序循环。
- continue 当 continue 语句用于 while 或 for 语句时，使程序循环移动到下一个迭代。
- next 能能够导致读入下一个输入行，并返回到脚本的顶部。这可以避免对当前输入行执行其他的操作过程。
- exit 语句使主输入循环退出并将控制转移到END,如果END存在的话。如果没有定义END规则，或在END中应用exit语句，则终止脚本的执行。

*** if
#+begin_src bash
if(表达式)
  {语句1}
else if(表达式)
  {语句2}
else
  {语句3}

#+END_SRC
示例:
#+begin_src bash
awk 'BEGIN{
test=100;
if(test>90){
  print "very good";
  }
  else if(test>60){
    print "good";
  }
  else{
    print "no pass";
  }
}'

very good

#+END_SRC
每条命令语句后面可以用; 分号 结尾。

*** while语句
#+begin_src bash
while(表达式)
  {语句}
#+END_SRC
示例：
#+begin_src bash
awk 'BEGIN{
test=100;
total=0;
while(i<=test){
  total+=i;
  i++;
}
print total;
}'
5050

#+END_SRC

*** for循环
for循环有两种格式：

**** 格式1：
#+begin_src bash
for(变量 in 数组)
  {语句}
#+END_SRC
示例：
#+begin_src bash
awk 'BEGIN{
for(k in ENVIRON){
  print k"="ENVIRON[k];
}

}'
TERM=linux
G_BROKEN_FILENAMES=1
SHLVL=1
pwd=/root/text
...
logname=root
HOME=/root
SSH_CLIENT=192.168.1.21 53087 22
#+END_SRC
注：ENVIRON是awk常量，是子典型数组。

**** 格式2：
#+begin_src bash
for(变量;条件;表达式)
  {语句}

#+END_SRC
示例：
#+begin_src bash
awk 'BEGIN{
total=0;
for(i=0;i<=100;i++){
  total+=i;
}
print total;
}'
5050
#+END_SRC

*** do循环
#+begin_src bash
do
{语句} while(条件)
#+END_SRC
例子：
#+begin_src bash
awk 'BEGIN{ 
total=0;
i=0;
do {total+=i;i++;} while(i<=100)
  print total;
}'
5050
#+END_SRC
** 数组
在awk中数组叫做关联数组(associative arrays)。
数组索引（下标）可以是数字和字符串.
awk 中的数组不必提前声明，也不必声明大小。
数组元素用0或空字符串来初始化，这根据上下文而定。
数组下标是从1开始，与C数组不一样。
awk数组是关联数组，只要通过数组引用它的key，就会自动创建改序列(这点类似于c++中的map).
*** 数组定义
数字做数组索引（下标）：
#+begin_src bash
Array[1]="sun"
Array[2]="kai"
#+END_SRC
字符串做数组索引（下标）：
#+begin_src bash
Array["first"]="www"
Array"[last"]="name"
Array["birth"]="1987"
#+END_SRC
使用中print Array[1]会打印出sun；
使用print Array[2]会打印出kai；
使用print["birth"]会得到1987。
*** length
length返回字符串以及数组长度，split进行分割字符串为数组，也会返回分割得到数组长度。
#+begin_src bash
awk 'BEGIN{info="it is a test";lens=split(info,tA," ");print length(tA),lens;}'
4 4

#+END_SRC
*** asort
asort对数组进行排序，返回数组长度。

#+begin_src bash
awk 'BEGIN{info="it is a test";split(info,tA," ");print asort(tA);}'
4
#+END_SRC
*** 判断键值存在以及删除键值：
#+begin_src bash
# 错误的判断方法：
awk 'BEGIN{tB["a"]="a1";tB["b"]="b1";if(tB["c"]!="1"){print "no found";};for(k in tB){print k,tB[k];}}' 
no found
a a1
b b1
c

#+END_SRC
以上出现奇怪问题，tB[“c”]没有定义，但是循环时候，发现已经存在该键值，它的值为空，这里需要注意，awk数组是关联数组，只要通过数组引用它的key，就会自动创建改序列。
#+begin_src bash
# 正确判断方法：
awk 'BEGIN{tB["a"]="a1";tB["b"]="b1";if( "c" in tB){print "ok";};for(k in tB){print k,tB[k];}}'  
a a1
b b1
#+END_SRC
if(key in array)通过这种方法判断数组中是否包含key键值。
#+begin_src bash
#删除键值：
awk 'BEGIN{tB["a"]="a1";tB["b"]="b1";delete tB["a"];for(k in tB){print k,tB[k];}}'
b b1
#+END_SRC
delete array[key]可以删除对应数组key的序列值。

二维、多维数组使用
awk的多维数组在本质上是一维数组，更确切一点，awk在存储上并不支持多维数组。awk提供了逻辑上模拟二维数组的访问方式。例如，array[2,4]=1这样的访问是允许的。awk使用一个特殊的字符串SUBSEP(�34)作为分割字段，在上面的例子中，关联数组array存储的键值实际上是2�344。

类似一维数组的成员测试，多维数组可以使用if ( (i,j) in array)这样的语法，但是下标必须放置在圆括号中。类似一维数组的循环访问，多维数组使用for ( item in array )这样的语法遍历数组。与一维数组不同的是，多维数组必须使用split()函数来访问单独的下标分量。

awk 'BEGIN{
for(i=1;i<=9;i++){
  for(j=1;j<=9;j++){
    tarr[i,j]=i*j; print i,"*",j,"=",tarr[i,j];
  }
}
}'
1 * 1 = 1
1 * 2 = 2
1 * 3 = 3
1 * 4 = 4
1 * 5 = 5
1 * 6 = 6 
...
9 * 6 = 54
9 * 7 = 63
9 * 8 = 72
9 * 9 = 81
可以通过array[k,k2]引用获得数组内容。

另一种方法：

awk 'BEGIN{
for(i=1;i<=9;i++){
  for(j=1;j<=9;j++){
    tarr[i,j]=i*j;
  }
}
for(m in tarr){
  split(m,tarr2,SUBSEP); print tarr2[1],"*",tarr2[2],"=",tarr[m];
}
}'
*** 二维、多维数组使用
awk的多维数组在本质上是一维数组，更确切一点，awk在存储上并不支持多维数组。
awk提供了逻辑上模拟二维数组的访问方式。例如，array[2,4]=1这样的访问是允许的。

类似一维数组的成员测试，多维数组可以使用if ( (i,j) in array)这样的语法，但是下标必须放置在圆括号中。
类似一维数组的循环访问，多维数组使用for ( item in array )这样的语法遍历数组。
与一维数组不同的是，多维数组必须使用split()函数来访问单独的下标分量。

#+begin_src bash
awk 'BEGIN{
for(i=1;i<=9;i++){
  for(j=1;j<=9;j++){
    tarr[i,j]=i*j; print i,"*",j,"=",tarr[i,j];
  }
}
}'
1 * 1 = 1
1 * 2 = 2
1 * 3 = 3
1 * 4 = 4
1 * 5 = 5
1 * 6 = 6 
...
9 * 6 = 54
9 * 7 = 63
9 * 8 = 72
9 * 9 = 81
#+END_SRC
** 内置函数
awk内置函数，主要分以下3种类似：算数函数、字符串函数、其它一般函数、时间函数。

*** 算术函数
atan2( y, x )	返回 y/x 的反正切。
cos( x )	返回 x 的余弦；x 是弧度。
sin( x )	返回 x 的正弦；x 是弧度。
exp( x )	返回 x 幂函数。
log( x )	返回 x 的自然对数。
sqrt( x )	返回 x 平方根。
int( x )	返回 x 的截断至整数的值。
rand( )	返回任意数字 n，其中 0 <= n < 1。
srand( [expr] )	将 rand 函数的种子值设置为 Expr 参数的值，或如果省略 Expr 参数则使用某天的时间。返回先前的种子值。

举例说明：
#+begin_src bash
awk 'BEGIN{OFMT="%.3f";fs=sin(1);fe=exp(10);fl=log(10);fi=int(3.1415);print fs,fe,fl,fi;}'
0.841 22026.466 2.303 3
#+END_SRC

OFMT 设置输出数据格式是保留3位小数。

获得随机数：
#+begin_src bash
awk 'BEGIN{srand();fr=int(100*rand());print fr;}'
78
awk 'BEGIN{srand();fr=int(100*rand());print fr;}'
31
awk 'BEGIN{srand();fr=int(100*rand());print fr;}'
41 

#+END_SRC

*** 字符串函数
- gsub( Ere, Repl, [ In ] )	除了正则表达式所有具体值被替代这点，它和 sub 函数完全一样地执行。
- sub( Ere, Repl, [ In ] )	用 Repl 参数指定的字符串替换 In 参数指定的字符串中的由 Ere 参数指定的扩展正则表达式的第一个具体值。sub 函数返回替换的数量。出现在 Repl 参数指定的字符串中的 &（和符号）由 In 参数指定的与 Ere 参数的指定的扩展正则表达式匹配的字符串替换。如果未指定 In 参数，缺省值是整个记录（$0 记录变量）。
- index( String1, String2 )	在由 String1 参数指定的字符串（其中有出现 String2 指定的参数）中，返回位置，从 1 开始编号。如果 String2 参数不在 String1 参数中出现，则返回 0（零）。
- length [(String)]	返回 String 参数指定的字符串的长度（字符形式）。如果未给出 String 参数，则返回整个记录的长度（$0 记录变量）。
- blength [(String)]	返回 String 参数指定的字符串的长度（以字节为单位）。如果未给出 String 参数，则返回整个记录的长度（$0 记录变量）。
- substr( String, M, [ N ] )	返回具有 N 参数指定的字符数量子串。子串从 String 参数指定的字符串取得，其字符以 M 参数指定的位置开始。M 参数指定为将 String 参数中的第一个字符作为编号 1。如果未指定 N 参数，则子串的长度将是 M 参数指定的位置到 String 参数的末尾 的长度。
- match( String, Ere )	在 String 参数指定的字符串（Ere 参数指定的扩展正则表达式出现在其中）中返回位置（字符形式），从 1 开始编号，或如果 Ere 参数不出现，则返回 0（零）。RSTART 特殊变量设置为返回值。RLENGTH 特殊变量设置为匹配的字符串的长度，或如果未找到任何匹配，则设置为 -1（负一）。
- split( String, A, [Ere] )	将 String 参数指定的参数分割为数组元素 A[1], A[2], . . ., A[n]，并返回 n 变量的值。此分隔可以通过 Ere 参数指定的扩展正则表达式进行，或用当前字段分隔符（FS 特殊变量）来进行（如果没有给出 Ere 参数）。除非上下文指明特定的元素还应具有一个数字值，否则 A 数组中的元素用字符串值来创建。
- tolower( String )	返回 String 参数指定的字符串，字符串中每个大写字符将更改为小写。大写和小写的映射由当前语言环境的 LC_CTYPE 范畴定义。
- toupper( String )	返回 String 参数指定的字符串，字符串中每个小写字符将更改为大写。大写和小写的映射由当前语言环境的 LC_CTYPE 范畴定义。
- sprintf(Format, Expr, Expr, . . . )	根据 Format 参数指定的 printf 子例程格式字符串来格式化 Expr 参数指定的表达式并返回最后生成的字符串。

注：Ere都可以是正则表达式。

**** gsub,sub使用
#+begin_src bash
awk 'BEGIN{info="this is a test2010test!";gsub(/[0-9]+/,"!",info);print info}'
this is a test!test!

#+END_SRC
在 info中查找满足正则表达式，/[0-9]+/ 用””替换，并且替换后的值，赋值给info 未给info值，默认是$0

**** 查找字符串（index使用）
#+begin_src bash
awk 'BEGIN{info="this is a test2010test!";print index(info,"test")?"ok":"no found";}'
ok
#+END_SRC
未找到，返回0

**** 正则表达式匹配查找(match使用）

awk 'BEGIN{info="this is a test2010test!";print match(info,/[0-9]+/)?"ok":"no found";}'
ok

**** 截取字符串(substr使用）

[wangsl@centos5 ~]$ awk 'BEGIN{info="this is a test2010test!";print substr(info,4,10);}'
s is a tes
从第 4个 字符开始，截取10个长度字符串

**** 字符串分割（split使用）

awk 'BEGIN{info="this is a test";split(info,tA," ");print length(tA);for(k in tA){print k,tA[k];}}'
4
4 test
1 this
2 is
3 a
分割info，动态创建数组tA，这里比较有意思，awk for …in循环，是一个无序的循环。 并不是从数组下标1…n ，因此使用时候需要注意。

**** 格式化字符串输出（sprintf使用）

格式化字符串格式：

其中格式化字符串包括两部分内容：一部分是正常字符，这些字符将按原样输出; 另一部分是格式化规定字符，以"%"开始，后跟一个或几个规定字符,用来确定输出内容格式。

格式	描述	格式	描述
%d	十进制有符号整数	%u	十进制无符号整数
%f	浮点数	%s	字符串
%c	单个字符	%p	指针的值
%e	指数形式的浮点数	%x	%X 无符号以十六进制表示的整数
%o	无符号以八进制表示的整数	%g	自动选择合适的表示法
awk 'BEGIN{n1=124.113;n2=-1.224;n3=1.2345; printf("%.2f,%.2u,%.2g,%X,%on",n1,n2,n3,n1,n1);}'
124.11,18446744073709551615,1.2,7C,174

*** 一般函数
- close( Expression )	用同一个带字符串值的 Expression 参数来关闭由 print 或 printf 语句打开的或调用 getline 函数打开的文件或管道。如果文件或管道成功关闭，则返回 0；其它情况下返回非零值。如果打算写一个文件，并稍后在同一个程序中读取文件，则 close 语句是必需的。
- system(command )	执行 Command 参数指定的命令，并返回退出状态。等同于 system 子例程。
- Expression | getline [ Variable ]	从来自 Expression 参数指定的命令的输出中通过管道传送的流中读取一个输入记录，并将该记录的值指定给 Variable 参数指定的变量。如果当前未打开将 Expression 参数的值作为其命令名称的流，则创建流。创建的流等同于调用 popen 子例程，此时 Command 参数取 Expression 参数的值且 Mode 参数设置为一个是 r 的值。只要流保留打开且 Expression 参数求得同一个字符串，则对 getline 函数的每次后续调用读取另一个记录。如果未指定 Variable 参数，则 $0 记录变量和 NF 特殊变量设置为从流读取的记录。
- getline [ Variable ] < Expression	从 Expression 参数指定的文件读取输入的下一个记录，并将 Variable 参数指定的变量设置为该记录的值。只要流保留打开且 Expression 参数对同一个字符串求值，则对 getline 函数的每次后续调用读取另一个记录。如果未指定 Variable 参数，则 $0 记录变量和 NF 特殊变量设置为从流读取的记录。
- getline [ Variable ]	将 Variable 参数指定的变量设置为从当前输入文件读取的下一个输入记录。如果未指定 Variable 参数，则 $0 记录变量设置为该记录的值，还将设置 NF、NR 和 FNR 特殊变量。
**** 打开外部文件（close用法）

awk 'BEGIN{while("cat /etc/passwd"|getline){print $0;};close("/etc/passwd");}'
root:x:0:0:root:/root:/bin/bash
bin:x:1:1:bin:/bin:/sbin/nologin
daemon:x:2:2:daemon:/sbin:/sbin/nologin
**** 逐行读取外部文件(getline使用方法）

awk 'BEGIN{while(getline < "/etc/passwd"){print $0;};close("/etc/passwd");}'
root:x:0:0:root:/root:/bin/bash
bin:x:1:1:bin:/bin:/sbin/nologin
daemon:x:2:2:daemon:/sbin:/sbin/nologin
awk 'BEGIN{print "Enter your name:";getline name;print name;}'
Enter your name:
chengmo
chengmo
**** 调用外部应用程序(system使用方法）

awk 'BEGIN{b=system("ls -al");print b;}'
total 42092
drwxr-xr-x 14 chengmo chengmo     4096 09-30 17:47 .
drwxr-xr-x 95 root   root       4096 10-08 14:01 ..
b返回值，是执行结果。
*** 时间函数
- mktime( YYYY MM dd HH MM ss[ DST])	生成时间格式
- strftime([format [, timestamp]])	格式化时间输出，将时间戳转为时间字符串具体格式，见下表。
- systime()	得到时间戳，返回从1970年1月1日开始到当前时间(不计闰年)的整秒数

建指定时间(mktime使用）
awk 'BEGIN{tstamp=mktime("2001 01 01 12 12 12");print strftime("%c",tstamp);}'
2001年01月01日 星期一 12时12分12秒
awk 'BEGIN{tstamp1=mktime("2001 01 01 12 12 12");tstamp2=mktime("2001 02 01 0 0 0");print tstamp2-tstamp1;}'
2634468

求2个时间段中间时间差，介绍了strftime使用方法
awk 'BEGIN{tstamp1=mktime("2001 01 01 12 12 12");tstamp2=systime();print tstamp2-tstamp1;}' 
308201392
strftime日期和时间格式说明符

格式	描述
%a	星期几的缩写(Sun)
%A	星期几的完整写法(Sunday)
%b	月名的缩写(Oct)
%B	月名的完整写法(October)
%c	本地日期和时间
%d	十进制日期
%D	日期 08/20/99
%e	日期，如果只有一位会补上一个空格
%H	用十进制表示24小时格式的小时
%I	用十进制表示12小时格式的小时
%j	从1月1日起一年中的第几天
%m	十进制表示的月份
%M	十进制表示的分钟
%p	12小时表示法(AM/PM)
%S	十进制表示的秒
%U	十进制表示的一年中的第几个星期(星期天作为一个星期的开始)
%w	十进制表示的星期几(星期天是0)
%W	十进制表示的一年中的第几个星期(星期一作为一个星期的开始)
%x	重新设置本地日期(08/20/99)
%X	重新设置本地时间(12:00:00)
%y	两位数字表示的年(99)
%Y	当前月份
%%	百分号(%)
** next:跳过当前记录
awk中next语句使用：在循环逐行匹配，如果遇到next，就会跳过当前行，直接忽略下面语句。而进行下一行匹配。next语句一般用于多行合并：
#+begin_src bash
cat text.txt
a
b
c
d
e

awk 'NR%2==1{next}{print NR,$0;}' text.txt
2 b
4 d
#+END_SRC
当记录行号除以2余1，就跳过当前行。下面的print NR,$0也不会执行。下一行开始，程序又开始判断NR%2值。这个时候记录行号是：2 ，就会执行下面语句块：'print NR,$0'

分析发现需要将包含有“web”行进行跳过，然后需要将内容与下面行合并为一行：
#+begin_src bash
$ cat text.txt
web01[192.168.2.100]
httpd            ok
tomcat               ok
sendmail               ok
web02[192.168.2.101]
httpd            ok
postfix               ok
web03[192.168.2.102]
mysqld            ok
httpd               ok
0
$ awk '/^web/{T=$0;next;}{print T":"t,$0;}' text.txt
web01[192.168.2.100]:   httpd            ok
web01[192.168.2.100]:   tomcat               ok
web01[192.168.2.100]:   sendmail               ok
web02[192.168.2.101]:   httpd            ok
web02[192.168.2.101]:   postfix               ok
web03[192.168.2.102]:   mysqld            ok
web03[192.168.2.102]:   httpd               ok

#+END_SRC
** getline
当其左右无重定向符|或<时： getline作用于当前文件，读入当前文件的第一行给其后跟的变量var或$0（无变量），应该注意到，由于awk在处理getline之前已经读入了一行，所以getline得到的返回结果是隔行的。

当其左右有重定向符|或<时：
getline则作用于定向输入文件，由于该文件是刚打开，并没有被awk读入一行，只是getline读入，那么getline返回的是该文件的第一行，而不是隔行。

#+begin_src bash
# 执行linux的date命令，并通过管道输出给getline，然后再把输出赋值给自定义变量out，并打印它
awk 'BEGIN{ "date" | getline out; print out }' test

# 执行shell的date命令，并通过管道输出给getline，然后getline从管道中读取并将输入赋值给out
# split函数把变量out转化成数组mon，然后打印数组mon的第二个元素：
awk 'BEGIN{ "date" | getline out; split(out,mon); print mon[2] }' test

# 命令ls的输出传递给geline作为输入，循环使getline从ls的输出中读取一行，并把它打印到屏幕。
# 这里没有输入文件，因为BEGIN块在打开输入文件前执行，所以可以忽略输入文件。
awk 'BEGIN{ while( "ls" | getline) print }'
#+END_SRC
** 关闭文件
awk中允许在程序中关闭一个输入或输出文件，方法是使用awk的close语句。
#+begin_src bash
close("filename")
#+END_SRC

filename可以是getline打开的文件，也可以是stdin，包含文件名的变量或者getline使用的确切命令。或一个输出文件，可以是stdout，包含文件名的变量或使用管道的确切命令。

* Aria2
** 安装方法
#+begin_src bash
yum install aria2  #CentOS系统
apt-get install aria2  #Debian/Ubuntu系统
#+END_SRC
** 用法
1、直链下载
下载直链文件，只需在命令后附加地址，如：

aria2c http://xx.com/xx
如果需要重命名为yy的话加上--out或者-o参数，如：

aria2c --out=yy http://xx.com/xx
aria2c -o yy http://xx.com/xx
使用aria2的分段和多线程下载功能可以加快文件的下载速度，对于下载大文件时特别有用。-x 分段下载，-s 多线程下载，如：

aria2c -s 2 -x 2 http://xx.com/xx
这将使用2个连接和2个线程来下载该文件。

2、BT下载
种子和磁力下载：

aria2c ‘xxx.torrnet‘
aria2c '磁力链接'
列出种子内容：

aria2c -S xxx.torrent
下载种子内编号为1、4、5、6、7的文件，如：

aria2c --select-file=1,4-7 xxx.torrent
设置bt端口：

aria2c --listen-port=3653 ‘xxx.torrent’
3、限速下载
单个文件最大下载速度：

aria2c --max-download-limit=300K -s10 -x10 'http://xx.com/xx'
整体下载最大速度：

aria2c --max-overall-download-limit=300k -s10 -x10 'http://xx.com/xx'
这些基本都是常用的几个命令，更多的可以使用man aria2c和aria2c -h查看。
* Axel
这是wget的出色替代者，是一款轻量级下载实用工具。它实际上是个加速器，因为它打开了多路http连接，可下载独立文件片段，因而文件下载起来更快速。
* bash脚本
** 判断表达式
*** 文件判断
以下表达式用来判断文件状态。
- [ -a file ]：如果 file 存在，则为true。
- [ -b file ]：如果 file 存在并且是一个块（设备）文件，则为true。
- [ -c file ]：如果 file 存在并且是一个字符（设备）文件，则为true。
- [ -d file ]：如果 file 存在并且是一个目录，则为true。
- [ -e file ]：如果 file 存在，则为true。
- [ -f file ]：如果 file 存在并且是一个普通文件，则为true。
- [ -g file ]：如果 file 存在并且设置了组 ID，则为true。
- [ -G file ]：如果 file 存在并且属于有效的组 ID，则为true。
- [ -h file ]：如果 file 存在并且是符号链接，则为true。
- [ -k file ]：如果 file 存在并且设置了它的“sticky bit”，则为true。
- [ -L file ]：如果 file 存在并且是一个符号链接，则为true。
- [ -N file ]：如果 file 存在并且自上次读取后已被修改，则为true。
- [ -O file ]：如果 file 存在并且属于有效的用户 ID，则为true。
- [ -p file ]：如果 file 存在并且是一个命名管道，则为true。
- [ -r file ]：如果 file 存在并且可读（当前用户有可读权限），则为true。
- [ -s file ]：如果 file 存在且其长度大于零，则为true。
- [ -S file ]：如果 file 存在且是一个网络 socket，则为true。
- [ -t fd ]：如果 fd 是一个文件描述符，并且重定向到终端，则为true。 这可以用来判断是否重定向了标准输入／输出／错误。
- [ -u file ]：如果 file 存在并且设置了 setuid 位，则为true。
- [ -w file ]：如果 file 存在并且可写（当前用户拥有可写权限），则为true。
- [ -x file ]：如果 file 存在并且可执行（有效用户有执行／搜索权限），则为true。
- [ file1 -nt file2 ]：如果 FILE1 比 FILE2 的更新时间最近，或者 FILE1 存在而 FILE2 不存在，则为true。
- [ file1 -ot file2 ]：如果 FILE1 比 FILE2 的更新时间更旧，或者 FILE2 存在而 FILE1 不存在，则为true。
- [ FILE1 -ef FILE2 ]：如果 FILE1 和 FILE2 引用相同的设备和 inode 编号，则为true。
*** 字符串判断
以下表达式用来判断字符串。
- [ string ]：如果string不为空（长度大于0），则判断为真。
- [ -n string ]：如果字符串string的长度大于零，则判断为真。
- [ -z string ]：如果字符串string的长度为零，则判断为真。
- [ string1 = string2 ]：如果string1和string2相同，则判断为真。
- [ string1 == string2 ] 等同于[ string1 = string2 ]。
- [ string1 != string2 ]：如果string1和string2不相同，则判断为真。
- [ string1 '>' string2 ]：如果按照字典顺序string1排列在string2之后，则判断为真。
- [ string1 '<' string2 ]：如果按照字典顺序string1排列在string2之前，则判断为真。

注意，test命令内部的>和<，必须用引号引起来（或者是用反斜杠转义）。否则，它们会被 shell 解释为重定向操作符。
*** 整数判断
下面的表达式用于判断整数。
- [ integer1 -eq integer2 ]：如果integer1等于integer2，则为true。
- [ integer1 -ne integer2 ]：如果integer1不等于integer2，则为true。
- [ integer1 -le integer2 ]：如果integer1小于或等于integer2，则为true。
- [ integer1 -lt integer2 ]：如果integer1小于integer2，则为true。
- [ integer1 -ge integer2 ]：如果integer1大于或等于integer2，则为true。
- [ integer1 -gt integer2 ]：如果integer1大于integer2，则为true。
*** 逻辑运算
通过逻辑运算，可以把多个test判断表达式结合起来，创造更复杂的判断。三种逻辑运算AND，OR，和NOT，都有自己的专用符号。
- AND运算：符号&&，也可使用参数-a。
- OR运算：符号||，也可使用参数-o。
- NOT运算：符号!。

* cuda
** 如何查看显卡支持的CUDA版本
1. 在开始中找到并打开NVIDIA控制面板，如下图所示。
#+DOWNLOADED: file:F:/org/图片/201702141648462427.jpg @ 2020-08-11 23:06:13
[[file:cuda/2020-08-11_23-06-13_201702141648462427.jpg]]


2. 打开NVIDIA控制面板，如下图所示。选择“系统信息”--“组件”，找到NVCUDA.DLL信息显示即为显卡支持的CUDA最高版本。

#+DOWNLOADED: file:F:/org/图片/20170214164846247.jpg @ 2020-08-11 23:01:36
[[file:cuda/2020-08-11_23-01-36_20170214164846247.jpg]]

3. 在编译caffe时，若显卡的计算能力比较低的话，需要修改caffe-master\windows下的CommonSettings.props的属性表，现有的gpu计算能力参数：有compute_20,sm_20;compute_30,sm_30;compute_35,sm_35;compute_50,sm_50;compute_52,sm_52

#+DOWNLOADED: file:F:/org/图片/20170214174642686.jpg @ 2020-08-11 23:07:19
[[file:cuda/2020-08-11_23-07-19_20170214174642686.jpg]]

** 关于pytorch、cuda、cudnn、显卡驱动之间的关系
pytorch本质上只是一个深度学习框架，帮我们封装好了数据加载、损失函数、优化器、网络等信息，但是他调用GPU进行加速还需要cuda驱动，这里也经常遇到一个名字叫cudnn，而显卡驱动与cuda以及cudnn也不是一个东西，下面是大致的介绍：

英伟达显卡驱动：
英伟达显卡驱动是为我们提供显示功能的，我们点亮屏幕，让游戏画面能够很流畅需要它，它和我们其他几个名词没有关系，因为剩下的几个名词都是我们进行更高级的GPU功能准备的。

Cuda：
Cuda驱动可以在官网下载，它是NVIDIA推出的用于自家GPU的并行计算框架，也就是说CUDA只能在NVIDIA的GPU上运行，而且只有当要解决的计算问题是可以大量并行计算的时候才能发挥CUDA的作用，而我们需要进行的深度学习跑神经网络的时候需要使用使用。

cuDNN：
cuDNN是一个专门用于神经网络的加速包，注意，它跟我们的CUDA没有完全一一对应的关系，即每一个版本的CUDA可能有好几个版本的cuDNN与之对应，但一般是有大致对应关系的（见后图）。

pytorch（torch）框架：
pytorch是一个深度学习框架，封装好了很多网络和深度学习相关的工具方便我们调用，而不用我们一个个去单独写了，他分为CPU和GPU版本，其他框架还有TensorFlow，Caffe等。

那么这几个概念就很清晰了，显卡驱动复杂给我们进行屏幕显示、游戏的画质渲染，而我们在调用pytorch的时候实际上是调用cuDNN这个加速包，这个包调用cuda驱动这个并行加速框架来调用GPU的流处理器进行计算的。

在网上可以查到cuda与pytorch版本的大致对应关系：[[https://pytorch.org/get-started/previous-versions/][INSTALLING PREVIOUS VERSIONS OF PYTORCH]]

关于cudnn可以直接在官网搜索搜索cuda对应的cudnn版本进行安装，官网链接如下：[[https://developer.nvidia.com/rdp/cudnn-archive#a-collapse742-10][cuDNN Archive]]

** 查看 CUDA 和 cuDNN 版本的方法
*** Linux
**** 查看 CUDA 版本
方法一：
nvcc --version

或

nvcc -V

如果 nvcc 没有安装，那么用方法二。

方法二：

去安装目录下查看：
#+begin_src bash
cat /usr/local/cuda/version.txt
#+END_SRC
**** 查看 cuDNN 版本
#+begin_src bash
cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2
#+END_SRC
如果没有，那么可能没有安装 cuDNN。

如果是为了使用 PyTorch/TensorFlow，在 Linux 服务器上推荐使用 conda 安装，使用 conda 可以很方便安装 PyTorch/TensorFlow 以及对应版本的 CUDA 和 cuDNN。
*** Windows
**** 查看 CUDA 版本
在命令行中执行：

nvcc --version

或者进入 CUDA 的安装目录查看：

C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA
**** 查看 cuDNN 版本
进入 CUDA 的安装目录查看文件 cudnn.h ：（注意修改v9.0）

C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\include\cudnn.h

如下所示，cuDNN 版本为 7.2.1 :

#+DOWNLOADED: file:E:/org/图片/Snipaste_2021-11-22_14-43-33.png @ 2021-11-22 14:43:40
[[file:cuda/2021-11-22_14-43-40_Snipaste_2021-11-22_14-43-33.png]]

如果不知道安装路径，或者安装了多个版本的 CUDA，可以去环境变量内查看 CUDA_PATH 或 path。
*** 使用 PyTorch 查看 CUDA 和 cuDNN 版本
#+begin_src python
import torch
print(torch.__version__)

print(torch.version.cuda)
print(torch.backends.cudnn.version())
#+END_SRC
*** 参考文章
[[https://www.cnblogs.com/wuliytTaotao/p/11453265.html#%25E6%259F%25A5%25E7%259C%258B-cudnn-%25E7%2589%2588%25E6%259C%25AC][Linux 和 Windows 查看 CUDA 和 cuDNN 版本]]
** 升级cuda
安装cuda时需要重启机器，所以我放弃升级了。
这个教程没有完全写完。
#+DOWNLOADED: file:E:/org/图片/Snipaste_2021-11-24_21-09-38.png @ 2021-11-24 21:10:03
[[file:cuda/2021-11-24_21-10-03_Snipaste_2021-11-24_21-09-38.png]]

先在NVIDIA官网找到对应版本的cuda，执行命令
#+begin_src bash
wget http://developer.download.nvidia.com/compute/cuda/11.0.2/local_installers/cuda_11.0.2_450.51.05_linux.run
sudo sh cuda_11.0.2_450.51.05_linux.run
#+END_SRC
安装过程中全选，收到报错提示，查看cuda安装log
#+begin_src bash
cat /var/log/cuda-installer.log
#+END_SRC
提示：
#+BEGIN_EXAMPLE
[INFO]: Driver installation detected by command: apt list --installed | grep -e nvidia-driver-[0-9][0-9][0-9] -e nvidia-[0-9][0-9][0-9]
[INFO]: Cleaning up window
[INFO]: Complete
[INFO]: Checking compiler version...
[INFO]: gcc location: /usr/bin/gcc
[INFO]: gcc version: gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.9)
[INFO]: Initializing menu
[INFO]: Setup complete
[INFO]: Components to install:
[INFO]: Driver
[INFO]: 450.51.05
[INFO]: Executing NVIDIA-Linux-x86_64-450.51.05.run --ui=none --no-questions --accept-license --disable-nouveau --no-cc-version-check --install-libglvnd  2>&1
[INFO]: Finished with code: 256
[ERROR]: Install of driver component failed.
[ERROR]: Install of 450.51.05 failed, quitting
#+END_EXAMPLE
查看nvidia-installer.log
#+begin_src bash
cat /var/log/nvidia-installer.log
#+END_SRC
#+BEGIN_EXAMPLE
nvidia-installer log file '/var/log/nvidia-installer.log'
creation time: Wed Nov 24 13:06:21 2021
installer version: 465.19.01

PATH: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin

nvidia-installer command line:
    ./nvidia-installer
    --ui=none
    --no-questions
    --accept-license
    --disable-nouveau
    --no-cc-version-check
    --install-libglvnd

Using built-in stream user interface
-> Detected 12 CPUs online; setting concurrency level to 12.
ERROR: Unable to find the module utility `modprobe`; please make sure you have the package 'module-init-tools' or 'kmod' installed.  If you do have 'module-init-tools' or 'kmod' installed, then please check that `modprobe` is in your PATH.
#+END_EXAMPLE
按提示安装module-init-tools、kmod
#+begin_src bash
apt-get install module-init-tools kmod
#+END_SRC
* cp命令
Linux cp（英文全拼：copy file）命令主要用于复制文件或目录。

语法
#+BEGIN_EXAMPLE
cp [options] source dest
或
cp [options] source... directory
#+END_EXAMPLE

参数说明：
- -a：此选项通常在复制目录时使用，它保留链接、文件属性，并复制目录下的所有内容。其作用等于dpR参数组合。
- -d：复制时保留链接。这里所说的链接相当于 Windows 系统中的快捷方式。
- -f：覆盖已经存在的目标文件而不给出提示。
- -i：与 -f 选项相反，在覆盖目标文件之前给出提示，要求用户确认是否覆盖，回答 y 时目标文件将被覆盖。
- -p：除复制文件的内容外，还把修改时间和访问权限也复制到新文件中。
- -r：若给出的源文件是一个目录文件，此时将复制该目录下所有的子目录和文件。
- -l：不复制文件，只是生成链接文件。
* chsh命令
Linux chsh命令用于更改使用者 shell 设定。

使用权限：所有使用者。

语法:shell>> chsh

通过 -s 参数改变当前的shell设置
** 实例
#+begin_src bash
shell>> chsh
Changing fihanging shell for user1
Password: [del]
New shell [/bin/tcsh]: ### [是目前使用的 shell]
[del]
shell>> chsh -l ### 展示 /etc/shells 档案内容
/bin/bash
/bin/sh
/bin/ash
/bin/bsh
/bin/tcsh
/bin/csh
#+END_SRC
改变当前的shell。当前的shell 设置为/bin/bash，通过chsh命令，改变shell的设置/bin/csh。
#+begin_src bash
$ chsh
Changing shell for root.
New shell [/bin/bash]: /bin/csh //输入新的shell地址
Shell changed.
#+END_SRC

通过 -s 参数改变当前的shell设置
#+begin_src bash
$ chsh -s /bin/csh //改变当前设置为 /bin/csh
Changing shell for root.
Shell not changed.
#+END_SRC
* cmake
** 简介
什么是cmake

你或许听过好几种 Make 工具，例如 GNU Make ，QT 的 qmake ，微软的 MSnmake，BSD Make（pmake），Makepp，等等。这些 Make 工具遵循着不同的规范和标准，所执行的 Makefile 格式也千差万别。这样就带来了一个严峻的问题：如果软件想跨平台，必须要保证能够在不同平台编译。而如果使用上面的 Make 工具，就得为每一种标准写一次 Makefile ，这将是一件让人抓狂的工作。

CMake就是针对上面问题所设计的工具：它首先允许开发者编写一种平台无关的 CMakeList.txt 文件来定制整个编译流程，然后再根据目标用户的平台进一步生成所需的本地化 Makefile 和工程文件，如 Unix 的 Makefile 或 Windows 的 Visual Studio 工程。从而做到“Write once, run everywhere”。显然，CMake 是一个比上述几种 make 更高级的编译配置工具。一些使用 CMake 作为项目架构系统的知名开源项目有 VTK、ITK、KDE、OpenCV、OSG 等。

在 linux 平台下使用 CMake 生成 Makefile 并编译的流程如下：
- 编写 CMake 配置文件 CMakeLists.txt 。
- 执行命令 cmake PATH 或者 ccmake PATH 生成 Makefile。其中， PATH 是 CMakeLists.txt 所在的目录。（ccmake 和 cmake 的区别在于前者提供了一个交互式的界面）
- 使用 make 命令进行编译。
** 入门案例
*** 单个源文件
本节对应的源代码所在目录：Demo1。

对于简单的项目，只需要写几行代码就可以了。例如，假设现在我们的项目中只有一个源文件 main.cc ，该程序的用途是计算一个数的指数幂。
#+BEGIN_SRC c++
#include <stdio.h>
#include <stdlib.h>
/**
 * power - Calculate the power of number.
 * @param base: Base value.
 * @param exponent: Exponent value.
 *
 * @return base raised to the power exponent.
 */
double power(double base, int exponent)
{
  int result = base;
  int i;
  
  if (exponent == 0) {
    return 1;
  }
  
  for(i = 1; i < exponent; ++i){
    result = result * base;
  }
  return result;
}
int main(int argc, char *argv[])
{
  if (argc < 3){
    printf("Usage: %s base exponent \n", argv[0]);
    return 1;
  }
  double base = atof(argv[1]);
  int exponent = atoi(argv[2]);
  double result = power(base, exponent);
  printf("%g ^ %d is %g\n", base, exponent, result);
  return 0;
}

#+END_SRC

首先编写 CMakeLists.txt 文件，并保存在与 main.cc 源文件同个目录下：
#+BEGIN_SRC c++
# CMake 最低版本号要求
cmake_minimum_required(VERSION 2.8)
# 项目信息
project(Demo1)
# 指定生成目标
add_executable(Demo main.cc)
#+END_SRC
CMakeLists.txt 的语法比较简单，由命令、注释和空格组成，其中命令是不区分大小写的。符号 # 后面的内容被认为是注释。命令由命令名称、小括号和参数组成，参数之间使用空格进行间隔。

对于上面的 CMakeLists.txt 文件，依次出现了几个命令：
- cmake_minimum_required：指定运行此配置文件所需的 CMake 的最低版本；
- project：参数值是 Demo1，该命令表示项目的名称是 Demo1 。
- add_executable： 将名为 main.cc 的源文件编译成一个名称为 Demo 的可执行文件。

编译项目:之后，在当前目录执行 cmake . ，得到 Makefile 后再使用 make 命令编译得到 Demo1 可执行文件。
#+BEGIN_SRC c++
[ehome@xman Demo1]$ cmake .
-- The C compiler identification is GNU 4.8.2
-- The CXX compiler identification is GNU 4.8.2
-- Check for working C compiler: /usr/sbin/cc
-- Check for working C compiler: /usr/sbin/cc -- works
-- Detecting C compiler ABI info
-- Detecting C compiler ABI info - done
-- Check for working CXX compiler: /usr/sbin/c++
-- Check for working CXX compiler: /usr/sbin/c++ -- works
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Configuring done
-- Generating done
-- Build files have been written to: /home/ehome/Documents/programming/C/power/Demo1
[ehome@xman Demo1]$ make
Scanning dependencies of target Demo
[100%] Building C object CMakeFiles/Demo.dir/main.cc.o
Linking C executable Demo
[100%] Built target Demo
[ehome@xman Demo1]$ ./Demo 5 4
5 ^ 4 is 625
[ehome@xman Demo1]$ ./Demo 7 3
7 ^ 3 is 343
[ehome@xman Demo1]$ ./Demo 2 10
2 ^ 10 is 1024

#+END_SRC
*** 多个源文件
同一目录，多个源文件

本小节对应的源代码所在目录：Demo2。

上面的例子只有单个源文件。现在假如把 power 函数单独写进一个名为MathFunctions.c 的源文件里，使得这个工程变成如下的形式：
#+BEGIN_EXAMPLE
./Demo2
    |
    +--- main.cc
    |
    +--- MathFunctions.cc
    |
    +--- MathFunctions.h
#+END_EXAMPLE
这个时候，CMakeLists.txt 可以改成如下的形式：
#+BEGIN_SRC c++
# CMake 最低版本号要求
cmake_minimum_required(VERSION 2.8)
# 项目信息
project(Demo2)
# 指定生成目标
add_executable(Demo main.cc MathFunctions.cc)
#+END_SRC
唯一的改动只是在 add_executable 命令中增加了一个 MathFunctions.cc 源文件。这样写当然没什么问题，但是如果源文件很多，把所有源文件的名字都加进去将是一件烦人的工作。更省事的方法是使用 aux_source_directory 命令，该命令会查找指定目录下的所有源文件，然后将结果存进指定变量名。其语法如下：
#+BEGIN_SRC c++
aux_source_directory(<dir> <variable>)
#+END_SRC
因此，可以修改 CMakeLists.txt 如下：
#+BEGIN_SRC c++
# CMake 最低版本号要求
cmake_minimum_required(VERSION 2.8)
# 项目信息
project (Demo2)
# 查找当前目录下的所有源文件
# 并将名称保存到 DIR_SRCS 变量
aux_source_directory(. DIR_SRCS)
# 指定生成目标
add_executable(Demo ${DIR_SRCS})
#+END_SRC
这样，CMake 会将当前目录所有源文件的文件名赋值给变量 DIR_SRCS ，再指示变量 DIR_SRCS 中的源文件需要编译成一个名称为 Demo 的可执行文件。
*** 多个目录，多个源文件
本小节对应的源代码所在目录：Demo3。

现在进一步将 MathFunctions.h 和 MathFunctions.cc 文件移动到 math 目录下。
#+BEGIN_EXAMPLE
./Demo3
    |
    +--- main.cc
    |
    +--- math/
          |
          +--- MathFunctions.cc
          |
          +--- MathFunctions.h
#+END_EXAMPLE
对于这种情况，需要分别在项目根目录 Demo3 和 math 目录里各编写一个 CMakeLists.txt 文件。为了方便，我们可以先将 math 目录里的文件编译成静态库再由 main 函数调用。

根目录中的 CMakeLists.txt ：
#+BEGIN_SRC c++
# CMake 最低版本号要求
cmake_minimum_required(VERSION 2.8)
# 项目信息
project(Demo3)
# 查找当前目录下的所有源文件
# 并将名称保存到 DIR_SRCS 变量
aux_source_directory(. DIR_SRCS)
# 添加 math 子目录
add_subdirectory(math)
# 指定生成目标
add_executable(Demo main.cc)
# 添加链接库
target_link_libraries(Demo MathFunctions)
#+END_SRC
该文件添加了下面的内容: 第3行，使用命令 add_subdirectory 指明本项目包含一个子目录 math，这样 math 目录下的 CMakeLists.txt 文件和源代码也会被处理 。第6行，使用命令 target_link_libraries 指明可执行文件 main 需要连接一个名为 MathFunctions 的链接库 。

子目录中的 CMakeLists.txt：
#+BEGIN_SRC c++
# 查找当前目录下的所有源文件
# 并将名称保存到 DIR_LIB_SRCS 变量
aux_source_directory(. DIR_LIB_SRCS)
# 生成链接库
add_library (MathFunctions ${DIR_LIB_SRCS})
#+END_SRC
在该文件中使用命令 add_library 将 src 目录中的源文件编译为静态链接库。
*** 自定义编译选项
本节对应的源代码所在目录：Demo4。

CMake 允许为项目增加编译选项，从而可以根据用户的环境和需求选择最合适的编译方案。

例如，可以将 MathFunctions 库设为一个可选的库，如果该选项为 ON ，就使用该库定义的数学函数来进行运算。否则就调用标准库中的数学函数库。

修改 CMakeLists 文件：我们要做的第一步是在顶层的 CMakeLists.txt 文件中添加该选项： 
#+BEGIN_SRC c++
# CMake 最低版本号要求
cmake_minimum_required(VERSION 2.8)
# 项目信息
project(Demo4)
# 加入一个配置头文件，用于处理 CMake 对源码的设置
configure_file(
"${PROJECT_SOURCE_DIR}/config.h.in"
"${PROJECT_BINARY_DIR}/config.h"
)
# 是否使用自己的 MathFunctions 库
option(USE_MYMATH
"Use provided math implementation" ON)
# 是否加入 MathFunctions 库
if (USE_MYMATH)
 include_directories("${PROJECT_SOURCE_DIR}/math")
add_subdirectory(math)
set (EXTRA_LIBS ${EXTRA_LIBS} MathFunctions)
endif (USE_MYMATH)
# 查找当前目录下的所有源文件
# 并将名称保存到 DIR_SRCS 变量
aux_source_directory(. DIR_SRCS)
# 指定生成目标
add_executable(Demo ${DIR_SRCS})
target_link_libraries (Demo ${EXTRA_LIBS})
#+END_SRC
其中：

第7行的 configure_file 命令用于加入一个配置头文件 config.h ，这个文件由 CMake 从 config.h.in 生成，通过这样的机制，将可以通过预定义一些参数和变量来控制代码的生成。

第13行的 option 命令添加了一个 USE_MYMATH 选项，并且默认值为 ON 。

第17行根据 USE_MYMATH 变量的值来决定是否使用我们自己编写的 MathFunctions 库。
** 语法的基本原则
- 变量使用${}方式取值，但是在 IF 控制语句中是直接使用变量名
- 指令(参数 1 参数 2...) 参数使用括弧括起，参数之间使用空格或分号分开。 
- 指令是大小写无关的，参数和变量是大小写相关的。推荐全部使用大写指令 
** compile_commands.json
用DCMAKE_EXPORT_COMPILE_COMMANDS标志
#+begin_src bash
% cmake -H. -BDebug -DCMAKE_BUILD_TYPE=Debug -DCMAKE_EXPORT_COMPILE_COMMANDS=YES
#+end_src
** PROJECT
可以用来指定工程的名字和支持的语言，默认支持所有语言

- PROJECT (HELLO)   指定了工程的名字，并且支持所有语言（建议）
- PROJECT (HELLO CXX)      指定了工程的名字，并且支持语言是C++
- PROJECT (HELLO C CXX)      指定了工程的名字，并且支持语言是C和C++

该指定隐式定义了两个CMAKE的变量
- <projectname>_BINARY_DIR，例如： HELLO_BINARY_DIR
- <projectname>_SOURCE_DIR，例如： HELLO_SOURCE_DIR

MESSAGE关键字就可以直接使用者两个变量，当前都指向当前的工作目录。
** set
set 有三种，分别为: 
- 设置一般变量(Set Normal Variable) 
- 设置缓存变量(Set Cache Entry)
- 设置环境变量(Set Environment Variable)
#+BEGIN_SRC c++
// 1. 设置一般变量(Set Normal Variable)
set(<variable> <value>... [PARENT_SCOPE])

// 2. 设置缓存变量(Set Cache Entry)
set(<variable> <value>... CACHE <type> <docstring> [FORCE])

// 3. 设置环境变量(Set Environment Variable)
set(ENV{<variable>} [<value>])
#+END_SRC

注意：SET(SRC_LIST main.cpp) 可以写成 SET(SRC_LIST “main.cpp”)，
如果源文件名中含有空格（例如 m ain.cpp），就必须要加双引号
*** 设置一般变量set(<variable> <value>... [PARENT_SCOPE])
#+BEGIN_SRC bash
set(<variable> <value>... [PARENT_SCOPE])
#+END_SRC
将一个或者多个值 <value>... 赋值给变量 <variable>， 多个值之间以分号（；）分隔。
**** 参数
- PARENT_SCOPE，配置该选项后，表示该变量在父级作用域上有效, 在当前作用域上是无效的;
**** 例子
目录结构如下:
#+BEGIN_EXAMPLE
rs:cmake-set$ tree
.
├── CMakeLists.txt
├── main.cpp
└── subdir
    └── CMakeLists.txt
#+END_EXAMPLE
顶层的　CMakeLists.txt
#+BEGIN_SRC c++
cmake_minimum_required(VERSION 3.5)

project(DEMO VERSION 10.2.1.3 LANGUAGES CXX C ASM )

# 设置一般变量
set(PNAME rsenjoyer)
set(PGRADE 80 85 90 95)

message("top name = ${PNAME}")  # top name = rsenjoyer
message("top grade = ${PGRADE}") #top grade = 80;85;90;95

add_subdirectory(subdir)

message("top after name = ${PNAME}")  # top name = rsenjoyer

add_executable(DEMO main.cpp)
#+END_SRC
子目录的 CMakeLists.txt
#+BEGIN_SRC c++
set(PNAME jack)
message("sub name = ${PNAME}") # sub name = jack

# 仅仅会改变父级的　PNAME，　对当前的变量不会更改
set(PNAME rose PARENT_SCOPE)
message("sub name = ${PNAME}") #sub name = jack
#+END_SRC
*** 设置缓存变量(Set Cache Entry)
什么是缓存变量，缓存变量可以理解为当第一次运行cmake时，这些变量缓存到一份文件中(即编译目录下的CMakeCache.txt)。当再次运行cmake时，这些变量会直接使用缓存值，可以利用ccmake或者cmake-gui等工具来重新赋值。缓存变量在整个cmake运行过程中都可以起作用。

当使用CACHE时，且缓存(cache)中没有该变量时，变量被创建并存入缓存(cache)中，如果原缓存(cache)中有该变量，也不会改变原缓存中该变量的值，除非后面使用FORCE。
#+BEGIN_SRC c++
set(<variable> <value>... CACHE <type> <docstring> [FORCE])
#+END_SRC
作用:
- 设置变量并缓存到 CMakeCache.txt
- 默认不会覆盖已缓存(已存在于 CMakeCache.txt )的变量；
**** 参数
- 类型 type,必须为以下的一种
    - BOOL,布尔值(ON/OFF)
    - FILEPATH,文件路径
    - PATH,目录路径
    - STRING,字符串
    - INTERNAL,单行文字.INTERNAL将变量为内部变量，即cmake-gui不会向用户显示这类变量，而其它类型的缓存变量用户都可以通cmake-gui按照特定的类型改变。
- 描述字符串 <docstring>: 单行文字,用于 CMAKE-GUI 的时提示用户
- FORCE 用于是否强制更新缓存里面的值，配置后，每次都会强制更新　CMakeCache.txt 里面的值
**** 例子
#+BEGIN_SRC c++
set(FOO, "x" CACHE <type>)  
//原缓存中没有FOO则将FOO赋值为x且存入cache中。
//原缓存中有FOO则不做任何改变，即便原cache中FOO存的不是x。
set(FOO, "x" CACHE <type><docstring> FORCE) 　　　
//即便原cache中存在FOO也会创建另一个FOO，官方文档原话(If FORCE is specified, the value of the cache variable 
//is set, even if the variable is already in the cache.This should normally be avoided, as it will 
//remove any changes to the cache variable’s value by the user.)，小弟笨拙没有搞懂。
#+END_SRC
**** 注意
1. CACHE与PARENT_SCOPE不能一起使用。
2. 同一名称(例FOO)的一般变量和缓存变量可以同时存在，但在调用该变量时(${FOO})会在先取一般变量的值，一般变量中没有再取缓存变量的值。
一些栗子：
#+BEGIN_EXAMPLE
set(FOO “x”)　　　　　　　　//设置一般变量FOO，不会触及cache，但是会隐藏cache中的FOO。

set(FOO “x” CACHE ...)　　//忽视相同名称的一般变量，在cache中检查FOO是否存在，
#+END_EXAMPLE
3. 当改变cache中的变量时，同名的一般变量会被删除。一般不建议使用相同名称的一般变量和缓存变量。

然而在有些工程中可以很好的借助这一交互例如：

一个工程利用ADD_SUBDIRECTOTY()添加子工程，子工程有它自己的CMakeList.txt。如果在父工程和子工程中都对同一缓存变量赋值，cmake时父工程率先将变量存入cache中，子工程直接在cache中调用该值，保证了父子工程的一致性。当父工程需要改变该变量，而子程序需要利用原值时，可以直接在父工程中设置同名称的一般变量即可。

*** 设置环境变量(Set Environment Variable)
#+BEGIN_SRC c++
set(ENV{<variable>} [<value>])
#+END_SRC
作用
- 设置环境变量 <variable>,值为 <value>
- 如果 <value> 不存在或者为空字符串 表示清除该环境变量
** SET_TARGET_PROPERTIES
这条指令可以用来设置输出的名称，对于动态库，还可以用来指定动态库版本和 API 版本。
cmake 在构建一个新的target 时，会尝试清理掉其他使用这个名字的库。

SET_TARGET_PROPERTIES(hello_static PROPERTIES  OUTPUT_NAME "hello")

** ADD_EXECUTABLE
生成可执行文件

#+begin_src bash
ADD_EXECUTABLE(hello ${SRC_LIST})     
#+END_SRC
生成的可执行文件名是hello，源文件读取变量SRC_LIST中的内容

也可以直接写 ADD_EXECUTABLE(hello main.cpp) 。
后缀可以不行，他会自动去找.c和.cpp，最好不要这样写，可能会有这两个文件main.cpp和main

** ADD_SUBDIRECTORY
#+begin_src bash
ADD_SUBDIRECTORY(source_dir [binary_dir] [EXCLUDE_FROM_ALL])
#+END_SRC
这个指令用于向当前工程添加存放源文件的子目录，并可以指定中间二进制和目标二进制存放的位置。

每个目录下都要有一个CMakeLists.txt
#+begin_src bash
[root@localhost cmake]# tree
.
├── build
├── CMakeLists.txt
└── src
    ├── CMakeLists.txt
    └── main.cpp
#+END_SRC
外层CMakeLists.txt：
#+begin_src bash
PROJECT(HELLO)
ADD_SUBDIRECTORY(src)
#+END_SRC
src下的CMakeLists.txt：
#+begin_src bash
ADD_EXECUTABLE(hello main.cpp)
#+END_SRC
ADD_SUBDIRECTORY用于将外层的CMakeLists.txt与src目录下的CMakeLists.txt关联起来。

下面的命令将 src 子目录加入工程并指定编译输出(包含编译中间结果)路径为bin 目录
#+begin_src bash
ADD_SUBDIRECTORY(src bin)
#+END_SRC
如果不进行 bin 目录的指定，那么编译结果(包括中间结果)都将存放在build/src 目录

** ADD_LIBRARY
ADD_LIBRARY(hello SHARED ${LIBHELLO_SRC})

- hello：就是正常的库名，生成的名字前面会加上lib，最终产生的文件是libhello.so
- SHARED，动态库    STATIC，静态库
- ${LIBHELLO_SRC} ：源文件

*** 同时生成动态库与静态库
在cmake中，同时生成静态库与动态库的时候，需要一些技巧，因为cmake中不能生成同名的静态库和动态库，只能先生成不同名的库之后再把其中一个库的名字改名。
#+begin_src bash
# 生成动态库目标
add_library(MathFunctions SHARED ${srcs})
# 生成静态库目标
add_library(MathFunctions_static STATIC ${srcs})
 
# 指定静态库的输出名称
set_target_properties(MathFunctions_static PROPERTIES OUTPUT_NAME "MathFunctions")
# 使动态库和静态库同时存在
set_target_properties(MathFunctions PROPERTIES CLEAN_DIRECT_OUTPUT 1)
set_target_properties(MathFunctions_static PROPERTIES CLEAN_DIRECT_OUTPUT 1)
 
# 指定动态库版本
# VERSION 动态库版本
# SOVERSION API版本
set_target_properties(person PROPERTIES VERSION 1.0 SOVERSION 1)
 
# 将动态库与动态库同时安装到lib目录中
install (TARGETS MathFunctions MathFunctions_static DESTINATION lib)
#+END_SRC
CLEAN_DIRECT_OUTPUT 部分用于指示在生成具有相同名字的（OUTPUT_NAME）的目标时，是否清理上次生成的内容。由于这时的动态和静态库都使用 hello 这个名字，因此需要设置此不见标志。
** 变量
*** 变量的作用域
- Function Scope: 在函数内部定义,仅仅在当前函数以及所调用的子函数内有效;
- Directory Scope: 在当前目录的定义的变量,当调用子目录时候,子目录会复制一份父级目录内的变量到子目录中
- Persistent Cache: 持久化的缓存,一般由CACHE 存储起来.
*** 变量的搜索路径
- 在当前 Function Scope 调用内查找,找到后使用,未找到进行下一步;
- 在当前目录下面查找,找到使用,未找到下一步;
- 在 CACHE 中寻找,找到使用,未找到,则为空.
*** Variables for Languages
**** CMAKE_COMPILER_IS_GNUCXX
True if the C++ (CXX) compiler is GNU. Use CMAKE_CXX_COMPILER_ID instead
*** Variables that Change Behavior.
**** CMAKE_MODULE_PATH
这个变量用来定义自己的 cmake 模块所在的路径。如果你的工程比较复杂,有可能会自己编写一些 cmake 模块,这些 cmake 模块是随你的工程发布的,为了让 cmake 在处理CMakeLists.txt 时找到这些模块,你需要通过 SET 指令,将自己的 cmake 模块路径设置一下。
比如 
#+BEGIN_SRC c++
SET(CMAKE_MODULE_PATH ${PROJECT_SOURCE_DIR}/cmake)
#+END_SRC
这时候你就可以通过 INCLUDE 指令来调用自己的模块了。
*** Variables that Provide Information
**** CMAKE_SOURCE_DIR
#+BEGIN_EXAMPLE
The path to the top level of the source tree.

This is the full path to the top level of the current CMake source tree. For an in-source build, this would be the same as CMAKE_BINARY_DIR.

When run in -P script mode, CMake sets the variables CMAKE_BINARY_DIR, CMAKE_SOURCE_DIR, CMAKE_CURRENT_BINARY_DIR and CMAKE_CURRENT_SOURCE_DIR to the current working directory.
#+END_EXAMPLE
PROJECT_SOURCE_DIR,<projectname>_SOURCE_DIR

这三个变量指代的内容是一致的,不论采用何种编译方式,都是工程顶层目录。
也就是在 in source 编译时,他跟 CMAKE_BINARY_DIR 等变量一致。
PROJECT_SOURCE_DIR 跟其他指令稍有区别,现在,你可以理解为他们是一致的。

** STREQUAL
STREQUAL 用于比较字符串，相同返回 true 。
** file命令
#+BEGIN_SRC c++
file(GLOB <variable>
     [LIST_DIRECTORIES true|false] [RELATIVE <path>] [CONFIGURE_DEPENDS]
     [<globbing-expressions>...])
file(GLOB_RECURSE <variable> [FOLLOW_SYMLINKS]
     [LIST_DIRECTORIES true|false] [RELATIVE <path>] [CONFIGURE_DEPENDS]
     [<globbing-expressions>...])
#+END_SRC
Generate a list of files that match the <globbing-expressions> and store it into the <variable>. Globbing expressions are similar to regular expressions, but much simpler. If RELATIVE flag is specified, the results will be returned as relative paths to the given path. The results will be ordered lexicographically.

On Windows and macOS, globbing is case-insensitive even if the underlying filesystem is case-sensitive (both filenames and globbing expressions are converted to lowercase before matching). On other platforms, globbing is case-sensitive.

If the CONFIGURE_DEPENDS flag is specified, CMake will add logic to the main build system check target to rerun the flagged GLOB commands at build time. If any of the outputs change, CMake will regenerate the build system.

产生一个匹配 <globbing-expressions> 的文件列表并将它存储到变量 <variable> 中。文件名替代表达式和正则表达式相似，但更简单。如果 RELATIVE 标志位被设定，将返回指定路径的相对路径。结果将按字典顺序排序。

如果 CONFIGURE_DEPENDS 标志位被指定，CMake 将在编译时给主构建系统添加逻辑来检查目标，以重新运行 GLOB 标志的命令。如果任何输出被改变，CMake都将重新生成这个构建系统。
** include指令
[[https://blog.csdn.net/qq_38410730/article/details/102677143][参考文章]]
*** include指令
include指令一般用于语句的复用，也就是说，如果有一些语句需要在很多CMakeLists.txt文件中使用，为避免重复编写，可以将其写在.cmake文件中，然后在需要的CMakeLists.txt文件中进行include操作就行了。

include指令的结构为：
#+BEGIN_EXAMPLE
include(<file|module> [OPTIONAL] [RESULT_VARIABLE <var>]
                      [NO_POLICY_SCOPE])
#+END_EXAMPLE
虽然，有不少的可选参数，但是一般情况下，都是直接写：
#+BEGIN_EXAMPLE
include(file|module)
#+END_EXAMPLE

注意，为了使CMakeLists.txt能够找到该文件，需要指定文件完整路径(绝对路径或相对路径)，当然如果指定了CMAKE_MODULE_PATH，就可以直接include该目录下的.cmake文件了。

.cmake文件里面通常是什么信息呢？

.cmake文件里包含了一些cmake命令和一些宏/函数，当CMakeLists.txt包含该.cmake文件时，当编译运行时，该.cmake里的一些命令就会在该包含处得到执行，并且在包含以后的地方能够调用该.cmake里的一些宏和函数。

什么是宏？什么是函数？
*** 宏和函数的定义
先看一下关键字：cmake的宏是MACRO，函数是function。它们的用法是：
#+BEGIN_SRC c++
macro(<name> [arg1 [arg2 [arg3 ...]]])
  COMMAND1(ARGS ...)            # 命令语句
  COMMAND2(ARGS ...)
  ...
endmacro()

function(<name> [arg1 [arg2 [arg3 ...]]])
  COMMAND1(ARGS ...)            # 命令语句
  COMMAND2(ARGS ...)
  ...
function()
#+END_SRC
定义一个名称为name的宏（函数），arg1...是传入的参数。我们除了可以用${arg1}来引用变量以外，系统为我们提供了一些特殊的变量：

| 变量  | 说明                                                 |
|-------+------------------------------------------------------|
| argv# | #是一个下标，0指向第一个参数，累加                   |
| argv  | 所有的定义时要求传入的参数                           |
| argn  | 定义时要求传入的参数以外的参数                       |
| argc  | 传入的实际参数的个数，也就是调用函数是传入的参数个数 |

*** 宏和函数的区别
那么宏和函数之间的区别是什么呢？

其实和C/C++里面宏和函数之间的区别差不多，宏就是字符串替换，函数就是使用变量，在命令中途可以对改变量进行修改。

以StackOverflow的例子来了解一下区别：

首先创建一个CMakeLists.txt：
#+BEGIN_EXAMPLE
cmake_minimum_required(VERSION 3.0)
include(test.cmake)
#+END_EXAMPLE
在同目录下创建文件test.cmake：
#+BEGIN_EXAMPLE
set(var "ABC")

macro(Moo arg)
  message("arg = ${arg}")
  set(arg "abc")
  message("# After change the value of arg.")
  message("arg = ${arg}")
endmacro()
message("=== Call macro ===")
Moo(${var})

function(Foo arg)
  message("arg = ${arg}")
  set(arg "abc")
  message("# After change the value of arg.")
  message("arg = ${arg}")
endfunction()
message("=== Call function ===")
Foo(${var})
#+END_EXAMPLE
运行cmake：
#+BEGIN_SRC bash
mkdir build && cd build
cmake ..
#+END_SRC
运行后的输出结果是：
#+BEGIN_EXAMPLE
-- The C compiler identification is GNU 5.4.0
-- The CXX compiler identification is GNU 5.4.0
-- Check for working C compiler: /usr/bin/cc
-- Check for working C compiler: /usr/bin/cc -- works
-- Detecting C compiler ABI info
-- Detecting C compiler ABI info - done
-- Detecting C compile features
-- Detecting C compile features - done
-- Check for working CXX compiler: /usr/bin/c++
-- Check for working CXX compiler: /usr/bin/c++ -- works
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Detecting CXX compile features
-- Detecting CXX compile features - done
=== Call macro ===
arg = ABC
# After change the value of arg.
arg = ABC
=== Call function ===
arg = ABC
# After change the value of arg.
arg = abc
-- Configuring done
-- Generating done
-- Build files have been written to: /home/yngzmiao/test/build
#+END_EXAMPLE
从这里可以看出，宏实现的仅仅是字符串替换，宏定义的过程中是无法进行修改的，而函数却是可以的。

*** 宏和函数参数的差异
一般情况下，从上面的例子就能看出宏和函数的用法了，但很多情况下，我们自以为的“懂了”都是假懂。比如一不小心，就会出错。

更换test.cmake为下面的内容，并运行：
#+BEGIN_EXAMPLE
set(var "ABC")

macro(Moo arg)
  message("arg = ${arg}")
  set(arg "abc")
  message("# After change the value of arg.")
  message("arg = ${arg}")
endmacro()
message("=== Call macro ===")
Moo(var)

function(Foo arg)
  message("arg = ${arg}")
  set(arg "abc")
  message("# After change the value of arg.")
  message("arg = ${arg}")
endfunction()
message("=== Call function ===")
Foo(var)
#+END_EXAMPLE
运行后的输出结果是：
#+BEGIN_EXAMPLE
-- The C compiler identification is GNU 5.4.0
-- The CXX compiler identification is GNU 5.4.0
-- Check for working C compiler: /usr/bin/cc
-- Check for working C compiler: /usr/bin/cc -- works
-- Detecting C compiler ABI info
-- Detecting C compiler ABI info - done
-- Detecting C compile features
-- Detecting C compile features - done
-- Check for working CXX compiler: /usr/bin/c++
-- Check for working CXX compiler: /usr/bin/c++ -- works
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Detecting CXX compile features
-- Detecting CXX compile features - done
=== Call macro ===
arg = var
# After change the value of arg.
arg = var
=== Call function ===
arg = var
# After change the value of arg.
arg = abc
-- Configuring done
-- Generating done
-- Build files have been written to: /home/yngzmiao/test/build
#+END_EXAMPLE
对比两段程序可以看出其中的区别：无论是宏还是函数，当调用的时候如果使用的是set出来的变量，都必须通过${}将变量的内容传递进去，而不能只写上变量名。

这是将实参传递给形参时的注意点，但在宏和函数的实现过程中，还有需要注意的内容。

例子：
#+BEGIN_EXAMPLE
set(var "ABC")

macro(Moo arg)
  if (arg STREQUAL "ABC")
    message("arg1 = ${arg}")
  endif()
  if (${arg} STREQUAL "ABC")
    message("arg2 = ${arg}")
  endif()
endmacro()
message("=== Call macro ===")
Moo(${var})

function(Foo arg)
  if (arg STREQUAL "ABC")
    message("arg1 = ${arg}")
  endif()
  if (${arg} STREQUAL "ABC")
    message("arg2 = ${arg}")
  endif()
endfunction()
message("=== Call function ===")
Foo(${var})
#+END_EXAMPLE
运行后的输出结果是：
#+BEGIN_EXAMPLE
-- The C compiler identification is GNU 5.4.0
-- The CXX compiler identification is GNU 5.4.0
-- Check for working C compiler: /usr/bin/cc
-- Check for working C compiler: /usr/bin/cc -- works
-- Detecting C compiler ABI info
-- Detecting C compiler ABI info - done
-- Detecting C compile features
-- Detecting C compile features - done
-- Check for working CXX compiler: /usr/bin/c++
-- Check for working CXX compiler: /usr/bin/c++ -- works
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Detecting CXX compile features
-- Detecting CXX compile features - done
=== Call macro ===
arg2 = ABC
=== Call function ===
arg1 = ABC
arg2 = ABC
-- Configuring done
-- Generating done
-- Build files have been written to: /home/yngzmiao/test/build
#+END_EXAMPLE
可以看出，在宏和函数的实现过程中，宏的参数由于不是传统意义上的变量，而是字符串替换，因此需要通过${}取出内容。而函数却不一定需要这样。

也就是说，对于macro宏而言：
#+BEGIN_EXAMPLE
if(argv0)                         # 错误用法
if(${argv0})                      # 正确用法
if(defined argv0)                 # 错误用法
if(defined ${argv0})              # 正确用法
#+END_EXAMPLE
也就是说，对于宏和函数的参数而言：
- 当宏和函数调用的时候，如果传递的是经set设置的变量，必须通过${}取出内容；
- 在宏的定义过程中，对变量进行的操作必须通过${}取出内容，而函数就没有这个必要。
** install
install 用于将项目生成的库文件、头文件、可执行文件或相关文件等安装到指定位置（系统目录，或发行包目录）。

INSTALL的安装可以包括：二进制、动态库、静态库以及文件、目录、脚本等
#+begin_src bash
install(TARGETS <target>... [...])
install(IMPORTED_RUNTIME_ARTIFACTS <target>... [...])
install({FILES | PROGRAMS} <file>... [...])
install(DIRECTORY <dir>... [...])
install(SCRIPT <file> [...])
install(CODE <code> [...])
install(EXPORT <export-name> [...])
install(RUNTIME_DEPENDENCY_SET <set-name> [...])
#+END_SRC
DESTINATION：
1. 写绝对路径
2. 可以写相对路径，相对路径实际路径是：${CMAKE_INSTALL_PREFIX}/<DESTINATION 定义的路径>

CMAKE_INSTALL_PREFIX  默认是在 /usr/local/

cmake -DCMAKE_INSTALL_PREFIX=/usr    在cmake的时候指定CMAKE_INSTALL_PREFIX变量的路径

注意：abc 和 abc/有很大的区别
- 目录名不以/结尾：这个目录将被安装为目标路径下的
- 目录名以/结尾：将这个目录中的内容安装到目标路径
** cmake命令选项

#+DOWNLOADED: file:E:/org/图片/Snipaste_2021-05-01_15-36-45.png @ 2021-05-01 15:36:52
[[file:cmake/2021-05-01_15-36-52_Snipaste_2021-05-01_15-36-45.png]]

** message
向终端输出用户自定义的信息

主要包含三种信息：
- SEND_ERROR，产生错误，生成过程被跳过。
- SATUS，输出前缀为—的信息。
- FATAL_ERROR，立即终止所有 cmake 过程.
*** General messages
#+BEGIN_SRC c++
message([<mode>] "message text" ...)
#+END_SRC
Record the specified message text in the log. If more than one message string is given, they are concatenated into a single message with no separator between the strings.

The optional <mode> keyword determines the type of message, which influences the way the message is handled:

The CMake command-line tool displays STATUS to TRACE messages on stdout with the message preceded by two hyphens and a space. All other message types are sent to stderr and are not prefixed with hyphens. The CMake GUI displays all messages in its log area. The curses interface shows STATUS to TRACE messages one at a time on a status line and other messages in an interactive pop-up box. The --log-level command-line option to each of these tools can be used to control which messages will be shown.

New in version 3.17: To make a log level persist between CMake runs, the CMAKE_MESSAGE_LOG_LEVEL variable can be set instead. Note that the command line option takes precedence over the cache variable.

New in version 3.16: Messages of log levels NOTICE and below will have each line preceded by the content of the CMAKE_MESSAGE_INDENT variable (converted to a single string by concatenating its list items). For STATUS to TRACE messages, this indenting content will be inserted after the hyphens.

New in version 3.17: Messages of log levels NOTICE and below can also have each line preceded with context of the form [some.context.example]. The content between the square brackets is obtained by converting the CMAKE_MESSAGE_CONTEXT list variable to a dot-separated string. The message context will always appear before any indenting content but after any automatically added leading hyphens. By default, message context is not shown, it has to be explicitly enabled by giving the cmake --log-context command-line option or by setting the CMAKE_MESSAGE_CONTEXT_SHOW variable to true. See the CMAKE_MESSAGE_CONTEXT documentation for usage examples.

CMake Warning and Error message text displays using a simple markup language. Non-indented text is formatted in line-wrapped paragraphs delimited by newlines. Indented text is considered pre-formatted.
**** mode
- FATAL_ERROR: CMake Error, stop processing and generation.立即终止所有cmake过程。
- SEND_ERROR: CMake Error, continue processing, but skip generation.
- WARNING: CMake Warning, continue processing.
- AUTHOR_WARNING: CMake Warning (dev), continue processing.
- DEPRECATION: CMake Deprecation Error or Warning if variable CMAKE_ERROR_DEPRECATED or CMAKE_WARN_DEPRECATED is enabled, respectively, else no message.
- (none) or NOTICE: Important message printed to stderr to attract user's attention.
- STATUS： The main interesting messages that project users might be interested in. Ideally these should be concise, no more than a single line, but still informative.产生带前缀 - 的信息。
- VERBOSE： Detailed informational messages intended for project users. These messages should provide additional details that won't be of interest in most cases, but which may be useful to those building the project when they want deeper insight into what's happening.
- DEBUG： Detailed informational messages intended for developers working on the project itself as opposed to users who just want to build it. These messages will not typically be of interest to other users building the project and will often be closely related to internal implementation details.
- TRACE： Fine-grained messages with very low-level implementation details. Messages using this log level would normally only be temporary and would expect to be removed before releasing the project, packaging up the files, etc.

*** Reporting checks
A common pattern in CMake output is a message indicating the start of some sort of check, followed by another message reporting the result of that check. For example:
#+BEGIN_SRC c++
message(STATUS "Looking for someheader.h")
#... do the checks, set checkSuccess with the result
if(checkSuccess)
  message(STATUS "Looking for someheader.h - found")
else()
  message(STATUS "Looking for someheader.h - not found")
endif()
#+END_SRC
This can be more robustly and conveniently expressed using the CHECK_... keyword form of the message() command:
#+BEGIN_SRC c++
message(<checkState> "message" ...)where <checkState> must be one of the following:
#+END_SRC
- CHECK_START:Record a concise message about the check about to be performed.
- CHECK_PASS:Record a successful result for a check.
- CHECK_FAIL:Record an unsuccessful result for a check.

When recording a check result, the command repeats the message from the most recently started check for which no result has yet been reported, then some separator characters and then the message text provided after the CHECK_PASS or CHECK_FAIL keyword. Check messages are always reported at STATUS log level.

Checks may be nested and every CHECK_START should have exactly one matching CHECK_PASS or CHECK_FAIL. The CMAKE_MESSAGE_INDENT variable can also be used to add indenting to nested checks if desired. For example:
#+BEGIN_SRC c++
message(CHECK_START "Finding my things")
list(APPEND CMAKE_MESSAGE_INDENT "  ")
unset(missingComponents)

message(CHECK_START "Finding partA")
# ... do check, assume we find A
message(CHECK_PASS "found")

message(CHECK_START "Finding partB")
# ... do check, assume we don't find B
list(APPEND missingComponents B)
message(CHECK_FAIL "not found")

list(POP_BACK CMAKE_MESSAGE_INDENT)
if(missingComponents)
  message(CHECK_FAIL "missing components: ${missingComponents}")
else()
  message(CHECK_PASS "all components found")
endif()
#+END_SRC
Output from the above would appear something like the following:
#+BEGIN_EXAMPLE
-- Finding my things
--   Finding partA
--   Finding partA - found
--   Finding partB
--   Finding partB - not found
-- Finding my things - missing components: B
#+END_EXAMPLE
** include
include 用于加载makefile文件

-include 表示当文件不存在时，make不会报错
*** 参考文章
[[https://www.gnu.org/software/make/manual/html_node/Include.html][3.3 Including Other Makefiles]]
[[https://blog.csdn.net/xiaozhi_su/article/details/4202779][Makefile中指示符“include”、“-include”和“sinclude”的区别]]
[[https://stackoverflow.com/questions/16981464/difference-between-include-and-include-in-a-makefile][Difference between "include" and "-include" in a makefile]]
** Makefile选项CFLAGS,LDFLAGS,LIBS
CFLAGS 表示用于 C 编译器的选项，
CXXFLAGS 表示用于 C++ 编译器的选项。
这两个变量实际上涵盖了编译和汇编两个步骤。

CFLAGS： 指定头文件（.h文件）的路径，如：CFLAGS=-I/usr/include -I/path/include。同样地，安装一个包时会在安装路径下建立一个include目录，当安装过程中出现问题时，试着把以前安装的包的include目录加入到该变量中来。

LDFLAGS：gcc 等编译器会用到的一些优化参数，也可以在里面指定库文件的位置。用法：LDFLAGS=-L/usr/lib -L/path/to/your/lib。每安装一个包都几乎一定的会在安装目录里建立一个lib目录。如果明明安装了某个包，而安装另一个包时，它愣是说找不到，可以抒那个包的lib路径加入的LDFALGS中试一下。

LIBS：告诉链接器要链接哪些库文件，如LIBS = -lpthread -liconv

简单地说，LDFLAGS是告诉链接器从哪里寻找库文件，而LIBS是告诉链接器要链接哪些库文件。不过使用时链接阶段这两个参数都会加上，所以你即使将这两个的值互换，也没有问题。

有时候LDFLAGS指定-L虽然能让链接器找到库进行链接，但是运行时链接器却找不到这个库，如果要让软件运行时库文件的路径也得到扩展，那么我们需要增加这两个库给"-Wl,R"：

LDFLAGS = -L/var/xxx/lib -L/opt/mysql/lib -Wl,R/var/xxx/lib -Wl,R/opt/mysql/lib

如果在执行./configure以前设置环境变量export LDFLAGS="-L/var/xxx/lib -L/opt/mysql/lib -Wl,R/var/xxx/lib -Wl,R/opt/mysql/lib" ，注意设置环境变量等号两边不可以有空格，而且要加上引号（shell的用法）。那么执行configure以后，Makefile将会设置这个选项，链接时会有这个参数，编译出来的可执行程序的库文件搜索路径就得到扩展了。
*** 参考文章
[[https://www.cnblogs.com/taskiller/archive/2012/12/14/2817650.html][Makefile选项CFLAGS,LDFLAGS,LIBS - Taskiller - 博客园]]
** =和:=的区别
如果使用=，make会将整个makefile展开后，再决定变量的值。也就是说，变量的值将会是整个makefile中最后被指定的值。看例子：
#+begin_src bash
x = foo
y = $(x) bar
x = xyz
#+END_SRC

在上例中，y的值将会是 xyz bar ，而不是 foo bar 。
#+begin_src bash
x := foo
y := $(x) bar
x := xyz
#+END_SRC
而:=表示变量在赋值时就先设置为该值，而不是整个makefile展开后的最终值，后面如果再有赋值，则会将前面的赋值覆盖，使用新的值。

在上例中，y的值将会是 foo bar ，而不是 xyz bar 了。

#+BEGIN_EXAMPLE
Simple assignment :=
A simple assignment expression is evaluated only once, at the very first occurrence. For example, if CC :=${GCC} ${FLAGS} during the first encounter is evaluated to gcc -W then each time ${CC} occurs it will be replaced with gcc -W.

Recursive assignment =
A Recursive assignment expression is evaluated everytime the variable is encountered in the code. For example, a statement like CC = ${GCC} {FLAGS} will be evaluated only when an action like ${CC} file.c is executed. However, if the variable GCC is reassigned i.e GCC=c++ then the ${CC} will be converted to c++ -W after the reassignment.

Conditional assignment ?=
Conditional assignment assigns a value to a variable only if it does not have a value

Appending +=
Assume that CC = gcc then the appending operator is used like CC += -w
then CC now has the value gcc -W
#+END_EXAMPLE
For more check out these [[https://github.com/amjadmajid/Makefile][tutorials]]
*** 参考文章
[[https://www.cnblogs.com/wanqieddy/archive/2011/09/21/2184257.html][Makefile 中:= ?= += =的区别- wanqi - 博客园]]
[[https://www.sunxidong.com/237.html][Makefile中“=”、“:=”、“?=”、“+=”的区别 - 孙希栋的博客]]
[[https://stackoverflow.com/questions/4879592/whats-the-difference-between-and-in-makefile][What's the difference between := and = in Makefile?]]
** 外部构建方式举例
外部构建会把生成的临时文件放在build目录下，不会对源文件有任何影响。
强烈建议使用外部构建方式

1. 建立一个build目录，可以在任何地方，建议在当前目录下

2. 进入build，运行cmake ..    当然..表示上一级目录，你可以写CMakeLists.txt所在的绝对路径，生产的文件都在build目录下了

3. 在build目录下，运行make来构建工程

注意外部构建的两个变量
1. <projectname>_BINARY_DIR，编译路径 也就是 /root/cmake/bulid
2. <projectname>_SOURCE_DIR，还是工程路径
* compdb
可以用于生成带头文件的compile_commands.json

compdb -p build/ list > compile_commands.json

https://github.com/Sarcasm/compdb#generate-a-compilation-database-with-header-files
* declare命令
Linux declare命令用于声明 shell 变量。

declare [-aAfFgilnrtux] [-p] [name[=value] ...]


** 参数说明
#+BEGIN_EXAMPLE
-f 将操作或显示限制为函数名及函数定义。
-F 只显示函数名（调试时附加行号和源文件）。
-g 在shell函数中使用时创建全局变量；其他情况下忽略。
-p 显示每个名称的属性和值。

*设置属性的选项:
-a 创建数组（如果支持）。
-A 创建关联数组（如果支持）。
-i 增加整型属性。
+i 删除整型属性。
-l 增加小写属性，变量的值将转换为小写。
+l 删除小写属性。
-n 增加引用属性（如果该选项存在）。
+n 删除引用属性（如果该选项存在）。
-r 增加只读属性。
-t 增加追踪属性。
+t 删除追踪属性。
-u 增加大写属性，变量的值将转换为大写。
+u 删除大写属性。
-x 增加导出属性。
+x 删除导出属性。
#+END_EXAMPLE

** 例子
#+begin_src bash
# 声明变量
declare reference_website='https://wangchujiang.com/linux-command/'

# 显示所有包含整型属性的变量和值。
declare -i
# 定义变量b并赋值为3，具有整型属性。
declare -i b=5
# 显示属性，返回 declare -i b="5"。
declare -p b
# 删除整型属性。
declare +i b
# 显示属性，返回 declare -- b="5"。
declare -p b
# 根据变量属性强制转换值的英文大小写。
declare -u uc_var='abc'
declare -l lc_var='ABC'
# 显示'ABC abc';
echo "${uc_var} ${lc_var}"
# 定义函数内的全局变量
function test(){
  declare -g a=3
  # 或者
  local -g b=3
  # 或者
  c=3
  # 让我们查看它们的属性。
  declare -p a b c
}
# 执行函数。
test
# 返回结果。
# declare -- a="3"
# declare -- b="3"
# declare -- c="3"

# 定义函数外的全局变量
declare a=3
b=3
declare –p a b
# 返回结果如下。
# declare -- a="3"
# declare -- b="3"

# 定义局部变量
function test2(){
  local -i a=3
  declare -i b=3
}
test2
# 没有该变量（已经被销毁了）
echo "${a} ${b}"
# 因此，我们日常脚本中最常见的类似于'a=3'实际上是声明并赋值了一个全局变量。
# 在接下来的 **讨论** 环节会延伸讨论全局和局部变量问题。
# 注意，不能使用 `+a` 或 `+A` 取消数组，也不能使用 `+r` 取消只读属性。

# 定义只读数组，设置属性的同时定义赋值。
declare -ar season=('Spring' 'Summer' 'Autumn' 'Winter')
# 或者这样。
season=('Spring' 'Summer' 'Autumn' 'Winter')
declare -ar season
# 显示所有数组。
declare -a
# 定义关联数组。

declare -A fruits=(['apple']='red' ['banana']='yellow')
# 显示所有关联数组。
declare -A
# 显示所有变量的属性和值并显示函数的定义，输出很长。
declare
# 显示所有变量的属性和值。
declare -p
# 显示所有全局变量的属性和值。
declare -g
# 显示全部函数名和函数定义。
declare -f
# 只显示全部函数名。
declare -F

# 定义两个函数。
function func_a(){ echo $(date +"%F %T"); }
function func_b(){ cd /; ls -lh --sort=time; }
# 显示一到多个函数名和函数定义。
declare -f func_a func_b
# 只显示一到多个函数名，验证某个名称是否已经定义为函数时有用。
declare -F func_a func_b
# 最好不要让函数名和变量名相同。
#+END_SRC
* df查看磁盘空间
df -hl：查看磁盘剩余空间

df -h：查看每个根路径的分区大小

du -sh [目录名]：返回该目录的大小

du -sm [文件夹]：返回该文件夹总M数

du -h [目录名]：查看指定文件夹下的所有文件大小（包含子文件夹）
* DISPLAY环境变量的作用
在Linux/Unix 类操作系统上, DISPLAY用来设置将图形显示到何处. 
直接登陆图形界面或者登陆命令行界面后使用startx启动图形, DISPLAY环境变量将自动设置为:0.0, 此时可以打开终端, 输出图形程序的名称(比如xclock)来启动程序, 图形将显示在本地窗口上

在终端上输入printenv查看当前环境变量, 输出结果中有如下内容: DISPLAY=:0.0

使用xdpyinfo可以查看到当前显示的更详细的信息。

DISPLAY 环境变量格式如下host:NumA.NumB, 
- host指Xserver所在的主机主机名或者ip地址, 图形将显示在这一机器上, 可以是启动了图形界面的Linux/Unix机器, 也可以是安装了Exceed, - X-Deep/32等Windows平台运行的Xserver的Windows机器. 如果Host为空, 则表示Xserver运行于本机, 并且图形程序(Xclient)使用unix socket方式连接到Xserver, 而不是TCP方式. 
- 使用TCP方式连接时, NumA为连接的端口减去6000的值, 如果NumA为0, 则表示连接到6000端口; 使用unix socket方式连接时则表示连接的unix socket的路径, 如果为0, 则表示连接到/tmp/.X11-unix/X0 . 
- NumB则几乎总是0.

Xserver默认情况下不允许别的用户的图形程序的图形显示在当前屏幕上. 

如果使用su username或者su - username切换到别的用户, 并且使用命令
#+begin_src bash
export DISPLAY=:0.0
#+END_SRC
设置DISPLAY环境变量, 运行图形程序(如xclock)时会收到如下错误:
#+BEGIN_EXAMPLE
Xlib: connection to ":0.0" refused by server Xlib: No protocol specified Error: Can't open display: :0.0
#+END_EXAMPLE
如果需要别的用户的图形显示在当前屏幕上, 则应以当前登陆的用户, 也就是切换身份前的用户执行如下命令：
#+begin_src bash
xhost +
#+END_SRC
这个命令将允许别的用户启动的图形程序将图形显示在当前屏幕上。

* dos2unix和unix2dos
dos2unix是将Windows格式文件转换为Unix、Linux格式的实用命令。Windows格式文件的换行符为\r\n ,而Unix&Linux文件的换行符为\n. dos2unix命令其实就是将文件中的\r\n 转换为\n。

而unix2dos则是和dos2unix互为孪生的一个命令，它是将Linux&Unix格式文件转换为Windows格式文件的命令。

命令语法：
#+begin_src bash
dos2unix [options] [-c convmode] [-o file ...] [-n infile outfile ...]
unix2dos [options] [-c convmode] [-o file ...] [-n infile outfile ...]
#+END_SRC
dos2unix 可以一次转换多个文件:
dos2unix filename1 filename2 filename3
** 命令参数
此命令参数是Red Hat Enterprise Linux Server release 5.7下dos2unix命令参数，不同版本Linux的dos2nnix命令参数有可能不同。


参数 描叙
-h 显示命令dos2unix联机帮助信息。
-k 保持文件时间戳不变
-q 静默模式，不输出转换结果信息等
-V 显示命令版本信息
-c 转换模式
-o 在源文件转换，默认参数
-n 保留原本的旧档，将转换后的内容输出到新档案.默认都会直接在原来的文件上修改，如果需要保留源文件，那么可以使用参数-n,格式为dos2unix -n oldfilename newfilename
** 示例
将Windows格式文本转换为Unix&Linux格式文件
#+begin_src bash
[root@DB-Server myscript]# cat -v test.sh 
. /home/oracle/.bash_profile^M
echo ' '^M
date^M
echo ' '^M
^M
sqlplus test/test @/home/oracle/scripts/test.sql^M
^M
echo ' '^M
date^M
echo ' '^M
[root@DB-Server myscript]# dos2unix test.sh 
dos2unix: converting file test.sh to UNIX format ...
[root@DB-Server myscript]# cat -v test.sh 
. /home/oracle/.bash_profile
echo ' '
date
echo ' '
 
sqlplus test/test @/home/oracle/scripts/test.sql
 
echo ' '
date
echo ' '
#+END_SRC

* docker
** 命令
#+BEGIN_SRC bash
docker ps  #可以用来查看当前正在运行的容器
docker ps -a #查看所有容器，包括已停止运行的
docker images #可以查看docker registry上已有的镜像
docker run [OPTIONS] IMAGE [COMMAND] [ARG...]
#用于创建容器,参数使用方法可参考[官方文档](https://docs.docker.com/engine/reference/commandline/run/)
docker run busybox echo "111"  #用镜像busybox创建容器，然后执行命令echo，然后退出容器

docker exec -u root -t -i cpd /bin/bash #用于以root身份进入容器
#需要注意的是，在容器内以root身份安装软件将会导致宿主机也安装软件

docker attach 容器名 #用于进入容器

docker search 镜像名 #查找镜像

docker rm 容器名 #删除容器
docker rmi 镜像名 # 删除镜像

# 从容器拷贝文件到宿主机
docker cp mycontainer:/opt/testnew/file.txt /opt/test/
# 从宿主机拷贝文件到容器
docker cp /opt/test/file.txt mycontainer:/opt/testnew/
#+END_SRC
** 基本概念
*** 镜像
我们都知道，操作系统分为 内核 和 用户空间。对于 Linux 而言，内核启动后，会挂载 root 文件系统为其提供用户空间支持。而 Docker 镜像（Image），就相当于是一个 root 文件系统。比如官方镜像 ubuntu:18.04 就包含了完整的一套 Ubuntu 18.04 最小系统的 root 文件系统。
Docker 镜像 是一个特殊的文件系统，除了提供容器运行时所需的程序、库、资源、配置等文件外，还包含了一些为运行时准备的一些配置参数（如匿名卷、环境变量、用户等）。镜像 不包含 任何动态数据，其内容在构建之后也不会被改变。
**** 分层存储
因为镜像包含操作系统完整的 root 文件系统，其体积往往是庞大的，因此在 Docker 设计时，就充分利用 Union FS 的技术，将其设计为分层存储的架构。所以严格来说，镜像并非是像一个 ISO 那样的打包文件，镜像只是一个虚拟的概念，其实际体现并非由一个文件组成，而是由一组文件系统组成，或者说，由多层文件系统联合组成。
镜像构建时，会一层层构建，前一层是后一层的基础。每一层构建完就不会再发生改变，后一层上的任何改变只发生在自己这一层。比如，删除前一层文件的操作，实际不是真的删除前一层的文件，而是仅在当前层标记为该文件已删除。在最终容器运行的时候，虽然不会看到这个文件，但是实际上该文件会一直跟随镜像。因此，在构建镜像的时候，需要额外小心，每一层尽量只包含该层需要添加的东西，任何额外的东西应该在该层构建结束前清理掉。

分层存储的特征还使得镜像的复用、定制变的更为容易。甚至可以用之前构建好的镜像作为基础层，然后进一步添加新的层，以定制自己所需的内容，构建新的镜像。
*** 容器
镜像（Image）和容器（Container）的关系，就像是面向对象程序设计中的 类 和 实例 一样，镜像是静态的定义，容器是镜像运行时的实体。容器可以被创建、启动、停止、删除、暂停等。

容器的实质是进程，但与直接在宿主执行的进程不同，容器进程运行于属于自己的独立的 命名空间。因此容器可以拥有自己的 root 文件系统、自己的网络配置、自己的进程空间，甚至自己的用户 ID 空间。容器内的进程是运行在一个隔离的环境里，使用起来，就好像是在一个独立于宿主的系统下操作一样。这种特性使得容器封装的应用比直接在宿主运行更加安全。也因为这种隔离的特性，很多人初学 Docker 时常常会混淆容器和虚拟机。

前面讲过镜像使用的是分层存储，容器也是如此。每一个容器运行时，是以镜像为基础层，在其上创建一个当前容器的存储层，我们可以称这个为容器运行时读写而准备的存储层为 容器存储层。
容器存储层的生存周期和容器一样，容器消亡时，容器存储层也随之消亡。因此，任何保存于容器存储层的信息都会随容器删除而丢失。

按照 Docker 最佳实践的要求，容器不应该向其存储层内写入任何数据，容器存储层要保持无状态化。所有的文件写入操作，都应该使用 数据卷（Volume）、或者 绑定宿主目录，在这些位置的读写会跳过容器存储层，直接对宿主（或网络存储）发生读写，其性能和稳定性更高。

数据卷的生存周期独立于容器，容器消亡，数据卷不会消亡。因此，使用数据卷后，容器删除或者重新运行之后，数据却不会丢失。
*** 仓库
镜像构建完成后，可以很容易的在当前宿主机上运行，但是，如果需要在其它服务器上使用这个镜像，我们就需要一个集中的存储、分发镜像的服务，Docker Registry 就是这样的服务。

一个 Docker Registry 中可以包含多个 仓库（Repository）；每个仓库可以包含多个 标签（Tag）；每个标签对应一个镜像。

通常，一个仓库会包含同一个软件不同版本的镜像，而标签就常用于对应该软件的各个版本。我们可以通过 <仓库名>:<标签> 的格式来指定具体是这个软件哪个版本的镜像。如果不给出标签，将以 latest 作为默认标签。

以 Ubuntu 镜像 为例，ubuntu 是仓库的名字，其内包含有不同的版本标签，如，16.04, 18.04。我们可以通过 ubuntu:16.04，或者 ubuntu:18.04 来具体指定所需哪个版本的镜像。如果忽略了标签，比如 ubuntu，那将视为 ubuntu:latest。

仓库名经常以 两段式路径 形式出现，比如 jwilder/nginx-proxy，前者往往意味着 Docker Registry 多用户环境下的用户名，后者则往往是对应的软件名。但这并非绝对，取决于所使用的具体 Docker Registry 的软件或服务。
**** Docker Registry 公开服务
Docker Registry 公开服务是开放给用户使用、允许用户管理镜像的 Registry 服务。一般这类公开服务允许用户免费上传、下载公开的镜像，并可能提供收费服务供用户管理私有镜像。

最常使用的 Registry 公开服务是官方的 Docker Hub，这也是默认的 Registry，并拥有大量的高质量的 官方镜像。除此以外，还有 Red Hat 的 Quay.io；Google 的 Google Container Registry，Kubernetes 的镜像使用的就是这个服务；代码托管平台 GitHub 推出的 ghcr.io。

由于某些原因，在国内访问这些服务可能会比较慢。国内的一些云服务商提供了针对 Docker Hub 的镜像服务（Registry Mirror），这些镜像服务被称为 加速器。常见的有 阿里云加速器、DaoCloud 加速器 等。使用加速器会直接从国内的地址下载 Docker Hub 的镜像，比直接从 Docker Hub 下载速度会提高很多。在 安装 Docker 一节中有详细的配置方法。

国内也有一些云服务商提供类似于 Docker Hub 的公开服务。比如 网易云镜像服务、DaoCloud 镜像市场、阿里云镜像库 等。
**** 私有 Docker Registry
除了使用公开服务外，用户还可以在本地搭建私有 Docker Registry。Docker 官方提供了 Docker Registry 镜像，可以直接使用做为私有 Registry 服务。在 私有仓库 一节中，会有进一步的搭建私有 Registry 服务的讲解。

开源的 Docker Registry 镜像只提供了 Docker Registry API 的服务端实现，足以支持 docker 命令，不影响使用。但不包含图形界面，以及镜像维护、用户管理、访问控制等高级功能。

除了官方的 Docker Registry 外，还有第三方软件实现了 Docker Registry API，甚至提供了用户界面以及一些高级功能。比如，Harbor 和 Sonatype Nexus。
** docker container prune
删除所有已停止的容器
** docker commit 
docker commit :从容器创建一个新的镜像。

语法

docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]]

OPTIONS说明：

-a :提交的镜像作者；

-c :使用Dockerfile指令来创建镜像；

-m :提交时的说明文字；

-p :在commit时，将容器暂停。

*** 实例
将容器a404c6c174a2 保存为新的镜像,并添加提交人信息和说明信息。
#+BEGIN_SRC bash
runoob@runoob:~$ docker commit -a "runoob.com" -m "my apache" a404c6c174a2  mymysql:v1 
sha256:37af1236adef1544e8886be23010b66577647a40bc02c0885a6600b33ee28057
runoob@runoob:~$ docker images mymysql:v1
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
mymysql             v1                  37af1236adef        15 seconds ago      329 MB
#+END_SRC
** docker exec
docker exec <container-id> cat /data.txt

用root进入容器：
docker exec -it --user root <container id> /bin/bash

** docker history
查看每个镜像中层的大小
#+begin_src bash
$ docker history bd09118bcef6
IMAGE               CREATED             CREATED BY                                      SIZE                COMMENT
bd09118bcef6        4 minutes ago       /bin/sh -c #(nop) COPY dir:35a7eb158c1504e...   100B                
d131e0fa2585        3 months ago        /bin/sh -c #(nop)  CMD ["/bin/bash"]            0B                  
<missing>           3 months ago        /bin/sh -c mkdir -p /run/systemd && echo '...   7B                  
<missing>           3 months ago        /bin/sh -c sed -i 's/^#\s*\(deb.*universe\...   2.78kB              
<missing>           3 months ago        /bin/sh -c rm -rf /var/lib/apt/lists/*          0B                  
<missing>           3 months ago        /bin/sh -c set -xe   && echo '#!/bin/sh' >...   745B                
<missing>           3 months ago        /bin/sh -c #(nop) ADD file:eef57983bd66e3a...   103MB
#+END_SRC

** docker run
#+BEGIN_SRC bash
docker run --rm --shm-size=32G --runtime=nvidia -it -p 8000:8888 --user 1036:1036 -v /etc/group:/etc/group:ro -v /etc/passwd:/etc/passwd:ro -v /home/yangliu/:/home/yangliu --name 容器名 镜像名称 /bin/bash
#+END_SRC
- --rm,当容器退出时,自动删除容器.
- –shm-size:分配/dev/shm/文件夹的大小./dev/shm/是linux下一个非常有用的目录，因为这个目录不在硬盘上，而是在内存里。
- –runtime指容器运行时.容器运行时是管理容器和容器镜像的程序,有各种不同的标准.用nvidia-docker才能启用GPU
- -it: -t让docker分配一个伪终端并绑定到容器的标准输入上, -i则让容器的标准输入保持打开.
- Docker中系统镜像的缺省命令是 bash，如果不加 -ti bash 命令执行了自动会退出。这是因为如果没有衔接输入流，本身就会马上结束。加-ti 后docker命令会为容器分配一个伪终端，并接管其stdin/stdout支持交互操作，这时候bash命令不会自动退出。
- -p:将容器指定端口指定映射到宿主机的一个端口上.以上指令会将宿主机的8000端口映射到容器的8888端口上。
- –user:如果不做相关的设置，容器中的进程默认以 root 用户权限启动.
- -v:将 host 上已存在的目录或文件挂载(mount)到容器.挂载后的目录或文件使得宿主机和容器可以同步修改文件。 路径映射 /a : /b将主机的/a路径映射到容器的/b 。-v也可用–mount来代替.
- –name:可以指定容器的名字
- /bin/bash 启动镜像后执行的命令
- d:后台执行
*** 例子
用镜像busybox创建容器，然后执行命令echo，然后退出容器
#+begin_src bash
$ docker run busybox echo "hello from busybox"  
hello from busybox
#+END_SRC
用交互式tty执行容器，如果不加-it参数，该命令创建容器后直接退出容器
#+BEGIN_EXAMPLE
#+begin_src bash
$ docker run -it busybox sh
$ ls
bin   dev   etc   home  proc  root  sys   tmp   usr   var
$ uptime
 05:45:21 up  5:58,  0 users,  load average: 0.00, 0.01, 0.04
#+END_SRC
#+END_EXAMPLE
** docker rm
#+begin_src bash
$ docker rm 305297d7a235 ff0a5c3750b9
305297d7a235
ff0a5c3750b9
# 一次性删除全部stuatus=exited的容器
$ docker rm $(docker ps -a -q -f status=exited)   #-q表示只返回IDs,-f表示过滤条件
#+END_SRC
** docker pull
docker pull : 从镜像仓库中拉取或者更新指定镜像

语法：
docker pull [OPTIONS] NAME[:TAG|@DIGEST]

OPTIONS说明：
- -a :拉取所有 tagged 镜像
- --disable-content-trust :忽略镜像的校验,默认开启

实例：
从Docker Hub下载java最新版镜像。
#+begin_src bash
docker pull java
#+END_SRC
从Docker Hub下载REPOSITORY为java的所有镜像。
#+begin_src bash
docker pull -a java
#+END_SRC
** docker ps
docker ps -a #查看所有容器，包括已停止运行的

docker ps -s 查看容器的大小。
- size表示每个容器的可写层使用的大小。
- virtual size表示容器使用的用于只读镜像的数据的数据量加上容器可写层的大小。多个容器可以共享一些或者所有的只读镜像数据。

因此每个正在运行的容器所使用磁盘总空间大小是virtual size和size的某种组合。如果多个容器从相同的基础镜像开始，所以这些容器在磁盘上的总大小为所有容器的大小size（SUM of all container size)加上一个镜像的大小(virtual size-size)
** docker images ls
查看镜像的大小。
#+begin_src bash
$ docker image ls

REPOSITORY                         TAG                     IMAGE ID            CREATED             SIZE
acme/my-final-image                1.0                     dbf995fc07ff        58 seconds ago      103MB
acme/my-base-image                 1.0                     bd09118bcef6        3 minutes ago       103MB
#+END_SRC
** 查找镜像
从远程仓库上查找镜像有两种方法
- 一是通过访问 Docker Hub 网站来搜索镜像，Docker Hub 网址为 https://hub.docker.com/
- 二是通过 docker search 命令来查找镜像

两种方法都好用，一般情况下对于精确的镜像，我们都使用 docker search 命令，比如 nginx 、php 和 python 等，除此之外，我们使用 Docker Hub 网站来查找

比如我们需要一个 httpd 的镜像来作为我们的 web 服务。我们可以通过 docker search 命令搜索 httpd 来寻找适合我们的镜像。
#+begin_src bash
runoob@runoob:~$  docker search httpd
#+END_SRC

#+DOWNLOADED: screenshot @ 2022-07-13 11:32:08
[[file:images/docker学习总结/docker_search/2022-07-13_11-32-08_screenshot.png]]
- NAME: 镜像仓库源的名称
- DESCRIPTION: 镜像的描述
- OFFICIAL: 是否 docker 官方发布
- stars: 类似 Github 里面的 star，表示点赞、喜欢的意思。
- AUTOMATED: 自动构建。

** Docker 退出容器但不关闭当前容器
方法一：如果要正常退出不关闭容器，请按Ctrl+P+Q进行退出容器

方法二：如果使用exit退出，那么在退出之后会关闭容器，可以使用下面的流程进行恢复

使用docker restart命令重启容器
使用docker attach命令进入容器
重启httpd（service httpd restart）和radosgw(/etc/init.d/ceph-radosgw restart)，并且使用wget验证是否将radosgw重启成功(wget http://127.0.0.1)
** Docker镜像分层
*** 镜像分层
Docker镜像是由一系列层来构成的，每层代表Dockerfile中的一条指令，依下面Dockerfile为例：
#+begin_src bash
FROM ubuntu:18.04
COPY . /app
RUN make /app
CMD python /app/app.py
#+END_SRC
该Dockerfile包含四个命令，每个命令都会新创建一个层。
FROM语句会从ubuntu:18.04镜像创建一个层。
COPY指令会从Docker客户端的当前目录下添加一些文件。
RUN指令使用了make指令来构建。
最后CMD是在容器中运行命令。

而对于Docker来说，创建新容器时，每一层都会彼此堆叠，可以在基础层的基础上添加新的可写容器层。
对容器的所做的所有更改都将写入到该可写容器层中。

下图显示了基于Ubuntu 15.04 的容器。对于Image layers都是Read Only的。

#+DOWNLOADED: screenshot @ 2022-07-13 14:26:58
[[file:images/docker学习总结/Docker镜像分层/2022-07-13_14-26-58_screenshot.png]]

启动镜像的时候，一个新的可写层会加载到镜像的顶部。这一层通常称为“容器层”， 之下是“镜像层”。

容器层可以读写，容器所有发生文件变更写都发生在这一层。镜像层read-only,只允许读取。

#+begin_src bash
>>> docker history f2b58b1192de
IMAGE               CREATED             CREATED BY                                      SIZE                COMMENT
f2b58b1192de        About an hour ago   /bin/sh -c #(nop)  CMD ["/bin/bash"]            0B                  
17d8c4095dc4        About an hour ago   /bin/sh -c yum install -y httpd                 110MB               
74bdbea98f73        About an hour ago   /bin/sh -c yum install -y vim                   133MB               
1e1148e4cc2c        2 months ago        /bin/sh -c #(nop)  CMD ["/bin/bash"]            0B                  
<missing>           2 months ago        /bin/sh -c #(nop)  LABEL org.label-schema....   0B                  
<missing>           2 months ago        /bin/sh -c #(nop) ADD file:6f877549795f479...   202MB   
#+END_SRC
第一列是imageid, 最上面的id就是我们新创建ryan/httpd:latest. 下面几行都是我们dockerfile里定义的步骤堆栈。由此可以看出，每个步骤都将创建一个imgid, 一直追溯到1e1148e4cc2c正好是我们的base镜像的id。关于<missing>的部分，则不在本机上。

最后一列是每一层的大小。最后一层只是启动bash，所以没有文件变更，大小是0. 我们创建的镜像是在base镜像之上的，并不是完全复制一份base，然后修改，而是共享base的内容。这时候，如果我们新建一个新的镜像，同样也是共享base镜像。

那修改了base镜像，会不会导致我们创建的镜像也被修改呢？ 不会！因为不允许修改历史镜像，只允许修改容器，而容器只可以在最上面的容器层进行写和变更。
*** 容器和层
对于容器和镜像(container和image)的主要区别就是顶部的可写层(the top writable layer),在容器中添加数据或者修改现有数据的所有读写操作都会存储在此可写层中。
删除容器后，可写层也会被删除，而基础镜像则保持不变。

每个容器都会有自己的可写层，所有的改变都存储在该容器层中。
多个容器可以共享对同一基础镜像的访问，但可以拥有自己的数据状态。

#+DOWNLOADED: screenshot @ 2022-07-13 14:28:05
[[file:images/docker学习总结/Docker镜像分层/2022-07-13_14-28-05_screenshot.png]]
#+BEGIN_EXAMPLE
如果需要对完全相同的数据的访问权限，需要将该数据存储在Docker volume中并且装入到容器中。
#+END_EXAMPLE
*** 修改时复制策略 copy-on-write (CoW)
docker通过一个叫做copy-on-write (CoW) 的策略来保证base镜像的安全性，以及更高的性能和空间利用率。
#+BEGIN_EXAMPLE
Copy-on-write is a strategy of sharing and copying files for maximum efficiency. If a file or directory exists in a lower layer within the image, and another layer (including the writable layer) needs read access to it, it just uses the existing file. The first time another layer needs to modify the file (when building the image or running the container), the file is copied into that layer and modified. This minimizes I/O and the size of each of the subsequent layers. These advantages are explained in more depth below.

Copying makes containers efficient
When you start a container, a thin writable container layer is added on top of the other layers. Any changes the container makes to the filesystem are stored here. Any files the container does not change do not get copied to this writable layer. This means that the writable layer is as small as possible.

When an existing file in a container is modified, the storage driver performs a copy-on-write operation. The specifics steps involved depend on the specific storage driver. For the aufs, overlay, and overlay2 drivers, the copy-on-write operation follows this rough sequence:

Search through the image layers for the file to update. The process starts at the newest layer and works down to the base layer one layer at a time. When results are found, they are added to a cache to speed future operations.

Perform a copy_up operation on the first copy of the file that is found, to copy the file to the container’s writable layer.

Any modifications are made to this copy of the file, and the container cannot see the read-only copy of the file that exists in the lower layer.

Btrfs, ZFS, and other drivers handle the copy-on-write differently. You can read more about the methods of these drivers later in their detailed descriptions.

Containers that write a lot of data consume more space than containers that do not. This is because most write operations consume new space in the container’s thin writable top layer.
#+END_EXAMPLE
简单的说，启动容器的时候，最上层容器层是可写层，之下的都是镜像层，只读层。

当容器需要读取文件的时候

从最上层镜像开始查找，往下找，找到文件后读取并放入内存，若已经在内存中了，直接使用。(即，同一台机器上运行的docker容器共享运行时相同的文件)。

当容器需要添加文件的时候

直接在最上面的容器层可写层添加文件，不会影响镜像层。

当容器需要修改文件的时候

从上往下层寻找文件，找到后，复制到容器可写层，然后，对容器来说，可以看到的是容器层的这个文件，看不到镜像层里的文件。容器在容器层修改这个文件。

当容器需要删除文件的时候

从上往下层寻找文件，找到后在容器中记录删除。即，并不会真正的删除文件，而是软删除。这将导致镜像体积只会增加，不会减少。

综上，Docker镜像通过分层实现了资源共享，通过copy-on-write实现了文件隔离。

对于文件只增加不减少问题，我们应当在同一层做增删操作，从而减少镜像体积。

比如，如下测试。

Dockerfile.A: 分层删除文件
#+begin_src bash
FROM centos:7
RUN yum install -y vim
RUN yum install -y httpd
WORKDIR /home
RUN dd if=/dev/zero of=50M.file bs=1M count=50
#创建大小为50M的测试文件
RUN rm -rf 50M.file
CMD ["/bin/bash"]
#+END_SRC
构建
#+begin_src bash
docker build -t test:a -f Dockerfile.A .
#+END_SRC
Dockerfile.B: 同层删除
#+begin_src bash
FROM centos:7
RUN yum install -y vim
RUN yum install -y httpd
WORKDIR /home
RUN dd if=/dev/zero of=50M.file bs=1M count=50 && rm -rf 50M.file
#+END_SRC
构建
#+begin_src bash
docker build -t test:b -f Dockerfile.B .
#+END_SRC
比较二者大小
#+begin_src bash
[root@sh-k8s-001 tmp]# docker images | grep test
test                                                                     a                          ae673aa7db48        9 minutes ago       497MB
test                                                                     b                          21b2bc49f0bd        12 minutes ago      444MB
#+END_SRC
显然，分层删除操作并没有真正删除掉文件。
*** 参考文章
[[https://zhuanlan.zhihu.com/p/139653646][Docker镜像分层]]
[[https://www.cnblogs.com/woshimrf/p/docker-container-lawyer.html][理解Docker镜像分层]]
** Dockerfile构建镜像
Dockerfile 中的每条指定都会创建镜像层，不过只有 RUN, COPY, ADD 会使镜像的体积增加。

可以通过命令 docker history image_id 来查看每一层的大小。
#+BEGIN_EXAMPLE
# syntax=docker/dockerfile:1
FROM node:12-alpine
RUN apk add --no-cache python g++ make
WORKDIR /app
COPY . .
RUN yarn install --production
CMD ["node", "src/index.js"]
#+END_EXAMPLE

#+begin_src bash
# -t 表示设置镜像名，下面命令镜像名为getting-started
docker build -t getting-started .
#+END_SRC
*** 指令
**** FROM
 FROM ubuntu:16.04

 表示使用当前Dockerfile在构建镜像时，是基于哪一个镜像。一般来说，不会从零开始构建镜像，一般都会选择一个已有的镜像作为基础，在上面安装各种软件，然后构建出一个加工过的镜像。

除了选择现有镜像为基础镜像外，Docker 还存在一个特殊的镜像，名为 scratch。这个镜像是虚拟的概念，并不实际存在，它表示一个空白的镜像。
#+begin_src bash
FROM scratch
...
#+END_SRC
如果你以 scratch 为基础镜像的话，意味着你不以任何镜像为基础，接下来所写的指令将作为镜像第一层开始存在。

不以任何系统为基础，直接将可执行文件复制进镜像的做法并不罕见，对于 Linux 下静态编译的程序来说，并不需要有操作系统提供运行时支持，所需的一切库都已经在可执行文件里了，因此直接 FROM scratch 会让镜像体积更加小巧。使用 Go 语言 开发的应用很多会使用这种方式来制作镜像，这也是为什么有人认为 Go 是特别适合容器微服务架构的语言的原因之一。

**** MAINTAINER
 MAINTAINER  beyond ubuntu ”1355036599@qq.com"

 用来提示用户，这个Dockerfile的作者、以及作者的联系方式

 MAINTAINER 语法: 
 MAINTAINER <name>

 指定镜像作者信息，即镜像的Author属性。
**** RUN
 RUN apt-get update && apt-get install -y nginx

 RUN用来执行一条Linux命令，执行的时机：在构建镜像的时候。

RUN命令格式有两种：
- shell 格式：RUN <命令>，就像直接在命令行中输入的命令一样。例如： RUN echo '<h1>Hello, Docker!</h1>' > /usr/share/nginx/html/index.html
- exec 格式：RUN ["可执行文件", "参数1", "参数2"]，这更像是函数调用中的格式。

执行多条命令应该像下面这样写：
#+begin_src bash
FROM debian:stretch

RUN set -x; buildDeps='gcc libc6-dev make wget' \
    && apt-get update \
    && apt-get install -y $buildDeps \
    && wget -O redis.tar.gz "http://download.redis.io/releases/redis-5.0.3.tar.gz" \
    && mkdir -p /usr/src/redis \
    && tar -xzf redis.tar.gz -C /usr/src/redis --strip-components=1 \
    && make -C /usr/src/redis \
    && make -C /usr/src/redis install \
    && rm -rf /var/lib/apt/lists/* \
    && rm redis.tar.gz \
    && rm -r /usr/src/redis \
    && apt-get purge -y --auto-remove $buildDeps
#+END_SRC
首先，之前所有的命令只有一个目的，就是编译、安装 redis 可执行文件。因此没有必要建立很多层，这只是一层的事情。因此，这里没有使用很多个 RUN 一一对应不同的命令，而是仅仅使用一个 RUN 指令，并使用 && 将各个所需命令串联起来。将之前的 7 层，简化为了 1 层。在撰写 Dockerfile 的时候，要经常提醒自己，这并不是在写 Shell 脚本，而是在定义每一层该如何构建。

并且，这里为了格式化还进行了换行。Dockerfile 支持 Shell 类的行尾添加 \ 的命令换行方式，以及行首 # 进行注释的格式。良好的格式，比如换行、缩进、注释等，会让维护、排障更为容易，这是一个比较好的习惯。

此外，还可以看到这一组命令的最后添加了清理工作的命令，删除了为了编译构建所需要的软件，清理了所有下载、展开的文件，并且还清理了 apt 缓存文件。这是很重要的一步，我们之前说过，镜像是多层存储，每一层的东西并不会在下一层被删除，会一直跟随着镜像。因此镜像构建时，一定要确保每一层只添加真正需要添加的东西，任何无关的东西都应该清理掉。
**** ADD
 ADD  ./index.html   /var/www/html/index.html

 这个命令的作用就是将Dockerfile文件所在目录中的某个文件，添加到要构建的镜像中。

 如果将Dockerfile所在的环境叫做外部环境，而构建出的镜像成为内部环境的话，ADD命令的作用就是将外部环境中的文件 添加到 内部环境中。

 注意，目标路径，如果不是以 / 结尾，表示文件；如果以 / 结尾，表示目录
**** WORKDIR
 设置一个工作目录，后面的RUN命令、CMD命令都会在这个工作目录中执行。

 相当于cd path
 #+begin_src bash
 WORKDIR /var/www/html
 RUN echo "hello docker" > demo.html
 WORKDIR /root
 RUN echo "hello root" > hey.txt
 #+END_SRC
 上面的代码表示，在/var/www/html目录下的demo.html中输入内容“hello world”；

 然后切换工作目录，在/root目录中，在hey.txt中输入内容，“hello root”
**** ENV
 定义环境变量，相当于全局变量

 ENV SELF_DEFINE_ENVIROMENT_VAR "123456789"

 在镜像中设置一个环境变量，SELF_DEFINE_ENVIROMENT_VAR ，值为123456789

 之后可以使用$SELF_DEFINE_ENVIROMENT_VAR来使用这个变量
**** USER
 指定启动容器后，是以什么身份来运行，可以同时设置组和用户

 USER root:root

 表示启动容器后，是以root组的root身份运行
**** COPY
 COPY命令和ADD命令功能类似，

 COPY index.html /tmp/test
 将外部环境的index.html拷贝到内部环境/tmp目录下，重命名为test。如果是要将index.html拷贝到/tmp/test目录下，即，将test看作是目录，那么，就要在test后面加 / ，即 /tmp/test/

 注意，目标路径，如果不是以 / 结尾，表示的文件；如果以 / 结尾，表示目录
**** CMD
 CMD /bin/bash

 表示在使用镜像，启动容器的时候，会运行的命令。

 和RUN的区别：
 1. RUN是在构建镜像的时候运行，而CMD是在容器启动的时候运行。可以理解为，RUN命令只是在构建时执行一次，而CMD命令在每次启动容器时，都会执行一次。
 2. 一个Dockerfile中可以有多个RUN命令，多个RUN命令都会执行；而CMD命令虽然可以出现多次，但是只有最后一个会被执行。
 3. RUN命令只运行一次，所以说不存在命令覆盖的情况，而CMD会出现命令覆盖的情况（即第2点区别），在启动容器时，如果指定了要执行的命令，那么Dockerfile中的CMD命令同样会被覆盖。
**** EXPOSE
 EXPOSE 80，表示将容器的80端口，映射到外部环境（宿主机）的某个端口上。

 可以通过启动容器的时候指定映射到宿主机的哪个端口
**** ONBUILD 
格式：ONBUILD <其它指令>。

ONBUILD 是一个特殊的指令，它后面跟的是其它指令，比如 RUN, COPY 等，而这些指令，在当前镜像构建时并不会被执行。只有当以当前镜像为基础镜像，去构建下一级镜像的时候才会被执行。
*** 构建Docker镜像
使用命令docker build命令即可触发构建操作，但是需要注意，构建时，要指定构建出的镜像名称（使用-t选项）以及tag，以及Dockerfile所在的路径。

一般构建的时候，都是进入到Dockerfile所在的目录
#+begin_src bash
#VERSION 0.0.1
FROM ubuntu:16.04
MAINTAINER ganlixin ubuntu "1355036599@qq.com"
RUN apt-get update && apt-get install -y nginx
RUN apt-get install -y vim
RUN rm -rf /var/www/html/index.html
ADD ./index.html /var/www/html/index.html
WORKDIR /var/www/html
RUN echo "hello docker" > demo.html
WORKDIR /root
RUN echo "hello root" > hey.txt
ENV SELF_DEFINE_ENVIROMENT_VAR "123456789"
RUN echo $SELF_DEFINE_ENVIROMENT_VAR > env_var.html
USER root:root
COPY index.html /tmp/test
CMD /bin/bash
EXPOSE 80
#+END_SRC
假设现在使用前面的Dockerfile构建一个镜像，镜像名为beyond/test，标签为v1，则执行如下命令
#+begin_src bash
>>> cd TestDockerfile
>>> docker build -t="beyond/test:v1" .
            .......等待
            ........
            .......构建完成
>>> docker run -i -t --name first_test beyond/test
>>> root@38ff683ba587:~#    #进入到容器中
#+END_SRC
注意，此时，在运行容器的时候，并没有在后面加上/bin/bash，这是因为Dockerfile中CMD命令已经指定了在启动容器时执行的命令。

build命令最后的 . 代表本次执行的上下文路径，如果不指定该路径，则默认为Dockerfile文件的路径。

可以用 -f ../Dockerfile.php 参数指定某个文件作为 Dockerfile
**** 上下文路径
Docker 在运行时分为 Docker 引擎（也就是服务端守护进程）和客户端工具。Docker 的引擎提供了一组 REST API，被称为 Docker Remote API，而如 docker 命令这样的客户端工具，则是通过这组 API 与 Docker 引擎交互，从而完成各种功能。因此，虽然表面上我们好像是在本机执行各种 docker 功能，但实际上，一切都是使用的远程调用形式在服务端（Docker 引擎）完成。也因为这种 C/S 设计，让我们操作远程服务器的 Docker 引擎变得轻而易举。

当我们进行镜像构建的时候，并非所有定制都会通过 RUN 指令完成，经常会需要将一些本地文件复制进镜像，比如通过 COPY 指令、ADD 指令等。而 docker build 命令构建镜像，其实并非在本地构建，而是在服务端，也就是 Docker 引擎中构建的。那么在这种客户端/服务端的架构中，如何才能让服务端获得本地文件呢？

这就引入了上下文的概念。当构建的时候，用户会指定构建镜像上下文的路径，docker build 命令得知这个路径后，会将路径下的所有内容打包，然后上传给 Docker 引擎。这样 Docker 引擎收到这个上下文包后，展开就会获得构建镜像所需的一切文件。

如果在 Dockerfile 中这么写：
#+begin_src bash
COPY ./package.json /app/
#+END_SRC
这并不是要复制执行 docker build 命令所在的目录下的 package.json，也不是复制 Dockerfile 所在目录下的 package.json，而是复制 上下文（context） 目录下的 package.json。

因此，COPY 这类指令中的源文件的路径都是相对路径。这也是初学者经常会问的为什么 COPY ../package.json /app 或者 COPY /opt/xxxx /app 无法工作的原因，因为这些路径已经超出了上下文的范围，Docker 引擎无法获得这些位置的文件。如果真的需要那些文件，应该将它们复制到上下文目录中去。

现在就可以理解刚才的命令 docker build -t nginx:v3 . 中的这个 .，实际上是在指定上下文的目录，docker build 命令会将该目录下的内容打包交给 Docker 引擎以帮助构建镜像。

如果观察 docker build 输出，我们其实已经看到了这个发送上下文的过程：
#+begin_src bash
$ docker build -t nginx:v3 .
Sending build context to Docker daemon 2.048 kB
...
#+END_SRC
理解构建上下文对于镜像构建是很重要的，避免犯一些不应该的错误。比如有些初学者在发现 COPY /opt/xxxx /app 不工作后，于是干脆将 Dockerfile 放到了硬盘根目录去构建，结果发现 docker build 执行后，在发送一个几十 GB 的东西，极为缓慢而且很容易构建失败。那是因为这种做法是在让 docker build 打包整个硬盘，这显然是使用错误。

一般来说，应该会将 Dockerfile 置于一个空目录下，或者项目根目录下。如果该目录下没有所需文件，那么应该把所需文件复制一份过来。如果目录下有些东西确实不希望构建时传给 Docker 引擎，那么可以用 .gitignore 一样的语法写一个 .dockerignore，该文件是用于剔除不需要作为上下文传递给 Docker 引擎的。

那么为什么会有人误以为 . 是指定 Dockerfile 所在目录呢？这是因为在默认情况下，如果不额外指定 Dockerfile 的话，会将上下文目录下的名为 Dockerfile 的文件作为 Dockerfile。

这只是默认行为，实际上 Dockerfile 的文件名并不要求必须为 Dockerfile，而且并不要求必须位于上下文目录中，比如可以用 -f ../Dockerfile.php 参数指定某个文件作为 Dockerfile。

当然，一般大家习惯性的会使用默认的文件名 Dockerfile，以及会将其置于镜像构建上下文目录中。
*** 多阶段构建
Docker 17.05版本以后，新增了Dockerfile多阶段构建。所谓多阶段构建，实际上是允许一个Dockerfile 中出现多个 FROM 指令。
**** 老版本Docker中为什么不支持多个 FROM 指令
在17.05版本之前的Docker，只允许Dockerfile中出现一个FROM指令，这得从镜像的本质说起。

Dockerfile 中，大多数指令会生成一个层，比如下方的两个例子：

示例一，foo 镜像的Dockerfile
#+begin_src bash
# 基础镜像中已经存在若干个层了
FROM ubuntu:16.04

# RUN指令会增加一层，在这一层中，安装了 git 软件
RUN apt-get update \
  && apt-get install -y --no-install-recommends git \
  && apt-get clean \
  && rm -rf /var/lib/apt/lists/*
#+END_SRC
示例二，bar 镜像的Dockerfile
#+begin_src bash
FROM foo

# RUN指令会增加一层，在这一层中，安装了 nginx
RUN apt-get update \
  && apt-get install -y --no-install-recommends nginx \
  && apt-get clean \
  && rm -rf /var/lib/apt/lists/*
#+END_SRC
假设基础镜像ubuntu:16.04已经存在5层，使用第一个Dockerfile打包成镜像 foo，则foo有6层，又使用第二个Dockerfile打包成镜像bar，则bar中有7层。

如果ubuntu:16.04 等其他镜像不算，如果系统中只存在 foo 和 bar 两个镜像，那么系统中一共保存了7层，并非13层，这是因为，foo和bar共享了6层。

层的共享机制可以节约大量的磁盘空间和传输带宽，比如你本地已经有了foo镜像，又从镜像仓库中拉取bar镜像时，只拉取本地所没有的最后一层就可以了，不需要把整个bar镜像连根拉一遍。但是层共享是怎样实现的呢？

原来，Docker镜像的每一层只记录文件变更，在容器启动时，Docker会将镜像的各个层进行计算，最后生成一个文件系统，这个被称为 联合挂载。对此感兴趣的话可以进入了解一下 AUFS。

Docker的各个层是有相关性的，在联合挂载的过程中，系统需要知道在什么样的基础上再增加新的文件。那么这就要求一个Docker镜像只能有一个起始层，只能有一个根。所以，Dockerfile中，就只允许一个FROM指令。因为多个FROM 指令会造成多根，则是无法实现的。
**** 多个 FROM 指令的意义
17.05 版本以后允许 Dockerfile支持多个 FROM 指令。

多个 FROM 指令并不是为了生成多根的层关系，最后生成的镜像，仍以最后一条 FROM 为准，之前的 FROM 会被抛弃，那么之前的FROM 又有什么意义呢？

每一条 FROM 指令都是一个构建阶段，多条 FROM 就是多阶段构建，虽然最后生成的镜像只能是最后一个阶段的结果，但是，能够将前置阶段中的文件拷贝到后边的阶段中，这就是多阶段构建的最大意义。

最大的使用场景是将编译环境和运行环境分离，比如，之前我们需要构建一个Go语言程序，那么就需要用到go命令等编译环境，我们的Dockerfile可能是这样的：
#+begin_src bash
# Go语言环境基础镜像
FROM golang:1.10.3

# 将源码拷贝到镜像中
COPY server.go /build/

# 指定工作目录
WORKDIR /build

# 编译镜像时，运行 go build 编译生成 server 程序
RUN CGO_ENABLED=0 GOOS=linux GOARCH=amd64 GOARM=6 go build -ldflags '-w -s' -o server

# 指定容器运行时入口程序 server
ENTRYPOINT ["/build/server"]
#+END_SRC
基础镜像golang:1.10.3是非常庞大的，因为其中包含了所有的Go语言编译工具和库，而运行时候我们仅仅需要编译后的server程序就行了，不需要编译时的编译工具，最后生成的大体积镜像就是一种浪费。

使用脉冲云的解决办法是将程序编译和镜像打包分开，使用脉冲云的编译构建服务，选择增加构Go语言构建工具，然后在构建步骤中编译。

最后将编译接口拷贝到镜像中就行了，那么Dockerfile的基础镜像并不需要包含Go编译环境：
#+begin_src bash
# 不需要Go语言编译环境
FROM scratch

# 将编译结果拷贝到容器中
COPY server /server

# 指定容器运行时入口程序 server
ENTRYPOINT ["/server"]
#+END_SRC
提示：scratch 是内置关键词，并不是一个真实存在的镜像。 FROM scratch 会使用一个完全干净的文件系统，不包含任何文件。 因为Go语言编译后不需要运行时，也就不需要安装任何的运行库。FROM scratch可以使得最后生成的镜像最小化，其中只包含了 server 程序。
在 Docker 17.05版本以后，就有了新的解决方案，直接一个Dockerfile就可以解决：
#+begin_src bash
# 编译阶段
FROM golang:1.10.3

COPY server.go /build/

WORKDIR /build

RUN CGO_ENABLED=0 GOOS=linux GOARCH=amd64 GOARM=6 go build -ldflags '-w -s' -o server

# 运行阶段
 FROM scratch

# 从编译阶段的中拷贝编译结果到当前镜像中
COPY --from=0 /build/server /

ENTRYPOINT ["/server"]

#+END_SRC

这个 Dockerfile 的玄妙之处就在于 COPY 指令的--from=0 参数，从前边的阶段中拷贝文件到当前阶段中，多个FROM语句时，0代表第一个阶段。除了使用数字，我们还可以给阶段命名，比如：
#+begin_src bash
# 编译阶段 命名为 builder
FROM golang:1.10.3 as builder

# ... 省略

# 运行阶段
FROM scratch

# 从编译阶段的中拷贝编译结果到当前镜像中
COPY --from=builder /build/server /
更为强大的是，COPY --from 不但可以从前置阶段中拷贝，还可以直接从一个已经存在的镜像中拷贝。比如，

   FROM ubuntu:16.04
    
   COPY --from=quay.io/coreos/etcd:v3.3.9 /usr/local/bin/etcd /usr/local/bin/

#+END_SRC

我们直接将etcd镜像中的程序拷贝到了我们的镜像中，这样，在生成我们的程序镜像时，就不需要源码编译etcd了，直接将官方编译好的程序文件拿过来就行了。

有些程序要么没有apt源，要么apt源中的版本太老，要么干脆只提供源码需要自己编译，使用这些程序时，我们可以方便地使用已经存在的Docker镜像作为我们的基础镜像。但是我们的软件有时候可能需要依赖多个这种文件，我们并不能同时将 nginx 和 etcd 的镜像同时作为我们的基础镜像（不支持多根），这种情况下，使用 COPY --from 就非常方便实用了。
**** 参考文章
[[https://segmentfault.com/a/1190000016137548][Dockerfile多阶段构建原理和使用场景]]
*** 参考文章
[[https://www.cnblogs.com/-beyond/p/9687314.html#command][使用Dockerfile来构建镜像]]
[[https://yeasy.gitbook.io/docker_practice/image/build][使用 Dockerfile 定制镜像]]
[[https://yeasy.gitbook.io/docker_practice/image/dockerfile/onbuild][Docker从入门到实践]]
** 其它 docker build 的用法
*** 直接用 Git repo 进行构建
或许你已经注意到了，docker build 还支持从 URL 构建，比如可以直接从 Git repo 中构建：
#+begin_src bash
# $env:DOCKER_BUILDKIT=0
# export DOCKER_BUILDKIT=0

$ docker build -t hello-world https://github.com/docker-library/hello-world.git#master:amd64/hello-world

Step 1/3 : FROM scratch
 --->
Step 2/3 : COPY hello /
 ---> ac779757d46e
Step 3/3 : CMD ["/hello"]
 ---> Running in d2a513a760ed
Removing intermediate container d2a513a760ed
 ---> 038ad4142d2b
Successfully built 038ad4142d2b

#+END_SRC

这行命令指定了构建所需的 Git repo，并且指定分支为 master，构建目录为 /amd64/hello-world/，然后 Docker 就会自己去 git clone 这个项目、切换到指定分支、并进入到指定目录后开始构建。
*** 用给定的 tar 压缩包构建
#+begin_src bash
$ docker build http://server/context.tar.gz
#+END_SRC
如果所给出的 URL 不是个 Git repo，而是个 tar 压缩包，那么 Docker 引擎会下载这个包，并自动解压缩，以其作为上下文，开始构建。
*** 从标准输入中读取 Dockerfile 进行构建
#+begin_src bash
docker build - < Dockerfile
#+END_SRC
或
#+begin_src bash
cat Dockerfile | docker build -
#+END_SRC
如果标准输入传入的是文本文件，则将其视为 Dockerfile，并开始构建。这种形式由于直接从标准输入中读取 Dockerfile 的内容，它没有上下文，因此不可以像其他方法那样可以将本地文件 COPY 进镜像之类的事情。
*** 从标准输入中读取上下文压缩包进行构建
#+begin_src bash
$ docker build - < context.tar.gz
#+END_SRC
如果发现标准输入的文件格式是 gzip、bzip2 以及 xz 的话，将会使其为上下文压缩包，直接将其展开，将里面视为上下文，并开始构建。
*** 参考文章
[[https://yeasy.gitbook.io/docker_practice/image/build][使用 Dockerfile 定制镜像]]
** SSH远程登录连接docker容器
环境：
- 计算机A为本机计算机；
- 计算机B上创建docker容器；

目的：
在A上ssh远程登录B上的docker容器：

计算机B上创建docker容器步骤：

1. 在ubuntu镜像中创建容器：
docker run -it ubuntu:16.04 /bin/bash

2. 进入容器，设置容器root密码
修改容器的root密码：passwd
密码设置为：123456

3. 修改ssh配置,允许root登录
vi /etc/ssh/sshd_config
将PermitRootLogin的值从withoutPassword改为yes

下面是可选设置
#+BEGIN_EXAMPLE
RSAAuthentication yes #启用 RSA 认证
PubkeyAuthentication yes #启用公钥私钥配对认证方式 
AuthorizedKeysFile .ssh/authorized_keys #公钥文件路径（和上面生成的文件同）
PermitRootLogin yes #root能使用ssh登录
#+END_EXAMPLE

4. 重启ssh服务
service ssh start

5. 将新的镜像启动，并将docker服务器的50001端口映射到容器的22端口上
docker run -it -p 50001:22 ubuntu-ssh /bin/bash

6. 在计算机A上ssh远程登录上述B创建的容器：
#+begin_src bash
ssh root@192.168.1.249 -p 50001
192.168.1.249为B的ip地址

ww@NiandeMacBook-Pro  ~  ssh root@192.168.1.249 -p 50001
The authenticity of host '[192.168.1.249]:50001 ([192.168.1.249]:50001)' can't be established.
ECDSA key fingerprint is SHA256:/i5usXixuOlLTjQO49xbMQEqE/Zj88UsnRmgKlZZ7Rc.
Are you sure you want to continue connecting (yes/no)? yes
Warning: Permanently added '[192.168.1.249]:50001' (ECDSA) to the list of known hosts.
root@192.168.1.249's password:
#+END_SRC
此时输入的密码是当时在容器中所设置修改的root密码，123456

7. 如果需要免密登录，需要把公钥添加到容器里的authorized_keys，而不是宿主机的authorized_keys文件
** VScode + docker进行代码调试
首先docker容器要打开ssh服务，使得可以用ssh连接到docker容器里。

配置VS Code：

打开VS code，在扩展栏（或者按ctr+shift+X）查找安装Remote Development

#+DOWNLOADED: file:E:/org/图片/Snipaste_2021-10-16_21-17-12.png @ 2021-10-16 21:17:25
[[file:VScode_+_docker进行代码调试/2021-10-16_21-17-25_Snipaste_2021-10-16_21-17-12.png]]
安装完成后需要reload一下，然后按ctr+shift+p，打开查找栏，输入remote-ssh，选择open Configuration file
#+DOWNLOADED: file:E:/org/图片/Snipaste_2021-10-16_21-17-36.png @ 2021-10-16 21:17:44
[[file:VScode_+_docker进行代码调试/2021-10-16_21-17-44_Snipaste_2021-10-16_21-17-36.png]]
#+DOWNLOADED: file:E:/org/图片/Snipaste_2021-10-16_21-17-50.png @ 2021-10-16 21:17:54
[[file:VScode_+_docker进行代码调试/2021-10-16_21-17-54_Snipaste_2021-10-16_21-17-50.png]]
Host随便起名字，这里我用AutoML_docker命名。在HostName的地方输入服务器的ip，注意端口Port是我们之前docker映射到服务器上的端口号。
配置成功后左边会多出一个远程浏览的标签，点开就可以看到刚才配置的远程连接了。点击之后要输入密码，即我们创建docker后修改的root密码。

#+DOWNLOADED: file:E:/org/图片/Snipaste_2021-10-16_21-18-16.png @ 2021-10-16 21:18:21
[[file:VScode_+_docker进行代码调试/2021-10-16_21-18-21_Snipaste_2021-10-16_21-18-16.png]]

配置vscode debugger:
菜单查看-扩展或者Ctrl + Shift + X，在商店中搜索“Python”，找到“适Python extension for Visual Studio Code”安装在服务器docker中，然后重启VSCode。
之后，菜单查看-命令面板或者Ctrl + Shift + P，输入“python: select interpreter”,点击选择解析器，稍等几秒钟，就会列出在系统中找到的Python环境（Python环境要加入环境变量才能被找到），点击需要的python解析器即可。
打开debug选项卡，选择Add configuration

#+DOWNLOADED: file:E:/org/图片/Snipaste_2021-10-16_21-19-03.png @ 2021-10-16 21:19:08
[[file:VScode_+_docker进行代码调试/2021-10-16_21-19-08_Snipaste_2021-10-16_21-19-03.png]]
编辑launch.json文件如下：
#+DOWNLOADED: file:E:/org/图片/Snipaste_2021-10-16_21-19-22.png @ 2021-10-16 21:19:27
[[file:VScode_+_docker进行代码调试/2021-10-16_21-19-27_Snipaste_2021-10-16_21-19-22.png]]
launch.json常用的调试配置有：
- “Python: Current File (Integrated Terminal)”：该配置表示在VSCode内置的命令行中直接执行当前激活的Python文件。如果需要制定要执行的文件，可以修改"program": "${file}"中的${file}宏为需要的文件。
- “Python: Current File (External Terminal)”：该配置功能和上面的相同，区别是不使用VSCode内置命令行，而新打开一个命令行。
- “Python: Attach”：该配置是附件到另外一个进程的调试方式。

** docker 拷贝镜像文件
*** 概述

我们制作好镜像后，有时需要将镜像复制到另一台服务器使用。

能达到以上目的有两种方式，一种是上传镜像到仓库中（本地或公共仓库），但是另一台服务器很肯能只是与当前服务器局域网想通而没有公网的，所以如果使用仓库的方式，只能自己搭建私有仓库，这会在另一篇文章中介绍。

如果我们仅仅是要复制到另外少数的服务器，搭建私有仓库显然没有这个必要，而将镜像保存为文件上传到其他服务器再从文件中载入镜像也是一个不错的选择。

可以使用Docker save和Docker load命令来存储和载入镜像。

*** 保存镜像为文件
**** docker save
如果要讲镜像保存为本地文件，可以使用Docker save命令。

命令格式：
docker save -o 要保存的文件名  要保存的镜像

首先查看当前的镜像列表：

docker images

#+DOWNLOADED: file:E:/org/图片/Snipaste_2021-10-11_15-50-43.png @ 2021-10-11 23:07:40
[[file:docker_拷贝镜像文件/2021-10-11_23-07-40_Snipaste_2021-10-11_15-50-43.png]]

比如这里,我们将java8的镜像保存为文件：

docker save -o java8.tar lwieske/java-8

完成后通过 ls 命令即可看到文件。 
**** docker expory
***** Description
Export a container’s filesystem as a tar archive
***** Usage
#+begin_src bash
 docker export [OPTIONS] CONTAINER
#+END_SRC
***** Extended description
The docker export command does not export the contents of volumes associated with the container. If a volume is mounted on top of an existing directory in the container, docker export will export the contents of the underlying directory, not the contents of the volume.

Refer to Backup, restore, or migrate data volumes in the user guide for examples on exporting data in a volume.

For example uses of this command, refer to the examples section below.
***** Options
| Name, shorthand | Default | Description                        |
|-----------------+---------+------------------------------------|
| --output , -o   |         | Write to a file, instead of STDOUT |
***** Examples
Each of these commands has the same result.
#+begin_src bash
docker export red_panda > latest.tar
docker export --output="latest.tar" red_panda
#+END_SRC

*** 从文件载入镜像
**** docker load 
从文件载入镜像可以使用Docker load命令。

命令格式：

docker load --input 文件

或者

docker load < 文件名

此时会导入镜像以及相关的元数据信息等。

首先使用SSH工具将文件上传到另一台服务器。

然后通过命令载入镜像：


docker load < java8.tar

导入后可以使用docker images命令查看:

#+DOWNLOADED: file:E:/org/图片/Snipaste_2021-10-11_23-08-30.png @ 2021-10-11 23:08:52
[[file:docker_拷贝镜像文件/2021-10-11_23-08-52_Snipaste_2021-10-11_23-08-30.png]]
**** docker import
***** Description
Import the contents from a tarball to create a filesystem image
***** Usage
#+begin_src bash
docker import [OPTIONS] file|URL|- [REPOSITORY[:TAG]]
#+END_SRC
***** Extended description
You can specify a URL or - (dash) to take data directly from STDIN. The URL can point to an archive (.tar, .tar.gz, .tgz, .bzip, .tar.xz, or .txz) containing a filesystem or to an individual file on the Docker host. If you specify an archive, Docker untars it in the container relative to the / (root). If you specify an individual file, you must specify the full path within the host. To import from a remote location, specify a URI that begins with the http:// or https:// protocol.

The --change option will apply Dockerfile instructions to the image that is created. Supported Dockerfile instructions: CMD|ENTRYPOINT|ENV|EXPOSE|ONBUILD|USER|VOLUME|WORKDIR

For example uses of this command, refer to the examples section below.
***** Options
| Name, shorthand | Default | Description                                                 |
|-----------------+---------+-------------------------------------------------------------|
| --change , -c   |         | Apply Dockerfile instruction to the created image           |
| --message , -m  |         | Set commit message for imported image                       |
| --platform      |         | API 1.32+  Set platform if server is multi-platform capable |
***** Examples
****** Import from a remote location
This will create a new untagged image.
#+begin_src bash
 docker import https://example.com/exampleimage.tgz
#+END_SRC
****** Import from a local file
Import to docker via pipe and STDIN.
#+begin_src bash
 cat exampleimage.tgz | docker import - exampleimagelocal:new
#+END_SRC
****** Import with a commit message.
#+begin_src bash
 cat exampleimage.tgz | docker import --message "New image imported from tarball" - exampleimagelocal:new
#+END_SRC
****** Import to docker from a local archive.
#+begin_src bash
 docker import /path/to/exampleimage.tgz
#+END_SRC
****** Import from a local directory
#+begin_src bash
 sudo tar -c . | docker import - exampleimagedir
#+END_SRC
****** Import from a local directory with new configurations
#+begin_src bash
 sudo tar -c . | docker import --change "ENV DEBUG=true" - exampleimagedir
#+END_SRC
Note the sudo in this example – you must preserve the ownership of the files (especially root ownership) during the archiving with tar. If you are not root (or the sudo command) when you tar, then the ownerships might not get preserved.
*** docker save与docker export的区别
docker save和docker export的区别:
- docker save保存的是镜像（image），docker export保存的是容器（container）；
- docker load用来载入镜像包，docker import用来载入容器包，但两者都会恢复为镜像；
- docker load不能对载入的镜像重命名，而docker import可以为镜像指定新名称。

docker export的应用场景主要用来制作基础镜像，比如你从一个ubuntu镜像启动一个容器，然后安装一些软件和进行一些设置后，使用docker export保存为一个基础镜像。然后，把这个镜像分发给其他人使用，比如作为基础的开发环境。

docker save的应用场景是，如果你的应用是使用docker-compose.yml编排的多个镜像组合，但你要部署的客户服务器并不能连外网。这时，你可以使用docker save将用到的镜像打个包，然后拷贝到客户服务器上使用docker load载入。

导出后再导入(exported-imported)的镜像会丢失所有的历史，而保存后再加载（saveed-loaded）的镜像没有丢失历史和层(layer)。这意味着使用导出后再导入的方式，你将无法回滚到之前的层(layer)，同时，使用保存后再加载的方式持久化整个镜像，就可以做到层回滚（可以执行docker tag <LAYER ID> <IMAGE NAME>来回滚之前的层）。
** 镜像改名命令格式：
命令格式：

 docker  tag  镜像id  仓库：标签
 
或：
 
 docker  tag  旧镜像名  新镜像名

** linux docker 中实现某些程序段开机自启动
将服务添加到启动文件bashrc中即可

比如可以在root用户下设置自动启动ssh服务：
#+begin_src bash
vim /root/.bashrc
#+END_SRC
在.bashrc文件末尾添加下面的内容
#+begin_src bash
service ssh start >>/root/startup_run.log
#+END_SRC
** docker删除<none>镜像
以下是搜到的几种方案
http://blog.51yip.com/cloud/1859.html
#+begin_src bash
# 停止docker
docker stop $(docker ps -a | grep "Exited" | awk '{print $1 }')
# 删除docker
docker rm $(docker ps -a | grep "Exited" | awk '{print $1 }')
# 删除images
docker rmi $(docker images | grep "none" | awk '{print $3}')
#+END_SRC

或者 http://blog.csdn.net/u014221090/article/details/53186313
#+begin_src bash
docker ps -a | grep "Exited" | awk '{print $1 }'|xargs docker stop
docker ps -a | grep "Exited" | awk '{print $1 }'|xargs docker rm
docker images|grep none|awk '{print $3 }'|xargs docker rmi
#+END_SRC
或者 http://blog.csdn.net/goflyfreely/article/details/53149894
#+BEGIN_EXAMPLE
好的<none>:<none>镜像的产生
例如从镜像仓库里拿一个fedora 镜像。如图虽然docker images 只显示fedora:latest，但是
docker images -a 显示了两个镜像fedora:latest 和<none>:<none>.
原来docker中镜像是有垂直父子关系的，层级关系可以在/var/lib/docker/graph中看到。docker pull fedora执行的时候呢，就会每次下载一个镜像。
可以通过查看/var/lib/docker/graph的json查看父子关系。这些镜像都不会引起存储空间占用的问题。
#+END_EXAMPLE
#+begin_src bash
root@xxxx:/var/lib/docker/graph# more ff0e2b608af6b1901d8ad9e9556e9e8ffe91b4c5386039e32bdf087df6157f65/json
{"container_config":{"Hostname":"","Domainname":"","User":"","AttachStdin":false,"AttachStdout":false,"AttachStderr":false,"Tty":fal
se,"OpenStdin":false,"StdinOnce":false,"Env":null,"Cmd":["/bin/sh -c echo 'export PATH=$ORACLE_HOME/bin:$PATH' \u003e\u003e /etc/bas
h.bashrc"],"Image":"","Volumes":null,"WorkingDir":"","Entrypoint":null,"OnBuild":null,"Labels":null},"created":"2016-04-20T10:29:03.
276290831Z","layer_id":"sha256:a5d9cef8ef2a0ffd19fea965e22924c2717bdcec82f628344111ae5aeec3ec13","parent_id":"sha256:c74e9fd53a7e49d
4d4cd562a69aa8ccc094ee17aedb7cc26a161af2903af8f68"}
#+END_SRC
#+BEGIN_EXAMPLE
坏的<none>:<none>镜像的产生
而docker build 或是 pull 命令就会产生临时镜像。如果我们用dockerfile创建一个helloworld镜像后，因为版本更新需要重新创建，那么以前那个版本的镜像就会
成为临时镜像。这个是需要删除的。
#+END_EXAMPLE
删除命令见下。
#+begin_src bash
sudo docker rmi $(docker images -f "dangling=true" -q)
#+END_SRC


*** 参考文章
[[https://www.jianshu.com/p/d06830de219f][docker删除<none>镜像]]
** 压缩Docker镜像的方法
*** 优化基础镜像
优化基础镜像的方法就是选用合适的更小的基础镜像，常用的 Linux 系统镜像一般有 Ubuntu、CentOs、Alpine，其中Alpine更推荐使用。大小对比如下：
#+begin_src bash
lynzabo@ubuntu ~/s> docker images
REPOSITORY         TAG             IMAGE ID            CREATED             SIZE
ubuntu             latest        74f8760a2a8b        8 days ago          82.4MB
alpine             latest        11cd0b38bc3c        2 weeks ago         4.41MB
centos               7           49f7960eb7e4        7 weeks ago         200MB
debian             latest        3bbb526d2608        8 days ago          101MB
lynzabo@ubuntu ~/s>
#+END_SRC
Alpine是一个高度精简又包含了基本工具的轻量级Linux发行版，基础镜像只有4.41M，各开发语言和框架都有基于Alpine制作的基础镜像，强烈推荐使用它。

**** scratch镜像
scratch是一个空镜像，只能用于构建其他镜像，比如你要运行一个包含所有依赖的二进制文件，如Golang程序，可以直接使用scratch作为基础镜像。现在给大家展示一下上文提到的Google pause镜像Dockerfile：
#+begin_src bash
FROM scratch
ARG ARCH
ADD bin/pause-${ARCH} /pause
ENTRYPOINT ["/pause"]
#+END_SRC
Google pause镜像使用了scratch作为基础镜像，这个镜像本身是不占空间的，使用它构建的镜像大小几乎和二进制文件本身一样大，所以镜像非常小。当然在我们的Golang程序中也会使用。对于一些Golang/C程序，可能会依赖一些动态库，你可以使用自动提取动态库工具，比如ldd、linuxdeployqt等提取所有动态库，然后将二进制文件和依赖动态库一起打包到镜像中。

**** busybox镜像
scratch是个空镜像，如果希望镜像里可以包含一些常用的Linux工具，busybox镜像是个不错选择，镜像本身只有1.16M，非常便于构建小镜像。

*** 串联 Dockerfile 指令
大家在定义Dockerfile时，如果太多的使用RUN指令，经常会导致镜像有特别多的层，镜像很臃肿，而且甚至会碰到超出最大层数（127层）限制的问题，遵循 Dockerfile 最佳实践，我们应该把多个命令串联合并为一个 RUN（通过运算符&&和/ 来实现），每一个 RUN 要精心设计，确保安装构建最后进行清理，这样才可以降低镜像体积，以及最大化的利用构建缓存。

下面是一个优化前Dockerfile：
#+begin_src bash
FROM ubuntu

ENV VER     3.0.0  
ENV TARBALL http://download.redis.io/releases/redis-$VER.tar.gz  
==> Install curl and helper tools...
RUN apt-get update  
RUN apt-get install -y  curl make gcc  
==> Download, compile, and install...
RUN curl -L $TARBALL | tar zxv  
WORKDIR  redis-$VER  
RUN make  
RUN make install  
...
==> Clean up...
WORKDIR /  
RUN apt-get remove -y --auto-remove curl make gcc  
RUN apt-get clean  
RUN rm -rf /var/lib/apt/lists/*  /redis-$VER  
...
CMD ["redis-server"]

#+END_SRC

构建镜像，名称叫 test/test:0.1。

我们对Dockerfile做优化，优化后Dockerfile：
#+begin_src bash
FROM ubuntu

ENV VER     3.0.0  
ENV TARBALL http://download.redis.io/releases/redis-$VER.tar.gz

RUN echo "==> Install curl and helper tools..."  && \  
apt-get update                      && \
apt-get install -y  curl make gcc   && \
echo "==> Download, compile, and install..."  && \
curl -L $TARBALL | tar zxv  && \
cd redis-$VER               && \
make                        && \
make install                && \
echo "==> Clean up..."  && \
apt-get remove -y --auto-remove curl make gcc  && \
apt-get clean                                  && \
rm -rf /var/lib/apt/lists/*  /redis-$VER
...
CMD ["redis-server"]

#+END_SRC

构建镜像，名称叫 test/test:0.2。

对比两个镜像大小：
#+begin_src bash
root@k8s-master:/tmp/iops# docker images
REPOSITORY       TAG           IMAGE ID            CREATED             SIZE
test/test        0.2         58468c0222ed        2 minutes ago       98.1MB
test/test        0.1         e496cf7243f2        6 minutes ago       307MB
root@k8s-master:/tmp/iops#

#+END_SRC

可以看到，将多条RUN命令串联起来构建的镜像大小是每条命令分别RUN的三分之一。

提示：为了应对镜像中存在太多镜像层，Docker 1.13版本以后，提供了一个压扁镜像功能，即将 Dockerfile 中所有的操作压缩为一层。这个特性还处于实验阶段，Docker默认没有开启，如果要开启，需要在启动Docker时添加-experimental 选项，并在Docker build 构建镜像时候添加 --squash 。我们不推荐使用这个办法，请在撰写 Dockerfile 时遵循最佳实践编写，不要试图用这种办法去压缩镜像。

*** 使用多阶段构建
Dockerfile中每条指令都会为镜像增加一个镜像层，并且你需要在移动到下一个镜像层之前清理不需要的组件。实际上，有一个Dockerfile用于开发（其中包含构建应用程序所需的所有内容）以及一个用于生产的瘦客户端，它只包含你的应用程序以及运行它所需的内容。这被称为“建造者模式”。Docker 17.05.0-ce版本以后支持多阶段构建。使用多阶段构建，你可以在Dockerfile中使用多个FROM语句，每条FROM指令可以使用不同的基础镜像，这样您可以选择性地将服务组件从一个阶段COPY到另一个阶段，在最终镜像中只保留需要的内容。

下面是一个使用COPY --from 和 FROM … AS … 的Dockerfile：
#+begin_src bash
# Compile
FROM golang:1.9.0 AS builder
WORKDIR /go/src/v9.git...com/.../k8s-monitor
COPY . .
WORKDIR /go/src/v9.git...com/.../k8s-monitor
RUN make build
RUN mv k8s-monitor /root
Package
Use scratch image
FROM scratch
WORKDIR /root/
COPY --from=builder /root .
EXPOSE 8080
CMD ["/root/k8s-monitor"] 

#+END_SRC

构建镜像，你会发现生成的镜像只有上面COPY 指令指定的内容，镜像大小只有2M。这样在以前使用两个Dockerfile（一个Dockerfile用于开发和一个用于生产的瘦客户端），现在使用多阶段构建就可以搞定。

*** 构建业务服务镜像技巧
Docker在build镜像的时候，如果某个命令相关的内容没有变化，会使用上一次缓存（cache）的文件层，在构建业务镜像的时候可以注意下面两点：
不变或者变化很少的体积较大的依赖库和经常修改的自有代码分开；
因为cache缓存在运行Docker build命令的本地机器上，建议固定使用某台机器来进行Docker build，以便利用cache。

下面是构建Spring Boot应用镜像的例子，用来说明如何分层。其他类型的应用，比如Java WAR包，Nodejs的npm模块等，可以采取类似的方式。

1、在Dockerfile所在目录，解压缩maven生成的jar包。
$ unzip <path-to-app-jar>.jar -d app

2、Dockerfile我们把应用的内容分成4个部分COPY到镜像里面：其中前面3个基本不变，第4个是经常变化的自有代码。最后一行是解压缩后，启动spring boot应用的方式。
#+begin_src bash
FROM openjdk:8-jre-alpine

LABEL maintainer "opl-xws@xiaomi.com"
COPY app/BOOT-INF/lib/ /app/BOOT-INF/lib/
COPY app/org /app/org
COPY app/META-INF /app/META-INF
COPY app/BOOT-INF/classes /app/BOOT-INF/classes
EXPOSE 8080
CMD ["/usr/bin/java", "-cp", "/app", "org.springframework.boot.loader.JarLauncher"]

#+END_SRC

这样在构建镜像时候可大大提高构建速度。

*** RUN命令中执行apt、apk或者yum类工具技巧
如果在RUN命令中执行apt、apk或者yum类工具，可以借助这些工具提供的一些小技巧来减少镜像层数量及镜像大小。举几个例子：

（1）在执行apt-get install -y 时增加选项— no-install-recommends ，可以不用安装建议性（非必须）的依赖，也可以在执行apk add 时添加选项--no-cache 达到同样效果；

（2）执行yum install -y 时候， 可以同时安装多个工具，比如yum install -y gcc gcc-c++ make …。将所有yum install 任务放在一条RUN命令上执行，从而减少镜像层的数量；

（3）组件的安装和清理要串联在一条指令里面，如 apk --update add php7 && rm -rf /var/cache/apk/* ，因为Dockerfile的每条指令都会产生一个文件层，如果将apk add … 和 rm -rf … 命令分开，清理无法减小apk命令产生的文件层的大小。 Ubuntu或Debian可以使用 rm -rf /var/lib/apt/lists/* 清理镜像中缓存文件；CentOS等系统使用yum clean all 命令清理。

*** Docker命令压缩镜像

Docker自带的一些命令还能协助压缩镜像，比如export和import。
#+begin_src bash
$ docker run -d test/test:0.2
$ docker export 747dc0e72d13 | docker import - test/test:0.3

#+END_SRC


使用这种方式需要先将容器运行起来，而且这个过程中会丢失镜像原有的一些信息，比如：导出端口，环境变量，默认指令。

查看这两个镜像history信息，如下，可以看到test/test:0.3 丢失了所有的镜像层信息：
#+begin_src bash
root@k8s-master:/tmp/iops# docker history test/test:0.3
IMAGE               CREATED             CREATED BY          SIZE                COMMENT
6fb3f00b7a72        15 seconds ago                          84.7MB              Imported from -
root@k8s-master:/tmp/iops# docker history test/test:0.2
IMAGE               CREATED             CREATED BY                                      SIZE                COMMENT
58468c0222ed        2 hours ago         /bin/sh -c #(nop)  CMD ["redis-server"]         0B       
1af7ffe3d163        2 hours ago         /bin/sh -c echo "==> Install curl and helper…   15.7MB   
8bac6e733d54        2 hours ago         /bin/sh -c #(nop)  ENV TARBALL=http://downlo…   0B       
793282f3ef7a        2 hours ago         /bin/sh -c #(nop)  ENV VER=3.0.0                0B       
74f8760a2a8b        8 days ago          /bin/sh -c #(nop)  CMD ["/bin/bash"]            0B       
<missing>           8 days ago          /bin/sh -c mkdir -p /run/systemd && echo 'do…   7B
<missing>           8 days ago          /bin/sh -c sed -i 's/^#\s*\(deb.*universe\)$…   2.76kB
<missing>           8 days ago          /bin/sh -c rm -rf /var/lib/apt/lists/*          0B
<missing>           8 days ago          /bin/sh -c set -xe   && echo '#!/bin/sh' > /…   745B    
<missing>           8 days ago          /bin/sh -c #(nop) ADD file:5fabb77ea8d61e02d…   82.4MB   
root@k8s-master:/tmp/iops#

#+END_SRC

社区里还有很多压缩工具，比如Docker-squash ，用起来更简单方便，并且不会丢失原有镜像的自带信息，大家有兴趣可以试试。

*** 参考文章
[[https://dockone.io/article/8163][精简Docker镜像的五种通用方法]]
** 端口映射
*** 启动容器后
容器除了在启动时添加端口映射关系，还可以通过宿主机的iptables进行nat转发，将宿主机的端口映射到容器的内部端口上，这种方式适用于容器启动时没有指定端口映射的情况！
#+begin_src bash
[root@docker-test ~]# docker run -ti -d --name my-nginx9 docker.io/nginx
990752e39d75b977cbff5a944247366662211ce43d16843a452a5697ddded12f
[root@docker-test ~]# docker ps
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS            NAMES
990752e39d75        docker.io/nginx     "nginx -g 'daemon ..."   2 seconds ago       Up 1 second         80/tcp           my-nginx9
#+END_SRC 
这个时候，由于容器my-nginx9在启动时没有指定其内部的80端口映射到宿主机的端口上，所以默认是没法访问的！
现在通过宿主机的iptables进行net转发
 
首先获得容器的ip地址
#+begin_src bash
[root@docker-test ~]# docker inspect my-nginx9|grep IPAddress
            "SecondaryIPAddresses": null,
            "IPAddress": "172.17.0.9",
                    "IPAddress": "172.17.0.9",
 
[root@docker-test ~]# ping 172.17.0.9
PING 172.17.0.9 (172.17.0.9) 56(84) bytes of data.
64 bytes from 172.17.0.9: icmp_seq=1 ttl=64 time=0.105 ms
64 bytes from 172.17.0.9: icmp_seq=2 ttl=64 time=0.061 ms
.....
 
[root@docker-test ~]# telnet 172.17.0.9 80
Trying 172.17.0.9...
Connected to 172.17.0.9.
Escape character is '^]'
#+END_SRC  
 
centos7下部署iptables环境纪录（关闭默认的firewalle）
参考：http://www.cnblogs.com/kevingrace/p/5799210.html
 
将容器的80端口映射到dockers宿主机的9998端口
#+begin_src bash
[root@docker-test ~]# iptables -t nat -A PREROUTING -p tcp -m tcp --dport 9998 -j DNAT --to-destination 172.17.0.9:80
[root@docker-test ~]# iptables -t nat -A POSTROUTING -d 172.17.0.9/32 -p tcp -m tcp --sport 80 -j SNAT --to-source 192.16.10.214
[root@docker-test ~]# iptables -t filter -A INPUT -p tcp -m state --state NEW -m tcp --dport 9998 -j ACCEPT
#+END_SRC 
保存以上iptables规则
#+begin_src bash 
[root@docker-test ~]# iptables-save > /etc/sysconfig/iptables
#+END_SRC  
查看/etc/sysconfig/iptables文件，注意下面两行有关icmp-host-prohibited的设置一定要注释掉！否则nat转发会失败！
#+begin_src bash
[root@docker-test ~]# cat /etc/sysconfig/iptables
# Generated by iptables-save v1.4.21 on Fri Aug 10 11:13:57 2018
*nat
:PREROUTING ACCEPT [32:1280]
:INPUT ACCEPT [0:0]
:OUTPUT ACCEPT [0:0]
:POSTROUTING ACCEPT [0:0]
-A PREROUTING -p tcp -m tcp --dport 9998 -j DNAT --to-destination 172.17.0.9:80
-A POSTROUTING -d 172.17.0.9/32 -p tcp -m tcp --sport 80 -j SNAT --to-source 192.16.10.214
COMMIT
# Completed on Fri Aug 10 11:13:57 2018
# Generated by iptables-save v1.4.21 on Fri Aug 10 11:13:57 2018
*filter
:INPUT ACCEPT [0:0]
:FORWARD ACCEPT [0:0]
:OUTPUT ACCEPT [50:5056]
-A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT
-A INPUT -p icmp -j ACCEPT
-A INPUT -i lo -j ACCEPT
-A INPUT -p tcp -m state --state NEW -m tcp --dport 22 -j ACCEPT
-A INPUT -p tcp -m state --state NEW -m tcp --dport 9998 -j ACCEPT
#-A INPUT -j REJECT --reject-with icmp-host-prohibited
#-A FORWARD -j REJECT --reject-with icmp-host-prohibited
COMMIT
# Completed on Fri Aug 10 11:13:57 2018
#+END_SRC  
最后重启iptbales服务
#+begin_src bash
[root@docker-test ~]# systemctl restart iptables
#+END_SRC  
查看iptables规则
#+begin_src bash
[root@docker-test ~]# iptables -L
Chain INPUT (policy ACCEPT)
target     prot opt source               destination        
ACCEPT     all  --  anywhere             anywhere             state RELATED,ESTABLISHED
ACCEPT     icmp --  anywhere             anywhere           
ACCEPT     all  --  anywhere             anywhere           
ACCEPT     tcp  --  anywhere             anywhere             state NEW tcp dpt:ssh
ACCEPT     tcp  --  anywhere             anywhere             state NEW tcp dpt:distinct32
 
Chain FORWARD (policy ACCEPT)
target     prot opt source               destination        
 
Chain OUTPUT (policy ACCEPT)
target     prot opt source               destination       
 
[root@docker-test ~]# iptables -L -t nat
Chain PREROUTING (policy ACCEPT)
target     prot opt source               destination        
DNAT       tcp  --  anywhere             anywhere             tcp dpt:distinct32 to:172.17.0.9:80
 
Chain INPUT (policy ACCEPT)
target     prot opt source               destination        
 
Chain OUTPUT (policy ACCEPT)
target     prot opt source               destination        
 
Chain POSTROUTING (policy ACCEPT)
target     prot opt source               destination        
SNAT       tcp  --  anywhere             172.17.0.9           tcp spt:http to:192.16.10.214
#+END_SRC
然后访问http://192.168.10.214:9998/，就能转发访问到my-nginx9容器的80端口了！！！ 
*** 参考文章
[[https://www.cnblogs.com/kevingrace/p/9453987.html][Docker容器内部端口映射到外部宿主机端口 - 运维笔记]]
** docker 怎么查看远端仓库的标签
直接上 hub.docker.com 查
** 参考文档:
1. [官方文档](https://docs.docker.com/engine/reference/commandline)
2. [Docker 参数 -i -t 的作用](https://blog.csdn.net/upHailin/article/details/80892505)
3. [容器运行时笔记](https://gobomb.github.io/post/container-runtime-note/)
4. [解密容器运行时](https://gobomb.github.io/post/container-runtime-note/)
5. [Docker容器的创建、启动、和停止](https://www.cnblogs.com/linjiqin/p/8608975.html)
6. [启动容器](https://yeasy.gitbooks.io/docker_practice/container/run.html)
7. [认识/dev/shm](http://www.361way.com/dev-shm/4029.html)
8. [Docker-端口映射](https://www.jianshu.com/p/b92d4b845ed6)
9. [理解 docker 容器中的 uid 和 gid](https://www.cnblogs.com/sparkdev/p/9614164.html)
10. [Make “–user `whoami`” the default for “docker run”](https://forums.docker.com/t/make-user-whoami-the-default-for-docker-run/40874)
11. [Data Volume 之 bind mount - 每天5分钟玩转 Docker 容器技术（39）](https://www.ibm.com/developerworks/community/blogs/132cfa78-44b0-4376-85d0-d3096cd30d3f/entry/Data_Volume_%E4%B9%8B_bind_mount_%E6%AF%8F%E5%A4%A95%E5%88%86%E9%92%9F%E7%8E%A9%E8%BD%AC_Docker_%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF_39?lang=en)
12. [官方文档:Use bind mounts](https://docs.docker.com/storage/bind-mounts/)
13. [Docker数据管理-Volume， bind mount和tmpfs mount](https://michaelyou.github.io/2017/09/17/Docker%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86-Volume%EF%BC%8C-bind-mount%E5%92%8Ctmpfs-mount/)
14. [Docker数据持久之volume和bind mount](https://blog.csdn.net/docerce/article/details/79265858)
15. [Joe's Blog: Share volume between docker host and container](https://blog.johannes-beck.name/?p=571)
16. [running-docker-container-with-my-own-privileges](https://github.com/docker/for-mac/issues/2458)
17. [breaks mounting /etc/passwd or /etc/group #2458](https://github.com/docker/for-mac/issues/2458)
* 动态链接库
动态链接库的查找先后顺序为：
- LD_PRELOAD环境变量
- LD_LIBRARY_PATH环境变量中的路径
- /etc/ld.so.cache缓存文件
- /usr/lib和/lib

LD_PRELOAD里是具体的目标文件列表（A list of shared objects）；
LD_LIBRARY_PATH是目录列表（A list of directories）。
** ld.so.cache的生成方式
Linux提供了ldconfig工具，用于生成so缓存文件.
ldconfig搜索目录/lib和/usr/lib的so文件,同时读取/etc/ld.so.conf文件的内容,按照SONAME规则创建软连接,然后生成so缓存文件到/etc/ld.so.cache文件里.
链接器根据缓存可以更快地查找到各个.so文件。

/etc/ld.so.conf文件和ldconfig命令最好使用root账户操作。非root用户可以在某个路径下安装库文件，并将这个路径添加到/etc/ld.so.conf文件下，再由root用户调用一下ldconfig。
** 拷贝一个程序的所有so文件
拷贝程序FULL_GAME的所有so文件到desdir目录:
ldd FULL_GAME | awk 'NF == 4 { system("echo cp " $3 " destdir") }'
** 参考文章
[[https://www.zhihu.com/tardis/zm/art/235551437?source_id=1003][Linux的so文件到底是干嘛的？浅析Linux的动态链接库]]
[[https://stackoverflow.com/questions/63660871/copy-all-shared-objects-from-ldd-output/63663617#63663617][Copy all shared objects from ldd output]]
* dpkg
* dpkg,rpm和yum以及apt-get的区别
一般来说著名的 Linux 系统基本上分两大类：
- RedHat 系列：Redhat、Centos、Fedora 等
- Debian 系列：Debian、Ubuntu 等

Dpkg (Debian系)：Ubuntu 
RPM (Red Hat系)：CentOS、Fedora
** RedHat 系列
- 常见的安装包格式 rpm 包，安装rpm包的命令是“rpm -参数”
- 包管理工具 yum
- 支持 tar 包
** Debian系列
- 常见的安装包格式 deb 包，安装 deb 包的命令是“dpkg -参数”
- 包管理工具 apt-get
- 支持 tar 包
* du命令：查看文件夹和文件的磁盘占用情况
du 命令，全称是 disk usage，用来展示磁盘使用量的统计信息。

语法:
#+begin_src bash
du [-abcDhHklmsSx][-L <符号连接>][-X <文件>][--block-size][--exclude=<目录或文件>][--max-depth=<目录层数>][--help][--version][目录或文件]
#+END_SRC
** 参数
- -a或-all 显示目录中个别文件的大小。
- -b或-bytes 显示目录或文件大小时，以byte为单位。
- -c或--total 除了显示个别目录或文件的大小外，同时也显示所有目录或文件的总和。
- -D或--dereference-args 显示指定符号连接的源文件大小。
- -h或--human-readable 以K，M，G为单位，提高信息的可读性。
- -H或--si 与-h参数相同，但是K，M，G是以1000为换算单位。
- -k或--kilobytes 以1024 bytes为单位。
- -l或--count-links 重复计算硬件连接的文件。
- -L<符号连接>或--dereference<符号连接> 显示选项中所指定符号连接的源文件大小。
- -m或--megabytes 以1MB为单位。
- -s或--summarize 仅显示总计。
- -S或--separate-dirs 显示个别目录的大小时，并不含其子目录的大小。
- -x或--one-file-xystem 以一开始处理时的文件系统为准，若遇上其它不同的文件系统目录则略过。
- -X<文件>或--exclude-from=<文件> 在<文件>指定目录或文件。
- --exclude=<目录或文件> 略过指定的目录或文件。
- --max-depth=<目录层数> 超过指定层数的目录后，予以忽略。
- --help 显示帮助。
- --version 显示版本信息。
** 实例
显示目录或者文件所占空间:
#+begin_src bash
>>> du
608     ./test6
308     ./test4
4       ./scf/lib
4       ./scf/service/deploy/product
4       ./scf/service/deploy/info
12      ./scf/service/deploy
16      ./scf/service
4       ./scf/doc
4       ./scf/bin
32      ./scf
8       ./test3
1288    .
#+END_SRC
只显示当前目录下面的子目录的目录大小和当前目录的总的大小，最下面的1288为当前目录的总大小

显示指定文件所占空间:
#+begin_src bash
>>> du log2012.log 
300     log2012.log
#+END_SRC

方便阅读的格式显示test目录所占空间情况：
#+begin_src bash
>>> du -h test
608K    test/test6
308K    test/test4
4.0K    test/scf/lib
4.0K    test/scf/service/deploy/product
4.0K    test/scf/service/deploy/info
12K     test/scf/service/deploy
16K     test/scf/service
4.0K    test/scf/doc
4.0K    test/scf/bin
32K     test/scf
8.0K    test/test3
1.3M    test
#+END_SRC

** 参考文章
[[https://www.runoob.com/linux/linux-comm-du.html][菜鸟教程]]

* ELF文件格式
ELF (Executable and Linkable Format)是一种为可执行文件，目标文件，共享链接库和内核转储(core dumps)准备的标准文件格式。 Linux和很多类Unix操作系统都使用这个格式。 让我们来看一下64位ELF文件格式的结构以及内核源码中有关于它的一些定义。

一个ELF文件由以下三部分组成：
- ELF头(ELF header) - 描述文件的主要特性：类型，CPU架构，入口地址，现有部分的大小和偏移等等；
- 节头表(Section header table) - 包含对节(sections)的描述。
- 程序头表(Program header table) - 列举了所有有效的段(segments)和他们的属性。 程序头表需要加载器将文件中的节加载到虚拟内存段中；


#+DOWNLOADED: screenshot @ 2022-05-10 21:51:39
[[file:images/linux笔记/ELF文件格式/2022-05-10_21-51-39_screenshot.png]]

注意：段（Segment）与节（Section）的区别：段是程序执行的必要组成，当多个目标文件链接成一个可执行文件时，会将相同权限的节合并到一个段中。相比而言，节的粒度更小。
** ELF头(ELF header)
ELF头(ELF header)位于文件的开始位置。 它的主要目的是定位文件的其他部分。 文件头主要包含以下字段：
- ELF文件鉴定 - 一个字节数组用来确认文件是否是一个ELF文件，并且提供普通文件特征的信息；
- 文件类型 - 确定文件类型。 这个字段描述文件是一个重定位文件，或可执行文件,或...；
- 目标结构；
- ELF文件格式的版本；
- 程序入口地址；
- 程序头表的文件偏移；
- 节头表的文件偏移；
- ELF头(ELF header)的大小；
- 程序头表的表项大小；
- 其他字段...

你可以在内核源码种找到表示ELF64 header的结构体 elf64_hdr：
#+BEGIN_SRC c
typedef struct elf64_hdr {
    unsigned char    e_ident[EI_NIDENT];
    Elf64_Half e_type;
    Elf64_Half e_machine;
    Elf64_Word e_version;
    Elf64_Addr e_entry;
    Elf64_Off e_phoff;
    Elf64_Off e_shoff;
    Elf64_Word e_flags;
    Elf64_Half e_ehsize;
    Elf64_Half e_phentsize;
    Elf64_Half e_phnum;
    Elf64_Half e_shentsize;
    Elf64_Half e_shnum;
    Elf64_Half e_shstrndx;
} Elf64_Ehdr;
#+END_SRC
这个结构体定义在 [[https://github.com/torvalds/linux/blob/master/include/uapi/linux/elf.h#L312][elf.h]]

我们可以使用readelf工具来查看ELF Header。
#+begin_src bash
$ readelf -h hello.o

ELF Header:
  Magic:   7f 45 4c 46 02 01 01 00 00 00 00 00 00 00 00 00
  Class:                             ELF64
  Data:                              2's complement, little endian
  Version:                           1 (current)
  OS/ABI:                            UNIX - System V
  ABI Version:                       0
  Type:                              REL (Relocatable file)
  Machine:                           Advanced Micro Devices X86-64
  Version:                           0x1
  Entry point address:               0x0
  Start of program headers:          0 (bytes into file)
  Start of section headers:          672 (bytes into file)
  Flags:                             0x0
  Size of this header:               64 (bytes)
  Size of program headers:           0 (bytes)
  Number of program headers:         0
  Size of section headers:           64 (bytes)
  Number of section headers:         13
  Section header string table index: 10
#+END_SRC

ELF文件结构示意图中定义的Elf_Ehdr的各个成员的含义与readelf具有对应关系。如下所示
1. e_ident	Magic: 7f 45 4c 46 02 01 01 00 00 00 00 00 00 00 00 00
Class: ELF32
Data: 2’s complement, little end
Version: 1(current)
OS/ABI: UNIX - System V
ABI Version: 0
2. e_type	Type: REL (Relocatable file)
ELF文件类型
3. e_machine	Machine: Advanced Micro Devices X86-64
ELF文件的CPI平台属性
4. e_version	Version: 0x1
ELF版本号。一般为常数1
5. e_entry	Entry point address: 0x0
入口地址，规定ELF程序的入口虚拟地址，操作系统在加载完该程序后从这个地址开始执行进程的指令。可重定位指令一般没有入口地址，则该值为0
6. e_phoff	Start of program headers: 0(bytes into file)
7. e_shoff	Start of section headers: 672 (bytes into file)
Section Header Table 在文件中的偏移
8. e_word	Flags: 0x0
ELF标志位，用来标识一些ELF文件平台相关的属性。
9. e_ehsize	Size of this header: 64 (bytes)
ELF Header本身的大小
10. e_phentsize	Size of program headers: 0 (bytes)
11. e_phnum	Number of program headers: 0
12. e_shentsize	Size of section headers: 64 (bytes)
单个Section Header大小
13. e_shnum	Number of section headers: 13
Section Header的数量
14. e_shstrndx	Section header string table index: 10
Section Header字符串表在Section Header Table中的索引
*** ELF魔数
每种可执行文件的格式的开头几个字节都是很特殊的，特别是开头4个字节，通常被称为魔数（Magic Number）。
通过对魔数的判断可以确定文件的格式和类型。如：ELF的可执行文件格式的头4个字节为0x7F、e、l、f；Java的可执行文件格式的头4个字节为c、a、f、e；
如果被执行的是Shell脚本或perl、python等解释型语言的脚本，那么它的第一行往往是#!/bin/sh或#!/usr/bin/perl或#!/usr/bin/python，此时前两个字节#和!就构成了魔数，系统一旦判断到这两个字节，就对后面的字符串进行解析，以确定具体的解释程序路径。

*** ELF文件类型
ELF文件主要有三种类型，可以通过ELF Header中的e_type成员进行区分。
- 可重定位文件（Relocatable File）：ETL_REL。一般为.o文件。可以被链接成可执行文件或共享目标文件。静态链接库属于可重定位文件。
- 可执行文件（Executable File）：ET_EXEC。可以直接执行的程序。
- 共享目标文件（Shared Object File）：ET_DYN。一般为.so文件。有两种情况可以使用。
    - 链接器将其与其他可重定位文件、共享目标文件链接成新的目标文件；
    - 动态链接器将其与其他共享目标文件、结合一个可执行文件，创建进程映像。


#+DOWNLOADED: screenshot @ 2022-05-10 22:07:24
[[file:images/linux笔记/ELF文件格式/2022-05-10_22-07-24_screenshot.png]]

** 节(Section Header Table)
所有的数据都存储在ELF文件的节(sections)中。 
ELF 节头表是一个节头数组。
每一个节头都描述了其所对应的节的信息，如节名、节大小、在文件中的偏移、读写权限等。编译器、链接器、装载器都是通过节头表来定位和访问各个节的属性的。

我们通过节头表中的索引(index)来确认节(sections)。 节头表表项包含以下字段：
- 节的名字；
- 节的类型；
- 节的属性；
- 内存地址；
- 文件中的偏移；
- 节的大小；
- 到其他节的链接；
- 各种各样的信息；
- 地址对齐；
- 这个表项的大小，如果有的话；

而且，在linux内核中结构体 elf64_shdr 如下所示:
#+BEGIN_SRC c
typedef struct elf64_shdr {
    Elf64_Word sh_name;
    Elf64_Word sh_type;
    Elf64_Xword sh_flags;
    Elf64_Addr sh_addr;
    Elf64_Off sh_offset;
    Elf64_Xword sh_size;
    Elf64_Word sh_link;
    Elf64_Word sh_info;
    Elf64_Xword sh_addralign;
    Elf64_Xword sh_entsize;
} Elf64_Shdr;
#+END_SRC
我们可以使用readelf工具来查看节头表。
#+begin_src bash
$ readelf -S hello.o

There are 13 section headers, starting at offset 0x2a0:

Section Headers:
  [Nr] Name              Type             Address           Offset
       Size              EntSize          Flags  Link  Info  Align
  [ 0]                   NULL             0000000000000000  00000000
       0000000000000000  0000000000000000           0     0     0
  [ 1] .text             PROGBITS         0000000000000000  00000040
       0000000000000015  0000000000000000  AX       0     0     1
  [ 2] .rela.text        RELA             0000000000000000  000001f0
       0000000000000030  0000000000000018   I      11     1     8
  [ 3] .data             PROGBITS         0000000000000000  00000055
       0000000000000000  0000000000000000  WA       0     0     1
  [ 4] .bss              NOBITS           0000000000000000  00000055
       0000000000000000  0000000000000000  WA       0     0     1
  [ 5] .rodata           PROGBITS         0000000000000000  00000055
       000000000000000d  0000000000000000   A       0     0     1
  [ 6] .comment          PROGBITS         0000000000000000  00000062
       0000000000000035  0000000000000001  MS       0     0     1
  [ 7] .note.GNU-stack   PROGBITS         0000000000000000  00000097
       0000000000000000  0000000000000000           0     0     1
  [ 8] .eh_frame         PROGBITS         0000000000000000  00000098
       0000000000000038  0000000000000000   A       0     0     8
  [ 9] .rela.eh_frame    RELA             0000000000000000  00000220
       0000000000000018  0000000000000018   I      11     8     8
  [10] .shstrtab         STRTAB           0000000000000000  00000238
       0000000000000061  0000000000000000           0     0     1
  [11] .symtab           SYMTAB           0000000000000000  000000d0
       0000000000000108  0000000000000018          12     9     8
  [12] .strtab           STRTAB           0000000000000000  000001d8
       0000000000000013  0000000000000000           0     0     1
Key to Flags:
  W (write), A (alloc), X (execute), M (merge), S (strings), l (large)
  I (info), L (link order), G (group), T (TLS), E (exclude), x (unknown)
  O (extra OS processing required) o (OS specific), p (processor specific)
#+END_SRC
ELF文件结构示意图中定义的Elf_Shdr的各个成员的含义与readelf具有对应关系。如下所示：
1. sh_name	节名
节名是一个字符串，保存在一个名为.shstrtab的字符串表（可通过Section Header索引到）。sh_name的值实际上是其节名字符串在.shstrtab中的偏移值
2. sh_type	节类型
3. sh_flags	节标志位
4. sh_addr	节地址：节的虚拟地址
如果该节可以被加载，则sh_addr为该节被加载后在进程地址空间中的虚拟地址；否则sh_addr为0
5. sh_offset	节偏移
如果该节存在于文件中，则表示该节在文件中的偏移；否则无意义，如sh_offset对于BSS 节来说是没有意义的
6. sh_size	节大小
7. sh_link、sh_info	节链接信息
8. sh_addralign	节地址对齐方式
9. sh_entsize	节项大小
有些节包含了一些固定大小的项，如符号表，其包含的每个符号所在的大小都一样的，对于这种节，sh_entsize表示每个项的大小。如果为0，则表示该节不包含固定大小的项。
*** 节类型（sh_type）
节名是一个字符串，只是在链接和编译过程中有意义，但它并不能真正地表示节的类型。对于编译器和链接器来说，主要决定节的属性是节的类型（sh_type）和节的标志位（sh_flags）。

节的类型相关常量以SHT_开头，上述readelf -S命令执行的结果省略了该前缀。常见的节类型如下表所示：
| 常量         | 值 | 含义                                 |
|--------------+----+--------------------------------------|
| SHT_NULL     |  0 | 无效节                               |
| SHT_PROGBITS |  1 | 程序节。代码节、数据节都是这种类型。 |
| SHT_SYMTAB   |  2 | 符号表                               |
| SHT_STRTAB   |  3 | 字符串表                             |
| SHT_RELA     |  4 | 重定位表。该节包含了重定位信息。     |
| SHT_HASH     |  5 | 符号表的哈希表                       |
| SHT_DYNAMIC  |  6 | 动态链接信息                         |
| SHT_NOTE     |  7 | 提示性信息                           |
| SHT_NOBITS   |  8 | 表示该节在文件中没有内容。如.bss节   |
| SHT_REL      |  9 | 该节包含了重定位信息                 |
| SHT_SHLIB    | 10 | 保留                                 |
| SHT_DNYSYM   | 11 | 动态链接的符号表                     |
*** 节标志位（sh_flag）
节标志位表示该节在进程虚拟地址空间中的属性。如是否可写、是否可执行等。相关常量以SHF_开头。常见的节标志位如下表所示：
| 常量          | 值 | 含义                                                                                                       |
|---------------+----+------------------------------------------------------------------------------------------------------------|
| SHF_WRITE     |  1 | 表示该节在进程空间中可写                                                                                   |
| SHF_ALLOC     |  2 | 表示该节在进程空间中需要分配空间。有些包含指示或控制信息的节不需要在进程空间中分配空间，就不会有这个标志。 |
| SHF_EXECINSTR |  4 | 表示该节在进程空间中可以被执行                                                                             |
*** 节链接信息（sh_link、sh_info）
如果节的类型是与链接相关的（无论是动态链接还是静态链接），如重定位表、符号表、等，则sh_link、sh_info两个成员所包含的意义如下所示。其他类型的节，这两个成员没有意义。
| sh_type     | sh_link                                | sh_info                              |
|-------------+----------------------------------------+--------------------------------------|
| SHT_DYNAMIC | 该节所使用的字符串表在节头表中的下标   | 0                                    |
| SHT_HASH    | 该节所使用的符号表在节头表中的下标     | 0                                    |
| SHT_REL     | 该节所使用的相应符号表在节头表中的下标 | 该重定位表所作用的节在节头表中的下标 |
| SHT_RELA    | 该节所使用的相应符号表在节头表中的下标 | 该重定位表所作用的节在节头表中的下标 |
| SHT_SYMTAB  | 操作系统相关                           | 操作系统相关                         |
| SHT_DYNSYM  | 操作系统相关                           | 操作系统相关                         |
| other       | SHN_UNDEF                              | 0                                    |
** ELF Sections
*** 节的分类
.text节
.text节是保存了程序代码指令的代码节。一段可执行程序，如果存在Phdr，则.text节就会存在于text段中。由于.text节保存了程序代码，所以节类型为SHT_PROGBITS。

.rodata节
rodata节保存了只读的数据，如一行C语言代码中的字符串。由于.rodata节是只读的，所以只能存在于一个可执行文件的只读段中。因此，只能在text段（不是data段）中找到.rodata节。由于.rodata节是只读的，所以节类型为SHT_PROGBITS。

.plt节（过程链接表）
.plt节也称为过程链接表（Procedure Linkage Table），其包含了动态链接器调用从共享库导入的函数所必需的相关代码。由于.plt节保存了代码，所以节类型为SHT_PROGBITS。

.data节
.data节存在于data段中，其保存了初始化的全局变量等数据。由于.data节保存了程序的变量数据，所以节类型为SHT_PROGBITS。

.bss节
.bss节存在于data段中，占用空间不超过4字节，仅表示这个节本省的空间。.bss节保存了未进行初始化的全局数据。程序加载时数据被初始化为0，在程序执行期间可以进行赋值。由于.bss节未保存实际的数据，所以节类型为SHT_NOBITS。

.got.plt节（全局偏移表-过程链接表）
.got节保存了全局偏移表。.got节和.plt节一起提供了对导入的共享库函数的访问入口，由动态链接器在运行时进行修改。由于.got.plt节与程序执行有关，所以节类型为SHT_PROGBITS。

.dynsym节（动态链接符号表）
.dynsym节保存在text段中。其保存了从共享库导入的动态符号表。节类型为SHT_DYNSYM。

.dynstr节（动态链接字符串表）
.dynstr保存了动态链接字符串表，表中存放了一系列字符串，这些字符串代表了符号名称，以空字符作为终止符。

.rel.*节（重定位表）
重定位表保存了重定位相关的信息，这些信息描述了如何在链接或运行时，对ELF目标文件的某部分或者进程镜像进行补充或修改。由于重定位表保存了重定位相关的数据，所以节类型为SHT_REL。

.hash节
.hash节也称为.gnu.hash，其保存了一个用于查找符号的散列表。

.symtab节（符号表）
.symtab节是一个ElfN_Sym的数组，保存了符号信息。节类型为SHT_SYMTAB。

.strtab节（字符串表）
.strtab节保存的是符号字符串表，表中的内容会被.symtab的ElfN_Sym结构中的st_name引用。节类型为SHT_STRTAB。

.ctors节和.dtors节
.ctors（构造器）节和.dtors（析构器）节分别保存了指向构造函数和析构函数的函数指针，构造函数是在main函数执行之前需要执行的代码；析构函数是在main函数之后需要执行的代码。
*** 符号表
节的分类中我们介绍了.dynsym节和.symtab节，两者都是符号表。那么它们到底有什么区别呢？存在什么关系呢？

符号是对某些类型的数据或代码（如全局变量或函数）的符号引用，函数名或变量名就是符号名。例如，printf()函数会在动态链接符号表.dynsym中存有一个指向该函数的符号项（以Elf_Sym数据结构表示）。在大多数共享库和动态链接可执行文件中，存在两个符号表。即.dynsym和.symtab。

.dynsym保存了引用来自外部文件符号的全局符号。如printf库函数。.dynsym保存的符号是.symtab所保存符合的子集，.symtab中还保存了可执行文件的本地符号。如全局变量，代码中定义的本地函数等。

既然.dynsym是.symtab的子集，那为何要同时存在两个符号表呢？

通过readelf -S命令可以查看可执行文件的输出，一部分节标志位（sh_flags）被标记为了A（ALLOC）、WA（WRITE/ALLOC）、AX（ALLOC/EXEC）。其中，.dynsym被标记为ALLOC，而.symtab则没有标记。

ALLOC表示有该标记的节会在运行时分配并装载进入内存，而.symtab不是在运行时必需的，因此不会被装载到内存中。.dynsym保存的符号只能在运行时被解析，因此是运行时动态链接器所需的唯一符号。.dynsym对于动态链接可执行文件的执行是必需的，而.symtab只是用来进行调试和链接的。

#+DOWNLOADED: screenshot @ 2022-05-10 22:33:15
[[file:images/linux笔记/ELF文件格式/2022-05-10_22-33-15_screenshot.png]]
上图所示为通过符号表索引字符串表的示意图。符号表中的每一项都是一个Elf_Sym结构，对应可以在字符串表中索引得到一个字符串。该数据结构中成员的含义如下表所示：

| 成员     | 含义                                                   |
|----------+--------------------------------------------------------|
| st_name  | 符号名。该值为该符号名在字符串表中的偏移地址。         |
| st_value | 符号对应的值。存放符号的值（可能是地址或位置偏移量）。 |
| st_size  | 符号的大小。                                           |
| st_other | 0                                                      |
| st_shndx | 符号所在的节                                           |
| st_info  | 符号类型及绑定属性                                     |
使用readelf工具我们也能够看到符号表的相关信息。
#+begin_src bash
$ readelf -s hello.o

Symbol table '.symtab' contains 11 entries:
   Num:    Value          Size Type    Bind   Vis      Ndx Name
     0: 0000000000000000     0 NOTYPE  LOCAL  DEFAULT  UND
     1: 0000000000000000     0 FILE    LOCAL  DEFAULT  ABS hello.c
     2: 0000000000000000     0 SECTION LOCAL  DEFAULT    1
     3: 0000000000000000     0 SECTION LOCAL  DEFAULT    3
     4: 0000000000000000     0 SECTION LOCAL  DEFAULT    4
     5: 0000000000000000     0 SECTION LOCAL  DEFAULT    5
     6: 0000000000000000     0 SECTION LOCAL  DEFAULT    7
     7: 0000000000000000     0 SECTION LOCAL  DEFAULT    8
     8: 0000000000000000     0 SECTION LOCAL  DEFAULT    6
     9: 0000000000000000    21 FUNC    GLOBAL DEFAULT    1 main
    10: 0000000000000000     0 NOTYPE  GLOBAL DEFAULT  UND puts
#+END_SRC
*** 字符串表
类似于符号表，在大多数共享库和动态链接可执行文件中，也存在两个字符串表。即.dynstr和.strtab，分别对应于.dynsym和symtab。此外，还有一个.shstrtab的节头字符串表，用于保存节头表中用到的字符串，可通过sh_name进行索引。

ELF文件中所有字符表的结构基本一致，如上图所示。
*** 重定位表
重定位就是将符号定义和符号引用进行连接的过程。可重定位文件需要包含描述如何修改节内容的相关信息，从而使可执行文件和共享目标文件能够保存进程的程序镜像所需要的正确信息。

重定位表是进行重定位的重要依据。我们可以使用objdump工具查看目标文件的重定位表：
#+begin_src bash
$ objdump -r hello.o


hello.o:     file format elf64-x86-64

RELOCATION RECORDS FOR [.text]:
OFFSET           TYPE              VALUE
0000000000000005 R_X86_64_32       .rodata
000000000000000a R_X86_64_PC32     puts-0x0000000000000004


RELOCATION RECORDS FOR [.eh_frame]:
OFFSET           TYPE              VALUE
0000000000000020 R_X86_64_PC32     .text
#+END_SRC
重定位表是一个Elf_Rel类型的数组结构，每一项对应一个需要进行重定位的项。
其成员含义如下所示：
1. r_offset	重定位入口的偏移。
对于可重定位文件来说，这个值是该重定位入口所要修正的位置的第一个字节相对于节起始的偏移
对于可执行文件或共享对象文件来说，这个值是该重定位入口所要修正的位置的第一个字节的虚拟地址
2. r_info	重定位入口的类型和符号
因为不同处理器的指令系统不一样，所以重定位所要修正的指令地址格式也不一样。每种处理器都有自己的一套重定位入口的类型。
对于可执行文件和共享目标文件来说，它们的重定位入口是动态链接类型的。
重定位是目标文件链接成为可执行文件的关键。我们将在后面的进行介绍。
** 程序头表(Program header table)
在可执行文件或者共享链接库中所有的节(sections)都被分为多个段(segments)。 程序头是一个结构的数组，每一个结构都表示一个段(segments)。 
它的结构就像这样：
#+BEGIN_SRC c
typedef struct elf64_phdr {
    Elf64_Word p_type;
    Elf64_Word p_flags;
    Elf64_Off p_offset;
    Elf64_Addr p_vaddr;
    Elf64_Addr p_paddr;
    Elf64_Xword p_filesz;
    Elf64_Xword p_memsz;
    Elf64_Xword p_align;
} Elf64_Phdr;
#+END_SRC
在内核源码中。

elf64_phdr 定义在相同的 elf.h 文件中.

** 目标文件的格式
目前，PC平台流行的 可执行文件格式（Executable） 主要包含如下两种，它们都是 COFF（Common File Format） 格式的变种。
- Windows下的 PE（Portable Executable）
- Linux下的 ELF（Executable Linkable Format）

目标文件就是源代码经过编译后但未进行连接的那些中间文件（Windows的.obj和Linux的.o），它与可执行文件的格式非常相似，所以一般跟可执行文件格式一起采用同一种格式存储。
在Windows下采用PE-COFF文件格式；Linux下采用ELF文件格式。

事实上，除了可执行文件外，动态链接库（DDL，Dynamic Linking Library）、静态链接库（Static Linking Library） 均采用可执行文件格式存储。
它们在Window下均按照PE-COFF格式存储；Linux下均按照ELF格式存储。只是文件名后缀不同而已。
- 动态链接库：Windows的.dll、Linux的.so
- 静态链接库：Windows的.lib、Linux的.a

** 参考文章
[[http://chuquan.me/2018/05/21/elf-introduce/][计算机那些事(4)——ELF文件结构 - 楚权的世界]]
[[https://xinqiu.gitbooks.io/linux-inside-zh/content/Theory/linux-theory-2.html][ELF 文件格式· Linux Inside 中文版]]
* exec
exec命令 用于调用并执行指令的命令。exec命令通常用在shell脚本程序中，可以调用其他的命令。如果在当前终端中使用命令，则当指定的命令执行完毕后会立即退出终端。
在父进程中fork一个子进程，在子进程中调用exec函数启动新的程序。

exec函数一共有六个，其中execve为内核级系统调用，其他（execl，execle，execlp，execv，execvp）都是调用execve的库函数。
#+begin_src c++
int execl(const char *path, const char *arg, ...);

int execlp(const char *file, const char *arg, ...);

int execle(const char *path, const char *arg, ..., char * const envp[]);

int execv(const char *path, char *const argv[]);

int execvp(const char *file, char *const argv[]);

#+END_SRC

- path参数表示你要启动程序的名称包括路径名
- arg参数表示启动程序所带的参数，一般第一个参数为要执行命令名，不是带路径且arg必须以NULL结束
- 返回值:成功返回0,失败返回-1

** 语法
exec(选项)(参数)

** 选项
-c：在空环境中执行指定的命令。

** 参数
指令：要执行的指令和相应的参数。

** 实例
首先使用echo命令将文本“Linux C++”进行输出，输入如下命令：
#+begin_src bash
echo Linux C++           # 输出指定信息

#+END_SRC
执行上面的指令后，输出如下信息：
#+begin_example
Linux C++                # 输出信息
#+end_example

然后再使用exec命令调用echo命令输出同样的信息，并且对输出的信息进行对比，输入指令如下所示：
#+begin_src bash
exec -c echo Linux C++          # 调用命令
#+END_SRC
执行以上命令后，其输出信息如下：
#+begin_example
Linux C++                       # 使用指定指令输出信息
#+end_example

通过比较两者执行后的结果来看，所实现的功能是相同的，即使用exec命令调用echo命令成功。
** 带l 的exec函数：execl,execlp,execle
#+begin_src c++
int execl(const char *path, const char *arg, ...);

int execlp(const char *file, const char *arg, ...);

int execle(const char *path, const char *arg, ..., char * const envp[]);
#+END_SRC

带l 的exec函数：execl,execlp,execle，表示后边的参数以可变参数的形式给出且都以一个空指针结束。

示例：
#+begin_src c++
#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>

int main(void)
{
    printf("entering main process---\n");
    execl("/bin/ls","ls","-l",NULL);
    printf("exiting main process ----\n");
    return 0;
}
#+END_SRC

#+DOWNLOADED: screenshot @ 2023-04-30 11:44:24
[[file:images/linux笔记/exec/2023-04-30_11-44-24_screenshot.png]]
利用execl将当前进程main替换掉，所有最后那条打印语句不会输出

** 带 p 的exec函数：execlp,execvp
带 p 的exec函数：execlp,execvp，表示第一个参数path不用输入完整路径，只有给出命令名即可，它会在环境变量PATH当中查找命令

示例：

当不带p但没给出完整路径时：
#+begin_src c++
#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>

int main(void)
{
    printf("entering main process---\n");
    execl("/bin/ls","ls","-l",NULL);
    printf("exiting main process ----\n");
    return 0;
}
#+END_SRC
结果：
#+DOWNLOADED: screenshot @ 2023-04-30 11:45:48
[[file:images/linux笔记/exec/2023-04-30_11-45-48_screenshot.png]]
结果显示找不到，所有替换不成功，main进程继续执行

现在带p：

#+DOWNLOADED: screenshot @ 2023-04-30 11:46:07
[[file:images/linux笔记/exec/2023-04-30_11-46-07_screenshot.png]]
替换成功

** 不带 l 的exec函数：execv,execvp
不带 l 的exec函数：execv,execvp表示命令所需的参数以char *arg[]形式给出且arg最后一个元素必须
是NULL

示例：
#+begin_src c++
#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>

int main(void)
{
    printf("entering main process---\n");
    int ret;
    char *argv[] = {"ls","-l",NULL};
    ret = execvp("ls",argv);
    if(ret == -1)
        perror("execl error");
    printf("exiting main process ----\n");
    return 0;
}

#+END_SRC
结果：
#+DOWNLOADED: screenshot @ 2023-04-30 12:03:57
[[file:images/linux笔记/exec/2023-04-30_12-03-57_screenshot.png]]
进程替换成功
* execve
execve() executes the program referred to by pathname.
This causes the program that is currently being run by the calling process to be replaced with a new program, with newly initialized stack, heap, and (initialized and uninitialized) data segments.
#+begin_src c++
#include <unistd.h>

int execve(const char *pathname, char *const argv[],
                  char *const envp[]);
#+END_SRC
** 参数
execve()用来执行参数filename字符串所代表的文件路径，第二个参数是利用数组指针来传递给执行文件，并且需要以空指针(NULL)结束，最后一个参数则为传递给执行文件的新环境变量数组。

pathname must be either a binary executable, or a script starting with a line of the form:

#!interpreter [optional-arg]

For details of the latter case, see "Interpreter scripts" below.

argv is an array of pointers to strings passed to the new program as its command-line arguments.
By convention, the first of these strings (i.e., argv[0]) should contain the filename associated with the file being executed.
The argv array must be terminated by a NULL pointer.
(Thus, in the new program, argv[argc] will be NULL.)

envp is an array of pointers to strings, conventionally of the form key=value, which are passed as the environment of the new program.
The envp array must be terminated by a NULL pointer.
** ERRORS
#+begin_example
E2BIG  The total number of bytes in the environment (envp) and
              argument list (argv) is too large.

EACCES Search permission is denied on a component of the path
       prefix of pathname or the name of a script interpreter.
       (See also path_resolution(7).)

EACCES The file or a script interpreter is not a regular file.

       EACCES Execute permission is denied for the file or a script or
       ELF interpreter.

EACCES The filesystem is mounted noexec.

EAGAIN (since Linux 3.1)
       Having changed its real UID using one of the set*uid()
       calls, the caller was—and is now still—above its
       RLIMIT_NPROC resource limit (see setrlimit(2)).  For a
       more detailed explanation of this error, see NOTES.

EFAULT pathname or one of the pointers in the vectors argv or
       envp points outside your accessible address space.

EINVAL An ELF executable had more than one PT_INTERP segment
       (i.e., tried to name more than one interpreter).

EIO    An I/O error occurred.

EISDIR An ELF interpreter was a directory.

ELIBBAD
       An ELF interpreter was not in a recognized format.

ELOOP  Too many symbolic links were encountered in resolving
       pathname or the name of a script or ELF interpreter.

ELOOP  The maximum recursion limit was reached during recursive
       script interpretation (see "Interpreter scripts", above).
       Before Linux 3.8, the error produced for this case was
       ENOEXEC.

EMFILE The per-process limit on the number of open file
       descriptors has been reached.

ENAMETOOLONG
       pathname is too long.

ENFILE The system-wide limit on the total number of open files
       has been reached.

ENOENT The file pathname or a script or ELF interpreter does not
       exist.

ENOEXEC
       An executable is not in a recognized format, is for the
       wrong architecture, or has some other format error that
       means it cannot be executed.

ENOMEM Insufficient kernel memory was available.

ENOTDIR
       A component of the path prefix of pathname or a script or
       ELF interpreter is not a directory.

EPERM  The filesystem is mounted nosuid, the user is not the
       superuser, and the file has the set-user-ID or set-group-
       ID bit set.

EPERM  The process is being traced, the user is not the superuser
       and the file has the set-user-ID or set-group-ID bit set.

EPERM  A "capability-dumb" applications would not obtain the full
       set of permitted capabilities granted by the executable
       file.  See capabilities(7).

ETXTBSY
       The specified executable was open for writing by one or
       more processes.
#+end_example
* export 命令
Linux export 命令用于设置或显示环境变量。

在 shell 中执行程序时，shell 会提供一组环境变量。export 可新增，修改或删除环境变量，供后续执行的程序使用。export 的效力仅限于该次登陆操作。

语法：
export [-fnp][变量名称]=[变量设置值]

参数说明：
-f 　代表[变量名称]中为函数名称。
-n 　删除指定的变量。变量实际上并未删除，只是不会输出到后续指令的执行环境中。
-p 　列出所有的shell赋予程序的环境变量。

** 实例
列出当前所有的环境变量
#+begin_src bash
>>>export -p //列出当前的环境变量值
declare -x HOME=“/root“
declare -x LANG=“zh_CN.UTF-8“
declare -x LANGUAGE=“zh_CN:zh“
declare -x LESSCLOSE=“/usr/bin/lesspipe %s %s“
declare -x LESSOPEN=“| /usr/bin/lesspipe %s“
declare -x LOGNAME=“root“
declare -x LS_COLORS=““
declare -x MAIL=“/var/mail/root“
declare -x OLDPWD
declare -x PATH=“/opt/toolchains/arm920t-eabi/bin:/opt/toolchains/arm920t-eabi/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games“
declare -x PWD=“/root“
declare -x SHELL=“/bin/bash“
declare -x SHLVL=“1“
declare -x SPEECHD_PORT=“6560“
declare -x SSH_CLIENT=“192.168.1.65 1674 22“
declare -x SSH_CONNECTION=“192.168.1.65 1674 192.168.1.3 22“
declare -x SSH_TTY=“/dev/pts/2“
declare -x TERM=“XTERM“
declare -x USER=“root“
declare -x XDG_SESSION_COOKIE=“93b5d3d03e032c0cf892a4474bebda9f-1273864738.954257-340206484“
#+END_SRC
定义环境变量
#+begin_src bash
>>>export MYENV //定义环境变量
>>>export -p //列出当前的环境变量
declare -x HOME=“/root“
declare -x LANG=“zh_CN.UTF-8“
declare -x LANGUAGE=“zh_CN:zh“
declare -x LESSCLOSE=“/usr/bin/lesspipe %s %s“
declare -x LESSOPEN=“| /usr/bin/lesspipe %s“
declare -x LOGNAME=“root“
declare -x LS_COLORS=““
declare -x MAIL=“/var/mail/root“
declare -x MYENV
declare -x OLDPWD
declare -x PATH=“/opt/toolchains/arm920t-eabi/bin:/opt/toolchains/arm920t-eabi/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games“
declare -x PWD=“/root“
declare -x SHELL=“/bin/bash“
declare -x SHLVL=“1“
declare -x SPEECHD_PORT=“6560“
declare -x SSH_CLIENT=“192.168.1.65 1674 22“
declare -x SSH_CONNECTION=“192.168.1.65 1674 192.168.1.3 22“
declare -x SSH_TTY=“/dev/pts/2“
declare -x TERM=“XTERM“
declare -x USER=“root“
declare -x XDG_SESSION_COOKIE=“93b5d3d03e032c0cf892a4474bebda9f-1273864738.954257-340206484“
#+END_SRC
定义环境变量赋值
#+begin_src bash
>>>export MYENV=7 //定义环境变量并赋值
>>>export -p
declare -x HOME=“/root“
declare -x LANG=“zh_CN.UTF-8“
declare -x LANGUAGE=“zh_CN:zh“
declare -x LESSCLOSE=“/usr/bin/lesspipe %s %s“
declare -x LESSOPEN=“| /usr/bin/lesspipe %s“
declare -x LOGNAME=“root“
declare -x LS_COLORS=““
declare -x MAIL=“/var/mail/root“
declare -x MYENV=“7“
declare -x OLDPWD
declare -x PATH=“/opt/toolchains/arm920t-eabi/bin:/opt/toolchains/arm920t-eabi/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games“
declare -x PWD=“/root“
declare -x SHELL=“/bin/bash“
declare -x SHLVL=“1“
declare -x SPEECHD_PORT=“6560“
declare -x SSH_CLIENT=“192.168.1.65 1674 22“
declare -x SSH_CONNECTION=“192.168.1.65 1674 192.168.1.3 22“
declare -x SSH_TTY=“/dev/pts/2“
declare -x TERM=“XTERM“
declare -x USER=“root“
declare -x XDG_SESSION_COOKIE=“93b5d3d03e032c0cf892a4474bebda9f-1273864738.954257-340206484“
#+END_SRC

* expr命令
expr命令是一个手工命令行计数器，用于在UNIX/LINUX下求表达式变量的值，一般用于整数值，也可用于字符串。

语法：expr 表达式
表达式说明:
- 用空格隔开每个项；
- 用反斜杠 \ 放在 shell 特定的字符前面；
- 对包含空格和其他特殊字符的字符串要用引号括起来
** 实例
1、计算字串长度
#+begin_src bash
> expr length “this is a test”
 14
#+END_SRC

2、抓取字串
#+begin_src bash
> expr substr “this is a test” 3 5
is is
#+END_SRC
3、抓取第一个字符数字串出现的位置
#+begin_src bash
> expr index "sarasara"  a
 2
#+END_SRC
4、整数运算
#+begin_src bash
> expr 14 % 9
5
> expr 10 + 10
20
> expr 1000 + 900
1900
> expr 30 / 3 / 2
5
> expr 30 \* 3 (使用乘号时，必须用反斜线屏蔽其特定含义。因为shell可能会误解显示星号的意义)
90
> expr 30 * 3
expr: Syntax error
#+END_SRC
** 参考文章
[[https://www.runoob.com/linux/linux-comm-expr.html][Linux expr命令 - 菜鸟教程]]
* emacs
** 安装
源码下载地址：http://mirrors.ocf.berkeley.edu/gnu/emacs/

编译安装：
#+begin_src bash
./configure --prefix=/opt/emacs/
#+END_SRC
如果出现以下错误：
#+begin_src bash
checking for libXaw... configure: error: No X toolkit could be found.
If you are sure you want Emacs compiled without an X toolkit, pass
  --with-x-toolkit=no
to configure.  Otherwise, install the development libraries for the toolkit
that you want to use (e.g. Gtk+) and re-run configure.
#+END_SRC
解决方案：

安装依赖：
#+begin_src bash
sudo apt-get install build-essential texinfo libx11-dev libxpm-dev libjpeg-dev libpng-dev libgif-dev libtiff-dev libgtk2.0-dev libgtk-3-dev libncurses-dev libxpm-dev automake autoconf
#+END_SRC
如果出现以下错误：
#+begin_src bash
configure: error: The following required libraries were not found:
     gnutls
Maybe some development libraries/packages are missing?
If you don't want to link with them give
     --with-gnutls=no
as options to configure
#+END_SRC
解决方案：
#+begin_src bash
sudo apt-get install gnutls-dev
# 或者
./configure --with-gnutls=ifavailable
#+END_SRC
如果出现以下警告：
#+begin_src bash
configure: WARNING: This configuration installs a 'movemail' program
that does not retrieve POP3 email.  By default, Emacs 25 and earlier
installed a 'movemail' program that retrieved POP3 email via only
insecure channels, a practice that is no longer recommended but that
you can continue to support by using './configure --with-pop'.
configure: You might want to install GNU Mailutils
<https://mailutils.org> and use './configure --with-mailutils'.
#+END_SRC
解决方案：
#+begin_src bash
./configure --prefix=/opt/emacs/ --with-mailutils --with-pop
#+END_SRC
最后：
#+begin_src bash
make && make install
#+END_SRC
添加软连接
#+begin_src bash
ln -s /opt/emacs/bin/emacs /usr/bin/emacs
#+END_SRC
** 使Emacs在命令行中运行
首选：使用emacs-nox并将其设置为默认值：
#+begin_src bash
 yum install emacs-nox
 alternatives --config emacs
#+END_SRC
并选择emacs-nox。

第二选择：使用emacs但使用-nw禁用窗口系统 。 通过调用emacs
#+begin_src bash
emacs -nw
#+END_SRC
您可以编写一个小的脚本 ema并将其放入$PATH ，例如~/bin/：
#+begin_src bash
#!/bin/env bash
emacs -nw $*
#+END_SRC
并每次调用ema以使用emacs。
** 参考文章
[[https://www.cnblogs.com/felixwang2/p/10281092.html][emacs源码安装]]
[[https://stackoverflow.com/questions/52722096/build-emacs-and-gnutls-not-found/52722866][build emacs and gnutls not found]]
[[https://blog.csdn.net/cuma2369/article/details/107667517][emacs 命令行_默认情况下如何使Emacs在命令行中运行？]]
* fallocate
[root@centos8 logs]# fallocate --help
用法：
 fallocate [选项] <文件名>

为文件预分配空间或从文件回收空间。
** 选项
-c, --collapse-range 移除文件中的某个范围
-d, --dig-holes      检测零并替换为空洞
-i, --insert-range   insert a hole at range, shifting existing data
-l, --length <数字>  范围操作的长度(字节数)
-n, --keep-size      保持文件的显示大小
-o, --offset <数字>  范围操作的偏移量(字节数)
-p, --punch-hole     将某个范围替换为空洞(连带打开 -n)
-z, --zero-range     清零并保证分配某个范围
-x, --posix          use posix_fallocate(3) instead of fallocate(2)
-v, --verbose        详尽模式
-h, --help           display this help
-V, --version        display version
** 例子
*** 按指定大小生成文件

#-l: length,指定文件的长度

[root@centos8 logs]# fallocate -l 50M /data/web/www/html/b.zip
查看文件的显示大小

#-h: human-readable,用人性化的方性显示结果

[root@centos8 html]# ll -h b.zip 
-rw-r--r-- 1 root root 50M 5月   8 14:25 b.zip
查看文件占用磁盘空间的大小

[root@centos8 html]# du -sh b.zip 
50M b.zip
说明：我们用du查看文件可以看到，

用fallocate生成的文件在磁盘上确实占用了50M的空间

而不是一个空洞文件
*** 把前面创建的大文件中的零替换为空洞:

#-d：挖洞，仅替换为0的数据,使不再占用多余的磁盘空间

[root@centos8 html]# fallocate -d b.zip
查看占用磁盘空间的大小

[root@centos8 html]# du -sh b.zip 
84K b.zip
查看文件显示大小

[root@centos8 html]# ll -h b.zip 
-rw-r--r-- 1 root root 50M 5月   8 15:21 b.zip
逻辑大小还是50M,

但对磁盘的占用变成了84K
*** 在文件上挖出指定大小的空洞

生成一个占用30M磁盘空间的文件

生成一个30M大小的文件

[root@centos8 html]# fallocate -l 30M c.zip
[root@centos8 html]# ll -h c.zip
-rw-r--r-- 1 root root 30M 5月   8 15:33 c.zip
[root@centos8 html]# du -sh c.zip
30M c.zip
du命令显示文件确实是30M大小

从偏移10M的位置挖一个10M大小的洞

应该还剩20M

#-p：挖洞,不管文件中是否有非0数据,会改变文件的内容

#-o:  偏移位置

#-l: 挖洞的大小

[root@centos8 html]# fallocate -p -o 10M -l 10M c.zip
查看文件显示大小

[root@centos8 html]# ll -h c.zip
-rw-r--r-- 1 root root 30M 5月   8 15:38 c.zip
查看文件占用磁盘空间的大小

[root@centos8 html]# du -sh c.zip
20M c.zip
* gcc、make、cmake的关系和区别
1.gcc是GNU Compiler Collection（就是GNU编译器套件），也可以简单认为是编译器，它可以编译很多种编程语言（括C、C++、Objective-C、Fortran、Java等等）。

2.当你的程序只有一个源文件时，直接就可以用gcc命令编译它。

3.但是当你的程序包含很多个源文件时，用gcc命令逐个去编译时，你就很容易混乱而且工作量大

4.所以出现了make工具
make工具可以看成是一个智能的批处理工具，它本身并没有编译和链接的功能，而是用类似于批处理的方式—通过调用makefile文件中用户指定的命令来进行编译和链接的。

5.makefile是什么？简单的说就像一首歌的乐谱，make工具就像指挥家，指挥家根据乐谱指挥整个乐团怎么样演奏，make工具就根据makefile中的命令进行编译和链接的。

6.makefile命令中就包含了调用gcc（也可以是别的编译器）去编译某个源文件的命令。

7.makefile在一些简单的工程完全可以人工手下，但是当工程非常大的时候，手写makefile也是非常麻烦的，如果换了个平台makefile又要重新修改。

8.这时候就出现了Cmake这个工具，cmake就可以更加简单的生成makefile文件给上面那个make用。当然cmake还有其他功能，就是可以跨平台生成对应平台能用的makefile，你不用再自己去修改了。

9.可是cmake根据什么生成makefile呢？它又要根据一个叫CMakeLists.txt文件（学名：组态档）去生成makefile。

10.到最后CMakeLists.txt文件谁写啊？亲，是你自己手写的。

11.当然如果你用IDE，类似VS这些一般它都能帮你弄好了，你只需要按一下那个三角形
12.cmake是make maker，生成各种可以直接控制编译过程的控制器的配置文件，比如makefile、各种IDE的配置文件。
13.make是一个简单的通过文件时间戳控制自动过程、处理依赖关系的软件，这个自动过程可以是编译一个项目。
* gcc
** 编译选项
-lname来告诉GCC使用哪个库。链接时，GCC的链接器ld就会前往LD_LIBRARY_PATH环境变量、/etc/ld.so.cache缓存文件和/usr/lib和/lib目录下去查找libname.so。

-L/path/to/library告诉链接器去/path/to/library路径下去找库文件。
* gdb
作者：张小方
链接：https://www.zhihu.com/question/65306462/answer/2602659870
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

常用的 gdb 命令并不多，我这里总结了一个表：命令名称命令缩写命令说明
intountilu运行到指定行停下来
watchwatch监视某一个变量或内存地址的值是否发生变化
dirdir重定向源码文件的位置
** gdb安装
打开终端，在终端里输入以下指令：
#+BEGIN_SRC bash
apt-get update
apt-get install  gdb
#+END_SRC
** gdb原理
*** 概述
为了方便描述，先写一个最最简单的C程序：
#+begin_src bash
#include <stdio.h>

int main(int argc, char *argv[])
{
    int a = 1;
    int b = 2;
    int c = a + b;
    printf("c = %d \n", c);
    return 0;
}
#+END_SRC
编译命令:
#+begin_src bash
$ gcc -g test.c -o test
#+END_SRC
我们对可执行程序 test 进行调试，输入命令：
#+begin_src bash
$ gdb ./test
#+END_SRC
系统首先会启动gdb进程，这个进程会调用系统函数fork()来创建一个子进程，这个子进程做两件事情： 
1. 调用系统函数ptrace(PTRACE_TRACEME，[其他参数])； 
2. 通过execc来加载、执行可执行程序test，那么test程序就在这个子进程中开始执行了。

#+DOWNLOADED: screenshot @ 2022-05-16 15:27:19
[[file:images/linux笔记/gdb/2022-05-16_15-27-19_screenshot.png]]
*** ptrach
ptrash函数原型是：
#+BEGIN_EXAMPLE
#include <sys/ptrace.h>
long ptrace(enum __ptrace_request request, pid_t pid, void *addr, void *data);
#+END_EXAMPLE
我们先来看一下 man 中对这个函数的简介：

#+DOWNLOADED: screenshot @ 2022-05-16 15:34:35
[[file:images/linux笔记/gdb/2022-05-16_15-34-35_screenshot.png]]
tracer就是调试程序，可以理解为gdb程序；tracee就是被调试程序，对应于图中的目标程序test。老外一般喜欢用-er和-ee来表示主动和被动的关系，例如：employer就是雇主(老板)，employee就是苦逼的被雇佣者(打工人)。

ptrace系统函数是Linux内核提供的一个用于进程跟踪的系统调用，通过它，一个进程(gdb)可以读写另外一个进程(test)的指令空间、数据空间、堆栈和寄存器的值。而且gdb进程接管了test进程的所有信号，也就是说系统向test进程发送的所有信号，都被gdb进程接收到，这样一来，test进程的执行就被gdb控制了，从而达到调试的目的。

也就是说，如果没有gdb调试，操作系统与目标进程之间是直接交互的；如果使用gdb来调试程序，那么操作系统发送给目标进程的信号就会被gdb截获，gdb根据信号的属性来决定：在继续运行目标程序时是否把当前截获的信号转交给目标程序，如此一来，目标程序就在gdb发来的信号指挥下进行相应的动作。
*** GDB如何调试已经执行的服务进程
ptrace系统函数的第一个参数是一个枚举类型的值，其中重要的是2个：PTRACE_TRACEME和PTRACE_ATTACH<。

在上面的讲解中，子进程在调用ptrace系统函数时使用的参数是PTRACE_TRACEME，注意是子进程调用ptrace，相当于子进程对操作系统说：gdb进程是我的爸爸，以后你有任何想发给我的信号，请直接发给gdb进程吧！

如果想对一个已经执行的进程B进行调试，那么就要在gdb这个父进程中调用ptrace(PTRACE_ATTACH,[其他参数])，此时，gdb进程会attach(绑定)到已经执行的进程B，gdb把进程B收养成为自己的子进程，而子进程B的行为等同于它进行了一次 PTRACE_TRACEME操作。此时gdb进程会发送SIGSTO信号给子进程B，子进程B接收到SIGSTOP信号后，就会暂停执行进入TASK_STOPED状态，表示自己准备好被调试了。

#+DOWNLOADED: screenshot @ 2022-05-16 15:39:50
[[file:images/linux笔记/gdb/2022-05-16_15-39-50_screenshot.png]]
，不论是调试一个新程序，还是调试一个已经处于执行中状态的服务程序，通过ptrace系统调用，最终的结果都是：gdb程序是父进程，被调试程序是子进程，子进程的所有信号都被父进程gdb来接管，并且父进程gdb可查看、修改子进程的内部信息，包括：堆栈、寄存器等。
*** GDB如何实现断点指令
#+begin_src bash
int main(int argc, char *argv[])
{
    int a = 1;
    int b = 2;
    int c = a + b;
    printf("c = %d \n", c);
    return 0;
}
#+END_SRC
来看一下编译出来的反汇编代码是什么样的，编译指令：
#+begin_src bash
gcc -S test.c; cat test.S)
#+END_SRC

#+DOWNLOADED: screenshot @ 2022-05-16 15:40:56
[[file:images/linux笔记/gdb/2022-05-16_15-40-56_screenshot.png]]
我们把源码和汇编代码放在一起，方便理解：
#+DOWNLOADED: screenshot @ 2022-05-16 15:41:31
[[file:images/linux笔记/gdb/2022-05-16_15-41-31_screenshot.png]]
在调试窗口输入设置断点指令“break 5”，此时gdb做2件事情： 1. 对第5行源码所对应的第10行汇编代码存储到断点链表中。 2. 在汇编代码的第10行，插入中断指令INT3，也就是说：汇编代码中的第10行被替换为INT3。

#+DOWNLOADED: screenshot @ 2022-05-16 15:42:21
[[file:images/linux笔记/gdb/2022-05-16_15-42-21_screenshot.png]]
然后，在调试窗口继续输入执行指令“run”(一直执行，直到遇到断点就暂停)，汇编代码中PC指针(一个内部指针，指向即将执行的那行代码)执行第10行时，发现是INT3指令，于是操作系统就发送一个SIGTRAP信号给test进程。

此刻，第10行汇编代码被执行过了，PC指针就指向第11行了。

#+DOWNLOADED: screenshot @ 2022-05-16 15:42:44
[[file:images/linux笔记/gdb/2022-05-16_15-42-44_screenshot.png]]
上面已经说过，操作系统发给test的任何信号，都被gdb接管了，也就是说gdb会首先接收到这SIGTRAP个信号，gdb发现当前汇编代码执行的是第10行，于是到断点链表中查找，发现链表中存储了第10行的代码，说明第10行被设置了断点。于是gdb又做了2个操作： 1. 把汇编代码中的第10行"INT3"替换为断点链表中原来的代码。 2. 把 PC 指针回退一步，也即是设置为指向第10 行。

然后，gdb继续等待用户的调试指令。
#+DOWNLOADED: screenshot @ 2022-05-16 15:43:01
[[file:images/linux笔记/gdb/2022-05-16_15-43-01_screenshot.png]]
此刻，就相当于下一条执行的指令是汇编代码中的第10行，也就是源码中的第5行。从我们调试者角度看，就是被调试程序在第5行断点处暂停了下来，此时我们可以继续输入其他调试指令来debug，比如：查看变量值、查看堆栈信息、修改局部变量的值等等。
*** GDB如何实现单步指令next
假设此时程序停止在源码的第6行，即汇编代码的第11行：

#+DOWNLOADED: screenshot @ 2022-05-16 15:43:49
[[file:images/linux笔记/gdb/2022-05-16_15-43-49_screenshot.png]]
在调试窗口输入单步执行指令next，我们的目的是执行一行代码，也就是把源码中第6行代码执行完，然后停止在第7行。gdb在接收到next执行时，会计算出第7行源码，应该对应到汇编代码的第14行，于是gdb就控制汇编代码中的PC指针一直执行，直到第13行执行结束，也就是PC指向第14行时，就停止下来，然后继续等待用户输入调试指令。

#+DOWNLOADED: screenshot @ 2022-05-16 15:44:04
[[file:images/linux笔记/gdb/2022-05-16_15-44-04_screenshot.png]]
*** 参考文章
[[https://zhuanlan.zhihu.com/p/336922639][原来gdb的底层调试原理这么简单]]
** 符号表
A Debugging Symbol Table maps instructions in the compiled binary program to their corresponding variable, function, or line in the source code. This mapping could be something like:

Program instruction --> item name, item type, original file, line number defined.

Symbol tables may be embedded into the program or stored as a separate file. So if you plan to debug your program, then it is required to create a symbol table which will have the required information to debug the program.

We can infer the following facts about symbol tables:
- A symbol table works for a particular version of the program – if the program changes, a new table must be created.
- Debug builds are often larger and slower than retail (non-debug) builds; debug builds contain the symbol table and other ancillary information.
- If you wish to debug a binary program you did not compile yourself, you must get the symbol tables from the author.

To let GDB be able to read all that information line by line from the symbol table, we need to compile it a bit differently. Normally we compile our programs as:
#+begin_src bash
gcc hello.cc -o hello 
#+END_SRC
Instead of doing this, we need to compile with the -g flag as shown below:
#+begin_src bash
gcc -g hello.cc -o hello 
#+END_SRC

*** 参考文章
[[https://www.tutorialspoint.com/gnu_debugger/gdb_debugging_symbols.htm][GDB - Debugging Symbols - Tutorialspoint]]
** 调试信息
一般来说GDB主要调试的是C/C++的程序。要调试C/C++的程序，首先在编译时，我们必须要把调试信息加到可执行文件中。使用编译器（cc/gcc/g++）的 -g 参数可以做到这一点。如：
#+begin_src bash
> gcc -g hello.c -o hello

> g++ -g hello.cpp -o hello
#+END_SRC
如果没有-g，你将看不见程序的函数名、变量名，所代替的全是运行时的内存地址。

在实际生成调试程序时，我们一般不仅要加上 -g 选项，也建议关闭编译器的程序的优化选项。
编译器的程序的优化选项一般有五个级别，从 O0~O4（注意第一个O0，是字母 O 加上数字 0），
O0 表示不优化（关闭优化），从 O1~O4 优化级别越来越高，O4 最大。
关闭优化的目的是为了调试的时候，符号文件显示的调试变量等能与源代码完全对应起来。

举个例子，假设有以下代码
#+BEGIN_SRC c++
int func()
{
int a = 1;
int b = a + 1;
int c = a + b;
return a + b + c;
}
int main()
{
int a = func();
printf("%d\n", a);
}
#+END_SRC
以上代码中，由于在 main() 函数中调用了 func() 函数，由于 func() 函数值可以在编译期间直接算出来，如果开启了优化选项，可能你实际调试的时候，这个函数中的局部变量 a，b，c 可能已经被编译器优化掉，取而代之的是直接的值，甚至连函数 func() 也可能被优化掉。
如果出现这种情况，调试的时候，您看到的代码和您实际的代码可能就会有差异了，这会给排查和定位问题带来困难。
当然，上面说的优化现象是否一定会出现，不同版本的编译器可能会有不同的行为。
总之一句话，生成调试文件时建议关闭编译器优化选项（使用 O0 选项）。
** 启动gdb方式
1. gdb program
program 也就是你的执行文件，一般在当前目录下。

2. gdb program core
用gdb同时调试一个运行程序和core文件，core是程序非法执行后core dump后产生的文件。

3. gdb program 1234
如果你的程序是一个服务程序，那么你可以指定这个服务程序运行时的进程ID。gdb会自动attach上去，并调试他。program应该在PATH环境变量中搜索得到。

4. gdb attach pid
某些情况下，一个程序已经启动了，我们想调试这个程序，但是又不想重启这个程序。
假设有这样一个场景，我们的聊天测试服务器程序正在运行，我们运行一段时间之后，发现这个聊天服务器再也没法接受新的客户端连接了，这个时候我们肯定是不能重启程序的，如果重启，当前程序的各种状态信息就丢失了。
这个时候，我们只需要使用 gdb attach 程序进程ID来将 gdb 调试器附加到我们的聊天测试服务器程序上即可。


GDB启动时，可以加上一些GDB的启动开关，详细的开关可以用gdb -help查看。下面只列举一些比较常用的参数：
#+BEGIN_EXAMPLE
--symbols=SYMFILE
从指定文件中读取符号表。

--se=FILE
从指定文件中读取符号表信息，并把他用在可执行文件中。

--core=COREFILE
调试时core dump的core文件。

--directory=DIR
加入一个源文件的搜索路径。默认搜索路径是环境变量中PATH所定义的路径。
#+END_EXAMPLE
*** 调试已运行的程序（附加进程）
两种方法：
1. 在UNIX下用ps查看正在运行的程序的PID（进程ID），然后用gdb PID process-id 格式挂接正在运行的程序。
2. 先用gdb 关联上源代码，并进行gdb，在gdb中用attach process-id 命令来挂接进程的PID。并用detach来取消挂接的进程。

假设，我们的聊天程序叫 chatserver，我们可以使用 ps 命令获取该进程的 PID，然后gdb attach 上去，就可以调试了。
#+begin_src bash
[zhangyl@localhost flamingoserver]$ ps -ef | grep chatserver
zhangyl 42921 1 17 11:18 ? 00:00:04 ./chatserver -d
zhangyl 42936 42898 0 11:18 pts/0 00:00:00 grep --color=auto chatserver
#+END_SRC
我们得到 chatserver 的 PID 为 42921，然后我们使用 gdb attach 42921 把 gdb 附加到 chatserver
进程：
#+begin_src bash
[zhangyl@localhost flamingoserver]$ gdb attach 42921
attach: No such file or directory.
Attaching to process 42921
Reading symbols from /home/zhangyl/flamingoserver/chatserver...done.
Reading symbols from /usr/lib64/mysql/libmysqlclient.so.18...Reading symbols
from /usr/lib64/mysql/libmysqlclient.so.18...(no debugging symbols
found)...done.
Reading symbols from /lib64/libpthread.so.0...(no debugging symbols
found)...done.
[New LWP 42931]
[New LWP 42930]
[New LWP 42929]
[New LWP 42928]
[New LWP 42927]
[New LWP 42926]
[New LWP 42925]
[New LWP 42924]
[New LWP 42922]
[Thread debugging using libthread_db enabled]
Using host libthread_db library "/lib64/libthread_db.so.1".
Loaded symbols for /lib64/libpthread.so.0
Reading symbols from /lib64/libc.so.6...(no debugging symbols found)...done.
#+END_SRC
为了节约篇幅，上述代码中我删掉了一些无关的信息。当提示 “Attaching to process 42921” 说明我们已经成功将 gdb 附加到目标进程了。
需要注意的是，由于我们的程序使用了一些系统库（如libc.so），由于这是发行版本的 Linux 系统，这些库是没有调试符号的，所以 gdb 会提示找不到这些库的调试符号。我们的目的是调试 chatserver，对系统 API 调用的内部实现并不关注，所以这些提示我们可以不关注，只要 chatserver 这个文件有调试信息即可。

当用 gdb attach 上目标进程后，调试器会暂停下来，此时我们可以使用 continue 命令让程序继续运行，或者加上相应的断点再继续运行程序。

当您调试完程序想结束此次调试，且不对当前进程 chatserver 有任何影响，也就是说想让这个程序继续运行，可以在gdb的命令行界面输入 detach 命令让程序与 gdb 调试器分离，这样 chatserver 可以继续运行。
#+begin_src bash
(gdb) detach
Detaching from program: /home/zhangyl/flamingoserver/chatserver, process 42921
#+END_SRC
然后再退出gdb就可以了。
#+begin_src bash
(gdb) quit
[zhangyl@localhost flamingoserver]$
#+END_SRC
*** 调试 core 文件（进程 Crash 之后如何定位问题）
有时候，我们的服务器程序运行一段时间后，会突然崩溃。这当然不是我们希望看到的，我们需要解决这个问题。
只要程序在崩溃的时候，有 core 文件产生，我们就可以使用这个 core 文件来定位崩溃的原因。
当然，Linux 系统默认是不开启程序崩溃产生 core 文件的这一机制的，我们可以使用 ulimit -c 来查看系统是否开启了这一机制。
#+begin_src bash
[zhangyl@localhost flamingoserver]$ ulimit -a
core file size (blocks, -c) 0
data seg size (kbytes, -d) unlimited
scheduling priority (-e) 0
file size (blocks, -f) unlimited
pending signals (-i) 15045
max locked memory (kbytes, -l) 64
max memory size (kbytes, -m) unlimited
open files (-n) 1024
pipe size (512 bytes, -p) 8
POSIX message queues (bytes, -q) 819200
real-time priority (-r) 0
stack size (kbytes, -s) 8192
cpu time (seconds, -t) unlimited
max user processes (-u) 4096
virtual memory (kbytes, -v) unlimited
file locks (-x) unlimited
#+END_SRC
我们发现 core file size 那一行默认是 0，表示关闭生成 core 文件，如果我们需要修改某个选项的值，可以使用 ulimit 选项名 设置值来修改，例如我们可以将 core 文件生成改成具体某个值（最大允许的字节数）或不限制大小。
这里我们直接改成不限制大小，执行命令 ulimit -c unlimited：
#+begin_src bash
[zhangyl@localhost flamingoserver]$ ulimit -c unlimited
[zhangyl@localhost flamingoserver]$ ulimit -a
core file size (blocks, -c) unlimited
data seg size (kbytes, -d) unlimited
scheduling priority (-e) 0
file size (blocks, -f) unlimited
pending signals (-i) 15045
max locked memory (kbytes, -l) 64
max memory size (kbytes, -m) unlimited
open files (-n) 1024
pipe size (512 bytes, -p) 8
POSIX message queues (bytes, -q) 819200
real-time priority (-r) 0
stack size (kbytes, -s) 8192
cpu time (seconds, -t) unlimited
max user processes (-u) 4096
virtual memory (kbytes, -v) unlimited
file locks (-x) unlimited
#+END_SRC
注意，这个命令容易记错，第一个 ulimit 是 Linux 命令，-c 选项后面的 unlimited 是选项的值，表示不限制大小，当然您也可以改成具体的数值大小。
还有一个问题就是，这样修改以后，当我们关闭这个 Linux 会话后，这个设置项的值就会被还原成 0，而我们的服务器程序一般是以后台程序（守护进程）长周期运行，也就是说当前会话虽然被关闭，服务器程序仍然继续在后台运行，这样这个程序崩溃在某个时刻崩溃后，是无法产生 core 文件，这种情形不利于排查问题。

所以，我们希望这个选项永久生效。设置永久生效的方式有两种：
1. 在 /etc/security/limits.conf 中增加一行
#+BEGIN_EXAMPLE
#<domain> <type> <item> <value>
\* soft core unlimited
#+END_EXAMPLE
这里设置的是不限制 core 文件的大小，也可以设置成具体的数值，如 1024 表示生成的 core 文件最大是 1024k。

2. 把“ulimit -c unlimited”这一行，加到 /etc/profile 文件中去，放到这个文件最后一行即可，修正成功以后执行“source /etc/profile”让配置立即生效。当然这只是对 root 用户，如果想仅仅作用于某一用户，可以把“ulimit -c unlimited”加到该用户对应的 ~/.bashrc 或 ~/.bash_profile 文件中去。

生成的core文件的默认命名方式是：core.pid，其位置是崩溃程序所在目录，
举个例子，比如某个程序当时运行时其进程 ID 是16663，那么如果其崩溃产生的 core 文件的名称是 core.16663。
我们来看一个具体的例子吧，某次我发现的我的服务器上 msg_server 崩溃了，在当前目录下产生了一个如下的core 文件：
#+begin_src bash
-rw------- 1 root root 10092544 Sep 9 15:14 core.21985
#+END_SRC
那么我们就可以通过这个 core.21985 的文件来排查崩溃的原因，调试 core 文件的命令是：
#+begin_src bash
gdb filename corename
#+END_SRC
- filename 就是程序名，这里就是 msg_server；
- corename 是 core.21985。

我们输入 gdb msg_server core.21985 来启动调试：
#+begin_src bash
[root@myaliyun msg_server]# gdb msg_server core.21985
Reading symbols from /root/teamtalkserver/src/msg_server/msg_server...done.
[New LWP 21985]
[Thread debugging using libthread_db enabled]
Using host libthread_db library "/lib64/libthread_db.so.1".
Core was generated by `./msg_server -d'.
Program terminated with signal 11, Segmentation fault.
#0 0x00000000004ceb1f in std::less<CMsgConn*>::operator() (this=0x2283878,
__x=@0x7ffca83563a0: 0x2284430, __y=@0x51: <error reading variable>)
at /usr/include/c++/4.8.2/bits/stl_function.h:235
235 { return __x < __y; }
#+END_SRC
我们可以看到程序崩溃的地方是在 stl_function.h 的 235 行，然后通过 bt 命令(下文将详细介绍)查看崩溃时的调用堆栈，进一步分析就能找到崩溃的原因。
#+begin_src bash
(gdb) bt
#0 0x00000000004ceb1f in std::less<CMsgConn*>::operator() (this=0x2283878,
__x=@0x7ffca83563a0: 0x2284430, __y=@0x51: <error reading variable>)
at /usr/include/c++/4.8.2/bits/stl_function.h:235
#1 0x00000000004cdd70 in std::_Rb_tree<CMsgConn*, CMsgConn*,
std::_Identity<CMsgConn*>, std::less<CMsgConn*>, std::allocator<CMsgConn*>
>::_M_get_insert_unique_pos
(this=0x2283878, __k=@0x7ffca83563a0: 0x2284430) at
/usr/include/c++/4.8.2/bits/stl_tree.h:1324
#2 0x00000000004cd18a in std::_Rb_tree<CMsgConn*, CMsgConn*,
std::_Identity<CMsgConn*>, std::less<CMsgConn*>, std::allocator<CMsgConn*>
>::_M_insert_unique<CMsgConn* const&> (this=0x2283878, __v=@0x7ffca83563a0:
0x2284430) at /usr/include/c++/4.8.2/bits/stl_tree.h:1377
#3 0x00000000004cc8bd in std::set<CMsgConn*, std::less<CMsgConn*>,
std::allocator<CMsgConn*> >::insert (this=0x2283878, __x=@0x7ffca83563a0:
0x2284430)
at /usr/include/c++/4.8.2/bits/stl_set.h:463
#4 0x00000000004cb011 in CImUser::AddUnValidateMsgConn (this=0x2283820,
pMsgConn=0x2284430) at /root/teamtalkserver/src/msg_server/ImUser.h:42
#5 0x00000000004c64ae in CDBServConn::_HandleValidateResponse (this=0x227f6a0,
pPdu=0x22860d0) at /root/teamtalkserver/src/msg_server/DBServConn.cpp:319
#6 0x00000000004c5e3d in CDBServConn::HandlePdu (this=0x227f6a0,
pPdu=0x22860d0) at /root/teamtalkserver/src/msg_server/DBServConn.cpp:203
#7 0x00000000005022b3 in CImConn::OnRead (this=0x227f6a0) at
/root/teamtalkserver/src/base/imconn.cpp:148
#8 0x0000000000501db3 in imconn_callback (callback_data=0x7f4b20
<g_db_server_conn_map>, msg=3 '\003', handle=8, pParam=0x0)
at /root/teamtalkserver/src/base/imconn.cpp:47
#9 0x0000000000504025 in CBaseSocket::OnRead (this=0x227f820) at
/root/teamtalkserver/src/base/BaseSocket.cpp:178
#10 0x0000000000502f8a in CEventDispatch::StartDispatch (this=0x2279990,
wait_timeout=100) at /root/teamtalkserver/src/base/EventDispatch.cpp:386
#11 0x00000000004fddbe in netlib_eventloop (wait_timeout=100) at
/root/teamtalkserver/src/base/netlib.cpp:160
#12 0x00000000004d18c2 in main (argc=2, argv=0x7ffca8359978) at
/root/teamtalkserver/src/msg_server/msg_server.cpp:213
(gdb)
#+END_SRC
堆栈 #4 就不是库代码了，我们可以排查这里我们的代码，找到问题原因。

但是细心的读者会发现一个问题：一个正在程序运行时，其 PID 我们是可以获取到的，但是当程序崩溃后，产生了 core 文件，尤其是多个程序同时崩溃，我们根本没法通过 core 文件名称中的 PID 来区分到底是哪个服务。

解决这个问题有两个方法：
1. 程序启动时，记录一下自己的 PID；
#+begin_src bash
void writePid()
{
uint32_t curPid = (uint32_t) getpid();
FILE* f = fopen("xxserver.pid", "w");
assert(f);
char szPid[32];
snprintf(szPid, sizeof(szPid), "%d", curPid);
fwrite(szPid, strlen(szPid), 1, f);
fclose(f);
}
#+END_SRC
我们在程序启动时调用上述 writePID 函数，将程序当时的 PID 记录到 xxserver.pid 文件中去，这样当程序崩溃时，我们可以从这个文件中得到进程当时运行的 PID，这样就可以与默认的 core文件名后面的 PID 做匹配了。

2. 自定义 core 文件的名称和目录
/proc/sys/kernel/core_uses_pid 可以控制产生的 core 文件的文件名中是否添加 PID 作为扩展，如果添加则文件内容为 1，否则为 0;
/proc/sys/kernel/core_pattern 可以设置格式化的core 文件保存位置或文件名。
修改方式如下：
#+begin_src bash
echo "/corefile/core-%e-%p-%t" > /proc/sys/kernel/core_pattern
#+END_SRC
各个参数的说明如下：
#+DOWNLOADED: screenshot @ 2022-08-03 14:07:44
[[file:images/linux笔记/soft_core_unlimited/2022-08-03_14-07-44_screenshot.png]]
假设我们现在的程序叫 test，我们设置该程序崩溃时的 core 文件名如下:
#+begin_src bash
echo "/root/testcore/core-%e-%p-%t" > /proc/sys/kernel/core_pattern
#+END_SRC
那么最终会在 /root/testcore/ 目录下生成的 test 的 core 文件名格式如下：
#+begin_src bash
-rw-------. 1 root root 409600 Jan 14 13:54 core-test-13154-1547445291
#+END_SRC

** GDB 的命令概貌
启动gdb后，就进入gdb的调试环境中，就可以使用gdb的命令开始调试程序了，gdb的命令可以使用help命令来查看，如下所示：
#+begin_src bash
root@linux:/home/benben# gdb
GNU gdb 5.1.1
Copyright 2002 Free Software Foundation, Inc.
GDB is free software, covered by the GNU General Public License, and you are
welcome to change it and/or distribute copies of it under certain conditions.
Type "show copying" to see the conditions.
There is absolutely no warranty for GDB. Type "show warranty" for details.
This GDB was configured as "i386-suse-linux".
(gdb) help
List of classes of commands:
 
aliases -- Aliases of other commands
breakpoints -- Making program stop at certain points
data -- Examining data
files -- Specifying and examining files
internals -- Maintenance commands
obscure -- Obscure features
running -- Running the program
stack -- Examining the stack
status -- Status inquiries
support -- Support facilities
tracepoints -- Tracing of program execution without stopping the program
user-defined -- User-defined commands
 
Type "help" followed by a class name for a list of commands in that class.
Type "help" followed by command name for full documentation.
Command name abbreviations are allowed if unambiguous.
(gdb)
#+END_SRC
gdb的命令很多，gdb把之分成许多个种类。help命令只是例出gdb的命令种类，如果要看种类中的命令，可以使用 help 命令，如：help breakpoints，查看设置断点的所有命令。也可以直接help 来查看命令的帮助。

gdb中，输入命令时，可以不用打全命令，只用打命令的前几个字符就可以了，当然，命令的前几个字符应该要标志着一个唯一的命令，在Linux下，你可以敲击两次TAB键来补齐命令的全称，如果有重复的，那么gdb会把其列出来。

示例一： 在进入函数func时，设置一个断点。可以敲入break func，或是直接就是b func
#+begin_src bash
(gdb) b func
Breakpoint 1 at 0x8048458: file hello.c, line 10.
#+END_SRC
示例二： 敲入b按两次TAB键，你会看到所有b打头的命令：
#+begin_src bash
(gdb) b
backtrace break bt
#+END_SRC
示例三： 只记得函数的前缀，可以这样：
#+begin_src bash
(gdb) b make_ <按TAB键>
（再按下一次TAB键，你会看到:）
make_a_section_from_file make_environ
make_abs_section make_function_type
make_blockvector make_pointer_type
make_cleanup make_reference_type
make_command make_symbol_completion_list
#+END_SRC
GDB把所有make开头的函数全部例出来给你查看。

要退出gdb时，只用发quit或命令简称q就行了。
** GDB 中运行UNIX的shell程序
在gdb环境中，你可以执行UNIX的shell的命令，使用gdb的shell命令来完成：
#+begin_src bash
shell
#+END_SRC
调用UNIX的shell来执行，环境变量SHELL中定义的UNIX的shell将会被用来执行，如果SHELL没有定义，那就使用UNIX的标准shell：/bin/sh。

退出用exit命令，回到gdb提示符

还有一个gdb命令是make：
#+begin_src bash
make
#+END_SRC
可以在gdb中执行make命令来重新build自己的程序。这个命令等价于“shell make ”。
** 在GDB中运行程序
当以 gdb 方式启动gdb后，gdb会在PATH路径和当前目录中搜索源文件。如要确认gdb是否读到源文件，可使用l或list命令，看看gdb是否能列出源代码。

默认情况下，gdb+filename 只是附加一个调试文件，并没有启动这个程序，我们需要输入 run 命令启动这个程序（run 命令简写成 r）。
假设程序已经启动，我们再次输入 run 命令则是重启程序。
我们在gdb 界面按 Ctrl + C （界面中的 ^C）让程序中断下来，再次输入 r 命令，gdb 会提示我们是否重启程序，输入 y 确认重启。


你有可能需要设置下面三方面的事。
1. 运行环境。
#+BEGIN_EXAMPLE
path  可设定程序的运行路径。
show paths 查看程序的运行路径。
set env environmentVarname=value 设置环境变量。如：set env USER=benben
show env [varname] 查看环境变量，不带varname，打印出当前所有环境变量。
#+END_EXAMPLE
2. 工作目录。
#+BEGIN_EXAMPLE
cd 相当于shell的cd命令。
pwd 显示当前的所在目录。
#+END_EXAMPLE
3. 程序的输入输出。
#+BEGIN_EXAMPLE
info terminal 显示你程序用到的终端的模式。
使用重定向控制程序输出。如：run > outfile
tty命令可以设置输入输出使用的终端设备。如：tty /dev/tty1
#+END_EXAMPLE
*** 设置命令行参数
程序运行参数。
#+BEGIN_EXAMPLE
set args 可指定运行时参数。（如：set args 10 20 30 40 50 ）
show args 命令可以查看设置好的运行参数。
#+END_EXAMPLE

很多程序，需要我们传递命令行参数。
在 gdb 调试中，很多人会觉得可以使用 gdb filename args 这种形式来给 gdb 调试的程序传递命令行参数，这样是不行的。
正确的做法是在用 gdb 附加程序后，在使用 run 命令之前，使用 set args 您要的命令行参数来指定，还是以 redis-server 为例，redis 启动时可以指定一个命令行参数，就是它的配置文件，它的默认配置文件位于 redis-server 这个文件的上一层目录，所以我们可以在 gdb 中这样传递这个参数：
#+begin_src bash
set args ../redis.conf
#+END_SRC
可以通过 show args查看命令行参数是否设置成功。
#+begin_src bash
(gdb) set args ../redis.conf
(gdb) show args
Argument list to give program being debugged when it is started is
"../redis.conf ".
(gdb)
#+END_SRC
如果您单个命令行参数之间含有空格，可以使用引号将参数包裹起来。
#+begin_src bash
(gdb) set args "999 xx" "hu jj"
(gdb) show args
Argument list to give program being debugged when it is started is ""999 xx" "hujj"".
(gdb)
#+END_SRC
如果想清除掉已经设置好的命令行参数，使用 set args 不加任何参数即可。
#+begin_src bash
(gdb) set args
(gdb) show args
Argument list to give program being debugged when it is started is "".
(gdb)
#+END_SRC
** 暂停 / 恢复程序运行
调试程序中，暂停程序运行是必须的，GDB可以方便地暂停程序的运行。你可以设置程序的在哪行停住，在什么条件下停住，在收到什么信号时停往等等。以便于你查看运行时的变量，以及运行时的流程。

当进程被gdb停住时，你可以使用info program 来查看程序的是否在运行，进程号，被暂停的原因。

在gdb中，我们可以有以下几种暂停方式：断点（BreakPoint）、观察点（WatchPoint）、捕捉点（CatchPoint）、信号（Signals）、线程停止（Thread Stops）。如果要恢复程序运行，可以使用c或是continue命令。
*** 设置断点（BreakPoint）
我们用break命令来设置断点。正面有几点设置断点的方法：
#+BEGIN_EXAMPLE
break function
在进入指定函数时停住。C++中可以使用class::function或function(type,type)格式来指定函数名。

break linenum
在指定行号停住。

break +offset
break -offset
在当前行号的前面或后面的offset行停住。offset为自然数。

break filename:linenum
在源文件filename的linenum行处停住。

break filename:function
在源文件filename的function函数的入口处停住。

break *address
在程序运行的内存地址处停住。

break
break命令没有参数时，表示在下一条指令处停住。

break ... if cond
...可以是上述的参数，condition表示条件，在条件成立时停住。比如在循环境体中，可以设置break if i=100，表示当i为100时停住程序。
#+END_EXAMPLE
查看断点时，可使用info命令，如下所示：（注：n表示断点号）
info break 可以简写为 info b
#+BEGIN_EXAMPLE
info breakpoints [n]
info break [n]
info watchpoints [n]
#+END_EXAMPLE
**** 设置临时断点
break 命令是添加一个永久断点，tbreak 命令也是添加一个断点，第一个字母“t”的意思是“temporarily ”（“临时的”），也就是说这个命令加的断点是临时的，
所谓临时断点，就是一旦该断点触发一次后，就会自动删除。
添加断点的方法与上文中介绍的 break 命令一模一样，这里就不再赘述。

*** 设置观察点（WatchPoint）
观察点一般来观察某个表达式（变量也是一种表达式）的值是否有变化了，如果有变化，马上停住程序。我们有下面的几种方法来设置观察点：
#+BEGIN_EXAMPLE
watch expr
为表达式（变量）expr设置一个观察点。一量表达式值有变化时，马上停住程序。

rwatch expr
当表达式（变量）expr被读时，停住程序。

awatch expr
当表达式（变量）的值被读或被写时，停住程序。

info watchpoints
查看观察点、断点和捕捉点信息，同info break 一样.
#+END_EXAMPLE
*** 设置捕捉点（CatchPoint）

你可设置捕捉点来补捉程序运行时的一些事件。如：载入共享库（动态链接库）或是C++的异常。设置捕捉点的格式为：
#+BEGIN_EXAMPLE
catch event
#+END_EXAMPLE
当event发生时，停住程序。event可以是下面的内容：
- throw 一个C++抛出的异常。（throw为关键字）
- catch 一个C++捕捉到的异常。（catch为关键字）
- exec 调用系统调用exec时。（exec为关键字，目前此功能只在HP-UX下有用）
- fork 调用系统调用fork时。（fork为关键字，目前此功能只在HP-UX下有用）
- vfork 调用系统调用vfork时。（vfork为关键字，目前此功能只在HP-UX下有用）
- load 或 load 载入共享库（动态链接库）时。（load为关键字，目前此功能只在HP-UX下有用）
- unload 或 unload 卸载共享库（动态链接库）时。（unload为关键字，目前此功能只在HP-UX下有用）

#+BEGIN_EXAMPLE
tcatch event
只设置一次捕捉点，当程序停住以后，应点被自动删除。
#+END_EXAMPLE
*** 维护停止点
上面说了如何设置程序的停止点，GDB中的停止点也就是上述的三类。在GDB中，如果你觉得已定义好的停止点没有用了，你可以使用delete、clear、disable、enable这几个命令来进行维护。
#+BEGIN_EXAMPLE
clear
清除所有的已定义的停止点。

clear function
清除所有设置在函数上的停止点。

clear linenum
清除所有设置在指定行上的停止点。
clear filename:linenum
清除所有设置在指定文件：指定行上的停止点。

delete [breakpoints] [range...]
删除指定的断点，breakpoints为断点号。如果不指定断点号，则表示删除所有的断点。range 表示断点号的范围（如：3-7）。其简写命令为d。

比删除更好的一种方法是disable停止点，disable了的停止点，GDB不会删除，当你还需要时，enable即可，就好像回收站一样。

disable [breakpoints] [range...]
disable所指定的停止点，breakpoints为停止点号。如果什么都不指定，表示disable所有的停止点。简写命令是dis.

enable [breakpoints] [range...]
enable所指定的停止点，breakpoints为停止点号。

enable [breakpoints] once range...
enable所指定的停止点一次，当程序停止后，该停止点马上被GDB自动disable。

enable [breakpoints] delete range...
enable所指定的停止点一次，当程序停止后，该停止点马上被GDB自动删除。

如果 disable 和 enable 命令不加断点编号，则分别表示禁用和启用所有断点：
#+END_EXAMPLE
*** 停止条件维护
前面在说到设置断点时，我们提到过可以设置一个条件，当条件成立时，程序自动停止，这是一个非常强大的功能，这里，我想专门说说这个条件的相关维护命令。一般来说，为断点设置一个条件，我们使用if关键词，后面跟其断点条件。并且，条件设置好后，我们可以用condition命令来修改断点的条件。（只有 break和watch命令支持if，catch目前暂不支持if）
#+BEGIN_EXAMPLE
condition bnum expression
修改断点号为bnum的停止条件为expression。

condition bnum
清除断点号为bnum的停止条件。
#+END_EXAMPLE
还有一个比较特殊的维护命令ignore，你可以指定程序运行时，忽略停止条件几次。
#+BEGIN_EXAMPLE
ignore bnum count
表示忽略断点号为bnum的停止条件count次。
#+END_EXAMPLE
*** 为停止点设定运行命令
我们可以使用GDB提供的command命令来设置停止点的运行命令。也就是说，当运行的程序在被停止住时，我们可以让其自动运行一些别的命令，这很有利行自动化调试。对基于GDB的自动化调试是一个强大的支持。
#+BEGIN_EXAMPLE
commands [bnum]
... command-list ...
end
#+END_EXAMPLE
为断点号bnum指写一个命令列表。当程序被该断点停住时，gdb会依次运行命令列表中的命令。

例如：
#+BEGIN_EXAMPLE
break foo if x>0
commands
printf "x is %d ",x
continue
end
#+END_EXAMPLE
断点设置在函数foo中，断点条件是x>0，如果程序被断住后，也就是，一旦x的值在foo函数中大于0，GDB会自动打印出x的值，并继续运行程序。

如果你要清除断点上的命令序列，那么只要简单的执行一下commands命令，并直接在打个end就行了。
*** 断点菜单
在C++中，可能会重复出现同一个名字的函数若干次（函数重载），在这种情况下，break 不能告诉GDB要停在哪个函数的入口。当然，你可以使用break 也就是把函数的参数类型告诉GDB，以指定一个函数。否则的话，GDB会给你列出一个断点菜单供你选择你所需要的断点。你只要输入你菜单列表中的编号就可以了。如：
#+begin_src bash
(gdb) b String::after
[0] cancel
[1] all
[2] file:String.cc; line number:867
[3] file:String.cc; line number:860
[4] file:String.cc; line number:875
[5] file:String.cc; line number:853
[6] file:String.cc; line number:846
[7] file:String.cc; line number:735
> 2 4 6
Breakpoint 1 at 0xb26c: file String.cc, line 867.
Breakpoint 2 at 0xb344: file String.cc, line 875.
Breakpoint 3 at 0xafcc: file String.cc, line 846.
Multiple breakpoints were set.
Use the "delete" command to delete unwanted breakpoints.
(gdb)
#+END_SRC
*** 恢复程序运行和单步调试
当程序被停住了，你可以用continue命令恢复程序的运行直到程序结束，或下一个断点到来。也可以使用step或next命令单步跟踪程序。
#+BEGIN_EXAMPLE
continue [ignore-count]
c [ignore-count]
fg [ignore-count]
#+END_EXAMPLE
恢复程序运行，直到程序结束，或是下一个断点到来。ignore-count表示忽略其后的断点次数。continue，c，fg三个命令都是一样的意思。
#+BEGIN_EXAMPLE
step [count]
单步跟踪，如果有函数调用，他会进入该函数。进入函数的前提是，此函数被编译有debug信息。很像VC等工具中的step in。后面可以加count也可以不加，不加表示一条条地执行，加表示执行后面的count条指令，然后再停住。

next [count]
同样单步跟踪，如果有函数调用，他不会进入该函数。很像VC等工具中的step over。后面可以加count也可以不加，不加表示一条条地执行，加表示执行后面的count条指令，然后再停住。

set step-mode on
打开step-mode模式，于是，在进行单步跟踪时，程序会因为没有debug信息而停住。这个参数有很利于查看机器码。

set step-mod off
关闭step-mode模式。This is the default.

show step-mode
Show whether gdb will stop in or step over functions without source line debug information.

finish
运行程序，直到当前函数完成返回。并打印函数返回时的堆栈地址和返回值及参数值等信息。

until 或 u
当你厌倦了在一个循环体内单步跟踪时，这个命令可以运行程序直到退出循环体。

until location
u location
Continue running your program until either the specified location is reached,or the current stack frame returns. location is any of the forms of argument acceptable to break. This form of the command uses breakpoints, and hence is quicker than until without an argument. The specified location is actually reached only if it is in the current frame. This implies that until can be used to skip over recursive function invocations.
#+END_EXAMPLE
For instance in the code below, if the current location is line 96, issuing until 99 will execute the program up to 
#+BEGIN_SRC 
int factorial (int value)
{
if (value &gt; 1) {
value *= factorial (value - 1);
}
return (value);
}
#+END_SRC
#+BEGIN_EXAMPLE
stepi 或 si 或 stepi repeatCount

单步跟踪一条机器指令！一条程序代码有可能由数条机器指令完成，stepi可以单步执行机器指令。It is often useful to do ‘display/i $pc’ when stepping by machine instructions. This makes gdb automatically display the next instruction to be executed, each time your program stops.

An argument is a repeat count, as in step.

nexti
nexti repeatCount
ni
Execute one machine instruction, but if it is a function call, proceed until the function returns.An argument is a repeat count, as in next.
#+END_EXAMPLE

** 打印所有全局变量和局部变量
#+begin_src bash
#查看全局和静态变量
info variables

#查看当前stack frame局部变量
info locals

#查看当前stack frame参数
info args
#+END_SRC

** 函数的调用与返回
#+begin_src bash
call name 调用和执行一个函数
(gdb) call gen_and_sork( 1234,1,0 )
(gdb) call printf(“abcd”)
#+END_SRC
*** finish和return
在实际调试的时候，我们在某个函数中调试一会儿后，我们不需要再一步步执行到函数返回处，我们希望直接执行完当前函数并回到上一层调用处，我们可以使用 finish 命令。
与 finish 命令类似的还有return 命令，return 命令作用是结束执行当前函数，还可以指定该函数的返回值。

这里需要注意一下二者的区别：finish 命令会执行函数到正常退出该函数；而 return 命令是立即结束执行当前函数并返回，也就是说，如果当前函数还有剩余的代码未执行完毕，也不会执行了。

可以return指定函数返回值，例如 return 9999 指定函数返回值为9999。

** 寄存器的标准名字
- $pc 程序计数器
- $fp 帧指针（当前堆栈帧）
- $sp 栈指针
- $ps 处理器状态
** 查看当前位置 - where
** 查看函数调用栈
查看调用栈信息：
- backtrace：查看函数调用的顺序（函数调用栈的信息），可以用bt缩写
- backtrace n: 显示程序的调用栈信息，只显示栈顶n桢(frame)
- backtrace –n: 显示程序的调用栈信息，只显示栈底部n桢(frame)
- set backtrace limit n: 设置bt显示的最大桢层
- where, info stack：都是bt的别名，功能一样

查看桢信息：
- frame n: 查看第n桢的信息，切换到栈编号为n的上下文中,frame可以用f缩写
- frame addr: 查看pc地址为addr的桢的相关信息
- up n: 查看当前桢上面第n桢的信息
- down n: 查看当前桢下面第n桢的信息

查看更加详细的信息：
- info frame、info frame n或者info frame addr ：查看当前函数调用的栈帧信息数
- info args：查看当前桢中的参数
- info locals：查看当前桢中的局部变量
- info catch：查看当前桢中的异常处理器（exception handlers
** 调试fork多进程程序
这里说的多进程程序指的是一个进程使用 Linux 系统调用 fork 函数产生的子进程。

在实际的应用中，有一类应用会通过 Linux 函数 fork 出新的子进程。
以 nginx 为例，nginx 对客户端的连接是采用多进程模型，当 nginx 接受客户端连接后，创建一个新的进程来处理该连接上的信息来往。

新产生的进程与原进程互为父子关系。那么如何用 gdb 调试这样父子进程呢？一般有两种方法：
*** 方法一：attach
用 gdb 先调试父进程，等子进程被 fork 出来后，使用 gdb attach 到子进程上去。
当然，您需要重新开启一个 Shell 窗口用于调试。

**** 例子
我们这里以调试 nginx 服务为例。

从 nginx 官网 http://nginx.org/en/download.html 下载最新的 nginx 源码，然后编译安装（这里采用的的nginx 版本是 1.18.0）。
#+begin_src bash
## 下载 nginx 源码
[root@iZbp14iz399acush5e8ok7Z zhangyl]# wget http://nginx.org/download/nginx-
1.18.0.tar.gz
--2020-07-05 17:22:10-- http://nginx.org/download/nginx-1.18.0.tar.gz
Resolving nginx.org (nginx.org)... 95.211.80.227, 62.210.92.35,
2001:1af8:4060:a004:21::e3
Connecting to nginx.org (nginx.org)|95.211.80.227|:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 1039530 (1015K) [application/octet-stream]
Saving to: ‘nginx-1.18.0.tar.gz’
nginx-1.18.0.tar.gz 100%
[===============================================================================
====================>] 1015K 666KB/s in 1.5s
2020-07-05 17:22:13 (666 KB/s) - ‘nginx-1.18.0.tar.gz’ saved [1039530/1039530]
## 解压nginx
[root@iZbp14iz399acush5e8ok7Z zhangyl]# tar zxvf nginx-1.18.0.tar.gz
## 编译nginx
[root@iZbp14iz399acush5e8ok7Z zhangyl]# cd nginx-1.18.0
[root@iZbp14iz399acush5e8ok7Z nginx-1.18.0]# ./configure --
prefix=/usr/local/nginx
[root@iZbp14iz399acush5e8ok7Z nginx-1.18.0]make CFLAGS="-g -O0"
## 安装，这样nginx就被安装到/usr/local/nginx/目录下
[root@iZbp14iz399acush5e8ok7Z nginx-1.18.0]make install
#+END_SRC
#+BEGIN_EXAMPLE
注意：使用 make 命令编译时我们为了让生成的 nginx 带有调试符号信息同时关闭编译器优化，
我们设置了 "-g -O0" 选项。
#+END_EXAMPLE
启动 nginx：
#+begin_src bash
[root@iZbp14iz399acush5e8ok7Z sbin]# cd /usr/local/nginx/sbin
[root@iZbp14iz399acush5e8ok7Z sbin]# ./nginx -c /usr/local/nginx/conf/nginx.conf
[root@iZbp14iz399acush5e8ok7Z sbin]# lsof -i -Pn | grep nginx
nginx 5246 root 9u IPv4 22252908 0t0 TCP *:80 (LISTEN)
nginx 5247 nobody 9u IPv4 22252908 0t0 TCP *:80 (LISTEN)
#+END_SRC
如上所示，nginx 默认会开启两个进程，在我的机器上以 root 用户运行的 nginx 进程是父进程，进程号 5246，以 nobody 用户运行的进程是子进程，进程号 5247。
我们在当前窗口使用 gdb attach5246 命令将 gdb 附加到 nginx 主进程上去。
#+begin_src bash
[root@iZbp14iz399acush5e8ok7Z sbin]# gdb attach 5246
...省略部分输出信息...
0x00007fd42a103c5d in sigsuspend () from /lib64/libc.so.6
Missing separate debuginfos, use: yum debuginfo-install glibc-2.28-
72.el8_1.1.x86_64 libxcrypt-4.1.1-4.el8.x86_64 pcre-8.42-4.el8.x86_64 sssd-
client-2.2.0-19.el8.x86_64 zlib-1.2.11-10.el8.x86_64
(gdb)
#+END_SRC
此时我们就可以调试 nginx 父进程了，例如使用 bt 命令查看当前调用堆栈：
#+begin_src bash
(gdb) bt
#0 0x00007fd42a103c5d in sigsuspend () from /lib64/libc.so.6
#1 0x000000000044ae32 in ngx_master_process_cycle (cycle=0x1703720) at
src/os/unix/ngx_process_cycle.c:164
#2 0x000000000040bc05 in main (argc=3, argv=0x7ffe49109d68) at
src/core/nginx.c:382
(gdb) f 1
#1 0x000000000044ae32 in ngx_master_process_cycle (cycle=0x1703720) at
src/os/unix/ngx_process_cycle.c:164
164 sigsuspend(&set);
(gdb) l
159 }
160 }
161
162 ngx_log_debug0(NGX_LOG_DEBUG_EVENT, cycle->log, 0,
"sigsuspend");
163
164 sigsuspend(&set);
165
166 ngx_time_update();
167
168 ngx_log_debug1(NGX_LOG_DEBUG_EVENT, cycle->log, 0,
(gdb)
#+END_SRC
使用 f 1 命令切换到当前调用堆栈 #1，我们可以发现 nginx 父进程的主线程挂起在src/core/nginx.c:382 处。
此时你可以使用 c 命令让程序继续运行起来，也可以添加断点或者做一些其他的调试操作。
再开一个 shell 窗口，使用 gdb attach 5247 将 gdb 附加到 nginx 子进程：
#+begin_src bash
[root@iZbp14iz399acush5e8ok7Z sbin]# gdb attach 5247
...部署输出省略...
0x00007fd42a1c842b in epoll_wait () from /lib64/libc.so.6
Missing separate debuginfos, use: yum debuginfo-install glibc-2.28-
72.el8_1.1.x86_64 libblkid-2.32.1-17.el8.x86_64 libcap-2.26-1.el8.x86_64 libgcc-
8.3.1-4.5.el8.x86_64 libmount-2.32.1-17.el8.x86_64 libselinux-2.9-2.1.el8.x86_64
libuuid-2.32.1-17.el8.x86_64 libxcrypt-4.1.1-4.el8.x86_64 pcre-8.42-4.el8.x86_64
pcre2-10.32-1.el8.x86_64 sssd-client-2.2.0-19.el8.x86_64 systemd-libs-239-
18.el8_1.2.x86_64 zlib-1.2.11-10.el8.x86_64
(gdb)
#+END_SRC
我们使用 bt 命令查看一下子进程的主线程当前调用堆栈：
#+begin_src bash
(gdb) bt
#0 0x00007fd42a1c842b in epoll_wait () from /lib64/libc.so.6
#1 0x000000000044e546 in ngx_epoll_process_events (cycle=0x1703720,
timer=18446744073709551615, flags=1) at src/event/modules/ngx_epoll_module.c:800
#2 0x000000000043f317 in ngx_process_events_and_timers (cycle=0x1703720) at
src/event/ngx_event.c:247
#3 0x000000000044c38f in ngx_worker_process_cycle (cycle=0x1703720, data=0x0)
at src/os/unix/ngx_process_cycle.c:750
#4 0x000000000044926f in ngx_spawn_process (cycle=0x1703720, proc=0x44c2e1
<ngx_worker_process_cycle>, data=0x0, name=0x4cfd70 "worker process",
respawn=-3)
at src/os/unix/ngx_process.c:199
#5 0x000000000044b5a4 in ngx_start_worker_processes (cycle=0x1703720, n=1,
type=-3) at src/os/unix/ngx_process_cycle.c:359
#6 0x000000000044acf4 in ngx_master_process_cycle (cycle=0x1703720) at
src/os/unix/ngx_process_cycle.c:131
#7 0x000000000040bc05 in main (argc=3, argv=0x7ffe49109d68) at
src/core/nginx.c:382
(gdb) f 1
#1 0x000000000044e546 in ngx_epoll_process_events (cycle=0x1703720,
timer=18446744073709551615, flags=1) at src/event/modules/ngx_epoll_module.c:800
800 events = epoll_wait(ep, event_list, (int) nevents, timer);
(gdb)
#+END_SRC
可以发现子进程挂起在 src/event/modules/ngx_epoll_module.c:800 的 epoll_wait 函数处。
我们在 epoll_wait 函数返回后（ src/event/modules/ngx_epoll_module.c:804 ）加一个断点，然后使用 c 命令让 nginx 子进程继续运行。
#+begin_src bash
800 events = epoll_wait(ep, event_list, (int) nevents, timer);
(gdb) list
795 /* NGX_TIMER_INFINITE == INFTIM */
796
797 ngx_log_debug1(NGX_LOG_DEBUG_EVENT, cycle->log, 0,
798 "epoll timer: %M", timer);
799
800 events = epoll_wait(ep, event_list, (int) nevents, timer);
801
802 err = (events == -1) ? ngx_errno : 0;
803
804 if (flags & NGX_UPDATE_TIME || ngx_event_timer_alarm) {
(gdb) b 804
Breakpoint 1 at 0x44e560: file src/event/modules/ngx_epoll_module.c, line 804.
(gdb) c
Continuing.
#+END_SRC
接着我们在浏览器里面访问 nginx 的站点，我这里的 ip 地址是我的云主机地址，读者实际调试时改成自己的 nginx 服务器所在的地址，如果是本机就是 127.0.0.1，由于默认端口是 80，所以不用指定端口号。
#+begin_src bash
http://你的ip地址:80
等价于
http://你的ip地址
#+END_SRC
此时我们回到 nginx 子进程的调试界面发现断点被触发：
#+begin_src bash
Breakpoint 1, ngx_epoll_process_events (cycle=0x1703720,
timer=18446744073709551615, flags=1) at src/event/modules/ngx_epoll_module.c:804
804 if (flags & NGX_UPDATE_TIME || ngx_event_timer_alarm) {
(gdb)
#+END_SRC
使用 bt 命令可以获得此时的调用堆栈：
#+begin_src bash
(gdb) bt
#0 ngx_epoll_process_events (cycle=0x1703720, timer=18446744073709551615,
flags=1) at src/event/modules/ngx_epoll_module.c:804
#1 0x000000000043f317 in ngx_process_events_and_timers (cycle=0x1703720) at
src/event/ngx_event.c:247
#2 0x000000000044c38f in ngx_worker_process_cycle (cycle=0x1703720, data=0x0)
at src/os/unix/ngx_process_cycle.c:750
#3 0x000000000044926f in ngx_spawn_process (cycle=0x1703720, proc=0x44c2e1
<ngx_worker_process_cycle>, data=0x0, name=0x4cfd70 "worker process",
respawn=-3)
at src/os/unix/ngx_process.c:199
#4 0x000000000044b5a4 in ngx_start_worker_processes (cycle=0x1703720, n=1,
type=-3) at src/os/unix/ngx_process_cycle.c:359
#5 0x000000000044acf4 in ngx_master_process_cycle (cycle=0x1703720) at
src/os/unix/ngx_process_cycle.c:131
#6 0x000000000040bc05 in main (argc=3, argv=0x7ffe49109d68) at
src/core/nginx.c:382
(gdb)
#+END_SRC
使用 info threads 命令可以查看子进程所有线程信息，我们发现 nginx子进程只有一个主线程：
#+begin_src bash
(gdb) info threads
Id Target Id Frame
\* 1 Thread 0x7fd42b17c740 (LWP 5247) "nginx" ngx_epoll_process_events
(cycle=0x1703720, timer=18446744073709551615, flags=1) at
src/event/modules/ngx_epoll_module.c:804
(gdb)
#+END_SRC
nginx 父进程不处理客户端请求，处理客户端请求的逻辑在子进程中，在单个子进程客户端请求数量达到一定数量时，父进程会重新 fork 一个新的子进程来处理新的客户端请求，也就是说子进程数量可以有多个，你可以开多个 shell 窗口，使用 gdb attach 到各个子进程上去调试。

总结起来，我们可以使用这种方法添加各种断点调试 nginx 的功能，慢慢我们就能熟悉 nginx 的各个内部逻辑了。

然而，方法一存在一个缺点，即程序已经启动了，我们只能使用 gdb 观察程序在这之后的行为，如果我们想调试程序从启动到运行起来之间的执行流程，方法一可能不太适用。
有些读者可能会说，我用 gdb 附加到进程后，我加好断点然后使用 run 命令重启进程这样不就可以调试程序从启动到运行起来之间的执行流程了。问题是这种方法不是通用的，因为对于多进程服务模型，有些父子进程有一定的依赖关系，是不方便在运行过程中重启的。这个时候就可以使用方法二来调试了。
*** 方法二：follow-fork
gdb 调试器提供一个选项叫 follow-fork ，通过 set follow-fork mode 来设置是当一个进程 fork 出新的子进程时，gdb 是继续调试父进程（取值是 parent）还是子进程（取值是 child），默认是父进程（取值是 parent）。
#+begin_src bash
# fork之后gdb attach到子进程
set follow-fork child
# fork之后gdb attach到父进程，这是默认值
set follow-fork parent
#+END_SRC
我们可以使用 show follow-fork mode 查看当前值：
#+begin_src bash
(gdb) show follow-fork mode
Debugger response to a program call of fork or vfork is "child".
#+END_SRC
我们还是以调试 nginx 为例，先进入 nginx 可执行文件所在的目录，将方法一中的 nginx 服务停下来：
#+begin_src bash
[root@iZbp14iz399acush5e8ok7Z sbin]# cd /usr/local/nginx/sbin/
[root@iZbp14iz399acush5e8ok7Z sbin]# ./nginx -s stop
#+END_SRC
nginx 源码中存在这样的逻辑，这个逻辑会在程序 main 函数处被调用：
#+begin_src bash
//src/os/unix/ngx_daemon.c:13行
ngx_int_t
ngx_daemon(ngx_log_t *log)
{
    int fd;
    switch (fork()) {
    case -1:
    ngx_log_error(NGX_LOG_EMERG, log, ngx_errno, "fork() failed");
    return NGX_ERROR;
    //fork出来的子进程走这个case
    case 0:
    break;
    //父进程中fork返回值是子进程的PID，大于0，因此走这个case
    //因此主进程会退出
    default:
    exit(0);
    }
    //...省略部分代码...
}
#+END_SRC
如上述代码中注释所示，为了不让主进程退出，我们在 nginx 的配置文件中增加一行：
#+begin_src bash
daemon off;
#+END_SRC
这样 nginx 就不会调用 ngx_daemon 函数了。
接下来，我们执行 gdb nginx ，然后通过设置参数将配置文件 nginx.conf 传给待调试的 nginx 进程：
#+begin_src bash
Quit anyway? (y or n) y
[root@iZbp14iz399acush5e8ok7Z sbin]# gdb nginx
...省略部分输出...
Reading symbols from nginx...done.
(gdb) set args -c /usr/local/nginx/conf/nginx.conf
(gdb)
#+END_SRC
接着输入 run 命令尝试运行 nginx：
#+begin_src bash
(gdb) run
Starting program: /usr/local/nginx/sbin/nginx -c
/usr/local/nginx/conf/nginx.conf
[Thread debugging using libthread_db enabled]
...省略部分输出信息...
[Detaching after fork from child process 7509]
#+END_SRC
如前文所述，gdb 遇到 fork 指令时默认会 attach 到父进程去，因此上述输出中有一行提示 ”Detaching after fork from child process 7509“，我们按 Ctrl + C 将程序中断下来，然后输入 bt 命令查看当前调用堆栈，输出的堆栈信息和我们在方法一中看到的父进程的调用堆栈一样，说明 gdb 在程序 fork 之后确实 attach 了父进程：
#+begin_src bash
^C
Program received signal SIGINT, Interrupt.
0x00007ffff6f73c5d in sigsuspend () from /lib64/libc.so.6
(gdb) bt
#0 0x00007ffff6f73c5d in sigsuspend () from /lib64/libc.so.6
#1 0x000000000044ae32 in ngx_master_process_cycle (cycle=0x71f720) at
src/os/unix/ngx_process_cycle.c:164
#2 0x000000000040bc05 in main (argc=3, argv=0x7fffffffe4e8) at
src/core/nginx.c:382
(gdb)
#+END_SRC
如果想在 fork 之后 gdb 去 attach 子进程，我们可以在程序运行之前在 gdb 中设置 set follow-fork child ，然后使用 run 命令重新运行程序。
#+begin_src bash
(gdb) set follow-fork child
(gdb) run
The program being debugged has been started already.
Start it from the beginning? (y or n) y
Starting program: /usr/local/nginx/sbin/nginx -c
/usr/local/nginx/conf/nginx.conf
[Thread debugging using libthread_db enabled]
Using host libthread_db library "/lib64/libthread_db.so.1".
[Attaching after Thread 0x7ffff7fe7740 (LWP 7664) fork to child process 7667]
[New inferior 2 (process 7667)]
[Detaching after fork from parent process 7664]
[Inferior 1 (process 7664) detached]
[Thread debugging using libthread_db enabled]
Using host libthread_db library "/lib64/libthread_db.so.1".
^C
Thread 2.1 "nginx" received signal SIGINT, Interrupt.
[Switching to Thread 0x7ffff7fe7740 (LWP 7667)]
0x00007ffff703842b in epoll_wait () from /lib64/libc.so.6
(gdb) bt
#0 0x00007ffff703842b in epoll_wait () from /lib64/libc.so.6
#1 0x000000000044e546 in ngx_epoll_process_events (cycle=0x71f720,
timer=18446744073709551615, flags=1) at src/event/modules/ngx_epoll_module.c:800
#2 0x000000000043f317 in ngx_process_events_and_timers (cycle=0x71f720) at
src/event/ngx_event.c:247
#3 0x000000000044c38f in ngx_worker_process_cycle (cycle=0x71f720, data=0x0) at
src/os/unix/ngx_process_cycle.c:750
#4 0x000000000044926f in ngx_spawn_process (cycle=0x71f720, proc=0x44c2e1
<ngx_worker_process_cycle>, data=0x0, name=0x4cfd70 "worker process",
respawn=-3)
at src/os/unix/ngx_process.c:199
#5 0x000000000044b5a4 in ngx_start_worker_processes (cycle=0x71f720, n=1,
type=-3) at src/os/unix/ngx_process_cycle.c:359
#6 0x000000000044acf4 in ngx_master_process_cycle (cycle=0x71f720) at
src/os/unix/ngx_process_cycle.c:131
#7 0x000000000040bc05 in main (argc=3, argv=0x7fffffffe4e8) at
src/core/nginx.c:382
(gdb)
#+END_SRC
我们接着按 Ctrl +C 将程序中断下来，然后使用 bt 命令查看当前线程调用堆栈确实是我们在方法一中子进程的主线程所在的调用堆栈，这说明 gdb 确实 attach 到子进程了。

我们可以利用方法二调试程序 fork 之前和之后的任何逻辑，是一种较为通用的多进程调试方法。

** 明明函数存在，添加断点时却无效的解决方案
有时候，一个函数明明存在，并且我们的程序也存在调试符号，我们使用 break functionName 添加断点时，gdb 却提示：
#+begin_src bash
Make breakpoint pending on future shared library load? y/n
#+END_SRC
即使我们输入 y，添加的断点可能也不会被正确的触发。此时我们就需要改变添加断点的策略，使用该函数所在的代码文件和行号这种方式添加断点就能添加同样效果的断点。

** 自定义gdb调试命令
有些场景下，我们需要根据自己的程序情况，自定义一些可以在调试时输出我们程序特定信息的命令。
这个在 gdb 中很容易做到，只要在 Linux 用户根目录下，root 用户就是 /root 目录，非 root 用户，是/home/用户名 这个目录。
在上述目录中自定义一个 .gdbinit 文件即可，注意在 linux 系统中这是一个隐藏文件，可以使用 ls -a 命令查看；如果不存在，创建一个就可以。
然后在这个文件中写上你自定义命令的 shell 脚本就可以。

这里以 apache web 服务器的源码为例（apache server的源码下载地址：http://httpd.apache.org/），在源码根目录下有个文件叫 .gdbinit，这个就是 apache server 自定义的 gdb 命令：
#+begin_src bash
# gdb macros which may be useful for folks using gdb to debug
# apache. Delete it if it bothers you.
define dump_table
    set $t = (apr_table_entry_t *)((apr_array_header_t *)$arg0)->elts
    set $n = ((apr_array_header_t *)$arg0)->nelts
    set $i = 0
    while $i < $n
    if $t[$i].val == (void *)0L
        printf "[%u] '%s'=>NULL\n", $i, $t[$i].key
    else
        printf "[%u] '%s'='%s' [%p]\n", $i, $t[$i].key, $t[$i].val, $t[$i].val
    end
        set $i = $i + 1
    end
end
# 省略部分代码
# Set sane defaults for common signals:
handle SIGPIPE noprint pass nostop
handle SIGUSR1 print pass nostop
#+END_SRC
当然在这个文件的最底部，apache 的配置了让 gdb 调试器不要处理 SIGPIPE 和 SIGUSR1 这两个信号，而是将这两个信号直接传递给被调试的程序本身（这里就是 apache server）。
** apropos
apropos regexp命令查找所有符合regexp正则表达式的命令信息：
#+begin_src bash
(gdb) apropos set
awatch -- Set a watchpoint for an expression
b -- Set breakpoint at specified line or function
br -- Set breakpoint at specified line or function
bre -- Set breakpoint at specified line or function
brea -- Set breakpoint at specified line or function
......
#+END_SRC
** dir
你可能会遇到这样的场景：
我们在使用 gdb调试时由于生成可执行文件的机器和实际执行该可执行程序的机器不是同一台机器，
例如大多数企业产生目标服务程序的机器是编译机器，即发版机，然后把发版机产生的可执行程序拿到生产机器上去执行。
这个时候，如果可执行程序产生了崩溃，我们用 gdb 调试 core 文件时，gdb 会提示"No such file or directory"，如下所示：
#+begin_src bash
Program received signal SIGSEGV, Segmentation fault.
0x00000000004d5662 in CAsyncLog::crash () at
/home/flamingoserver/base/AsyncLog.cpp:475
475 /home/flamingoserver/base/AsyncLog.cpp: No such file or directory.
#+END_SRC
或者由于一些原因，编译时的源码文件被挪动了位置，使用 gdb 调试时也会出现上述情况。

gcc/g++ 编译出来的可执行程序并不包含完整源码，-g 只是加了一个可执行程序与源码之间的位置映射关系，
我们可以通过 dir 命令重新定位这种关系。

dir 命令使用格式：
#+begin_src bash
# 加一个源文件路径到当前路径的前面,指定多个路径，可以使用”:”
dir SourcePath1:SourcePath2:SourcePath3
#+END_SRC
SourcePath1、SourcePath2、SourcePath3 指的就是需要设置的源码目录，gdb 会依次去这些目录搜索相应的原文件。
以上面的错误提示为例，原来的 AsyncLog.cpp 文件位于 /home/flamingoserver/base/ 目录，由于这个目录被挪动了，所以 gdb 提示找不到该文件。
现在假设这个文件被移动到/home/zhangyl/flamingoserver/base/ 目录。
那么我们只需要在 gdb 调试中执行 dir /home/zhangyl/flamingoserver/base/ 即可重定向可执行程序与源码的位置关系：
#+begin_src bash
(gdb) dir /home/zhangyl/flamingoserver/base/
Source directories searched: /home/zhangyl/flamingoserver/base:$cdir:$cwd
(gdb) r
The program being debugged has been started already.
Start it from the beginning? (y or n) y
Starting program: /home/zhangyl/chatserver
warning: Loadable section ".note.gnu.property" outside of ELF segments
warning: Loadable section ".note.gnu.property" outside of ELF segments
warning: Loadable section ".note.gnu.property" outside of ELF segments
[Thread debugging using libthread_db enabled]
Using host libthread_db library "/lib64/libthread_db.so.1".
warning: Loadable section ".note.gnu.property" outside of ELF segments
warning: Loadable section ".note.gnu.property" outside of ELF segments
[FATAL][[2020-07-05 16:31:17:375]][140737354028864]
[/home/flamingoserver/chatserversrc/main.cpp:97]logdir is not set in config file
Program received signal SIGSEGV, Segmentation fault.
0x00000000004d5662 in CAsyncLog::crash () at
/home/flamingoserver/base/AsyncLog.cpp:475
475 *p = 0;
(gdb) list
470 }
471
472 void CAsyncLog::crash()
473 {
474 char* p = nullptr;
475 *p = 0;
476 }
477
478 void CAsyncLog::writeThreadProc()
479 {
(gdb)
#+END_SRC
使用 dir 命令重新定位源文件的位置之后 gdb就不再提示这样的错误了，此时我们也可以使用使用 gdb 其他命令（如 list 命令）查看源码了。
如果要查看当前设置了哪些源码搜索路径，可以使用 show dir 命令：
#+begin_src bash
(gdb) show dir
Source directories searched: /home/zhangyl/flamingoserver/base:$cdir:$cwd
(gdb)
#+END_SRC
dir 命令不加参数表示清空当前已设置的源码搜索目录：
#+begin_src bash
(gdb) dir
Reinitialize source path to empty? (y or n) y
Source directories searched: $cdir:$cwd
(gdb) show dir
Source directories searched: $cdir:$cwd
(gdb)
#+END_SRC

** disassemble 命令
在一些高级调试时，我们可能要查看某段代码的汇编指令去排查问题，或者是在调试一些没有调试信息的发布版程序时，也只能通过反汇编代码去定位问题，那么 disassemble 命令就派上用场了。

disassemble 会输出当前所在函数的汇编指令，假设我们现在在 redis 的 initServer() 中执行该命令会输出 initServer() 函数的汇编指令，操作如下：
#+begin_src bash
Breakpoint 1, initServer () at server.c:2742
2742 signal(SIGHUP, SIG_IGN);
(gdb) disassemble
Dump of assembler code for function initServer:
0x00000000004310cb <+0>: push %rbp
0x00000000004310cc <+1>: mov %rsp,%rbp
0x00000000004310cf <+4>: push %rbx
...太多了，省略...
0x0000000000431a93 <+2504>: add $0x18,%rsp
--Type <RET> for more, q to quit, c to continue without paging--
0x0000000000431a97 <+2508>: pop %rbx
0x0000000000431a98 <+2509>: pop %rbp
0x0000000000431a99 <+2510>: retq
End of assembler dump.
(gdb)
#+END_SRC
gdb 默认反汇编为 AT&T 格式的指令，可以通过 show disassembly-flavor 查看。
如果习惯 intel 汇编格式的，用命令 set disassembly-flavor intel 来设置。
#+begin_src bash
(gdb) set disassembly-flavor intel
(gdb) disassemble
Dump of assembler code for function initServer:
0x00000000004310cb <+0>: push rbp
0x00000000004310cc <+1>: mov rbp,rsp
0x00000000004310cf <+4>: push rbx
0x00000000004310d0 <+5>: sub rsp,0x18
...太多了，省略...
0x0000000000431a93 <+2504>: add rsp,0x18
--Type <RET> for more, q to quit, c to continue without paging--
0x0000000000431a97 <+2508>: pop rbx
0x0000000000431a98 <+2509>: pop rbp
0x0000000000431a99 <+2510>: ret
End of assembler dump.
(gdb)
#+END_SRC
这个命令在我们只有程序崩溃后产生 core 文件，且无对应的调试符号时非常有用，我们可以通过分析汇编代码定位一些错误。

** examine命令
examine命令缩写为x

用于显示内存内容或地址。

格式：
x/<n/f/u>  <addr>

n:是正整数，表示需要显示的内存单元的个数，即从当前地址向后显示n个内存单元的内容，
一个内存单元的大小由第三个参数u定义。

f:表示addr指向的内存内容的输出格式，s对应输出字符串，此处需特别注意输出整型数据的格式：
  x 按十六进制格式显示变量.
  d 按十进制格式显示变量。
  u 按十进制格式显示无符号整型。
  o 按八进制格式显示变量。
  t 按二进制格式显示变量。
  a 按十六进制格式显示变量。
  c 按字符格式显示变量。
  f 按浮点数格式显示变量。

u:就是指以多少个字节作为一个内存单元-unit,默认为4。u还可以用被一些字符表示:
  如b=1 byte, h=2 bytes,w=4 bytes,g=8 bytes.

<addr>:表示内存地址。

#+begin_src bash
>>> x/s argv
>>> x/d argv+6
>>> x/d argv+8
>>> x/2c $a1
#+END_SRC
** jump
jump 命令可以简写成 j.
jump 命令基本用法是：
#+begin_src bash
jump <location>
#+END_SRC
location 可以是程序的行号或者函数的地址，jump 会让程序执行流跳转到指定位置执行

如果 jump 跳转到的位置后续没有断点，那么 gdb 执行完跳转处的代码会继续执行。
举个例子：
#+BEGIN_EXAMPLE
int somefunc()
{
    //代码A
    //代码B
    //代码C
    //代码D
    //代码E
    //代码F
}
#+END_EXAMPLE
假设我们的断点初始位置在行号 3 处（代码 A），这个时候我们使用 jump 6，那么程序会跳过代码 B和 C 的执行，执行完代码 D（ 跳转点），程序并不会停在代码 6 处，而是继续执行后续代码，因此如果我们想查看执行跳转处的代码后的结果，需要在行号 6、7 或 8 处设置断点。

** layout的使用
layout用于分割窗口，可以一边查看代码，一边测试。主要有以下几种用法：
- layout src：显示源代码窗口
- layout asm：显示汇编窗口
- layout regs：显示源代码/汇编和寄存器窗口
- layout split：显示源代码和汇编窗口
- layout next：显示下一个layout
- layout prev：显示上一个layout
- Ctrl + L：刷新窗口
- Ctrl + x，再按1：单窗口模式，显示一个窗口
- Ctrl + x，再按2：双窗口模式，显示两个窗口
- Ctrl + x，再按a：回到传统模式，即退出layout，回到执行layout之前的调试窗口。

** list命令
list 命令可以查看当前断点附近的代码，可以简写成 l。

第一次输入 list 命令，会显示断点处前后的代码，继续输入 list指令会以递增行号的形式继续显示剩下的代码行，一直到文件结束为止。 
list 指令可以往前和往后显示代码，命令分别是 list + (即 list+加号 )和 list - (即 list+减号 )。
** print、ptype、display
*** print
打印变量或者表达式的值，也可以用于修改变量的值，print 命令可以缩写为 p

#+begin_src bash
p *argv    # 打印数组argv首个元素
p *argv@2  # 打印数组前两个元素
p *argv@argc  # 打印数组所有元素
#+END_SRC
print 命令不仅可以输出变量值，也可以输出特定表达式计算结果值，甚至可以输出一些函数的执行结果值。

举个例子，我们可以输入 p &server.port 来输出 server.port 的地址。
如果在 C++ 对象中，我们可以通过 p this 来显示当前对象的地址，也可以通过 p *this 来列出当前对象的各个成员变量值，
如果有三个变量可以相加（假设变量名分别叫 a、b、c），我们可以使用 p a+b+c 来打印这三个变量的结果值。

假设 func() 是一个可以执行的函数，p func() 命令可以输出该变量的执行结果。
我举一个最常用的例子，某个时刻，某个系统函数执行失败了，通过系统变量 errno 得到一个错误码，我们可以使用 p strerror(errno) 将这个错误码对应的文字信息打印出来，这样我们就不用费劲地去 man 手册上查找这个错误码对应的错误含义了。

print 命令不仅可以输出表达式结果，同时也可以修改变量的值：
#+begin_src bash
(gdb) p server.port=6400
$4 = 6400
(gdb) p server.port
$5 = 6400
(gdb)
#+END_SRC
**** 指定输出格式
print 输出变量值时可以指定输出格式，命令使用格式如下：
#+BEGIN_EXAMPLE
print /format variable
#+END_EXAMPLE
format常用的取值有：
#+BEGIN_EXAMPLE
o octal 八进制显示
x hex 十六进制显示
d decimal 十进制显示
u unsigned decimal 无符号十进制显示
t binary 二进制显示
f float 浮点值显示
a address 内存地址格式显示(与十六进制相似)
i instruction 指令格式显示
s string 字符串形式显示
z hex, zero padded on the left 十六进制左侧补0显示
#+END_EXAMPLE
完整的格式和用法读者可以在 gdb 中输入 help x 来查看。
演示如下：
#+begin_src bash
(gdb) p /x server.port
$6 = 0x1900
(gdb) p /s server.port
$7 = 6400
(gdb) p /o server.port
$8 = 014400
(gdb) p /i server.port
Format letter "i" is meaningless in "print" command.
(gdb) p /t server.port
$9 = 1100100000000
(gdb) p /f server.port
$10 = 8.96831017e-42
(gdb) p /t server.port
$11 = 1100100000000
(gdb) p /a server.port
$12 = 0x1900
(gdb)
#+END_SRC
**** 将 print 显示的字符串或字符数组显示完整
当我们使用 print 命令打印一个字符串或者字符数组时，如果该字符串太长，print 命令默认显示不全的，我们可以通过在 gdb 中输入 set print element 0 设置一下，这样再次使用 print 命令就能完整地显示该变量所有字符串了。

#+begin_src bash
void ChatSession::OnGetFriendListResponse(const std::shared_ptr<TcpConnection>&
conn)
{
    std::string friendlist;
    MakeUpFriendListInfo(friendlist, conn);
    std::ostringstream os;
    os << "{\"code\": 0, \"msg\": \"ok\", \"userinfo\":" << friendlist << "}";
    Send(msg_type_getofriendlist, m_seq, os.str());
    LOG_INFO << "Response to client: userid=" << m_userinfo.userid << ",
    cmd=msg_type_getofriendlist, data=" << os.str();
}
#+END_SRC
以上代码，当我们第一次用打印 friendlist 这个变量值时，只能显示部分字符串。当使用 set print element 0 设置以后就能完整地显示出来了。
#+begin_src bash
(gdb) n
563 os << "{\"code\": 0, \"msg\": \"ok\", \"userinfo\":" << friendlist
<< "}";
(gdb) p friendlist
$1 = "[{\"members\":
[{\"address\":\"\",\"birthday\":19900101,\"clienttype\":0,\"customface\":\"\",\"
facetype\":2,\"gender\":0,\"mail\":\"\",\"markname\":\"\",\"nickname\":\"bj_man\
",\"phonenumber\":\"\",\"signature\":\"\",\"status\":0,\"userid\":4,"...
(gdb) set print element 0
(gdb) p friendlist
$2 = "[{\"members\":
[{\"address\":\"\",\"birthday\":19900101,\"clienttype\":0,\"customface\":\"\",\"
facetype\":2,\"gender\":0,\"mail\":\"\",\"markname\":\"\",\"nickname\":\"bj_man\
",\"phonenumber\":\"\",\"signature\":\"\",\"status\":0,\"userid\":4,\"username\"
:\"13811411052\"},
{\"address\":\"\",\"birthday\":19900101,\"clienttype\":0,\"customface\":\"\",\"f
acetype\":0,\"gender\":0,\"mail\":\"\",\"markname\":\"\",\"nickname\":\"Half\",\
"phonenumber\":\"\",\"signature\":\"\",\"status\":0,\"userid\":5,\"username\":\"
15618326596\"},
{\"address\":\"\",\"birthday\":19900101,\"clienttype\":0,\"customface\":\"\",\"f
acetype\":34,\"gender\":0,\"mail\":\"\",\"markname\":\"\",\"nickname\":\"云淡风轻
\",\"phonenumber\":\"\",\"signature\":\"\",\"status\":0,\"userid\":7,\"username\
":\"china001\"},{\"address\":\"上海市浦东新区南泉路1200号409室
\",\"birthday\":20170914,\"clienttype\":0,\"customface\":\"\",\"facetype\":5,\"g
ender\":0,\"mail\":\"balloonwj@qq.com\",\"markname\":\"\",\"nickname\":\"qqq123\
",\"phonenumber\":\"\",\"signature\":\"{“id”：
12}\",\"status\":0,\"userid\":10,\"username\":\"qqq\"},
{\"address\":\"\",\"birthday\":19900101,\"clienttype\":0,\"customface\":\"be1957
4dcdd11fb9a96cf00f7e5f0e66\",\"facetype\":0,\"gender\":0,\"mail\":\"\",\"marknam
e\":\"\",\"nickname\":\"TzdnerC\",\"phonenumber\":\"\",\"signature\":\"\",\"stat
us\":0,\"userid\":15,\"username\":\"TzdnerC\"},
{\"address\":\"\",\"birthday\":19900101,\"clienttype\":0,\"customface\":\"\",\"f
acetype\":0,\"gender\":0,\"mail\":\"\",\"markname\":\"\",\"nickname\":\"Barry\",
\"phonenumber\":\"\",\"signature\":\"\",\"status\":0,\"userid\":16,\"username\":
\"17091203068\"},{\"address\":\"\",\"birthday\":19900101,\"clienttype\":0...太长了，这里省略...
#+END_SRC

*** ptype
gdb 还有另外一个命令叫 ptype，顾名思义，其含义是 “print type”，就是输出一个变量的类型。
#+begin_src bash
(gdb) ptype server
type = struct redisServer {
pid_t pid;
char *configfile;
char *executable;
char **exec_argv;
int dynamic_hz;
int config_hz;
...省略部分字段...
(gdb) ptype server.port
type = int
#+END_SRC
可以看到，对于一个复合数据类型的变量，ptype 不仅列出了这个变量的类型（这里是一个名叫redisServer 的结构体），而且详细地列出了每个成员变量的字段名，有了这个功能，在调试时我们不必去代码文件中翻看某个变量的类型定义。

*** display
使用 display 命令查看变量或表达式的值，每当程序暂停执行（例如单步执行）时，GDB 调试器都会自动帮我们打印出来，而 print 命令则不会。

display 命令没有缩写形式，常用的语法格式如下 2 种：
#+begin_src bash
(gdb) display expr
(gdb) display/fmt expr
#+END_SRC
其中，expr 表示要查看的目标变量或表达式；参数 fmt 用于指定输出变量或表达式的格式，下表罗列了常用的一些 fmt 参数。
| /fmt | 功 能                                |
|------+--------------------------------------|
| /x   | 以十六进制的形式打印出整数。         |
| /d   | 以有符号、十进制的形式打印出整数。   |
| /u   | 以无符号、十进制的形式打印出整数。   |
| /o   | 以八进制的形式打印出整数。           |
| /t   | 以二进制的形式打印出整数。           |
| /f   | 以浮点数的形式打印变量或表达式的值。 |
| /c   | 以字符形式打印变量或表达式的值。     |

注意，display 命令和 /fmt 之间不要留有空格。以 /x 为例，应写为 (gdb)display/x expr。

可以使用 infodisplay 查看当前已经自动添加了哪些值，
使用 delete display 清除全部需要自动输出的变量，
使用delete diaplay 编号 删除某个自动输出的变量。
#+begin_src bash
(gdb) delete display
Delete all auto-display expressions? (y or n) n
(gdb) delete display 3
(gdb) info display
Auto-display expressions now in effect:
Num Enb Expression
2: y $ebp
1: y $eax
#+END_SRC
*** undisplay：取消追踪观察变量
*** 参考文章
[[http://c.biancheng.net/view/8238.html][GDB print和display命令：查看变量的值]]
** si,ni,s,n的区别
n/s都是C语言级的断点定位。 s会进入C函数内部,但是不会进入没有定位信息的函数（比如没有加-g编译的代码，因为其没有C代码的行数标记，没办法定位），n不会。

ni/si都是汇编级别的断点定位。si会进入汇编和C函数内部,ni不会。


归纳:当要进入没有调试信息的库函数调试的时候，用si是唯一的方法。

当进入有调试信息的函数，用si和s都可以，但是他们不同，si是定位到汇编级别的第一个语句，但是s是进入到C级别的第一个语句

*** 函数调用方式
当函数的参数也是函数调用时，这个时候，我们使用 step 命令会依次进入各个函数，那么顺序是什么呢？举个例子，看下面这段代码：
#+BEGIN_SRC c
int func1(int a, int b)
{
    int c = a + b;
    c += 2;
    return c;
}
int func2(int p, int q)
{
    int t = q * p;
    return t * t;
}
int func3(int m, int n)
{
    return m + n;
}
int main()
{
    int c;
    c = func3(func1(1, 2), func2(8, 9));
    printf("c=%d.\n", c);
    return 0;
}
#+END_SRC
函数调用方式，我们常用的函数调用方式有 __cdecl、__stdcall，C++ 的非静态成员函数的调用方式是__thiscall，
这些调用方式，函数参数的传递本质上是函数参数的入栈的过程，而这三种调用方式参数的入栈顺序都是从右往左的，所以，这段代码中并没有显式标明函数的调用方式，所以采用默认__cdecl 方式。
当我们在 22 行代码处，输入 step 先进入的是 func2()，当从 func2() 返回时再次输入step 命令会接着进入 func1()，当从 func1返回时，此时两个参数已经计算出来了，这时候会最终进入 func3()。
** strip
Linux 的 strip 命令移除掉某个程序中的调试信
息，我们这里对 hello_server 使用 strip 命令试试：
#+BEGIN_SRC bash
[root@localhost testclient]# gcc -g -o hello_server hello_server.c
##生成一个带调试信息的程序hello_server。
[root@localhost testclient]# strip hello_server
##使用strip命令之前
-rwxr-xr-x. 1 root root 12416 Sep 8 09:45 hello_server
##使用strip命令之后
-rwxr-xr-x. 1 root root 6312 Sep 8 09:55 hello_server
#+END_SRC
可以发现，我们对 hello_server 使用 strip 命令之后，这个程序大小明显变小了（由 12416 个字节减
小为 6312 个字节）。我们通常会在程序测试没问题后，需要发布到生产环境或者正式环境，会生成不
带调试符号信息的程序，以减小程序体积或提高程序执行效率。

我们再用 gdb 验证一下这个程序的调试信息是否确实被移除了
#+begin_src bash
[root@localhost testclient]# gdb hello_server
GNU gdb (GDB) Red Hat Enterprise Linux 7.6.1-100.el7_4.1
Copyright (C) 2013 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law. Type "show copying"
and "show warranty" for details.
This GDB was configured as "x86_64-redhat-linux-gnu".
For bug reporting instructions, please see:
<http://www.gnu.org/software/gdb/bugs/>...
Reading symbols from /root/testclient/hello_server...(no debugging symbols
found)...done.
(gdb)
#+END_SRC
** thread
*** info查看线程信息
info threads 来查看进程当前所有线程信息和这些线程分别中断在何处。

#+DOWNLOADED: screenshot @ 2022-08-03 16:40:31
[[file:images/linux笔记/gdb/2022-08-03_16-40-31_screenshot.png]]
这里一共4个线程，其中一个主线程，三个工作线程，线程编号（Id 那一列）分别是 1、2、3、4。
注意：虽然第一栏的名称叫 Id，但第一栏的数值并不是线程的 Id，第三栏有个括号，内容如( LWP 747)，这个 747 这样的数值才是当前线程真正的线程 Id。
那 LWP 是什么意思呢？在早期的 Linux 系统的内核里面，其实不存在真正的线程实现，当时所有的线程都是用进程来实现的，这些模拟线程的进程被称为 Light WeightProcess（轻量级进程），后来新的 Linux 系统版本有了真正的线程实现，这个名字也被保留下来至今。

线程编号前面这个星号表示的是当前 gdb 的作用于哪个线程，而不是说标了星号就是主线程。
现在有 4 个线程，也就有 4 个调用堆栈，如果我们此时，查看输入 backtrace 命令查看调用堆栈，由于当前 gdb 作用在线程 1，所以 backtrace 命令显示的一定是线程 1 的调用堆栈：
*** 线程
我们可以通过 thread 线程编号 去切换到具体的线程上去。
例如，我们想切换到线程 2 上去，我们只要输入 thread 2 即可，然后输入 bt 就能查看这个线程的调用堆栈了：
#+BEGIN_EXAMPLE
(gdb) thread 2
[Switching to thread 2 (Thread 0x7ffff0bb9700 (LWP 5030))]
#0 0x00007ffff74bc965 in pthread_cond_wait@@GLIBC_2.3.2 () from
/usr/lib64/libpthread.so.0
(gdb) bt
#0 0x00007ffff74bc965 in pthread_cond_wait@@GLIBC_2.3.2 () from
/usr/lib64/libpthread.so.0
#1 0x00000000004991c0 in bioProcessBackgroundJobs (arg=0x0) at bio.c:190
#2 0x00007ffff74b8dd5 in start_thread () from /usr/lib64/libpthread.so.0
#3 0x00007ffff71e202d in clone () from /usr/lib64/libc.so.6
(gdb)
#+END_EXAMPLE
*** scheduler-locking
针对调试多线程存在的上述状况，gdb提供了一个在调试时将程序执行流锁定在当前调试线程的命令选项——scheduler-locking 选项，这个选项有三个值，分别是 on、step 和 off，使用方法如下：
#+begin_src bash
set scheduler-locking on/step/off
#+END_SRC
set scheduler-locking on 可以用来锁定当前线程，只观察这个线程的运行情况， 当锁定这个线程时， 其他线程就处于了暂停状态，也就是说你在当前线程执行 next、step、until、finish、return 命令时，其他线程是不会运行的。

#+BEGIN_EXAMPLE
需要注意的是，你在使用 set scheduler-locking on/step 选项时要确认下当前线程是否是你期望锁定的线程，如果不是，可以使用 thread + 线程编号 切换到你需要的线程再调用 set scheduler-locking on/step 进行锁定。
#+END_EXAMPLE
set scheduler-locking step 也是用来锁定当前线程，当且仅当使用 next 或 step 命令做单步调试时会锁定当前线程，如果你使用 until、finish、return 等线程内调试命令，但是它们不是单步命令，所以其他线程还是有机会运行的。
相比较 on 选项值，step 选项值给为单步调试提供了更加精细化的控制，因为通常我们只希望在单步调试时，不希望其他线程对当前调试的各个变量值造成影响。

set scheduler-locking off 用于关闭锁定当前线程。

**** 实例
我们以一个小的示例来说明这三个选项的使用吧。编写如下代码：
#+BEGIN_SRC c++
#include <stdio.h>
#include <pthread.h>
#include <unistd.h>
long g = 0;
void* worker_thread_1(void* p)
{
    while (true)
    {
        g = 100;
        printf("worker_thread_1\n");
        usleep(300000);
    }
    return NULL;
}
void* worker_thread_2(void* p)
{
    while (true)
    {
        g = -100;
        printf("worker_thread_2\n");
        usleep(500000);
    }
    return NULL;
}
int main()
{
    pthread_t thread_id_1;
    pthread_create(&thread_id_1, NULL, worker_thread_1, NULL);
    pthread_t thread_id_2;
    pthread_create(&thread_id_2, NULL, worker_thread_2, NULL);
    while (true)
    {
        g = -1;
        printf("g=%d\n", g);
        g = -2;
        printf("g=%d\n", g);
        g = -3;
        printf("g=%d\n", g);
        g = -4;
        printf("g=%d\n", g);
        usleep(1000000);
    }
    return 0;
}
#+END_SRC
上述代码在主线程（main 函数所在的线程）中创建了了两个工作线程，
主线程接下来的逻辑是在一个循环里面依次将全局变量 g 修改成 -1、-2、-3、-4，然后休眠 1 秒；
工作线程 worker_thread_1、worker_thread_2 在分别在自己的循环里面将全局变量 g 修改成 100 和 -100。

我们编译程序后将程序使用 gdb 跑起来，三个线程同时运行，交错输出：
#+begin_src bash
[root@myaliyun xx]# g++ -g -o main main.cpp -lpthread
[root@myaliyun xx]# gdb main
...省略部分无关输出...
Reading symbols from main...
(gdb) r
Starting program: /root/xx/main
[Thread debugging using libthread_db enabled]
...省略部分无关输出...
[New Thread 0x7ffff6f56700 (LWP 402)]
worker_thread_1
[New Thread 0x7ffff6755700 (LWP 403)]
g=-1
g=-2
g=-3
g=-4
worker_thread_2
worker_thread_1
worker_thread_2
worker_thread_1
worker_thread_1
g=-1
g=-2
g=-3
g=-4
worker_thread_2
worker_thread_1
worker_thread_1
worker_thread_2
worker_thread_1
g=-1
g=-2
g=-3
g=-4
worker_thread_2
worker_thread_1
worker_thread_1
worker_thread_2
#+END_SRC
我们按 Ctrl + C 将程序中断下来，如果当前线程不在主线程，可以先使用 info threads 和 threadid 切换到主线程：
#+begin_src bash
^C
Thread 1 "main" received signal SIGINT, Interrupt.
0x00007ffff701bfad in nanosleep () from /usr/lib64/libc.so.6
(gdb) info threads
Id Target Id Frame
\* 1 Thread 0x7ffff7feb740 (LWP 1191) "main" 0x00007ffff701bfad in nanosleep
() from /usr/lib64/libc.so.6
2 Thread 0x7ffff6f56700 (LWP 1195) "main" 0x00007ffff701bfad in nanosleep
() from /usr/lib64/libc.so.6
3 Thread 0x7ffff6755700 (LWP 1196) "main" 0x00007ffff701bfad in nanosleep
() from /usr/lib64/libc.so.6
(gdb) thread 1
[Switching to thread 1 (Thread 0x7ffff7feb740 (LWP 1191))]
#0 0x00007ffff701bfad in nanosleep () from /usr/lib64/libc.so.6
(gdb)
#+END_SRC
然后在代码 11 行和 41 行各加一个断点。我们反复执行 until 48 命令，发现工作线程 1 和 2 还是有机会被执行的。
#+begin_src bash
(gdb) b main.cpp:41
Breakpoint 1 at 0x401205: file main.cpp, line 41.
(gdb) b main.cpp:11
Breakpoint 2 at 0x40116e: file main.cpp, line 11.
(gdb) until 48
0x00007ffff704c884 in usleep () from /usr/lib64/libc.so.6
(gdb)
worker_thread_2
[Switching to Thread 0x7ffff6f56700 (LWP 1195)]
Thread 2 "main" hit Breakpoint 2, worker_thread_1 (p=0x0) at main.cpp:11
11 g = 100;
(gdb)
worker_thread_2
[Switching to Thread 0x7ffff7feb740 (LWP 1191)]
Thread 1 "main" hit Breakpoint 1, main () at main.cpp:41
41 printf("g=%d\n", g);
(gdb)
worker_thread_1
worker_thread_2
g=-1
g=-2
g=-3
g=-4
main () at main.cpp:49
49 usleep(1000000);
(gdb)
worker_thread_2
[Switching to Thread 0x7ffff6f56700 (LWP 1195)]
Thread 2 "main" hit Breakpoint 2, worker_thread_1 (p=0x0) at main.cpp:11
11 g = 100;
(gdb)
#+END_SRC
现在我们再次将线程切换到主线程（如果 gdb 中断后当前线程不是主线程的话），执行 set scheduler-locking on 命令，然后继续反复执行 until 48 命令。
#+begin_src bash
(gdb) set scheduler-locking on
(gdb) until 48
Thread 1 "main" hit Breakpoint 1, main () at main.cpp:41
41 printf("g=%d\n", g);
(gdb) until 48
g=-1
g=-2
g=-3
g=-4
main () at main.cpp:49
49 usleep(1000000);
(gdb) until 48
Thread 1 "main" hit Breakpoint 1, main () at main.cpp:41
41 printf("g=%d\n", g);
(gdb)
g=-1
g=-2
g=-3
g=-4
main () at main.cpp:49
49 usleep(1000000);
(gdb) until 48
Thread 1 "main" hit Breakpoint 1, main () at main.cpp:41
41 printf("g=%d\n", g);
(gdb)
g=-1
g=-2
g=-3
g=-4
main () at main.cpp:49
49 usleep(1000000);
(gdb) until 48
Thread 1 "main" hit Breakpoint 1, main () at main.cpp:41
41 printf("g=%d\n", g);
(gdb)
#+END_SRC
我们再次使用 until 命令时，gdb 锁定了主线程，其他两个工作线程再也不会被执行了，因此两个工作线程无任何输出。

我们再使用 set scheduler-locking step 模式再来锁定一下主线程，然后再次反复执行 until 48命令。
#+begin_src bash
(gdb) set scheduler-locking step
(gdb) until 48
worker_thread_2
worker_thread_1
g=-100
g=-2
g=-3
g=-4
main () at main.cpp:49
49 usleep(1000000);
(gdb) until 48
worker_thread_2
[Switching to Thread 0x7ffff6f56700 (LWP 1195)]
Thread 2 "main" hit Breakpoint 2, worker_thread_1 (p=0x0) at main.cpp:11
11 g = 100;
(gdb) until 48
worker_thread_2
worker_thread_1
Thread 2 "main" hit Breakpoint 2, worker_thread_1 (p=0x0) at main.cpp:11
11 g = 100;
(gdb) until 48
worker_thread_2
[Switching to Thread 0x7ffff7feb740 (LWP 1191)]
Thread 1 "main" hit Breakpoint 1, main () at main.cpp:41
41 printf("g=%d\n", g);
(gdb) until 48
worker_thread_1
worker_thread_2
g=-100
g=-2
g=-3
g=-4
main () at main.cpp:49
49 usleep(1000000);
(gdb) until 48
worker_thread_2
[Switching to Thread 0x7ffff6f56700 (LWP 1195)]
Thread 2 "main" hit Breakpoint 2, worker_thread_1 (p=0x0) at main.cpp:11
11 g = 100;
(gdb) until 48
worker_thread_2
worker_thread_1
Thread 2 "main" hit Breakpoint 2, worker_thread_1 (p=0x0) at main.cpp:11
11 g = 100;
(gdb)
#+END_SRC
可以看到使用 step 模式锁定的主线程，在使用 until 命令时另外两个工作线程仍然有执行的机会。
我们再次切换到主线程，然后使用 next 命令单步调试下试试。
#+begin_src bash
(gdb) info threads
Id Target Id Frame
1 Thread 0x7ffff7feb740 (LWP 1191) "main" 0x00007ffff701bfad in nanosleep
() from /usr/lib64/libc.so.6
\* 2 Thread 0x7ffff6f56700 (LWP 1195) "main" worker_thread_1 (p=0x0) at
main.cpp:11
 3 Thread 0x7ffff6755700 (LWP 1196) "main" 0x00007ffff701bfad in nanosleep
() from /usr/lib64/libc.so.6
(gdb) thread 1
[Switching to thread 1 (Thread 0x7ffff7feb740 (LWP 1191))]
#0 0x00007ffff701bfad in nanosleep () from /usr/lib64/libc.so.6
(gdb) set scheduler-locking step
(gdb) next
Single stepping until exit from function nanosleep,
which has no line number information.
0x00007ffff704c884 in usleep () from /usr/lib64/libc.so.6
(gdb) next
Single stepping until exit from function usleep,
which has no line number information.
main () at main.cpp:40
40 g = -1;
(gdb) next
Thread 1 "main" hit Breakpoint 1, main () at main.cpp:41
41 printf("g=%d\n", g);
(gdb) next
g=-1
42 g = -2;
(gdb) next
43 printf("g=%d\n", g);
(gdb) next
g=-2
44 g = -3;
(gdb) next
45 printf("g=%d\n", g);
(gdb) next
g=-3
46 g = -4;
(gdb) next
47 printf("g=%d\n", g);
(gdb) next
g=-4
49 usleep(1000000);
(gdb) next
40 g = -1;
(gdb) next
Thread 1 "main" hit Breakpoint 1, main () at main.cpp:41
41 printf("g=%d\n", g);
(gdb) next
g=-1
42 g = -2;
(gdb) next
43 printf("g=%d\n", g);
(gdb) next
g=-2
44 g = -3;
(gdb) next
45 printf("g=%d\n", g);
(gdb) next
g=-3
46 g = -4;
(gdb) next
47 printf("g=%d\n", g);
(gdb) next
g=-4
49 usleep(1000000);
(gdb) next
40 g = -1;
(gdb) next
Thread 1 "main" hit Breakpoint 1, main () at main.cpp:41
41 printf("g=%d\n", g);
(gdb)
#+END_SRC
此时我们发现设置了以 step 模式锁定主线程，工作线程不会在单步调试主线程时被执行，即使在工作线程设置了断点。
最后我们使用 set scheduler-locking off 取消对主线程的锁定，然后继续使用 next 命令单步调试。
#+begin_src bash
(gdb) set scheduler-locking off
(gdb) next
worker_thread_2
worker_thread_1
g=-100
42 g = -2;
(gdb) next
worker_thread_2
[Switching to Thread 0x7ffff6f56700 (LWP 1195)]
Thread 2 "main" hit Breakpoint 2, worker_thread_1 (p=0x0) at main.cpp:11
11 g = 100;
(gdb) next
g=100
g=-3
g=-4
worker_thread_2
12 printf("worker_thread_1\n");
(gdb) next
worker_thread_1
13 usleep(300000);
(gdb) next
worker_thread_2
[Switching to Thread 0x7ffff7feb740 (LWP 1191)]
Thread 1 "main" hit Breakpoint 1, main () at main.cpp:41
41 printf("g=%d\n", g);
(gdb) next
[Switching to Thread 0x7ffff6f56700 (LWP 1195)]
Thread 2 "main" hit Breakpoint 2, worker_thread_1 (p=0x0) at main.cpp:11
11 g = 100;
(gdb) next
g=-1
g=-2
g=-3
g=-4
worker_thread_2
12 printf("worker_thread_1\n");
(gdb)
#+END_SRC
取消了锁定之后，单步调试时三个线程都有机会被执行，线程 1 的断点也会被正常触发。
至此，我们搞清楚了如何利用 set scheduler-locking 选项来方便我们调试多线程程序。
** tui界面
TUI（TextUser Interface）为GDB调试的文本用户界面，可以方便地显示源代码、汇编和寄存器文本窗口

Tui界面可以通过运行gdbtui或gdb-tui命令进入(其它变种gdb也一样，如arm-none-eabi-gdb-tui)，当然也可以进入gdb界面后使用TUI快捷键打开，如C-x C-a快捷键
*** TUI Overview
在TUI模式中，可以显示以下几个窗口：
- 命令窗口:
用于 GDB调试时的命令输入和命令结果输出显示，与普通 GDB窗口无异。
- 源代码窗口:
用于显示程序源代码，包括当前运行行、中断以中断标识等。
- 汇编窗口:
显示当前程序的汇编代码。
- 寄存器窗口:
显示处理器的寄存器内容，当寄存器内容发生改变时会高亮显示。

源代码窗口和汇编窗口会高亮显示程序运行位置并以'>'符号标记。有两个特殊标记用于标识断点，第一个标记用于标识断点类型：
- B:程序至少有一次运行到了该断点
- b:程序没有运行到过该断点
- H:程序至少有一次运行到了该硬件断点
- h:程序没有运行到过该硬件断点 

第二个标记用于标识断点使能与否:
- +:断点使能 Breakpointis enabled. 
- -:断点被禁用 Breakpointis disabled. 

在命令窗口上方有一行状态栏，显示效果如下图所示，主要显示内容有：
#+DOWNLOADED: screenshot @ 2022-05-06 16:28:13
[[file:images/linux笔记/gdb/2022-05-06_16-28-13_screenshot.png]]
- target:
Indicates the current GDB target. (see Specifying a Debugging Target).

- process
Gives the current process or thread number. When no process is being debugged, this field is set to No process.

- function
Gives the current function name for the selected frame. The name is demangled if demangling is turned on (see Print Settings). When there is no symbol corresponding to the current program counter, the string ?? is displayed.

- line
Indicates the current line number for the selected frame. When the current line number is not known, the string ?? is displayed.

- pc
Indicates the current program counter address.
*** TUI 快捷键
The following key bindings are installed for both TUI mode and the GDB standard mode.

C-x C-a 或
C-x a  或
C-x A (按住Ctrl+x后松开再按a，以下快捷键操作方式相同)
进入或退出 TUI模式。

C-x 1
使 TUI只显示一个窗口。 Usea TUI layout with only one window. The layout will either be`source' or `assembly'.When the TUI mode is not active, it will switch to the TUI mode.Think of this key binding as the Emacs C-x 1binding. 

C-x 2
使TUI显示两个窗口，连接使用此快捷键可在三种窗口组合(只能同时显示两个，共3种组合)中不断切换。
Usea TUI layout with at least two windows. When the current layoutalready has two windows, the next layout with two windows is used.When a new layout is chosen, one window will always be common to theprevious layout and the new one. Think of it as the Emacs C-x2 binding. 

C-x o
更换激活窗口
Changethe active window. The TUI associates several key bindings (likescrolling and arrow keys) with the active window. This command givesthe focus to the next TUI window. Think of it as the Emacs C-xo binding. 

C-x s
在 TUI模式和 TUISingleKey模式之间切换
Switchin and out of the TUI SingleKey mode that binds single keys to GDBcommands (see section 22.3TUI Single Key Mode). 

下列快捷键只在TUI模式才能有效：

PgUp
激活窗口的内容向上滚动一页 Scroll the active window one page up. 

PgDn
激活窗口的内容向下滚动一页 Scroll the active window one page down. 

Up
激活窗口的内容向上滚动一行 Scroll the active window one line up. 

Down
激动窗口的内容向下滚动一行 Scroll the active window one line down. 

Left
激活窗口的内容向左移动一列 Scroll the active window one column left. 

Right
激活窗口的内容向右移动一列 Scroll the active window one column right. 

C-L
更新屏幕 Refresh the screen. 

当源代码和汇编窗口同时显示时，以上快捷键会同步更新两个窗口的内容。

Becausethe arrow keys scroll the active window in the TUI mode, they are notavailable for their normal use by readline unless the command windowhas the focus. When another window is active, you must use otherreadline key bindings such as C-p, C-n,C-b and C-f to control the command window. 
*** TUI Single Key Mode
The TUI also provides a SingleKey mode, which binds several frequently used GDB commands to single keys. Type C-x s to switch into this mode, where the following key bindings are used:

c
continue

d
down

f
finish

n
next

o
nexti. The shortcut letter ‘o’ stands for “step Over”.

q
exit the SingleKey mode.

r
run

s
step

i
stepi. The shortcut letter ‘i’ stands for “step Into”.

u
up

v
info locals

w
where

Other keys temporarily switch to the GDB command prompt. The key that was pressed is inserted in the editing buffer so that it is possible to type most GDB commands without interaction with the TUI SingleKey mode. Once the command is entered the TUI SingleKey mode is restored. The only way to permanently leave this mode is by typing q or C-x s.

If GDB was built with Readline 8.0 or later, the TUI SingleKey keymap will be named ‘SingleKey’. This can be used in .inputrc to add additional bindings to this keymap.
*** TUI-specific Commands 
TheTUI has specific commands to control the text windows. These commandsare always available, even when GDB is not in the TUI mode. When GDBis in the standard mode, most of these commands will automaticallyswitch to the TUI mode. 当处理GDB标准模式时，下列的大多数命令会自动切换到TUI模式。

tui enable
Activate TUI mode. The last active TUI window layout will be used if TUI mode has previously been used in the current debugging session, otherwise a default layout is used.

tui disable
Disable TUI mode, returning to the console interpreter.

info win：显示正在显示的窗口大小信息
Listand give the size of all displayed windows. 、

tui new-layout name window weight [window weight…]
#+BEGIN_EXAMPLE
Create a new TUI layout. The new layout will be named name, and can be accessed using the layout command (see below).

Each window parameter is either the name of a window to display, or a window description. The windows will be displayed from top to bottom in the order listed.

The names of the windows are the same as the ones given to the focus command (see below); additional, the status window can be specified. Note that, because it is of fixed height, the weight assigned to the status window is of no importance. It is conventional to use ‘0’ here.

A window description looks a bit like an invocation of tui new-layout, and is of the form {[-horizontal]window weight [window weight…]}.

This specifies a sub-layout. If -horizontal is given, the windows in this description will be arranged side-by-side, rather than top-to-bottom.

Each weight is an integer. It is the weight of this window relative to all the other windows in the layout. These numbers are used to calculate how much of the screen is given to each window.

For example:

(gdb) tui new-layout example src 1 regs 1 status 0 cmd 1
Here, the new layout is called ‘example’. It shows the source and register windows, followed by the status window, and then finally the command window. The non-status windows all have the same weight, so the terminal will be split into three roughly equal sections.

Here is a more complex example, showing a horizontal layout:

(gdb) tui new-layout example {-horizontal src 1 asm 1} 2 status 0 cmd 1
This will result in side-by-side source and assembly windows; with the status and command window being beneath these, filling the entire width of the terminal. Because they have weight 2, the source and assembly windows will be twice the height of the command window.
#+END_EXAMPLE

layout next：显示下一个窗口
Displaythe next layout. 

layout prev：显示上一个窗口
Displaythe previous layout. 

layout src：显示源代码窗口
Displaythe source window only. 

layout asm：显示汇编窗口
Displaythe assembly window only. 

layout split：显示源代码和汇编窗口
Displaythe source and assembly window. 

layout regs：显示寄存器窗口
Displaythe register window together with the source or assembly window. 

focus next：将一个窗口置为激活状态
Make the next window active for scrolling. 

focus prev：将上一个窗口置为激活状态
Make the previous window active for scrolling. 

focus src：将源代码窗口置为激活状态
Make the source window active for scrolling. 

focus asm：将汇编窗口置为激活状态
Make the assembly window active for scrolling. 

focus regs：将寄存器窗口置为激活状态
Make the register window active for scrolling. 

focus cmd：将命令行窗口置为激活状态
Make the command window active for scrolling. 

refresh：更新窗口，与 C-L快捷键同
Refresh the screen. This is similar to typing C-L.

tui reg float：寄存器窗口显示内容为浮点寄存器
Showthe floating point registers in the register window. 

tui reg general：寄存器窗口显示内容为普通寄存器
Show the general registers in the register window. 

tui reg next：显示下一组寄存器
Show the next register group. The list of register groups as well astheir order is target specific. The predefined register groups are the following:

 general, float,system, vector,all, save,restore. 

tui reg system ：显示上一组寄存器
Show the system registers in the register window. 

update ：更新源代码窗口到当前运行点
Update the source window and the current execution point. 
当我们通过方向键调整了 gdbtui 的 src 窗口以后，可以通过 update 命令重新把焦点定位到当前执行的代码上。

winheight winname +count：增加指定窗口的高度 
winheight winname -count：减小指定窗口的高度
Change the height of the window name by count lines. Positive counts increase the height, while negative counts decrease it. The name parameter can be one of src (the source window), cmd (the command window), asm (the disassembly window), or regs (the register display window).
*** TUI Configuration Variables
Several configuration variables control the appearance of TUI windows.

set tui border-kind kind
Select the border appearance for the source, assembly and register windows. The possible values are the following:

space
Use a space character to draw the border.
当前 gdb tui窗口放大或者缩小以后，gdbtui 窗口中的内容不会自己刷新以适应新的窗口尺寸，我们可以通过 space 键强行刷新 gdbtui 窗口。

ascii
Use ASCII characters ‘+’, ‘-’ and ‘|’ to draw the border.

acs
Use the Alternate Character Set to draw the border. The border is drawn using character line graphics if the terminal supports them.

set tui border-mode mode
set tui active-border-mode mode
Select the display attributes for the borders of the inactive windows or the active window. The mode can be one of the following:

normal
Use normal attributes to display the border.

standout
Use standout mode.

reverse
Use reverse video mode.

half
Use half bright mode.

half-standout
Use half bright and standout mode.

bold
Use extra bright or bold mode.

bold-standout
Use extra bright or bold and standout mode.

set tui tab-width nchars
Set the width of tab stops to be nchars characters. This setting affects the display of TAB characters in the source and assembly windows.

set tui compact-source [on|off]
Set whether the TUI source window is displayed in “compact” form. The default display uses more space for line numbers and starts the source text at the next tab stop; the compact display uses only as much space as is needed for the line numbers in the current file, and only a single space to separate the line numbers from the source.

Note that the colors of the TUI borders can be controlled using the appropriate set style commands. See Output Styling.
*** 参考文章
[[https://sourceware.org/gdb/onlinedocs/gdb/TUI.html#TUI][25.GDB Text User Interface]]
[[https://blog.csdn.net/xu415/article/details/19021759][GDB调试之TUI界面 - CSDN博客]]
** until
until 的命令，简写成 u，我们使用使用这个命令指定程序运行到某一行停下来。
** watch
watch：被设置观察点的变量发生修改时，打印显示

监视某个变量或者某个内存地址会产生一个“watch point”（观察点）。

i watch：显示观察点

watch 命令的使用方式是 watch 变量名或内存地址，一个 watch pointwatch 一般有以下几种格式：
#+BEGIN_EXAMPLE
# 整型
int i;
watch i

# 指针
char *p;
watch p 与 watch *p

# watch一个数组或者内存空间
# 这里是对 buf 的 128 个数据进行了监视。
char buf[128];
watch buf
#+END_EXAMPLE
需要注意的是：当设置的观察点是一个局部变量时。局部变量无效后，观察点也会失效。例如在观察点失效时， gdb 可能会提示如下信息：
#+begin_src bash
Watchpoint 2 deleted because the program has left the block in which its
expression is valid.
#+END_SRC

** 
代码的虚拟地址是在编译(链接)期生成的，而代码编译后的结果一般是一个ELF(Executable Linkable Format)文件。ELF文件记录了我们代码中每个函数的虚拟地址，此外还会有一些其他有助于我们的信息。
我们可以使用指令查看一下user/_sleep这个ELF文件的格式。
新开一个终端，输入命令readelf -a user/_sleep

b *0xde6
print $pc
info reg 打印全部32个用户寄存器
print/x $satp 查看satp寄存器
x/3i 0xde4
** 参考文章
[[https://www.zhihu.com/question/65306462/answer/2602659870][gdb 高级调试实战教程 张小方]]
* global
GNU Global 是一个源代码标记系统，以相同的方式工作在不同的环境中，比如 Emacs editor, Vi editor, Less viewer, Bash shell, various web browsers 等等。可以用来定位指定的符号，比如函数（function）、宏（macros）、结构体（struct）、类（class），并轻松跳转。对于包含很多子目录，有很多 #ifdef 和 main() 函数的大型项目是很有用的。它类似 ctags 或者 etags，不同之处在于其独立于编辑器。

GNU GLOBAL 将包含子目录的源码树视为项目。在项目的任意地方都可以使用一个高性能的 tag 数据库。不需要指定数据库的位置，global 会自行定位。由于这个特性，可以在项目中内和项目间自由切换。

可以通过命令行使用 tag 工具,和其他 tag 系统相比，这是 Global 的一大优点。

GNU GLOBAL 具有以下功能：
- 支持 C，C ++，Yacc，Java，PHP4 和 assembly。
- 以相同的方式工作在的环境中：Shell 命令行,Bash shell,Vi 编辑器（Nvi，Elvis，vim）,Less viewer,Emacs 编辑器（Emacs，Mule，Xemacs）,网页浏览器,Doxygen 文档系统
- 快速查找指定符号（symbol）位置。
- 定位 symbol 定义和引用。
- 允许重复 tag。
- 查找匹配指定模式的路径。
- 默认分层搜索。
- 搜索工程源码和依赖的库源码。
- 为补全输入方法生成补全列表。
- 支持多种输出格式。
- 允许自定义用来标记的候选文件。
- 支持 POSIX 1003.2 正则表达式。
- 支持 idutils 作为外部的搜索引擎。
- tag 文件独立于机器架构。
- 支持增量更新标记文件。
- 通过解析器插件来支持新语言。
- 通过 gtags.conf 来进行定制。
- 为源码生成超文本文件。
- 格式紧凑，节省磁盘空间。
- 支持客户端/服务器环境（使用 Tramp）。
- 忽略二进制文件、点文件和指定文件。
- 包含兼容 cscope 的程序（gtags-cscope）。
- 包含 grep-like 命令（-g command）。
- 支持 grep-like 符号高亮。
** 安装
*** 使用自带的源安装 global

1sudo apt-get install global
*** 编译安装global

Ubuntu 14.04 自带的 GLOBAL 版本是 5.7.1 但是官网都已经是 6.6. 因此如果想用最新版的 GLOBAL， 就需要自己编译安装.

安装编译依赖的库
sudo apt build-dep global
sudo apt install libncurses5-dev libncursesw5-dev

移驾至 GNU GLOBAL 官方下载最新的 tar.gz 包并解开.

1wget https://ftp.gnu.org/pub/gnu/global/global-6.6.tar.gz
编译安装
./configure --with-sqlite3   # gtags可以使用Sqlite3作为数据库, 在编译时需要加这个参数
make -j4
sudo make install

* gpg
Pretty Good Privacy (PGP) 是一款诞生于 1991 年的，一款用于认证、加密的一款软件，现如今已经有了标准化协议 OpenPGP，最常用的实现是 GnuPG，一般提到 GPG 时都是指的 GnuPG。
** 安装
GPG有两种安装方式。可以下载源码，自己编译安装。
#+begin_src bash
./configure
make
make install
#+END_SRC

也可以安装编译好的二进制包。
#+begin_src bash
# Debian / Ubuntu 环境
sudo apt-get install gnupg

# Fedora 环境
yum install gnupg
#+END_SRC

安装完成后，键入下面的命令：
#+begin_src bash
gpg --help
#+END_SRC

如果屏幕显示GPG的帮助，就表示安装成功。
** 生成密钥
安装成功后，使用gen-ken参数生成自己的密钥。
#+begin_src bash
gpg --gen-key
#+END_SRC

回车以后，会跳出一大段文字：
#+begin_src bash
gpg (GnuPG) 1.4.12; Copyright (C) 2012 Free Software Foundation, Inc.
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.

请选择您要使用的密钥种类：
(1) RSA and RSA (default)
(2) DSA and Elgamal
(3) DSA (仅用于签名)　
(4) RSA (仅用于签名)
您的选择？
#+END_SRC

第一段是版权声明，然后让用户自己选择加密算法。默认选择第一个选项，表示加密和签名都使用RSA算法。

然后，系统就会问你密钥的长度。
#+begin_src bash
RSA 密钥长度应在 1024 位与 4096 位之间。
您想要用多大的密钥尺寸？(2048)
#+END_SRC

密钥越长越安全，默认是2048位。

接着，设定密钥的有效期。
#+begin_src bash
请设定这把密钥的有效期限。
0 = 密钥永不过期
<n> = 密钥在 n 天后过期
<n>w = 密钥在 n 周后过期
<n>m = 密钥在 n 月后过期
<n>y = 密钥在 n 年后过期
密钥的有效期限是？(0)
#+END_SRC

如果密钥只是个人使用，并且你很确定可以有效保管私钥，建议选择第一个选项，即永不过期。回答完上面三个问题以后，系统让你确认。
#+begin_src bash
以上正确吗？(y/n)
#+END_SRC

输入y，系统就要求你提供个人信息。
#+begin_src bash
您需要一个用户标识来辨识您的密钥；本软件会用真实姓名、注释和电子邮件地址组合成用户标识，如下所示：
"Heinrich Heine (Der Dichter) <heinrichh@duesseldorf.de>"

真实姓名：
电子邮件地址：
注释：
#+END_SRC

"真实姓名"填入你姓名的英文写法，"电子邮件地址"填入你的邮件地址，"注释"这一栏可以空着。

然后，你的"用户ID"生成了。
#+begin_src bash
您选定了这个用户标识：
"Ruan YiFeng <yifeng.ruan@gmail.com>"
#+END_SRC

我的"真实姓名"是Ruan YiFeng，"电子邮件地址"是yifeng.ruan@gmail.com，所以我的"用户ID"就是"Ruan YiFeng <yifeng.ruan@gmail.com>"。系统会让你最后确认一次。
#+begin_src bash
更改姓名(N)、注释(C)、电子邮件地址(E)或确定(O)/退出(Q)？
#+END_SRC

输入O表示"确定"。

接着，系统会让你设定一个私钥的密码。这是为了防止误操作，或者系统被侵入时有人擅自动用私钥。
#+begin_src bash
您需要一个密码来保护您的私钥：
#+END_SRC

然后，系统就开始生成密钥了，这时会要求你做一些随机的举动，以生成一个随机数。
#+begin_src bash
我们需要生成大量的随机字节。这个时候您可以多做些琐事(像是敲打键盘、移动鼠标、读写硬盘之类的)，这会让随机数字发生器有更好的机会获得足够的熵数。
#+END_SRC

几分钟以后，系统提示密钥已经生成了。
#+begin_src bash
gpg: 密钥 EDDD6D76 被标记为绝对信任
公钥和私钥已经生成并经签名。
#+END_SRC

请注意上面的字符串"EDDD6D76"，这是"用户ID"的Hash字符串，可以用来替代"用户ID"。

这时，最好再生成一张"撤销证书"，以备以后密钥作废时，可以请求外部的公钥服务器撤销你的公钥。
#+begin_src bash
gpg --gen-revoke [用户ID]
#+END_SRC

上面的"用户ID"部分，可以填入你的邮件地址或者Hash字符串（以下同）。
** 密钥管理
*** 列出密钥

list-keys参数列出系统中已有的密钥．

　　gpg --list-keys

显示结果如下：

　　/home/ruanyf/.gnupg/pubring.gpg
　　-------------------------------
　　pub 4096R/EDDD6D76 2013-07-11
　　uid Ruan YiFeng <yifeng.ruan@gmail.com>
　　sub 4096R/3FA69BE4 2013-07-11

第一行显示公钥文件名（pubring.gpg），第二行显示公钥特征（4096位，Hash字符串和生成时间），第三行显示"用户ID"，第四行显示私钥特征。

如果你要从密钥列表中删除某个密钥，可以使用delete-key参数。

　　gpg --delete-key [用户ID]
*** 输出密钥

公钥文件（.gnupg/pubring.gpg）以二进制形式储存，armor参数可以将其转换为ASCII码显示。

　　gpg --armor --output public-key.txt --export [用户ID]

"用户ID"指定哪个用户的公钥，output参数指定输出文件名（public-key.txt）。

类似地，export-secret-keys参数可以转换私钥。

　　gpg --armor --output private-key.txt --export-secret-keys
*** 上传公钥

公钥服务器是网络上专门储存用户公钥的服务器。send-keys参数可以将公钥上传到服务器。

　　gpg --send-keys [用户ID] --keyserver hkp://subkeys.pgp.net

使用上面的命令，你的公钥就被传到了服务器subkeys.pgp.net，然后通过交换机制，所有的公钥服务器最终都会包含你的公钥。

由于公钥服务器没有检查机制，任何人都可以用你的名义上传公钥，所以没有办法保证服务器上的公钥的可靠性。通常，你可以在网站上公布一个公钥指纹，让其他人核对下载到的公钥是否为真。fingerprint参数生成公钥指纹。

　　gpg --fingerprint [用户ID]
*** 输入密钥

除了生成自己的密钥，还需要将他人的公钥或者你的其他密钥输入系统。这时可以使用import参数。

　　gpg --import [密钥文件]

为了获得他人的公钥，可以让对方直接发给你，或者到公钥服务器上寻找。

　　gpg --keyserver hkp://subkeys.pgp.net --search-keys [用户ID]

正如前面提到的，我们无法保证服务器上的公钥是否可靠，下载后还需要用其他机制验证．
** 加密和解密

*** 加密

假定有一个文本文件demo.txt，怎样对它加密呢？

encrypt参数用于加密。

　　gpg --recipient [用户ID] --output demo.en.txt --encrypt demo.txt

recipient参数指定接收者的公钥，output参数指定加密后的文件名，encrypt参数指定源文件。运行上面的命令后，demo.en.txt就是已加密的文件，可以把它发给对方。

*** 解密

对方收到加密文件以后，就用自己的私钥解密。

　　gpg --decrypt demo.en.txt --output demo.de.txt

decrypt参数指定需要解密的文件，output参数指定解密后生成的文件。运行上面的命令，demo.de.txt就是解密后的文件。

GPG允许省略decrypt参数。

　　gpg demo.en.txt

运行上面的命令以后，解密后的文件内容直接显示在标准输出。

** 签名

*** 对文件签名

有时，我们不需要加密文件，只需要对文件签名，表示这个文件确实是我本人发出的。sign参数用来签名。

　　gpg --sign demo.txt

运行上面的命令后，当前目录下生成demo.txt.gpg文件，这就是签名后的文件。这个文件默认采用二进制储存，如果想生成ASCII码的签名文件，可以使用clearsign参数。

　　gpg --clearsign demo.txt

运行上面的命令后 ，当前目录下生成demo.txt.asc文件，后缀名asc表示该文件是ASCII码形式的。

如果想生成单独的签名文件，与文件内容分开存放，可以使用detach-sign参数。

　　gpg --detach-sign demo.txt

运行上面的命令后，当前目录下生成一个单独的签名文件demo.txt.sig。该文件是二进制形式的，如果想采用ASCII码形式，要加上armor参数。

　　gpg --armor --detach-sign demo.txt

*** 签名+加密

上一节的参数，都是只签名不加密。如果想同时签名和加密，可以使用下面的命令。

　　gpg --local-user [发信者ID] --recipient [接收者ID] --armor --sign --encrypt demo.txt

local-user参数指定用发信者的私钥签名，recipient参数指定用接收者的公钥加密，armor参数表示采用ASCII码形式显示，sign参数表示需要签名，encrypt参数表示指定源文件。

*** 验证签名

我们收到别人签名后的文件，需要用对方的公钥验证签名是否为真。verify参数用来验证。

　　gpg --verify demo.txt.asc demo.txt

举例来说，openvpn网站就提供每一个下载包的gpg签名文件。你可以根据它的说明，验证这些下载包是否为真。
** emacs中的gpg
*** 密码输入
为了提高 key 安全系数，一般推荐在创建 key 时设置一个密码，这样即使密钥丢了，别人也无法使用。

但是每次 输入密码显得有些繁琐，解决方式是让 gpg-agent 这个进程记住密码，这样只需在系统第一次使用时输入即可。为了让 Emacs 能在首次使用 GPG 时，捕获密码输入框，在 minibuffer 中输入密码，需要做如下的配置：

修改 agent 的配置文件
#+begin_src bash
# cat ~/.gnupg/gpg-agent.conf
allow-emacs-pinentry allow-loopback-pinentry
#+END_SRC
之后然后加载即可
#+begin_src bash
gpgconf --reload gpg-agent
#+END_SRC
安装 pinentry 包，配置 loopback，
启动 pinentry server，参考配置
#+begin_src emacs-lisp
(use-package pinentry
  :config
  (setq epa-pinentry-mode 'loopback)
  (pinentry-start))
#+end_src
pinentry 进程的作用：它会让用户输入的密码不会因内存不足而换出到磁盘

*** 文件操作
GPG 格式的文件是一种二进制文件，一般的编辑器是无法打开的，但 Emacs 对 GPG 提供了非常方便的支持，比如创建一个名为 password.org.gpg 的文件，保存时 Emacs 会自动弹出选择框，让用户选择加密的公钥。
#+begin_example
Select recipients for encryption.
If no one is selected, symmetric encryption will be performed.
- ‘m’ to mark a key on the line
- ‘u’ to unmark a key on the line
[Cancel][OK]

  u D3026E5C08A0BAB4 Jiacai Liu <xxx@gmail.com>
#+end_example
而且，这个文件的 major mode 也能正确识别为 org mode，这样就可以非常方便的编辑 GPG 文件。与此同理，可以方便地创建任何格式的 GPG 文件，比如： diary.md.gpg ，重新打开文件时，Emacs 会自动解密，并设置相应的 major mode。

*** EasyPG
Emacs 自带的 EasyPG 包对常用 GPG 命令都提供了相应函数的支持：
- epa-sign-file
- epa-encrypt-file
- epa-decrypt-file
- epa-encrypt-region
- epa-decrypt-region
- epa-import-keys
- epa-export-keys
- epa-list-keys
- epa-list-secret-keys
- epa-delete-keys
** 参考文章
[[https://zhuanlan.zhihu.com/p/440603184][GPG in Emacs]]
[[http://www.ruanyifeng.com/blog/2013/07/gpg.html][GPG入门教程]]
* grep命令
Linux grep 命令用于查找文件里符合条件的字符串。

grep 指令用于查找内容包含指定的范本样式的文件，如果发现某文件的内容符合所指定的范本样式，预设 grep 指令会把含有范本样式的那一列显示出来。若不指定任何文件名称，或是所给予的文件名为 -，则 grep 指令会从标准输入设备读取数据。

语法：
#+begin_src bash
grep [-abcEFGhHilLnqrsvVwxy][-A<显示行数>][-B<显示列数>][-C<显示列数>][-d<进行动作>][-e<范本样式>][-f<范本文件>][--help][范本样式][文件或目录...]
#+END_SRC
参数：
- -a 或 --text : 不要忽略二进制的数据。
- -A<显示行数> 或 --after-context=<显示行数> : 除了显示符合范本样式的那一列之外，并显示该行之后的内容。
- -b 或 --byte-offset : 在显示符合样式的那一行之前，标示出该行第一个字符的编号。
- -B<显示行数> 或 --before-context=<显示行数> : 除了显示符合样式的那一行之外，并显示该行之前的内容。
- -c 或 --count : 计算符合样式的列数。
- -C<显示行数> 或 --context=<显示行数>或-<显示行数> : 除了显示符合样式的那一行之外，并显示该行之前后的内容。
- -d <动作> 或 --directories=<动作> : 当指定要查找的是目录而非文件时，必须使用这项参数，否则grep指令将回报信息并停止动作。
- -e<范本样式> 或 --regexp=<范本样式> : 指定字符串做为查找文件内容的样式。
- -E 或 --extended-regexp : 将样式为延伸的正则表达式来使用。
- -f<规则文件> 或 --file=<规则文件> : 指定规则文件，其内容含有一个或多个规则样式，让grep查找符合规则条件的文件内容，格式为每行一个规则样式。
- -F 或 --fixed-regexp : 将样式视为固定字符串的列表。
- -G 或 --basic-regexp : 将样式视为普通的表示法来使用。
- -h 或 --no-filename : 在显示符合样式的那一行之前，不标示该行所属的文件名称。
- -H 或 --with-filename : 在显示符合样式的那一行之前，表示该行所属的文件名称。
- -i 或 --ignore-case : 忽略字符大小写的差别。
- -l 或 --file-with-matches : 列出文件内容符合指定的样式的文件名称。
- -L 或 --files-without-match : 列出文件内容不符合指定的样式的文件名称。
- -n 或 --line-number : 在显示符合样式的那一行之前，标示出该行的列数编号。
- -o 或 --only-matching : 只显示匹配PATTERN 部分。
- -q 或 --quiet或--silent : 不显示任何信息。
- -r 或 --recursive : 此参数的效果和指定"-d recurse"参数相同。
- -s 或 --no-messages : 不显示错误信息。
- -v 或 --invert-match : 显示不包含匹配文本的所有行。
- -V 或 --version : 显示版本信息。
- -w 或 --word-regexp : 只显示全字符合的列。
- -x --line-regexp : 只显示全列符合的列。
- -y : 此参数的效果和指定"-i"参数相同。

* id命令
Linux id命令用于显示用户的ID，以及所属群组的ID。

id会显示用户以及所属群组的实际与有效ID。若两个ID相同，则仅显示实际ID。若仅指定用户名称，则显示目前用户的ID。

语法：id [-gGnru][--help][--version][用户名称]
参数说明：
- -g或--group 　显示用户所属群组的ID。
- -G或--groups 　显示用户所属附加群组的ID。
- -n或--name 　显示用户，所属群组或附加群组的名称。
- -r或--real 　显示实际ID。
- -u或--user 　显示用户ID。
- -help 　显示帮助。
- -version 　显示版本信息。
** 实例
显示当前用户信息
#+begin_src bash
>>>id //显示当前用户ID
uid=0(root) gid=0(root) groups=0(root),1(bin),2(daemon),3(sys),4(adm),6(disk),10(wheel) context=root:system_r:unconfined_t
#+END_SRC
显示用户群组的ID
#+begin_src bash
>>>id -g
0
#+END_SRC
显示所有群组的ID
#+begin_src bash
>>>id -g
0 1 2 3 4 5 6 10
#+END_SRC
显示指定用户信息
#+begin_src bash
>>>id hnlinux
#+END_SRC
** 参考文章
[[https://www.runoob.com/linux/linux-comm-id.html][Linux id命令 - 菜鸟教程]]
* jupyter notebook
** 使用Anaconda安装
#+BEGIN_SRC bash
conda install jupyter notebook
#+END_SRC
** 使用pip命令安装
#+BEGIN_SRC python
pip3 install jupyter #python3.x
pip install jupyter	#python2.x
#+END_SRC

6.sudo fdisk -l，/dev/sda1空间从40G扩展到了58G
#+DOWNLOADED: file:F:/org/图片/20180117102533147.png @ 2020-06-02 19:29:31
[[file:jupyter_notebook/2020-06-02_19-29-31_20180117102533147.png]]

** 切换conda环境的方法
切换到想要的环境，比如说adda
~conda activate adda~
安装ipykernel：
~conda install ipykernel~
添加kernel进jupyter notebook：
~python -m ipykernel install --user --name [虚拟环境名] --display-name "kernel命名"~
如： ~python -m ipykernel install --name adda~

执行完这个语句之后，会自动在目录【C:\ProgramData\jupyter\kernels】(类似)生成一个【adda】文件夹，里面有kernel.json文件

现在打开jupyter notebook，里面就会显示有这个虚拟环境了

选择conda环境新建文件
#+DOWNLOADED: file:F:/org/图片/20200304105902203.png @ 2020-10-29 09:25:50

[[file:jupyter_notebook/2020-10-29_09-25-50_20200304105902203.png]]

此时，就可以看到创建的Python[conda env:tf-gpu]了，选择该kernel运行即可
#+DOWNLOADED: file:F:/org/图片/20200304105932199.png @ 2020-10-29 09:25:56
[[file:jupyter_notebook/2020-10-29_09-25-56_20200304105932199.png]]

** 配置jupyter notebook
生成配置文件： ~jupyter notebook --generate-config~

设置密码： ~jupyter notebook password~

修改配置文件: ~vim ~/.jupyter/jupyter_notebook_config.py~

#+DOWNLOADED: file:F:/org/图片/20200805124102787.png @ 2020-10-29 09:35:59
[[file:jupyter_notebook/2020-10-29_09-35-59_20200805124102787.png]]

** 远程访问jupyter notebook
通常情况下,打开 jupyter notebook即从本地地址localhost:8888打开jupyter notebook.

如果希望远程操控jupyter notebook,则需要进行一些设置.

*** 1. 检查配置文件是否存在

首相必须确认jupyter notebook 的配置文件 =jupyter_notebook_config.py= 是否存在.

不同系统的默认配置文件路径如下:

- Windows: =C:\Users\USERNAME\.jupyter\jupyter_notebook_config.py=
- OS X: =/Users/USERNAME/.jupyter/jupyter_notebook_config.py=
- Linux: =/home/USERNAME/.jupyter/jupyter_notebook_config.py=

如果系统上没有Jupyter 文件夹或者Jupyter 文件夹里没有配置文件,那么必须执行以下命令生成配置文件:
#+BEGIN_SRC bash
jupyter notebook --generate-config
#+END_SRC

这个命令会创建Jupyter文件夹并在文件夹内生成配置文件 =jupyter_notebook_config.py=

*** 2.生成密码

**** 2.1生成访问密码

从 jupyter notebook 5.0 版本开始,我们就可以通过自动方式生成访问密码.

设置访问密码的命令为 =jupyter notebook password= ，设置后的访问密码存储在 =jupyter_notebook_config.json= 里面。

#+BEGIN_SRC bash
> jupyter notebook password
Enter password:  ****
Verify password: ****
[NotebookPasswordApp] Wrote hashed password to /Users/you/.jupyter/jupyter_notebook_config.json
#+END_SRC


**** 2.2 生成hash密码

如果没有hash密码，那么我们每次通过浏览器远程访问Jupyter时，都需要输入一次密码。如果设置了hash密码，那么我们只需要在首次远程访问jupyter的时候输入一次密码，之后再次访问jupyter的时候就不用重复输入密码了。
在终端输入 =ipython= ，进入ipython环境后输入下列代码。

#+BEGIN_SRC bash
In [1]: from notebook.auth import passwd
In [2]: passwd()
Enter password:
Verify password:
Out[2]: 'sha1:67c9e60bb8b6:9ffede0825894254b2e042ea597d771089e11aed'
#+END_SRC

这里输出的就是hash密码，后面的操作需要用到这个hash密码，所以需要将其复制下来。

输入 =exit= 退出ipython环境。

*** 3.修改配置文件

打开 =jupyter_notebook_config.py= 文件,可以看到里面很多注释行。如果我们要修改 =jupyter_notebook_config.py= 里的某一行，必须先把行首的 =#= 去掉。

找到 =#c.NotebookApp.password = ' '= 这一行，将注释去掉，并修改为
 =c.NotebookApp.password = u'sha1:67c9e60bb8b6:9ffede0825894254b2e042ea597d771089e11aed`=

这里将之前复制的hash密码填入即可，注意密码前面的 =u= 不可省略，其作用是提示Python编译器，要按照给定的方式来解析引号中的字符串。

=c.NotebookApp.allow_remote_access = True= 将默认值False修改为True，表示允许外部访问。

=c.NotebookApp.ip = '*'= 这里的 =*= 表示允许所有IP皆可访问

=c.NotebookApp.open_browser = False= 禁止自动打开浏览器

=c.NotebookApp.notebook_dir = '/eswai/jupyter'= 这里可修改在浏览器打开jupyter notebook后的工作目录。

=c.NotebookApp.port = 9999= 设置一个固定的notebook服务会监听的IP端口（这里设置为9999），这个值可以任意，只要保证不和其他已经启用的端口号冲突即可，也可以不修改，默认为8888。

修改完成后在终端输入 =jupyter notebook= 命令，这样确保Jupyter重新加载jupyter_notebook_config.py，进而使得新配置起效。

之后我们只要在任意浏览器地址栏输入 =主机ip：9999= 即可远程登录jupyter notebook了。

如果是服务器上docker容器内的jupyter notebook，那么浏览器地址栏应该输入 =宿主机ip:宿主机端口=

这里的宿主机端口是创建容器时分配的宿主机端口，比如你创建容器时使用的端口映射参数为： =-p 8002:9999= ，那么远程登录地址为 =宿主机ip:8002= .

参考文档：

1. [[https://jupyter-notebook.readthedocs.io/en/latest/public_server.html][官方英文指南]]

2. [[https://www.jianshu.com/p/444c3ae23035][设置 jupyter notebook 可远程访问]]

3. [[https://blog.csdn.net/eswai/article/details/79437428][利用Docker环境配置jupyter notebook服务器]]

4. [[https://zhuanlan.zhihu.com/p/64524822][如何设置远程访问的Jupyter Notebook服务器-04（服务器篇）]]

* Linux 任务前后台的切换
Shell支持作用控制，有以下命令实现前后台切换：
1. command& 让进程在后台运行
2. jobs 查看后台运行的进程
3. fg %n 让后台运行的进程n到前台来
4. bg %n 让进程n到后台去
5. kill %n 杀死job

PS:"n"为jobs命令查看到的job编号，不是进程编号.

fg、bg、jobs、&、ctrl + z都是跟系统任务有关的，虽然现在基本上不怎么需要用到这些命令，但学会了也是很实用的.

& 最经常被用到,这个用在一个命令的最后，可以把这个命令放到后台执行
 
ctrl + z,可以将一个正在前台执行的命令放到后台，并且暂停

jobs,查看当前有多少在后台运行的命令
 
fg,将后台中的命令调至前台继续运行,如果后台中有多个命令，可以用 fg %jobnumber将选中的命令调出，%jobnumber是通过jobs命令查到的后台正在执行的命令的序号(不是pid)。

bg,将一个在后台暂停的命令，变成继续执行,如果后台中有多个命令，可以用bg %jobnumber将选中的命令调出，%jobnumber是通过jobs命令查到的后台正在执行的命令的序号(不是pid)。
 
** 实例：
假设你发现前台运行的一个程序需要很长的时间，但是需要干其他的事情，你就可以用 Ctrl-Z ，终止这个程序，然后可以看到系统提示：
~[1]+ Stopped /root/bin/rsync.sh~

如果没有此提示，则用 jobs 命令查看任务：
#+BEGIN_SRC bash
>>>jobs
[1]+ suspended /root/bin/rsync.sh &
#+END_SRC
然后我们可以把程序调度到后台执行：（bg 后面的数字为作业号）
#+BEGIN_SRC bash
>>>bg 1
[1]+ /root/bin/rsync.sh &
#+END_SRC
用 jobs 命令查看正在运行的任务：
#+BEGIN_SRC bash
>>>jobs
[1]+ Running /root/bin/rsync.sh &
#+END_SRC
如果想把它调回到前台运行，可以用
#+BEGIN_SRC bash
>>>fg 1
/root/bin/rsync.sh
#+END_SRC
这样，你在控制台上就只能等待这个任务完成了。 
* Linux 命令行快捷键
涉及在linux命令行下进行快速移动光标、命令编辑、编辑后执行历史命令、Bang(!)命令、控制命令等。让basher更有效率。

** 常用
ctrl+左右键:在单词之间跳转
ctrl+a:跳到本行的行首
ctrl+e:跳到页尾
Ctrl+u：删除当前光标前面的文字 （还有剪切功能）
ctrl+k：删除当前光标后面的文字(还有剪切功能)
Ctrl+L：进行清屏操作
Ctrl+y:粘贴Ctrl+u或ctrl+k剪切的内容
Ctrl+w:删除光标前面的单词的字符
Alt – d ：由光标位置开始，往右删除单词。往行尾删
说明
Ctrl – k: 先按住 Ctrl 键，然后再按 k 键；
Alt – k: 先按住 Alt 键，然后再按 k 键；
M – k：先单击 Esc 键，然后再按 k 键。

** 移动光标
Ctrl – a ：移到行首
Ctrl – e ：移到行尾
Ctrl – b ：往回(左)移动一个字符
Ctrl – f ：往后(右)移动一个字符
Alt – b ：往回(左)移动一个单词
Alt – f ：往后(右)移动一个单词
Ctrl – xx ：在命令行尾和光标之间移动
M-b ：往回(左)移动一个单词
M-f ：往后(右)移动一个单词

** 编辑命令
Ctrl – h ：删除光标左方位置的字符
Ctrl – d ：删除光标右方位置的字符（注意：当前命令行没有任何字符时，会注销系统或结束终端）
Ctrl – w ：由光标位置开始，往左删除单词。往行首删
Alt – d ：由光标位置开始，往右删除单词。往行尾删
M – d ：由光标位置开始，删除单词，直到该单词结束。
Ctrl – k ：由光标所在位置开始，删除右方所有的字符，直到该行结束。
Ctrl – u ：由光标所在位置开始，删除左方所有的字符，直到该行开始。
Ctrl – y ：粘贴之前删除的内容到光标后。
ctrl – t ：交换光标处和之前两个字符的位置。
Alt + . ：使用上一条命令的最后一个参数。
Ctrl – _ ：回复之前的状态。撤销操作。
Ctrl -a + Ctrl -k 或 Ctrl -e + Ctrl -u 或 Ctrl -k + Ctrl -u 组合可删除整行。

** Bang(!)命令
!! ：执行上一条命令。
^foo^bar ：把上一条命令里的foo替换为bar，并执行。
!wget ：执行最近的以wget开头的命令。
!wget:p ：仅打印最近的以wget开头的命令，不执行。
!$ ：上一条命令的最后一个参数， 与 Alt - . 和 $_ 相同。
!* ：上一条命令的所有参数
!*:p ：打印上一条命令是所有参数，也即 !*的内容。
^abc ：删除上一条命令中的abc。
^foo^bar ：将上一条命令中的 foo 替换为 bar
^foo^bar^ ：将上一条命令中的 foo 替换为 bar
!-n ：执行前n条命令，执行上一条命令： !-1， 执行前5条命令的格式是： !-5

** 查找历史命令
Ctrl – p ：显示当前命令的上一条历史命令
Ctrl – n ：显示当前命令的下一条历史命令
Ctrl – r ：搜索历史命令，随着输入会显示历史命令中的一条匹配命令，Enter键执行匹配命令；ESC键在命令行显示而不执行匹配命令。
Ctrl – g ：从历史搜索模式（Ctrl – r）退出。

** 控制命令
Ctrl – l ：清除屏幕，然后，在最上面重新显示目前光标所在的这一行的内容。
Ctrl – o ：执行当前命令，并选择上一条命令。
Ctrl – s ：阻止屏幕输出
Ctrl – q ：允许屏幕输出
Ctrl – c ：终止命令
Ctrl – z ：挂起命令

** 重复执行操作动作
M – 操作次数 操作动作 ： 指定操作次数，重复执行指定的操作。
* Linux 命令行连接WiFi
1. 安装nmcli
sudo apt-get install nmcli

2. 查看网络设备
sudo nmcli dev

3. 开启wifi
sudo nmcli r wifi on

4. 扫描wifi
sudo nmcli dev wifi

5. 连接wifi
sudo nmcli dev wifi connect "wifi名" password "密码"
* Linux 让终端走代理的几种方法
参看文章：
[[https://zhuanlan.zhihu.com/p/46973701][Linux 让终端走代理的几种方法]]

可以用命令$ curl cip.cc 检查终端是否处于代理状态
** 方法一：（推荐使用）
为什么说这个方法推荐使用呢？因为他只作用于当前终端中，不会影响环境，而且命令比较简单
在终端中直接运行：

export http_proxy=http://proxyAddress:port

如果你是SSR,并且走的http的代理端口是12333，想执行wget或者curl来下载国外的东西，可以使用如下命令：

export http_proxy=http://127.0.0.1:12333

如果是https那么就经过如下命令：

export https_proxy=http://127.0.0.1:12333

下面这是cad实验室的代理设置：
#+begin_src bash
export http_proxy="socks5://proxy.in.zjulearning.org:7070"
export https_proxy="socks5://proxy.in.zjulearning.org:7070"
#+END_SRC

Linux上代理的临时取消
#+begin_src bash
unset  http_proxy
unset https_proxy
#+END_SRC

** 方法二 ：
这个办法的好处是把代理服务器永久保存了，下次就可以直接用了

把代理服务器地址写入shell配置文件.bashrc或者.zshrc 直接在.bashrc或者.zshrc添加下面内容
#+begin_src bash
export http_proxy="http://localhost:port"
export https_proxy="http://localhost:port"
#+END_SRC
或者走socket5协议（ss,ssr）的话，代理端口是1080
#+begin_src bash
export http_proxy="socks5://127.0.0.1:1080"
export https_proxy="socks5://127.0.0.1:1080"
#+END_SRC
或者干脆直接设置ALL_PROXY

export ALL_PROXY=socks5://127.0.0.1:1080

最后在执行如下命令应用设置

source ~/.bashrc

或者通过设置alias简写来简化操作，每次要用的时候输入setproxy，不用了就unsetproxy。
#+begin_src bash
alias setproxy="export ALL_PROXY=socks5://127.0.0.1:1080" 
alias unsetproxy="unset ALL_PROXY"
#+END_SRC
** 方法三:
改相应工具的配置，比如apt的配置

sudo vim /etc/apt/apt.conf

在文件末尾加入下面这行

Acquire::http::Proxy "http://proxyAddress:port"
** python走socks5代理的设置
python如果要使用socks5，除了需要上面的代理外，还要安装pysocks库.

参考文章：[[https://stackoverflow.com/questions/38794015/pythons-requests-missing-dependencies-for-socks-support-when-using-socks5-fro][Python's requests "Missing dependencies for SOCKS support" when using SOCKS5 from Terminal]]
* Linux 中查看某个软件的安装路径
** 查看文件安装路径：
由于软件安装的地方不止一个地方，所有先说查看文件安装的所有路径(地址)。

这里以Oracle为例。比如说我安装了Oracle，但是不知道文件都安装在哪些地方、放在哪些文件夹里，可以用下面的命令查看所有的文件路径

在终端输入：
#+begin_src bash
whereis oracle
#+END_SRC

回车，如果你安装好了Oracle，就会显示文件安装的地址，例如我的显示(安装地址可能会不同)
#+BEGIN_EXAMPLE
oracle: /usr/bin/oracle /usr/lib/oracle /usr/share/oracle /usr/share/man/man1/oracle.1.gz
#+END_EXAMPLE

可以看出来，Oracle安装在是个目录里。

如果你没有安装Oracle或者Oracle安装没成功，则不会显示文件路径出来。只提示:
#+begin_src bash
oracle:
#+END_SRC
** 查询运行文件所在路径：

如果你只要查询文件的运行文件所在地址，直接用下面的命令就可以了(还是以Oracle为例)：
#+begin_src bash
which oracle
#+END_SRC
结果会显示：
#+BEGIN_EXAMPLE
/usr/bin/oracle
#+END_EXAMPLE

* Linux shell中2>&1的含义解释
| 名称                 | 代码 | 操作符           |
|----------------------+------+------------------|
| 标准输入(stdin)      |    0 | < 或 <<          |
| 标准输出(stdout)     |    1 | >, >>, 1> 或 1>> |
| 标准错误输出(stderr) |    2 | 2> 或 2>>        |

从上表看的出来，我们平时使用的
#+begin_src bash
echo "hello" > t.log 
#+END_SRC
其实也可以写成
#+begin_src bash
echo "hello" 1> t.log
#+END_SRC
** 关于2>&1的含义
1. 含义：将标准错误输出重定向到标准输出
2. 符号>&是一个整体，不可分开
3. 2>1的写法其实是将标准错误输出重定向到名为"1"的文件里去了。
4. 写成2&>1也是不可以的

#+begin_src bash
# 标准错误输出和标准输出都定向到log中
nohup java -jar app.jar >log 2>&1 &
#+END_SRC
1. 本来1----->屏幕 （1指向屏幕）
2. 执行>log后， 1----->log (1指向log)
3. 执行2>&1后， 2----->1 (2指向1，而1指向log,因此2也指向了log)

">log 2>&1"可以有以下两种简写方式
#+begin_src bash
&>log
>&log
#+END_SRC
** 参考文章
[[https://blog.csdn.net/zhaominpro/article/details/82630528][Linux shell中2>&1的含义解释]]
* linux稀疏文件
** 创建文件的命令
The Unix command
#+begin_src bash
dd of=sparse-file bs=5M seek=1 count=0
#+END_SRC
will create a file of five mebibytes in size, but with no data stored on the media (only metadata). (GNU dd has this behavior because it calls ftruncate to set the file size; other implementations may merely create an empty file.)

Similarly the truncate command may be used, if available:
#+begin_src bash
truncate -s 5M <filename>
#+END_SRC
On Linux, an existing file can be converted to sparse by:
#+begin_src bash
fallocate -d <filename>
#+END_SRC
There is no portable system call to punch holes; Linux provides fallocate(FALLOC_FL_PUNCH_HOLE), and Solaris provides fcntl(F_FREESP).
* ldd命令
作用：用来查看程式运行所需的共享库,常用来解决程式因缺少某个库文件而不能运行的一些问题。ldd不是个可执行程式，而只是个shell脚本。

格式：
ldd [选项] 文件

选项：
- --version：打印ldd的版本号
- -v --verbose：打印所有信息，例如包括符号的版本信息
- -d --data-relocs：执行符号重部署，并报告缺少的目标对象（只对ELF格式适用）
- -r --function-relocs：对目标对象和函数执行重新部署，并报告缺少的目标对象和函数（只对ELF格式适用）
- --help：用法信息

* less命令
less 与 more 类似，less 可以随意浏览文件，支持翻页和搜索，支持向上翻页和向下翻页。

语法：
less [参数] 文件 

参数说明：
- -b <缓冲区大小> 设置缓冲区的大小
- -e 当文件显示结束后，自动离开
- -f 强迫打开特殊文件，例如外围设备代号、目录和二进制文件
- -F，就会有类似 tail -f 的效果，读取写入文件的最新内容， 按 ctrl+C 停止。
- -g 只标志最后搜索的关键词
- -i 忽略搜索时的大小写
- -m 显示类似more命令的百分比
- -N 显示每行的行号
- -o <文件名> 将less 输出的内容在指定文件中保存起来
- -Q 不使用警告音
- -v 进入编辑模型， shift+ZZ 保存退出到 less 查看模式。
- -s 显示连续空行为一行
- -S 行过长时间将超出部分舍弃
- -x <数字> 将"tab"键显示为规定的数字空格
- /字符串：向下搜索"字符串"的功能
- ?字符串：向上搜索"字符串"的功能
- n：重复前一个搜索（与 / 或 ? 有关）
- N：反向重复前一个搜索（与 / 或 ? 有关）
- b 向上翻一页
- d 向后翻半页
- h 显示帮助界面
- Q 退出less 命令
- u 向前滚动半页
- y 向前滚动一行
- 空格键 滚动一页
- 回车键 滚动一行
- [pagedown]： 向下翻动一页
- [pageup]： 向上翻动一页

** 附加备注
1.全屏导航
#+BEGIN_EXAMPLE
ctrl + F - 向前移动一屏
ctrl + B - 向后移动一屏
ctrl + D - 向前移动半屏
ctrl + U - 向后移动半屏
#+END_EXAMPLE
2.单行导航
#+BEGIN_EXAMPLE
j - 下一行
k - 上一行
#+END_EXAMPLE

3.其它导航
#+BEGIN_EXAMPLE
G - 移动到最后一行
g - 移动到第一行
q / ZZ - 退出 less 命令
#+END_EXAMPLE

4.其它有用的命令
#+BEGIN_EXAMPLE
v - 使用配置的编辑器编辑当前文件
h - 显示 less 的帮助文档
&pattern - 仅显示匹配模式的行，而不是整个文件
#+END_EXAMPLE

5.标记导航
当使用 less 查看大文件时，可以在任何一个位置作标记，可以通过命令导航到标有特定标记的文本位置：
#+BEGIN_EXAMPLE
ma - 使用 a 标记文本的当前位置
'a - 导航到标记 a 处
:e 查看下一个文件， 用 :n 和 :p 来回切换。
#+END_EXAMPLE
** 实例
1、查看文件

less log2013.log
2、ps查看进程信息并通过less分页显示

ps -ef |less
3、查看命令历史使用记录并通过less分页显示
#+begin_src bash
[root@localhost test]# history | less
22  scp -r tomcat6.0.32 root@192.168.120.203:/opt/soft
23  cd ..
24  scp -r web root@192.168.120.203:/opt/
25  cd soft
26  ls
……省略……
#+END_SRC
4、浏览多个文件
#+begin_src bash
less log2013.log log2014.log
#+END_SRC
可以按 :e 查看下一个文件， 用 :n 和 :p 来回切换。
说明：
输入 ：n后，切换到 log2014.log
输入 ：p 后，切换到log2013.log
* ln命令
ln（link files）命令可以为某一个文件在另外一个位置建立一个同步的链接。

当我们需要在不同的目录，用到相同的文件时，我们不需要在每一个需要的目录下都放一个必须相同的文件，我们只要在某个固定的目录，放上该文件，然后在 其它的目录下用ln命令链接（link）它就可以，不必重复的占用磁盘空间。

** 语法
#+begin_src bash
ln [参数][源文件或目录][目标文件或目录]

其中参数的格式为
[-bdfinsvF] [-S backup-suffix] [-V {numbered,existing,simple}]
[--help] [--version] [--]
#+END_SRC

** 硬链接和软链接
Linux文件系统中，有所谓的链接(link)，我们可以将其视为档案的别名，而链接又可分为两种 : 硬链接(hard link)与软链接(symbolic link)。

硬链接的意思是一个档案可以有多个名称，而软链接的方式则是产生一个特殊的档案，该档案的内容是指向另一个档案的位置。
硬链接是存在同一个文件系统中，而软链接却可以跨越不同的文件系统。

不论是硬链接或软链接都不会将原本的档案复制一份，只会占用非常少量的磁碟空间。

软链接：
1. 软链接，以路径的形式存在。类似于Windows操作系统中的快捷方式
2. 软链接可以 跨文件系统 ，硬链接不可以
3. 软链接可以对一个不存在的文件名进行链接
4. 软链接可以对目录进行链接

硬链接：
1. 硬链接，以文件副本的形式存在。但不占用实际空间。
2. 不允许给目录创建硬链接
3. 硬链接只有在同一个文件系统中才能创建

** 命令参数
必要参数：
- --backup[=CONTROL] 备份已存在的目标文件
- -b 类似 --backup ，但不接受参数
- -d 允许超级用户制作目录的硬链接
- -f 强制执行
- -i 交互模式，文件存在则提示用户是否覆盖
- -n 把符号链接视为一般目录
- -s 软链接(符号链接)
- -v 显示详细的处理过程

选择参数：
- -S "-S<字尾备份字符串> "或 "--suffix=<字尾备份字符串>"
- -V "-V<备份方式>"或"--version-control=<备份方式>"
- --help 显示帮助信息
- --version 显示版本信息

** 实例
给文件创建软链接，为log2013.log文件创建软链接link2013，如果log2013.log丢失，link2013将失效：
#+begin_src bash
ln -s log2013.log link2013
#+END_SRC
输出：
#+begin_src bash
[root@localhost test]# ll
-rw-r--r-- 1 root bin      61 11-13 06:03 log2013.log
[root@localhost test]# ln -s log2013.log link2013
[root@localhost test]# ll
lrwxrwxrwx 1 root root     11 12-07 16:01 link2013 -> log2013.log
-rw-r--r-- 1 root bin      61 11-13 06:03 log2013.log
#+END_SRC
给文件创建硬链接，为log2013.log创建硬链接ln2013，log2013.log与ln2013的各项属性相同
#+begin_src bash
ln log2013.log ln2013
#+END_SRC
输出：
#+begin_src bash
[root@localhost test]# ll
lrwxrwxrwx 1 root root     11 12-07 16:01 link2013 -> log2013.log
-rw-r--r-- 1 root bin      61 11-13 06:03 log2013.log
[root@localhost test]# ln log2013.log ln2013
[root@localhost test]# ll
lrwxrwxrwx 1 root root     11 12-07 16:01 link2013 -> log2013.log
-rw-r--r-- 2 root bin      61 11-13 06:03 ln2013
-rw-r--r-- 2 root bin      61 11-13 06:03 log2013.log
#+END_SRC
* locale命令
locale是linux系统中多语言环境的设置接口，Locale根据计算机用户所使用的语言，所在国家或者地区，以及当地的文化传统所定义的一个软件运行时的语言环境。

通过locale来设置程序运行的不同语言环境，locale由ANSI C提供支持。locale的命名规则为<语言>_<地区>.<字符集编码>，如zh_CN.UTF-8，zh代表中文，CN代表大陆地区，UTF-8表示字符集。在locale环境中，有一组变量，代表国际化环境中的不同设置。locale是linux系统中多语言环境的设置接口，Locale根据计算机用户所使用的语言，所在国家或者地区，以及当地的文化传统所定义的一个软件运行时的语言环境。

通过locale来设置程序运行的不同语言环境，locale由ANSI C提供支持。locale的命名规则为<语言>_<地区>.<字符集编码>，如zh_CN.UTF-8，zh代表中文，CN代表大陆地区，UTF-8表示字符集。在locale环境中，有一组变量，代表国际化环境中的不同设置。

语法格式：locale [参数]

常用参数：
- -a 查看当前系统所有可用locale
- -m 写入可用字符映射的名称
- -c 写入选定类别的名称
- -k 写入选定关键字的名称

** 查看当前locale设置:
#+begin_src bash
[root@linuxcool ~]# locale
LANG=en_US.UTF-8
LANGUAGE=en_US:en
LC_CTYPE="en_US.UTF-8"
LC_NUMERIC=en_US.UTF-8
LC_TIME=en_US.UTF-8
LC_COLLATE="en_US.UTF-8"
LC_MONETARY=en_US.UTF-8
LC_MESSAGES="en_US.UTF-8"
LC_PAPER=en_US.UTF-8
LC_NAME=en_US.UTF-8
LC_ADDRESS=en_US.UTF-8
LC_TELEPHONE=en_US.UTF-8
LC_MEASUREMENT=en_US.UTF-8
LC_IDENTIFICATION=en_US.UTF-8
LC_ALL=
#+END_SRC
分别介绍下
#+BEGIN_EXAMPLE
LANG：LANG的优先级是最低的，它是所有LC_*变量的默认值，下方所有以LC_开头变量（LC_ALL除外）中，如果存在没有设置变量值的变量，那么系统将会使用LANG的变量值来给这个变量进行赋值。如果变量有值，则保持不变

LC_CTYPE：用于字符分类和字符串处理，控制所有字符的处理方式，包括字符编码，字符是单字节还是多字节，如何打印等，非常重要的一个变量。
LC_NUMERIC：用于格式化非货币的数字显示
LC_TIME：用于格式化时间和日期
LC_COLLATE：用于比较和排序
LC_MONETARY：用于格式化货币单位
LC_MESSAGES：用于控制程序输出时所使用的语言，主要是提示信息，错误信息，状态信息，标题，标签，按钮和菜单等
LC_PAPER：默认纸张尺寸大小
LC_NAME：姓名书写方式
LC_ADDRESS：地址书写方式
LC_TELEPHONE：电话号码书写方式
LC_MEASUREMENT：度量衡表达方式
LC_IDENTIFICATION：locale对自身包含信息的概述

LC_ALL：它不是环境变量，它是一个宏，它可通过该变量的设置覆盖所有LC_*变量，这个变量设置之后，可以废除LC_*的设置值，使得这些变量的设置值与LC_ALL的值一致，注意LANG变量不受影响。

优先级：LC_ALL > LC_* > LANG
#+END_EXAMPLE

** 查看可用的语言环境：
#+begin_src bash
[root@linuxcool ~]# locale -a
C
C.UTF-8
POSIX
#+END_SRC
上面所列的，C是系统默认的locale，POSIX是C的别名，这是标准的C locale ，它所指定的属性和行为由ISO C标准所指定，当我们新安装完一个系统时，默认的locale就是C或POSIX（C就是ASCII编码）
** 设置系统的locale
修改/etc/profile文件
#+begin_src bash
#在最下面增加
export LC_ALL=zh_CN.utf8
export LANG=zh_CN.utf8
#+END_SRC
source一下配置文件，使其生效

修改/etc/default/locale
#+begin_src bash
LANG=“en_US.UTF-8”
LANGUAGE=“en_US:en”
#+END_SRC
注销一下，使其生效

修改/etc/locale.gen文件
#+begin_src bash
...
#en_SG ISO-8859-1
en_US.UTF-8 UTF-8
#en_US ISO-8859-1
…
#+END_SRC
将注释打开即可

修改完成后，执行下locale-gen命令使其生效

命令行模式下修改
#+begin_src bash
localectl set-locale LANG=en_US.UTF-8
#+END_SRC

创建/etc/locale.conf文件
#+begin_src bash
LANG=en_AU.UTF-8
LC_COLLATE=C
LC_TIME=en_DK.UTF-8
#+END_SRC
source使其生效
** locale 没有en_us的解决方法
#+begin_src bash
apt-get update

# Install locales package
apt-get install -y locales

# Uncomment en_US.UTF-8 for inclusion in generation
sed -i 's/^# *\(en_US.UTF-8\)/\1/' /etc/locale.gen

# Generate locale
locale-gen

# Export env vars
echo "export LC_ALL=en_US.UTF-8" >> ~/.bashrc
echo "export LANG=en_US.UTF-8" >> ~/.bashrc
echo "export LANGUAGE=en_US.UTF-8" >> ~/.bashrc
#+END_SRC
* ls命令
-a, –all 列出目录下的所有文件，包括以 . 开头的隐含文件

-A 同-a，但不列出“.”(表示当前目录)和“…”(表示当前目录的父目录)。

-c 配合 -lt：根据 ctime 排序及显示 ctime (文件状态最后更改的时间)配合 -l：显示 ctime 但根据名称排序否则：根据 ctime 排序

-C 每栏由上至下列出项目

–color[=WHEN] 控制是否使用色彩分辨文件。WHEN 可以是’never’、'always’或’auto’其中之一

-d, –directory 将目录象文件一样显示，而不是显示其下的文件。

-D, –dired 产生适合 Emacs 的 dired 模式使用的结果

-f 对输出的文件不进行排序，-aU 选项生效，-lst 选项失效

-g 类似 -l,但不列出所有者

-G, –no-group 不列出任何有关组的信息

-h, –human-readable 以容易理解的格式列出文件大小 (例如 1K 234M 2G)

–si 类似 -h,但文件大小取 1000 的次方而不是 1024

-H, –dereference-command-line 使用命令列中的符号链接指示的真正目的地

–indicator-style=方式 指定在每个项目名称后加上指示符号<方式>：none (默认)，classify (-F)，file-type (-p)

-i, –inode 印出每个文件的 inode 号

-I, –ignore=样式 不印出任何符合 shell 万用字符<样式>的项目

-k 即 –block-size=1K,以 k 字节的形式表示文件的大小。

-l 除了文件名之外，还将文件的权限、所有者、文件大小等信息详细列出来。

-L, –dereference 当显示符号链接的文件信息时，显示符号链接所指示的对象而并非符号链接本身的信息

-m 所有项目以逗号分隔，并填满整行行宽

-o 类似 -l,显示文件的除组信息外的详细信息。

-r, –reverse 依相反次序排列

-R, –recursive 同时列出所有子目录层

-s, –size 以块大小为单位列出所有文件的大小

-S 根据文件大小排序
** 仅列出目录
仅列出目录，下面是 4 种不同的方法。

1. 利用 ls 命令的 -d 选项：
#+begin_src bash
$ ls -d */
Desktop/  pic/  shell/  src/
#+END_SRC

2. 利用 ls 命令的 -F 选项：
#+begin_src bash
$ ls -F |grep "/$"
Desktop/
pic/
shell/
src/
#+END_SRC
-F 选项会给输出的不同文件类型加上一个后缀，比如普通文件会在其后加一个 * 符号，管道文件会在其后加上一个 | 符号，而目录则在其后加上一个 / 符号，因此使用上面的方法也可以实现仅列出目录。

3. 利用 ls 命令的 -l 选项：
#+begin_src bash
$ls -l |grep "^d"
drwxr-xr-x 2 root root 4096 2011-05-08 01:46 Desktop
drwxr-xr-x 2 root root 4096 2012-03-26 10:03 pic
drwxr-xr-x 2 root root 4096 2012-03-30 17:21 shell
drwxr-xr-x 3 root root 4096 2012-03-22 22:18 src
#+END_SRC


上面列出了目录的详细信息，如果只想列出目录名本身，那么可以：
#+begin_src bash
$ls -l |grep "^d" |awk '{print $8}'
Desktop
pic
shell
src
#+END_SRC
** 只显示隐藏文件
可以用ls .* 来显示。但是默认情况下，如果是目录，会显示目录包含的文件，此时可以用-d来避免。
#+begin_src bash
ls -d .*
#+END_SRC
** 基于文件名，大小，时间排序
linux ls命令中，-f 直接列出结果，而不进行排序（ls默认会以文件名排序）；-S 基于文件大小进行排序；-t 基于文件修改时间进行排序；-r 将排序结果反向输出，例如：原本文件名由小到大，反向则由大到小；

1. 基于文件名排序
ls -fl

2. 基于文件大小排序
ls -Sr

3. 基于文件时间排序
ls -tr 
* netstat
Linux netstat 命令用于显示网络状态。

利用 netstat 指令可让你得知整个 Linux 系统的网络情况。

语法：netstat [-acCeFghilMnNoprstuvVwx][-A<网络类型>][--ip]

- -a或--all 显示所有连线中的Socket。
- -A<网络类型>或--<网络类型> 列出该网络类型连线中的相关地址。
- -c或--continuous 持续列出网络状态。
- -C或--cache 显示路由器配置的快取信息。
- -e或--extend 显示网络其他相关信息。
- -F或--fib 显示路由缓存。
- -g或--groups 显示多重广播功能群组组员名单。
- -h或--help 在线帮助。
- -i或--interfaces 显示网络界面信息表单。
- -l或--listening 显示监控中的服务器的Socket。
- -M或--masquerade 显示伪装的网络连线。
- -n或--numeric 直接使用IP地址，而不通过域名服务器。
- -N或--netlink或--symbolic 显示网络硬件外围设备的符号连接名称。
- -o或--timers 显示计时器。
- -p或--programs 显示正在使用Socket的程序识别码和程序名称。
- -r或--route 显示Routing Table。
- -s或--statistics 显示网络工作信息统计表。
- -t或--tcp 显示TCP传输协议的连线状况。
- -u或--udp 显示UDP传输协议的连线状况。
- -v或--verbose 显示指令执行过程。
- -V或--version 显示版本信息。
- -w或--raw 显示RAW传输协议的连线状况。
- -x或--unix 此参数的效果和指定"-A unix"参数相同。
- --ip或--inet 此参数的效果和指定"-A inet"参数相同。

** 实例
*** 显示详细的网络状况
# netstat -a
*** 显示当前户籍UDP连接状况
# netstat -nu
*** 显示UDP端口号的使用情况
# netstat -apu
Active Internet connections (servers and established)
Proto Recv-Q Send-Q Local Address        Foreign Address       State    PID/Program name  
udp    0   0 *:32768           *:*                   -          
udp    0   0 *:nfs            *:*                   -          
udp    0   0 *:641            *:*                   3006/rpc.statd   
udp    0   0 192.168.0.3:netbios-ns   *:*                   3537/nmbd      
udp    0   0 *:netbios-ns        *:*                   3537/nmbd      
udp    0   0 192.168.0.3:netbios-dgm   *:*                   3537/nmbd      
udp    0   0 *:netbios-dgm        *:*                   3537/nmbd      
udp    0   0 *:tftp           *:*                   3346/xinetd     
udp    0   0 *:999            *:*                   3366/rpc.rquotad  
udp    0   0 *:sunrpc          *:*                   2986/portmap    
udp    0   0 *:ipp            *:*                   6938/cupsd     
udp    0   0 *:1022           *:*                   3392/rpc.mountd   
udp    0   0 *:638            *:*                   3006/rpc.statd
*** 显示网卡列表
# netstat -i
Kernel Interface table
Iface    MTU Met  RX-OK RX-ERR RX-DRP RX-OVR  TX-OK TX-ERR TX-DRP TX-OVR Flg
eth0    1500  0  181864   0   0   0  141278   0   0   0 BMRU
lo    16436  0   3362   0   0   0   3362   0   0   0 LRU
*** 显示组播组的关系
# netstat -g
IPv6/IPv4 Group Memberships
Interface    RefCnt Group
--------------- ------ ---------------------
lo       1   ALL-SYSTEMS.MCAST.NET
eth0      1   ALL-SYSTEMS.MCAST.NET
lo       1   ff02::1
eth0      1   ff02::1:ff0a:b0c
eth0      1   ff02::1
*** 显示网络统计信息
# netstat -s
Ip:
  184695 total packets received
  0 forwarded
  0 incoming packets discarded
  184687 incoming packets delivered
  143917 requests sent out
  32 outgoing packets dropped
  30 dropped because of missing route
Icmp:
  676 ICMP messages received
  5 input ICMP message failed.
  ICMP input histogram:
    destination unreachable: 44
    echo requests: 287
    echo replies: 345
  304 ICMP messages sent
  0 ICMP messages failed
  ICMP output histogram:
    destination unreachable: 17
    echo replies: 287
Tcp:
  473 active connections openings
  28 passive connection openings
  4 failed connection attempts
  11 connection resets received
  1 connections established
  178253 segments received
  137936 segments send out
  29 segments retransmited
  0 bad segments received.
  336 resets sent
Udp:
  5714 packets received
  8 packets to unknown port received.
  0 packet receive errors
  5419 packets sent
TcpExt:
  1 resets received for embryonic SYN_RECV sockets
  ArpFilter: 0
  12 TCP sockets finished time wait in fast timer
  572 delayed acks sent
  3 delayed acks further delayed because of locked socket
  13766 packets directly queued to recvmsg prequeue.
  1101482 packets directly received from backlog
  19599861 packets directly received from prequeue
  46860 packets header predicted
  14541 packets header predicted and directly queued to user
  TCPPureAcks: 12259
  TCPHPAcks: 9119
  TCPRenoRecovery: 0
  TCPSackRecovery: 0
  TCPSACKReneging: 0
  TCPFACKReorder: 0
  TCPSACKReorder: 0
  TCPRenoReorder: 0
  TCPTSReorder: 0
  TCPFullUndo: 0
  TCPPartialUndo: 0
  TCPDSACKUndo: 0
  TCPLossUndo: 0
  TCPLoss: 0
  TCPLostRetransmit: 0
  TCPRenoFailures: 0
  TCPSackFailures: 0
  TCPLossFailures: 0
  TCPFastRetrans: 0
  TCPForwardRetrans: 0
  TCPSlowStartRetrans: 0
  TCPTimeouts: 29
  TCPRenoRecoveryFail: 0
  TCPSackRecoveryFail: 0
  TCPSchedulerFailed: 0
  TCPRcvCollapsed: 0
  TCPDSACKOldSent: 0
  TCPDSACKOfoSent: 0
  TCPDSACKRecv: 0
  TCPDSACKOfoRecv: 0
  TCPAbortOnSyn: 0
  TCPAbortOnData: 1
  TCPAbortOnClose: 0
  TCPAbortOnMemory: 0
  TCPAbortOnTimeout: 3
  TCPAbortOnLinger: 0
  TCPAbortFailed: 3
  TCPMemoryPressures: 0
*** 显示监听的套接口
# netstat -l
Active Internet connections (only servers)
Proto Recv-Q Send-Q Local Address        Foreign Address       State   
tcp    0   0 *:32769           *:*             LISTEN   
tcp    0   0 *:nfs            *:*             LISTEN   
tcp    0   0 *:644            *:*             LISTEN   
tcp    0   0 *:1002           *:*             LISTEN   
tcp    0   0 *:netbios-ssn        *:*             LISTEN   
tcp    0   0 *:sunrpc          *:*             LISTEN   
tcp    0   0 vm-dev:ipp         *:*             LISTEN   
tcp    0   0 *:telnet          *:*             LISTEN   
tcp    0   0 *:601            *:*             LISTEN   
tcp    0   0 *:microsoft-ds       *:*             LISTEN   
tcp    0   0 *:http           *:*             LISTEN   
tcp    0   0 *:ssh            *:*             LISTEN   
tcp    0   0 *:https           *:*             LISTEN   
udp    0   0 *:32768           *:*                   
udp    0   0 *:nfs            *:*                   
udp    0   0 *:641            *:*                   
udp    0   0 192.168.0.3:netbios-ns   *:*                   
udp    0   0 *:netbios-ns        *:*                   
udp    0   0 192.168.0.3:netbios-dgm   *:*                   
udp    0   0 *:netbios-dgm        *:*                   
udp    0   0 *:tftp           *:*                   
udp    0   0 *:999            *:*                   
udp    0   0 *:sunrpc          *:*                   
udp    0   0 *:ipp            *:*                   
udp    0   0 *:1022           *:*                   
udp    0   0 *:638            *:*                   
Active UNIX domain sockets (only servers)
Proto RefCnt Flags    Type    State     I-Node Path
unix 2   [ ACC ]   STREAM   LISTENING   10621 @/tmp/fam-root-
unix 2   [ ACC ]   STREAM   LISTENING   7096  /var/run/acpid.socket
unix 2   [ ACC ]   STREAM   LISTENING   9792  /tmp/.gdm_socket
unix 2   [ ACC ]   STREAM   LISTENING   9927  /tmp/.X11-unix/X0
unix 2   [ ACC ]   STREAM   LISTENING   10489 /tmp/ssh-lbUnUf4552/agent.4552
unix 2   [ ACC ]   STREAM   LISTENING   10558 /tmp/ksocket-root/kdeinit__0
unix 2   [ ACC ]   STREAM   LISTENING   10560 /tmp/ksocket-root/kdeinit-:0
unix 2   [ ACC ]   STREAM   LISTENING   10570 /tmp/.ICE-unix/dcop4664-1270815442
unix 2   [ ACC ]   STREAM   LISTENING   10843 /tmp/.ICE-unix/4735
unix 2   [ ACC ]   STREAM   LISTENING   10591 /tmp/ksocket-root/klauncherah3arc.slave-socket
unix 2   [ ACC ]   STREAM   LISTENING   7763  /var/run/iiim/.iiimp-unix/9010
unix 2   [ ACC ]   STREAM   LISTENING   11047 /tmp/orbit-root/linc-1291-0-1e92c8082411
unix 2   [ ACC ]   STREAM   LISTENING   11053 /tmp/orbit-root/linc-128e-0-dc070659cbb3
unix 2   [ ACC ]   STREAM   LISTENING   8020  /var/run/dbus/system_bus_socket
unix 2   [ ACC ]   STREAM   LISTENING   58927 /tmp/mcop-root/vm-dev-2c28-4beba75f
unix 2   [ ACC ]   STREAM   LISTENING   7860  /tmp/.font-unix/fs7100
unix 2   [ ACC ]   STREAM   LISTENING   7658  /dev/gpmctl
unix 2   [ ACC ]   STREAM   LISTENING   10498 @/tmp/dbus-s2MLJGO5Ci
* Node.js安装
在Ubuntu系统上安装nodejs有很多种方法，分别为：apt-get在线安装，下载Node.js源码自己编译安装，下载编译好的文件，使用npm安装等方式。

** 在线安装
在线安装并不推荐，比较坑的一点是安装后node命令不可用，nondejs命令可用。使用在线安装步骤为：在我们安装 nodejs 之前，推荐你将系统更新到最新的补丁和升级包，所以请登录到系统中使用超级用户运行如下命令：

apt-get update，之后apt-get install nodejs。

此外在Node.js官网提供了一种在线安装的方式，我们可以通过

curl -sL https://deb.nodesource.com/setup_7.x | sudo -E bash - 

sudo apt-get install -y nodejs来安装node7.0及以上版本的nodejs。注意：如果在虚拟机上搭建的Linux系统，在执行以上在线安装的命令时网速可能会相当慢，解决办法可以参考这篇文章。

#+DOWNLOADED: screenshot @ 2022-03-07 22:34:16
[[file:images/linux笔记/Node.js安装/2022-03-07_22-34-16_screenshot.png]]

** 源码编译安装
通过源码编译安装。用以下命令来升级系统，并且安装一些Node.js必要的包

apt-get update

apt-get install python gcc make g++

接下来来到Node.js官网下载专区，在下图中红框内选中的标为Source Code的版本上点击鼠标

右键，选择复制下载链接。

#+DOWNLOADED: screenshot @ 2022-03-08 09:52:41
[[file:images/linux笔记/Node.js安装/2022-03-08_09-52-41_screenshot.png]]
执行以下命令：

wget https://nodejs.org/dist/v6.9.2/node-v6.9.2.tar.gz（该地址为Source Code下载地址）

tar -zxvf node-v6.9.2.tar.gz 解压下载的Source Code。

解压完成后依次执行：
#+begin_src bash
cd node-v6.9.2
./configure
make
sudo make install
#+END_SRC
此外，我们还可以使用git在github上将源码clone下来，同样执行以上命令编译安装。

** 下载编译好的文件进行安装
下载编译好的文件。简单说就是解压后，bin文件夹中存在node及npm，如果进入到对应文件中执行命令一点问题没有，不过不是全局的。所以设置为全局就可以了。

wget https://nodejs.org/dist/v6.9.2/node-v6.9.2-linux-x64.tar.xz  --下载
xz -d node-v6.9.2-linux-x64.tar.xz --解压为tar类型
tar -xvf node-v6.9.2-linux-x64.tar  --解压

解压完成后pwd查看当前下载目录，并执行以下命令设置全局：
ln -s /home/zlliu/tcl/node-v6.9.2-linux-64/bin/node /usr/local/node
ln -s /home/zlliu/tcl/node-v6.9.2-linux-64/bin/npm /usr/local/npm
其中/home/zlliu/tcl/这个路径是我下载nodejs存放的路径，你应该改成自己的存放路径。

** 使用npm安装
使用npm安装，首先要下载npm。同样可使用apt-get或者下载npm源码进行安装，安装后可使用npm各种命令，如npm ls，npm install <packageName>等等，我们可用npm指定安装nodejs的版本。
* makefile
** Make命令参数和选项
-b，-m	忽略，提供其他版本 make 的兼容性
-B，--always-make	强制重建所有的规则目标，不根据规则的依赖描述决定是否重建目标文件。
-C DIR，--directory=DIR	在读取 Makefile 之前，进入到目录 DIR，然后执行 make。当存在多个 "-C" 选项的时候，make 的最终工作目录是第一个目录的相对路径。
-d	make 在执行的过程中打印出所有的调试信息，包括 make 认为那些文件需要重建，那些文件需要比较最后的修改时间、比较的结果，重建目标是用的命令，遗憾规则等等。使用 "-d" 选项我们可以看到 make 构造依赖关系链、重建目标过程中的所有的信息。
--debug[=OPTIONS]	make 执行时输出调试信息，可以使用 "OPTIONS" 控制调试信息的级别。默认是 "OPTIONS=b" ，"OPTIONS" 的可值为以下这些，首字母有效：all、basic、verbose、implicit、jobs、makefile。
-e，--enveronment
-overrides	使用环境变量定义覆盖 Makefile 中的同名变量定义。
-f=FILE，--file=FILE，
--makefile=FILE	指定文件 "FILE" 为 make 执行的 Makefile 文件
-p，--help	打印帮助信息。
-i，--ignore-errors	执行过程中忽略规则命令执行的错误。
-I DIR，--include-dir=DIR	指定包含 Makefile 文件的搜索目录，在Makefile中出现另一个 "include" 文件时，将在 "DIR" 目录下搜索。多个 "-i" 指定目录时，搜索目录按照指定的顺序进行。
-j [JOBS]，--jobs[=JOBS]	可指定同时执行的命令数目，爱没有 "-j" 的情况下，执行的命令数目将是系统允许的最大可能数目，存在多个 "-j" 目标时，最后一个目标指定的 JOBS 数有效。
-k，--keep-going	执行命令错误时不终止 make 的执行，make 尽最大可能执行所有的命令，直至出现知名的错误才终止。
-l load，--load-average=[=LOAD]，--max-load[=LOAD]	告诉 make 在存在其他任务执行的时候，如果系统负荷超过 "LOAD"，不在启动新的任务。如果没有指定 "LOAD" 的参数  "-l" 选项将取消之前 "-l" 指定的限制。
-n，--just-print，--dry-run	只打印执行的命令，但是不执行命令。
-o FILE，--old-file=FILE，
--assume-old=FILE	指定 "FILE"文件不需要重建，即使是它的依赖已经过期；同时不重建此依赖文件的任何目标。注意：此参数不会通过变量 "MAKEFLAGS" 传递给子目录进程。
-p，--print-date-base	命令执行之前，打印出 make 读取的 Makefile 的所有数据，同时打印出 make 的版本信息。如果只需要打印这些数据信息，可以使用 "make -qp" 命令，查看 make 执行之前预设的规则和变量，可使用命令 "make -p -f /dev/null"
-q，-question	称为 "询问模式" ；不运行任何的命令，并且无输出。make 只返回一个查询状态。返回状态 0 表示没有目标表示重建，返回状态 1 表示存在需要重建的目标，返回状态 2 表示有错误发生。
-r，--no-builtin-rules	取消所有的内嵌函数的规则，不过你可以在 Makefile 中使用模式规则来定义规则。同时选项 "-r" 会取消所有后缀规则的隐含后缀列表，同样我们可以在 Makefile 中使用 ".SUFFIXES"，定义我们的后缀名的规则。"-r" 选项不会取消 make 内嵌的隐含变量。
-R，--no-builtin-variabes	取消 make 内嵌的隐含变量，不过我们可以在 Makefile 中明确定义某些变量。注意："-R" 和 "-r" 选项同时打开，因为没有了隐含变量，所以隐含规则将失去意义。
-s，--silent，--quiet	取消命令执行过程中的打印。
-S，--no-keep-going，
--stop	取消 "-k" 的选项在递归的 make 过程中子 make 通过 "MAKEFLAGS" 变量继承了上层的命令行选项那个。我们可以在子 make 中使用“-S”选项取消上层传递的 "-k" 选项，或者取消系统环境变量 "MAKEFLAGS" 中 "-k"选项。
-t，--touch	和 Linux 的 touch 命令实现功能相同，更新所有的目标文件的时间戳到当前系统时间。防止 make 对所有过时目标文件的重建。
-v，version	查看make的版本信息。
-w，--print-directory	在 make 进入一个子目录读取 Makefile 之前打印工作目录，这个选项可以帮助我们调试 Makefile，跟踪定位错误。使用 "-C" 选项时默认打开这个选项。
--no-print-directory	取消 "-w" 选项。可以是 用在递归的 make 调用的过程中 ，取消 "-C" 参数的默认打开 "-w" 的功能。
-W FILE，--what-if=FILE，
--new-file=FILE，
--assume-file=FILE	设定文件 "FILE" 的时间戳为当前的时间，但不更改文件实际的最后修改时间。此选项主要是为了实现对所有依赖于文件 "FILE" 的目标的强制重建。
--warn-undefined-variables	在发现 Makefile 中存在没有定义的变量进行引用时给出告警信息。此功能可以帮助我们在调试一个存在多级嵌套变量引用的复杂 Makefile。但是建议在书写的时候尽量避免超过三级以上的变量嵌套引用。
** 语法规则
#+begin_src bash
target ... : prerequisites ...
    command
    ...
    ...

#+END_SRC
或是这样：
#+begin_src bash
targets : prerequisites ; command
    command
    ...
#+END_SRC
这是一个文件的依赖关系，
也就是说，target这一个或多个的目标文件依赖于prerequisites中的文件，其生成规则定义在command中。

在Makefile中的命令，必须要以 Tab 键开始。
*** target
可以是一个object file（目标文件），也可以是一个执行文件，还可以是一个标签（label），以空格分开，可以使用通配符。

*** prerequisites
生成该target所依赖的文件和/或target。

如果其中的某个文件要比目标文件要新，那么，目标就被认为是“过时的”，被认为是需要重生成的。
*** command
该target要执行的命令（任意的shell命令）

如果其不与“target:prerequisites”在一行，那么，必须以 Tab 键开头，如果和prerequisites在一行，那么可以用分号做为分隔。

如果命令太长，你可以使用反斜杠（ \ ）作为换行符。make对一行上有多少个字符没有限制。规则告诉make两件事，文件的依赖关系和如何生成目标文件。

一般来说，make会以UNIX的标准Shell，也就是 /bin/sh 来执行命令。

如果想用其他键，可以用内置变量.RECIPEPREFIX声明。
#+begin_src 
.RECIPEPREFIX = >
all:
> echo Hello, world
#+end_src
上面代码用.RECIPEPREFIX指定，大于号（>）替代tab键。所以，每一行命令的起首变成了大于号，而不是tab键。

需要注意的是，每行命令在一个单独的shell中执行。这些Shell之间没有继承关系。
#+begin_src 
var-lost:
    export foo=bar
    echo "foo=[$$foo]"
#+end_src
上面代码执行后（make var-lost），取不到foo的值。因为两行命令在两个不同的进程执行。一个解决办法是将两行命令写在一行，中间用分号分隔。
#+begin_src
var-kept:
    export foo=bar; echo "foo=[$$foo]"
#+end_src
另一个解决办法是在换行符前加反斜杠转义。
#+begin_src
var-kept:
    export foo=bar; \
    echo "foo=[$$foo]"
#+end_src
最后一个方法是加上.ONESHELL:命令。
#+begin_src
.ONESHELL:
var-kept:
    export foo=bar; 
    echo "foo=[$$foo]"
#+end_src
** make工作方式
#+begin_src makefile
edit : main.o kbd.o command.o display.o \
        insert.o search.o files.o utils.o
    cc -o edit main.o kbd.o command.o display.o \
        insert.o search.o files.o utils.o

main.o : main.c defs.h
    cc -c main.c
kbd.o : kbd.c defs.h command.h
    cc -c kbd.c
command.o : command.c defs.h command.h
    cc -c command.c
display.o : display.c defs.h buffer.h
    cc -c display.c
insert.o : insert.c defs.h buffer.h
    cc -c insert.c
search.o : search.c defs.h buffer.h
    cc -c search.c
files.o : files.c defs.h buffer.h command.h
    cc -c files.c
utils.o : utils.c defs.h
    cc -c utils.c
clean :
    rm edit main.o kbd.o command.o display.o \
        insert.o search.o files.o utils.o
#+END_SRC
make会在当前目录下找名字叫“Makefile”或“makefile”的文件。

如果找到，它会找文件中的第一个目标文件（target），在上面的例子中，他会找到“edit”这个文件，并把这个文件作为最终的目标文件。

如果edit文件不存在，或是edit所依赖的后面的 .o 文件的文件修改时间要比 edit 这个文件新，那么，他就会执行后面所定义的命令来生成 edit 这个文件。

如果 edit 所依赖的 .o 文件也不存在，那么make会在当前文件中找目标为 .o 文件的依赖性，如果找到则再根据那一个规则生成 .o 文件。（这有点像一个堆栈的过程）

当然，你的C文件和H文件是存在的啦，于是make会生成 .o 文件，然后再用 .o 文件生成make的终极任务，也就是执行文件 edit 了。
** 变量
变量的定义：
#+BEGIN_SRC makefile
objects = main.o kbd.o command.o display.o \
     insert.o search.o files.o utils.o
#+END_SRC
makefile以 $(objects) 的方式来使用变量。

#+BEGIN_SRC makefile
objects = main.o kbd.o command.o display.o \
    insert.o search.o files.o utils.o

edit : $(objects)
    cc -o edit $(objects)
main.o : main.c defs.h
    cc -c main.c
kbd.o : kbd.c defs.h command.h
    cc -c kbd.c
command.o : command.c defs.h command.h
    cc -c command.c
display.o : display.c defs.h buffer.h
    cc -c display.c
insert.o : insert.c defs.h buffer.h
    cc -c insert.c
search.o : search.c defs.h buffer.h
    cc -c search.c
files.o : files.c defs.h buffer.h command.h
    cc -c files.c
utils.o : utils.c defs.h
    cc -c utils.c
clean :
    rm edit $(objects)
#+END_SRC
*** 使用变量
在Makefile中的定义的变量，就像是C/C++语言中的宏一样，他代表了一个文本字串，在Makefile中执行的时候其会自动原模原样地展开在所使用的地方。其与C/C++所不同的是，你可以在Makefile中改变其值。在Makefile中，变量可以使用在“目标”，“依赖目标”， “命令”或是Makefile的其它部分中。

变量的命名字可以包含字符、数字，下划线（可以是数字开头），但不应该含有 : 、 # 、 = 或是空字符（空格、回车等）。变量是大小写敏感的，“foo”、“Foo”和“FOO”是三个不同的变量名。传统的Makefile的变量名是全大写的命名方式，但我推荐使用大小写搭配的变量名，如：MakeFlags。这样可以避免和系统的变量冲突，而发生意外的事情。

有一些变量是很奇怪字串，如 $< 、 $@ 等，这些是自动化变量
*** 变量的基础
变量在声明时需要给予初值，而在使用时，需要给在变量名前加上 $ 符号，但最好用小括号 () 或是大括号 {} 把变量给包括起来。如果你要使用真实的 $ 字符，那么你需要用 $$ 来表示。

变量可以使用在许多地方，如规则中的“目标”、“依赖”、“命令”以及新的变量中。先看一个例子：
#+begin_src makefile
objects = program.o foo.o utils.o
program : $(objects)
    cc -o program $(objects)

$(objects) : defs.h
#+END_SRC
变量会在使用它的地方精确地展开，就像C/C++中的宏一样，例如：
#+begin_src makefile
foo = c
prog.o : prog.$(foo)
    $(foo)$(foo) -$(foo) prog.$(foo)

#+END_SRC
展开后得到：
#+begin_src makefile
prog.o : prog.c
    cc -c prog.c

#+END_SRC
当然，千万不要在你的Makefile中这样干，这里只是举个例子来表明Makefile中的变量在使用处展开的真实样子。可见其就是一个“替代”的原理。

另外，给变量加上括号完全是为了更加安全地使用这个变量，在上面的例子中，如果你不想给变量加上括号，那也可以，但我还是强烈建议你给变量加上括号。
*** 变量中的变量
在定义变量的值时，我们可以使用其它变量来构造变量的值，在Makefile中有两种方式来在用变量定义变量的值。

先看第一种方式，也就是简单的使用 = 号，在 = 左侧是变量，右侧是变量的值，右侧变量的值可以定义在文件的任何一处，也就是说，右侧中的变量不一定非要是已定义好的值，其也可以使用后面定义的值。如：
#+begin_src makefile
foo = $(bar)
bar = $(ugh)
ugh = Huh?

all:
    echo $(foo)

#+END_SRC
我们执行“make all”将会打出变量 $(foo) 的值是 Huh? （ $(foo) 的值是 $(bar) ， $(bar) 的值是 $(ugh) ， $(ugh) 的值是 Huh? ）可见，变量是可以使用后面的变量来定义的。

这个功能有好的地方，也有不好的地方，好的地方是，我们可以把变量的真实值推到后面来定义，如：
#+begin_src makefile
CFLAGS = $(include_dirs) -O
include_dirs = -Ifoo -Ibar

#+END_SRC
当 CFLAGS 在命令中被展开时，会是 -Ifoo -Ibar -O 。但这种形式也有不好的地方，那就是递归定义，如：
#+begin_src makefile
CFLAGS = $(CFLAGS) -O

#+END_SRC
或：
#+begin_src makefile
A = $(B)
B = $(A)

#+END_SRC
这会让make陷入无限的变量展开过程中去，当然，我们的make是有能力检测这样的定义，并会报错。还有就是如果在变量中使用函数，那么，这种方式会让我们的make运行时非常慢，更糟糕的是，他会使用得两个make的函数“wildcard”和“shell”发生不可预知的错误。因为你不会知道这两个函数会被调用多少次。

为了避免上面的这种方法，我们可以使用make中的另一种用变量来定义变量的方法。这种方法使用的是 := 操作符，如：
#+begin_src makefile
x := foo
y := $(x) bar
x := later

#+END_SRC
其等价于：
#+begin_src makefile
y := foo bar
x := later

#+END_SRC
值得一提的是，这种方法，前面的变量不能使用后面的变量，只能使用前面已定义好了的变量。如果是这样：
#+begin_src makefile
y := $(x) bar
x := foo

#+END_SRC
那么，y的值是“bar”，而不是“foo bar”。

上面都是一些比较简单的变量使用了，让我们来看一个复杂的例子，其中包括了make的函数、条件表达式和一个系统变量“MAKELEVEL”的使用：
#+begin_src makefile
ifeq (0,${MAKELEVEL})
cur-dir   := $(shell pwd)
whoami    := $(shell whoami)
host-type := $(shell arch)
MAKE := ${MAKE} host-type=${host-type} whoami=${whoami}
endif

#+END_SRC
关于条件表达式和函数，我们在后面再说，对于系统变量“MAKELEVEL”，其意思是，如果我们的make有一个嵌套执行的动作（参见前面的“嵌套使用make”），那么，这个变量会记录了我们的当前Makefile的调用层数。

下面再介绍两个定义变量时我们需要知道的，请先看一个例子，如果我们要定义一个变量，其值是一个空格，那么我们可以这样来：
#+begin_src makefile
nullstring :=
space := $(nullstring) # end of the line

#+END_SRC
nullstring是一个Empty变量，其中什么也没有，而我们的space的值是一个空格。因为在操作符的右边是很难描述一个空格的，这里采用的技术很管用，先用一个Empty变量来标明变量的值开始了，而后面采用“#”注释符来表示变量定义的终止，这样，我们可以定义出其值是一个空格的变量。请注意这里关于“#”的使用，注释符“#”的这种特性值得我们注意，如果我们这样定义一个变量：
#+begin_src makefile
dir := /foo/bar    # directory to put the frobs in

#+END_SRC
dir这个变量的值是“/foo/bar”，后面还跟了4个空格，如果我们这样使用这样变量来指定别的目录——“$(dir)/file”那么就完蛋了。

还有一个比较有用的操作符是 ?= ，先看示例：
#+begin_src makefile
FOO ?= bar

#+END_SRC
其含义是，如果FOO没有被定义过，那么变量FOO的值就是“bar”，如果FOO先前被定义过，那么这条语将什么也不做，其等价于：
#+begin_src makefile
ifeq ($(origin FOO), undefined)
    FOO = bar
endif

#+END_SRC
*** 变量高级用法（替换和嵌套使用）
这里介绍两种变量的高级使用方法，第一种是变量值的替换。

我们可以替换变量中的共有的部分，其格式是 $(var:a=b) 或是 ${var:a=b} ，其意思是，把变量“var”中所有以“a”字串“结尾”的“a”替换成“b”字串。这里的“结尾”意思是“空格”或是“结束符”。

还是看一个示例吧：
#+begin_src makefile
foo := a.o b.o c.o
bar := $(foo:.o=.c)

#+END_SRC
这个示例中，我们先定义了一个 $(foo) 变量，而第二行的意思是把 $(foo) 中所有以 .o 字串“结尾”全部替换成 .c ，所以我们的 $(bar) 的值就是“a.c b.c c.c”。

另外一种变量替换的技术是以“静态模式”（参见前面章节）定义的，如：
#+begin_src makefile
foo := a.o b.o c.o
bar := $(foo:%.o=%.c)

#+END_SRC
这依赖于被替换字串中的有相同的模式，模式中必须包含一个 % 字符，这个例子同样让 $(bar) 变量的值为“a.c b.c c.c”。

第二种高级用法是——“把变量的值再当成变量”。先看一个例子：
#+begin_src makefile
x = y
y = z
a := $($(x))

#+END_SRC
在这个例子中，$(x)的值是“y”，所以$($(x))就是$(y)，于是$(a)的值就是“z”。（注意，是“x=y”，而不是“x=$(y)”）

我们还可以使用更多的层次：
#+begin_src makefile
x = y
y = z
z = u
a := $($($(x)))

#+END_SRC
这里的 $(a) 的值是“u”。

让我们再复杂一点，使用上“在变量定义中使用变量”的第一个方式，来看一个例子：
#+begin_src makefile
x = $(y)
y = z
z = Hello
a := $($(x))

#+END_SRC
这里的 $($(x)) 被替换成了 $($(y)) ，因为 $(y) 值是“z”，所以，最终结果是： a:=$(z) ，也就是“Hello”。

再复杂一点，我们再加上函数：
#+begin_src makefile
x = variable1
variable2 := Hello
y = $(subst 1,2,$(x))
z = y
a := $($($(z)))

#+END_SRC
这个例子中， $($($(z))) 扩展为 $($(y)) ，而其再次被扩展为 $($(subst 1,2,$(x))) 。 $(x) 的值是“variable1”，subst函数把“variable1”中的所有“1”字串替换成“2”字串，于是，“variable1”变成 “variable2”，再取其值，所以，最终， $(a) 的值就是 $(variable2) 的值——“Hello”。（喔，好不容易）

在这种方式中，或要可以使用多个变量来组成一个变量的名字，然后再取其值：
#+begin_src makefile
first_second = Hello
a = first
b = second
all = $($a_$b)

#+END_SRC
这里的 $a_$b 组成了“first_second”，于是， $(all) 的值就是“Hello”。

再来看看结合第一种技术的例子：
#+begin_src makefile
a_objects := a.o b.o c.o
1_objects := 1.o 2.o 3.o

sources := $($(a1)_objects:.o=.c)

#+END_SRC
这个例子中，如果 $(a1) 的值是“a”的话，那么， $(sources) 的值就是“a.c b.c c.c”；如果 $(a1) 的值是“1”，那么 $(sources) 的值是“1.c 2.c 3.c”。

再来看一个这种技术和“函数”与“条件语句”一同使用的例子：
#+begin_src makefile
ifdef do_sort
    func := sort
else
    func := strip
endif

bar := a d b g q c

foo := $($(func) $(bar))

#+END_SRC
这个示例中，如果定义了“do_sort”，那么： foo := $(sort a d b g q c) ，于是 $(foo) 的值就是 “a b c d g q”，而如果没有定义“do_sort”，那么： foo := $(strip a d b g q c) ，调用的就是strip函数。

当然，“把变量的值再当成变量”这种技术，同样可以用在操作符的左边:
#+begin_src makefile
dir = foo
$(dir)_sources := $(wildcard $(dir)/*.c)
define $(dir)_print
lpr $($(dir)_sources)
endef

#+END_SRC
这个例子中定义了三个变量：“dir”，“foo_sources”和“foo_print”。
*** 追加变量值
我们可以使用 += 操作符给变量追加值，如：
#+begin_src makefile
objects = main.o foo.o bar.o utils.o
objects += another.o

#+END_SRC
于是，我们的 $(objects) 值变成：“main.o foo.o bar.o utils.o another.o”（another.o被追加进去了）

使用 += 操作符，可以模拟为下面的这种例子：
#+begin_src makefile
objects = main.o foo.o bar.o utils.o
objects := $(objects) another.o

#+END_SRC
所不同的是，用 += 更为简洁。

如果变量之前没有定义过，那么， += 会自动变成 = ，如果前面有变量定义，那么 += 会继承于前次操作的赋值符。如果前一次的是 := ，那么 += 会以 := 作为其赋值符，如：
#+begin_src makefile
variable := value
variable += more

#+END_SRC
等价于：
#+begin_src makefile
variable := value
variable := $(variable) more

#+END_SRC
但如果是这种情况：
#+begin_src makefile
variable = value
variable += more

#+END_SRC
由于前次的赋值符是 = ，所以 += 也会以 = 来做为赋值，那么岂不会发生变量的递补归定义，这是很不好的，所以make会自动为我们解决这个问题，我们不必担心这个问题。
*** override 指示符
如果有变量是通常make的命令行参数设置的，那么Makefile中对这个变量的赋值会被忽略。如果你想在Makefile中设置这类参数的值，那么，你可以使用“override”指示符。其语法是:
#+begin_src makefile
override <variable>; = <value>;

override <variable>; := <value>;

#+END_SRC
当然，你还可以追加:
#+begin_src makefile
override <variable>; += <more text>;

#+END_SRC
对于多行的变量定义，我们用define指示符，在define指示符前，也同样可以使用override指示符，如:
#+begin_src makefile
override define foo
bar
endef

#+END_SRC
*** 多行变量
还有一种设置变量值的方法是使用define关键字。使用define关键字设置变量的值可以有换行，这有利于定义一系列的命令（前面我们讲过“命令包”的技术就是利用这个关键字）。

define指示符后面跟的是变量的名字，而重起一行定义变量的值，定义是以endef 关键字结束。其工作方式和“=”操作符一样。变量的值可以包含函数、命令、文字，或是其它变量。因为命令需要以[Tab]键开头，所以如果你用define定义的命令变量中没有以 Tab 键开头，那么make 就不会把其认为是命令。

下面的这个示例展示了define的用法:
#+begin_src makefile
define two-lines
echo foo
echo $(bar)
endef

#+END_SRC
*** 环境变量
make运行时的系统环境变量可以在make开始运行时被载入到Makefile文件中，但是如果Makefile中已定义了这个变量，或是这个变量由make命令行带入，那么系统的环境变量的值将被覆盖。（如果make指定了“-e”参数，那么，系统环境变量将覆盖Makefile中定义的变量）

因此，如果我们在环境变量中设置了 CFLAGS 环境变量，那么我们就可以在所有的Makefile中使用这个变量了。这对于我们使用统一的编译参数有比较大的好处。如果Makefile中定义了CFLAGS，那么则会使用Makefile中的这个变量，如果没有定义则使用系统环境变量的值，一个共性和个性的统一，很像“全局变量”和“局部变量”的特性。

当make嵌套调用时（参见前面的“嵌套调用”章节），上层Makefile中定义的变量会以系统环境变量的方式传递到下层的Makefile 中。当然，默认情况下，只有通过命令行设置的变量会被传递。而定义在文件中的变量，如果要向下层Makefile传递，则需要使用export关键字来声明。（参见前面章节）

当然，我并不推荐把许多的变量都定义在系统环境中，这样，在我们执行不用的Makefile时，拥有的是同一套系统变量，这可能会带来更多的麻烦。
*** 目标变量
前面我们所讲的在Makefile中定义的变量都是“全局变量”，在整个文件，我们都可以访问这些变量。当然，“自动化变量”除外，如 $< 等这种类量的自动化变量就属于“规则型变量”，这种变量的值依赖于规则的目标和依赖目标的定义。

当然，我也同样可以为某个目标设置局部变量，这种变量被称为“Target-specific Variable”，它可以和“全局变量”同名，因为它的作用范围只在这条规则以及连带规则中，所以其值也只在作用范围内有效。而不会影响规则链以外的全局变量的值。

其语法是：
#+begin_src makefile
<target ...> : <variable-assignment>;

<target ...> : overide <variable-assignment>

#+END_SRC
<variable-assignment>;可以是前面讲过的各种赋值表达式，如 = 、 := 、 += 或是 ?= 。第二个语法是针对于make命令行带入的变量，或是系统环境变量。

这个特性非常的有用，当我们设置了这样一个变量，这个变量会作用到由这个目标所引发的所有的规则中去。如：
#+begin_src makefile
prog : CFLAGS = -g
prog : prog.o foo.o bar.o
    $(CC) $(CFLAGS) prog.o foo.o bar.o

prog.o : prog.c
    $(CC) $(CFLAGS) prog.c

foo.o : foo.c
    $(CC) $(CFLAGS) foo.c

bar.o : bar.c
    $(CC) $(CFLAGS) bar.c

#+END_SRC
在这个示例中，不管全局的 $(CFLAGS) 的值是什么，在prog目标，以及其所引发的所有规则中（prog.o foo.o bar.o的规则）， $(CFLAGS) 的值都是 -g
*** 模式变量
在GNU的make中，还支持模式变量（Pattern-specific Variable），通过上面的目标变量中，我们知道，变量可以定义在某个目标上。模式变量的好处就是，我们可以给定一种“模式”，可以把变量定义在符合这种模式的所有目标上。

我们知道，make的“模式”一般是至少含有一个 % 的，所以，我们可以以如下方式给所有以 .o 结尾的目标定义目标变量：
#+begin_src makefile
%.o : CFLAGS = -O

#+END_SRC
同样，模式变量的语法和“目标变量”一样：
#+begin_src makefile
<pattern ...>; : <variable-assignment>;

<pattern ...>; : override <variable-assignment>;

#+END_SRC
override同样是针对于系统环境传入的变量，或是make命令行指定的变量。
** make的推导以及文件功能
只要make看到一个 .o 文件，它就会自动的把 .c 文件加在依赖关系中，
如果make找到一个 whatever.o ，那么 whatever.c 就会是 whatever.o 的依赖文件。并且 cc -c whatever.c 也会被推导出来
#+BEGIN_SRC makefile
objects = main.o kbd.o command.o display.o \
    insert.o search.o files.o utils.o

edit : $(objects)
    cc -o edit $(objects)

main.o : defs.h
kbd.o : defs.h command.h
command.o : defs.h command.h
display.o : defs.h buffer.h
insert.o : defs.h buffer.h
search.o : defs.h buffer.h
files.o : defs.h buffer.h command.h
utils.o : defs.h

.PHONY : clean
clean :
    rm edit $(objects)
#+END_SRC
这种方法，也就是make的“隐晦规则”。上面文件内容中， .PHONY 表示 clean 是个伪目标文件。

可以用文件功能将上面重复出现的.h文件收拢起来写到一起
#+BEGIN_SRC makefile
objects = main.o kbd.o command.o display.o \
    insert.o search.o files.o utils.o

edit : $(objects)
    cc -o edit $(objects)

$(objects) : defs.h
kbd.o command.o files.o : command.h
display.o insert.o search.o files.o : buffer.h

.PHONY : clean
clean :
    rm edit $(objects)
#+END_SRC
** 清空目标文件的规则
每个Makefile中都应该写一个清空目标文件（ .o 和执行文件）的规则，这不仅便于重编译，也很利于保持文件的清洁。
一般的风格都是：
#+BEGIN_SRC makefile
clean:
    rm edit $(objects)
#+END_SRC
更为稳健的做法是：
#+BEGIN_SRC makefile
.PHONY : clean
clean :
    -rm edit $(objects)
#+END_SRC
前面说过， .PHONY 表示 clean 是一个“伪目标”。
而在 rm 命令前面加了一个小减号的意思就是，也许某些文件出现问题，但不要管，继续做后面的事。
** Makefile的文件名
默认的情况下，make命令会在当前目录下按顺序找寻文件名为“GNUmakefile”、“makefile”、“Makefile”的文件，找到了解释这个文件。

可以使用别的文件名来书写Makefile，比如：“Make.Linux”，“Make.Solaris”，“Make.AIX”等，

如果要指定特定的Makefile，你可以使用make的 -f 和 --file 参数，如： make -f Make.Linux 或 make --file Make.AIX 。
** include
在Makefile使用 include 关键字可以把别的Makefile包含进来，这很像C语言的 #include ，被包含的文件会原模原样的放在当前文件的包含位置。 

include 的语法是：
#+begin_src bash
include <filename>
#+END_SRC
filename 可以是当前操作系统Shell的文件模式（可以包含路径和通配符）。

在 include 前面可以有一些空字符，但是绝不能是 Tab 键开始。 
include 和 <filename> 可以用一个或多个空格隔开。
举个例子，你有这样几个Makefile： a.mk 、 b.mk 、 c.mk ，还有一个文件叫 foo.make ，以及一个变量 $(bar) ，其包含了 e.mk 和 f.mk ，那么，下面的语句：
#+begin_src bash
include foo.make *.mk $(bar)
#+END_SRC
等价于：
#+begin_src bash
include foo.make a.mk b.mk c.mk e.mk f.mk
#+END_SRC
make命令开始时，会找寻 include 所指出的其它Makefile，并把其内容安置在当前的位置。就好像C/C++的 #include 指令一样。
如果文件都没有指定绝对路径或是相对路径的话，make会在当前目录下首先寻找，
如果当前目录下没有找到，那么，make还会在下面的几个目录下找：
- 如果make执行时，有 -I 或 --include-dir 参数，那么make就会在这个参数所指定的目录下去寻找。
- 如果目录 <prefix>/include （一般是： /usr/local/bin 或 /usr/include ）存在的话，make也会去找。

如果有文件没有找到的话，make会生成一条警告信息，但不会马上出现致命错误。
它会继续载入其它的文件，一旦完成makefile的读取，make会再重试这些没有找到，或是不能读取的文件，如果还是不行，make才会出现一条致命信息。
如果你想让make不理那些无法读取的文件，而继续执行，你可以在include前加一个减号“-”。如：
#+begin_src bash
-include <filename>
#+END_SRC
其表示，无论include过程中出现什么错误，都不要报错继续执行。和其它版本make兼容的相关命令是sinclude，其作用和这一个是一样的。
** 环境变量MAKEFILES
如果你的当前环境中定义了环境变量 MAKEFILES ，那么，make会把这个变量中的值做一个类似于 include 的动作。
这个变量中的值是其它的Makefile，用空格分隔。只是，它和 include 不同的是，从这个环境变量中引入的Makefile的“目标”不会起作用，如果环境变量中定义的文件发现错误，make也会不理。

但是在这里我还是建议不要使用这个环境变量，因为只要这个变量一被定义，那么当你使用make时，所有的Makefile都会受到它的影响，这绝不是你想看到的。
在这里提这个事，只是为了告诉大家，也许有时候你的Makefile出现了怪事，那么你可以看看当前环境中有没有定义这个变量。
** 通配符
make支持三个通配符： * ， ? 和 ~ 。
这和Unix的B-Shell是相同的。

#+begin_src makefile
objects = *.o
#+END_SRC
上面例子中objects的值就是 *.o ，而不是 *.o 展开后的值。

Makefile中的变量其实就是C/C++中的宏。如果你要让通配符在变量中展开，也就是让objects的值是所有 .o 的文件名的集合，那么，你可以这样：
#+begin_src makefile
objects := $(wildcard *.o)
#+END_SRC

另给一个变量使用通配符的例子：
1. 列出一确定文件夹中的所有 .c 文件。
#+begin_src makefile
objects := $(wildcard *.c)
#+END_SRC
2. 列出(1)中所有文件对应的 .o 文件，在（3）中我们可以看到它是由make自动编译出的:
#+begin_src makefile
$(patsubst %.c,%.o,$(wildcard *.c))
#+END_SRC
3. 由(1)(2)两步，可写出编译并链接所有 .c 和 .o 文件
#+begin_src makefile
objects := $(patsubst %.c,%.o,$(wildcard *.c))
foo : $(objects)
    cc -o foo $(objects)
#+END_SRC
这种用法由关键字“wildcard”，“patsubst”指出，
** VPATH文件寻找
如果没有指明VPATH变量，make只会在当前的目录中去找寻依赖文件和目标文件。

如果定义了VPATH变量，那么，make就会在当前目录找不到的情况下，到所指定的目录中去找寻文件。

#+begin_src makefile
VPATH = src:../headers
#+END_SRC
上面的定义指定两个目录，“src”和“../headers”，make会按照这个顺序进行搜索。目录由“冒号”分隔。（当然，当前目录永远是最高优先搜索的地方）

另一个设置文件搜索路径的方法是使用make的“vpath”关键字（注意，它是全小写的），这不是变量，这是一个make的关键字，这和上面提到的那个VPATH变量很类似，但是它更为灵活。它可以指定不同的文件在不同的搜索目录中。

这是一个很灵活的功能。它的使用方法有三种：
#+BEGIN_EXAMPLE
vpath <pattern> <directories>
为符合模式<pattern>的文件指定搜索目录<directories>。

vpath <pattern>
清除符合模式<pattern>的文件的搜索目录。

vpath
清除所有已被设置好了的文件搜索目录。
#+END_EXAMPLE
vpath使用方法中的<pattern>需要包含 % 字符。 

% 的意思是匹配零或若干字符，（需引用 % ，使用 \ ）例如， %.h 表示所有以 .h 结尾的文件。

<pattern>指定了要搜索的文件集，而<directories>则指定了< pattern>的文件集的搜索的目录。例如：
#+begin_src makefile
vpath %.h ../headers
#+END_SRC
该语句表示，要求make在“../headers”目录下搜索所有以 .h 结尾的文件。（如果某文件在当前目录没有找到的话）

我们可以连续地使用vpath语句，以指定不同搜索策略。

如果连续的vpath语句中出现了相同的<pattern> ，或是被重复了的<pattern>，那么，make会按照vpath语句的先后顺序来执行搜索。如：
#+begin_src makefile
vpath %.c foo
vpath %   blish
vpath %.c bar
#+END_SRC
其表示 .c 结尾的文件，先在“foo”目录，然后是“blish”，最后是“bar”目录。
#+begin_src makefile
vpath %.c foo:bar
vpath %   blish
#+END_SRC
而上面的语句则表示 .c 结尾的文件，先在“foo”目录，然后是“bar”目录，最后才是“blish”目录。
** 伪目标
伪目标是这样一个目标：它不代表一个真正的文件名，在执行make时可以指定这个目标来执行其所在规则定义的命令，有时我们也可以将一个伪目标称为标签。使用伪目标有两点原因：
1. 避免在我们的Makefile中定义的只执行命令的的目标（此目标的目的为了执行执行一系列命令，而不需要创建这个目标）和工作目录下的实际文件出现名字冲突。
2. 提高执行make时的效率.

如果我们需要书写这样一个规则：规则所定义的命令不是去创建目标文件，而是使用make指定具体的目标来执一些特定的命令。像下边那样：
#+begin_src makefile
clean: 
rm *.o temp 
#+END_SRC
规则中rm不是创建文件clean的命令，只是删除当前目录下的所有.o文件和temp文件。

在工作目录下不存在clean这个文件时，我们输入make clean后，rm *.o temp总会被执行。这是我们的初衷。

但当前工作目录下存在文件clean时情况就不一样了，在我们输入make clean时。

规则没有依赖文件，所以目标被认为是最新的而不去执行规则作定义的命令，命令rm将不会被执行。这并不是我们的初衷。

为了避免这个问题，我们可以将目标clean明确的声明为伪目标。

将一个目标声明为伪目标需要将它作为特殊目标.PHONY的依赖。如下：
#+begin_src makefile
.PHONY : clean 
#+END_SRC
这样目标clean就是一个伪目标，无论当前目录下是否存在clean这个文件。

当我们输入make clean之后，rm命令都会被执行。

而且，当一个目标被声明为伪目标后，make在执行此规则时不会试图去查找隐含规则来创建这个目标。

这样也提高了make的执行效率，同时我们也不用担心由于目标和文件名重名而使我们的期望失败。

在书写伪目标规则时，首先需要声明目标是一个伪目标，之后才是伪目标的规则定义。

目标clean书写格式应该如下：
#+begin_src makefile
.PHONY: clean 
clean: 
rm *.o temp 
#+END_SRC
伪目标的另外一使用场合在make的并行和递归执行过程中。

此情况下一般存在一个变量，其定义为所有需要make的子目录。

对多个目录进行make的实现方式可以在一个规则中可以使用shell的循环来完成。

如下：
#+begin_src makefile
SUBDIRS = foo bar baz 
subdirs: 
for dir in $(SUBDIRS); do \ 
$(MAKE) -C $$dir; \ 
done 
#+END_SRC
但这种实现方法存在以下几个问题。

当子目录执行make出现错误时，make不会退出。

就是说，在对某一个目录执行make失败以后，会继续对其他的目录进行make。

在最终执行失败的情况下，我们很难根据错误的提示定位出具体是是那个目录下的Makefile出现错误。

这给问题定位造成了很大的困难。为了避免这样的问题，我们可以在命令行部分加入错误的监测，在命令执行错误后make退出。

不幸的是，如果在执行make时使用了-k选项，此方式将失效。

另外一个问题就是使用这种shell的循环方式时，没有用到make对目录的并行处理功能，因为规则的命令是一条完整的shell命令，不能被并行的执行。

我们可以通过伪目标方式来克服以上实现方式所存在的两个问题。
#+begin_src makefile
SUBDIRS = foo bar baz 
.PHONY: subdirs $(SUBDIRS) 
subdirs: $(SUBDIRS) 
$(SUBDIRS): 
$(MAKE) -C $@ 
foo: baz 
#+END_SRC
上边的实现中使用了一个没有命令行的规则foo: baz，用来限制子目录的make顺序。

此规则的含义时在处理foo目录之前，需要等待baz目录处理完成。

在书写一个并行执行make的Makefile时，目录的处理顺序是需要特别注意的。

一般情况下，一个伪目标不作为一个另外一个目标文件的依赖。

这是因为当一个目标文件的依赖包含伪目标时，每一次在执行这个规则时伪目标所定义的命令都会被执行（因为它是规则的依赖，重建规则目标文件时需要首先重建它的依赖）。

当伪目标没有作为任何目标（此目标是一个可被创建或者已存在的文件）的依赖时，我们只能通过make的命令行选项明确指定这个伪目标，来执行它所定义的命令。例如我们的make clean。

伪目标一般没有依赖的文件。但是，我们也可以为伪目标指定所依赖的文件。

伪目标同样可以作为“默认目标”，只要将其放在第一个。

一个示例就是，如果你的Makefile需要一口气生成若干个可执行文件，但你只想简单地敲一个make完事，并且，所有的目标文件都写在一个Makefile中，那么你可以使用“伪目标”这个特性,下边就是一个例子：
#+begin_src makefile
#sample Makefile 
all : prog1 prog2 prog3 
.PHONY : all 
prog1 : prog1.o utils.o 
cc -o prog1 prog1.o utils.o 
prog2 : prog2.o 
cc -o prog2 prog2.o 
prog3 : prog3.o sort.o utils.o 
cc -o prog3 prog3.o sort.o utils.o 
#+END_SRC
我们知道，Makefile中的第一个目标会被作为其默认目标。

我们声明了一个“all”的伪目标，其依赖于其它三个目标。

由于默认目标的特性是，总是被执行的，但由于“all”又是一个伪目标，伪目标只是一个标签不会生成文件，所以不会有“all”文件产生。

为了完成对它的更新，make会创建（不存在）或者重建（已存在）目标all的所有依赖文件（prog1、prog2和prog3）。

.PHONY : all 声明了“all”这个目标为“伪目标”。（注：这里的显式“.PHONY : all” 不写的话一般情况也可以正确的执行，这样make可通过隐式规则推导出， “all” 是一个伪目标，执行make不会生成“all”文件，而执行后面的多个目标。建议：显式写出是一个好习惯。）

当需要单独更新某一个程序时，我们可以通过make的命令行选项来明确指定需要重建的程序。（例如： make prog1）。

当一个伪目标作为另外一个伪目标依赖时，make将其作为另外一个伪目标的子例程来处理（可以这样理解：其作为另外一个伪目标的必须执行的部分，就行C语言中的函数调用一样）。

下边的例子就是这种用法：
#+begin_src makefile
.PHONY: cleanall cleanobj cleandiff 
cleanall : cleanobj cleandiff 
rm program 
cleanobj : 
rm *.o 
cleandiff : 
rm *.diff
#+END_SRC
cleanobj和cleandiff这两个伪目标有点像子程序的意思（执行目标clearall时会触发它们所定义的命令被执行）。

我们可以输入make cleanall和make cleanobj和make cleandiff命令来达到清除不同种类文件的目的。

例子首先通过特殊目标.PHONY声明了多个伪目标，它们之间使用空各分割，之后才是各个伪目标的规则定义。

说明：
通常在清除文件的伪目标所定义的命令中rm使用选项–f（--force）来防止在缺少删除文件时出错并退出，使make clean过程失败。

也可以在rm之前加上-来防止rm错误退出，这种方式时make会提示错误信息但不会退出。

为了不看到这些讨厌的信息，需要使用上述的第一种方式。

另外make存在一个内嵌隐含变量RM，它被定义为：RM = rm –f。因此在书写clean规则的命令行时可以使用变量$(RM)来代替rm，这样可以免出现一些不必要的麻烦！这是我们推荐的用法。
*** 参考文献
[[https://www.zybuluo.com/lishuhuakai/note/210174][Makefile伪目标]]
** 多目标
Makefile的规则中的目标可以不止一个，其支持多目标。

有可能我们的多个目标同时依赖于一个文件，并且其生成的命令大体类似。于是我们就能把其合并起来。

当然，多个目标的生成规则的执行命令不是同一个，这可能会给我们带来麻烦，

不过好在我们可以使用一个自动化变量 $@ ，这个变量表示目前规则中所有的目标的集合。
#+begin_src makefile
bigoutput littleoutput : text.g
    generate text.g -$(subst output,,$@) > $@
#+END_SRC
上述规则等价于：
#+begin_src makefile
bigoutput : text.g
    generate text.g -big > bigoutput
littleoutput : text.g
    generate text.g -little > littleoutput
#+END_SRC
其中， -$(subst output,,$@) 中的 $ 表示执行一个Makefile的函数，函数名为subst，后面的为参数。

这里的这个函数是替换字符串的意思， $@ 表示目标的集合，就像一个数组， $@ 依次取出目标，并执于命令。
** 静态模式
静态模式可以更加容易地定义多目标的规则，可以让我们的规则变得更加的有弹性和灵活。我们还是先来看一下语法：
#+begin_src makefile
<targets ...> : <target-pattern> : <prereq-patterns ...>
    <commands>
    ...
#+END_SRC
targets定义了一系列的目标文件，可以有通配符。是目标的一个集合。

target-pattern是指明了targets的模式，也就是的目标集模式。

prereq-patterns是目标的依赖模式，它对target-pattern形成的模式再进行一次依赖目标的定义。

如果我们的<target-pattern>定义成 %.o ，意思是我们的<target>;集合中都是以 .o 结尾的，而如果我们的<prereq-patterns>定义成 %.c ，意思是对<target-pattern>所形成的目标集进行二次定义，其计算方法是，取<target-pattern>模式中的 % （也就是去掉了 .o 这个结尾），并为其加上 .c 这个结尾，形成的新集合。

所以，我们的“目标模式”或是“依赖模式”中都应该有 % 这个字符，如果你的文件名中有 % 那么你可以使用反斜杠 \ 进行转义，来标明真实的 % 字符。

看一个例子：
#+begin_src makefile
objects = foo.o bar.o

all: $(objects)

$(objects): %.o: %.c
    $(CC) -c $(CFLAGS) $< -o $@
#+END_SRC
上面的例子中，指明了我们的目标从$object中获取， %.o 表明要所有以 .o 结尾的目标，也就是 foo.o bar.o ，也就是变量 $object 集合的模式，而依赖模式 %.c 则取模式 %.o 的 % ，也就是 foo bar ，并为其加下 .c 的后缀，于是，我们的依赖目标就是 foo.c bar.c 。而命令中的 $< 和 $@ 则是自动化变量， $< 表示第一个依赖文件， $@ 表示目标集（也就是“foo.o bar.o”）。于是，上面的规则展开后等价于下面的规则：
#+begin_src makefile
foo.o : foo.c
    $(CC) -c $(CFLAGS) foo.c -o foo.o
bar.o : bar.c
    $(CC) -c $(CFLAGS) bar.c -o bar.o
#+END_SRC
试想，如果我们的 %.o 有几百个，那么我们只要用这种很简单的“静态模式规则”就可以写完一堆规则，实在是太有效率了。“静态模式规则”的用法很灵活，如果用得好，那会是一个很强大的功能。再看一个例子：
#+begin_src makefile
files = foo.elc bar.o lose.o

$(filter %.o,$(files)): %.o: %.c
    $(CC) -c $(CFLAGS) $< -o $@
$(filter %.elc,$(files)): %.elc: %.el
    emacs -f batch-byte-compile $<
#+END_SRC
$(filter %.o,$(files))表示调用Makefile的filter函数，过滤“$files”集，只要其中模式为“%.o”的内容。其它的内容，我就不用多说了吧。这个例子展示了Makefile中更大的弹性。
** 自动生成依赖性
在Makefile中，我们的依赖关系可能会需要包含一系列的头文件，比如，如果我们的main.c中有一句 #include "defs.h" ，那么我们的依赖关系应该是：
#+begin_src makefile
main.o : main.c defs.h
#+END_SRC
但是，如果是一个比较大型的工程，你必需清楚哪些C文件包含了哪些头文件，并且，你在加入或删除头文件时，也需要小心地修改Makefile，这是一个很没有维护性的工作。为了避免这种繁重而又容易出错的事情，我们可以使用C/C++编译的一个功能。大多数的C/C++编译器都支持一个“-M”的选项，即自动找寻源文件中包含的头文件，并生成一个依赖关系。例如，如果我们执行下面的命令:
#+begin_src bash
cc -M main.c
#+END_SRC
其输出是：
#+begin_src makefile
main.o : main.c defs.h
#+END_SRC

于是由编译器自动生成的依赖关系，这样一来，你就不必再手动书写若干文件的依赖关系，而由编译器自动生成了。需要提醒一句的是，如果你使用GNU的C/C++编译器，你得用 -MM 参数，不然， -M 参数会把一些标准库的头文件也包含进来。

gcc -M main.c的输出是:
#+begin_src makefile
main.o: main.c defs.h /usr/include/stdio.h /usr/include/features.h \
    /usr/include/sys/cdefs.h /usr/include/gnu/stubs.h \
    /usr/lib/gcc-lib/i486-suse-linux/2.95.3/include/stddef.h \
    /usr/include/bits/types.h /usr/include/bits/pthreadtypes.h \
    /usr/include/bits/sched.h /usr/include/libio.h \
    /usr/include/_G_config.h /usr/include/wchar.h \
    /usr/include/bits/wchar.h /usr/include/gconv.h \
    /usr/lib/gcc-lib/i486-suse-linux/2.95.3/include/stdarg.h \
    /usr/include/bits/stdio_lim.h
#+END_SRC
gcc -MM main.c的输出则是:
#+begin_src makefile
main.o: main.c defs.h
#+END_SRC
那么，编译器的这个功能如何与我们的Makefile联系在一起呢。因为这样一来，我们的Makefile也要根据这些源文件重新生成，让 Makefile自已依赖于源文件？这个功能并不现实，不过我们可以有其它手段来迂回地实现这一功能。GNU组织建议把编译器为每一个源文件的自动生成的依赖关系放到一个文件中，为每一个 name.c 的文件都生成一个 name.d 的Makefile文件， .d 文件中就存放对应 .c 文件的依赖关系。

于是，我们可以写出 .c 文件和 .d 文件的依赖关系，并让make自动更新或生成 .d 文件，并把其包含在我们的主Makefile中，这样，我们就可以自动化地生成每个文件的依赖关系了。

这里，我们给出了一个模式规则来产生 .d 文件：
#+begin_src makefile
%.d: %.c
    @set -e; rm -f $@; \
    $(CC) -M $(CPPFLAGS) $< > $@.$$$$; \
    sed 's,\($*\)\.o[ :]*,\1.o $@ : ,g' < $@.$$$$ > $@; \
    rm -f $@.$$$$
#+END_SRC
这个规则的意思是，所有的 .d 文件依赖于 .c 文件， rm -f $@ 的意思是删除所有的目标，也就是 .d 文件，第二行的意思是，为每个依赖文件 $< ，也就是 .c 文件生成依赖文件， $@ 表示模式 %.d 文件，如果有一个C文件是name.c，那么 % 就是 name ， $$$$ 意为一个随机编号，第二行生成的文件有可能是“name.d.12345”，第三行使用sed命令做了一个替换，关于sed命令的用法请参看相关的使用文档。第四行就是删除临时文件。

总而言之，这个模式要做的事就是在编译器生成的依赖关系中加入 .d 文件的依赖，即把依赖关系：
#+begin_src makefile
main.o : main.c defs.h
#+END_SRC
转成：
#+begin_src makefile
main.o main.d : main.c defs.h
#+END_SRC
于是，我们的 .d 文件也会自动更新了，并会自动生成了，当然，你还可以在这个 .d 文件中加入的不只是依赖关系，包括生成的命令也可一并加入，让每个 .d 文件都包含一个完赖的规则。一旦我们完成这个工作，接下来，我们就要把这些自动生成的规则放进我们的主Makefile中。我们可以使用Makefile的“include”命令，来引入别的Makefile文件（前面讲过），例如：
#+begin_src makefile
sources = foo.c bar.c

include $(sources:.c=.d)
#+END_SRC
上述语句中的 $(sources:.c=.d) 中的 .c=.d 的意思是做一个替换，把变量 $(sources) 所有 .c 的字串都替换成 .d ，关于这个“替换”的内容，在后面我会有更为详细的讲述。当然，你得注意次序，因为include是按次序来载入文件，最先载入的 .d 文件中的目标会成为默认目标。
** 命令的书写
每条规则中的命令和操作系统Shell的命令行是一致的。make会一按顺序一条一条的执行命令，每条命令的开头必须以 Tab 键开头，除非，命令是紧跟在依赖规则后面的分号后的。在命令行之间中的空格或是空行会被忽略，但是如果该空格或空行是以Tab键开头的，那么make会认为其是一个空命令。

我们在UNIX下可能会使用不同的Shell，但是make的命令默认是被 /bin/sh ——UNIX的标准Shell 解释执行的。除非你特别指定一个其它的Shell。Makefile中， # 是注释符，很像C/C++中的 // ，其后的本行字符都被注释。
** 显示命令
通常，make会把其要执行的命令行在命令执行前输出到屏幕上。当我们用 @ 字符在命令行前，那么，这个命令将不被make显示出来，最具代表性的例子是，我们用这个功能来向屏幕显示一些信息。如:
#+begin_src makefile
@echo 正在编译XXX模块......
#+END_SRC
当make执行时，会输出“正在编译XXX模块……”字串，但不会输出命令，如果没有“@”，那么，make将输出:
#+begin_src makefile
echo 正在编译XXX模块......
正在编译XXX模块......
#+END_SRC
如果make执行时，带入make参数 -n 或 --just-print ，那么其只是显示命令，但不会执行命令，这个功能很有利于我们调试我们的Makefile，看看我们书写的命令是执行起来是什么样子的或是什么顺序的。

而make参数 -s 或 --silent 或 --quiet 则是全面禁止命令的显示。
** 命令执行
当依赖目标新于目标时，也就是当规则的目标需要被更新时，make会一条一条的执行其后的命令。需要注意的是，如果你要让上一条命令的结果应用在下一条命令时，你应该使用分号分隔这两条命令。比如你的第一条命令是cd命令，你希望第二条命令得在cd之后的基础上运行，那么你就不能把这两条命令写在两行上，而应该把这两条命令写在一行上，用分号分隔。如：

示例一：
#+begin_src makefile
exec:
    cd /home/hchen
    pwd
#+END_SRC
示例二：
#+begin_src makefile
exec:
    cd /home/hchen; pwd
#+END_SRC

当我们执行 make exec 时，第一个例子中的cd没有作用，pwd会打印出当前的Makefile目录，而第二个例子中，cd就起作用了，pwd会打印出“/home/hchen”。

make一般是使用环境变量SHELL中所定义的系统Shell来执行命令，默认情况下使用UNIX的标准Shell——/bin/sh来执行命令。
但在MS-DOS下有点特殊，因为MS-DOS下没有SHELL环境变量，当然你也可以指定。
如果你指定了UNIX风格的目录形式，首先，make会在SHELL所指定的路径中找寻命令解释器，
如果找不到，其会在当前盘符中的当前目录中寻找，
如果再找不到，其会在PATH环境变量中所定义的所有路径中寻找。
MS-DOS中，如果你定义的命令解释器没有找到，其会给你的命令解释器加上诸如 .exe 、 .com 、 .bat 、 .sh 等后缀。
** 命令出错
每当命令运行完后，make会检测每个命令的返回码，如果命令返回成功，那么make会执行下一条命令，当规则中所有的命令成功返回后，这个规则就算是成功完成了。如果一个规则中的某个命令出错了（命令退出码非零），那么make就会终止执行当前规则，这将有可能终止所有规则的执行。

有些时候，命令的出错并不表示就是错误的。例如mkdir命令，我们一定需要建立一个目录，如果目录不存在，那么mkdir就成功执行，万事大吉，如果目录存在，那么就出错了。我们之所以使用mkdir的意思就是一定要有这样的一个目录，于是我们就不希望mkdir出错而终止规则的运行。

为了做到这一点，忽略命令的出错，我们可以在Makefile的命令行前加一个减号 - （在Tab键之后），标记为不管命令出不出错都认为是成功的。如：
#+begin_src makefile
clean:
    -rm -f *.o
#+END_SRC
还有一个全局的办法是，给make加上 -i 或是 --ignore-errors 参数，那么，Makefile中所有命令都会忽略错误。而如果一个规则是以 .IGNORE 作为目标的，那么这个规则中的所有命令将会忽略错误。这些是不同级别的防止命令出错的方法，你可以根据你的不同喜欢设置。

还有一个要提一下的make的参数的是 -k 或是 --keep-going ，这个参数的意思是，如果某规则中的命令出错了，那么就终止该规则的执行，但继续执行其它规则。
** 嵌套执行make
在一些大的工程中，我们会把我们不同模块或是不同功能的源文件放在不同的目录中，我们可以在每个目录中都书写一个该目录的Makefile，这有利于让我们的Makefile变得更加地简洁，而不至于把所有的东西全部写在一个Makefile中，这样会很难维护我们的Makefile，这个技术对于我们模块编译和分段编译有着非常大的好处。

例如，我们有一个子目录叫subdir，这个目录下有个Makefile文件，来指明了这个目录下文件的编译规则。那么我们总控的Makefile可以这样书写：
#+begin_src makefile
subsystem:
    cd subdir && $(MAKE)
#+END_SRC
其等价于：
#+begin_src makefile
subsystem:
    $(MAKE) -C subdir
#+END_SRC
定义$(MAKE)宏变量的意思是，也许我们的make需要一些参数，所以定义成一个变量比较利于维护。这两个例子的意思都是先进入“subdir”目录，然后执行make命令。

我们把这个Makefile叫做“总控Makefile”，总控Makefile的变量可以传递到下级的Makefile中（如果你显示的声明），但是不会覆盖下层的Makefile中所定义的变量，除非指定了 -e 参数。

如果你要传递变量到下级Makefile中，那么你可以使用这样的声明:
#+begin_src makefile
export <variable ...>;
#+END_SRC
如果你不想让某些变量传递到下级Makefile中，那么你可以这样声明:
#+begin_src makefile
unexport <variable ...>;
#+END_SRC
如：

示例一：
#+begin_src makefile
export variable = value
#+END_SRC
其等价于：
#+begin_src makefile
variable = value
export variable
#+END_SRC
其等价于：
#+begin_src makefile
export variable := value
#+END_SRC
其等价于：
#+begin_src makefile
variable := value
export variable
#+END_SRC
示例二：
#+begin_src makefile
export variable += value
#+END_SRC
其等价于：
#+begin_src makefile
variable += value
export variable
#+END_SRC
如果你要传递所有的变量，那么，只要一个export就行了。后面什么也不用跟，表示传递所有的变量。

需要注意的是，有两个变量，一个是 SHELL ，一个是 MAKEFLAGS ，这两个变量不管你是否export，其总是要传递到下层 Makefile中，特别是 MAKEFLAGS 变量，其中包含了make的参数信息，
如果我们执行“总控Makefile”时有make参数或是在上层 Makefile中定义了这个变量，那么 MAKEFLAGS 变量将会是这些参数，并会传递到下层Makefile中，这是一个系统级的环境变量。

但是make命令中的有几个参数并不往下传递，它们是 -C , -f , -h, -o 和 -W （有关Makefile参数的细节将在后面说明），如果你不想往下层传递参数，那么，你可以这样来：
#+begin_src makefile
subsystem:
    cd subdir && $(MAKE) MAKEFLAGS=
#+END_SRC
如果你定义了环境变量 MAKEFLAGS ，那么你得确信其中的选项是大家都会用到的，如果其中有 -t , -n 和 -q 参数，那么将会有让你意想不到的结果，或许会让你异常地恐慌。

还有一个在“嵌套执行”中比较有用的参数， -w 或是 --print-directory 会在make的过程中输出一些信息，让你看到目前的工作目录。
比如，如果我们的下级make目录是“/home/hchen/gnu/make”，如果我们使用 make -w 来执行，那么当进入该目录时，我们会看到:
#+begin_src makefile
make: Entering directory `/home/hchen/gnu/make'.
#+END_SRC
而在完成下层make后离开目录时，我们会看到:
#+begin_src makefile
make: Leaving directory `/home/hchen/gnu/make'
#+END_SRC
当你使用 -C 参数来指定make下层Makefile时， -w 会被自动打开的。如果参数中有 -s （ --slient ）或是 --no-print-directory ，那么， -w 总是失效的。
** 定义命令包
如果Makefile中出现一些相同命令序列，那么我们可以为这些相同的命令序列定义一个变量。定义这种命令序列的语法以 define 开始，以 endef 结束，如:
#+begin_src makefile
define run-yacc
yacc $(firstword $^)
mv y.tab.c $@
endef
#+END_SRC
这里，“run-yacc”是这个命令包的名字，其不要和Makefile中的变量重名。在 define 和 endef 中的两行就是命令序列。这个命令包中的第一个命令是运行Yacc程序，因为Yacc程序总是生成“y.tab.c”的文件，所以第二行的命令就是把这个文件改改名字。还是把这个命令包放到一个示例中来看看吧。
#+begin_src makefile
foo.c : foo.y
    $(run-yacc)
#+END_SRC
我们可以看见，要使用这个命令包，我们就好像使用变量一样。在这个命令包的使用中，命令包“run-yacc”中的 $^ 就是 foo.y ， $@ 就是 foo.c （有关这种以 $ 开头的特殊变量，我们会在后面介绍），make在执行命令包时，命令包中的每个命令会被依次独立执行。
** 使用条件判断
使用条件判断，可以让make根据运行时的不同情况选择不同的执行分支。条件表达式可以是比较变量的值，或是比较变量和常量的值。
*** 示例
下面的例子，判断 $(CC) 变量是否 gcc ，如果是的话，则使用GNU函数编译目标。
#+begin_src makefile
libs_for_gcc = -lgnu
normal_libs =

foo: $(objects)
ifeq ($(CC),gcc)
    $(CC) -o foo $(objects) $(libs_for_gcc)
else
    $(CC) -o foo $(objects) $(normal_libs)
endif

#+END_SRC
可见，在上面示例的这个规则中，目标 foo 可以根据变量 $(CC) 值来选取不同的函数库来编译程序。

我们可以从上面的示例中看到三个关键字： ifeq 、 else 和 endif 。 ifeq 的意思表示条件语句的开始，并指定一个条件表达式，表达式包含两个参数，以逗号分隔，表达式以圆括号括起。 else 表示条件表达式为假的情况。 endif 表示一个条件语句的结束，任何一个条件表达式都应该以 endif 结束。

当我们的变量 $(CC) 值是 gcc 时，目标 foo 的规则是：
#+begin_src makefile
foo: $(objects)
    $(CC) -o foo $(objects) $(libs_for_gcc)

#+END_SRC
而当我们的变量 $(CC) 值不是 gcc 时（比如 cc ），目标 foo 的规则是：
#+begin_src makefile
foo: $(objects)
    $(CC) -o foo $(objects) $(normal_libs)

#+END_SRC
当然，我们还可以把上面的那个例子写得更简洁一些：
#+begin_src makefile
libs_for_gcc = -lgnu
normal_libs =

ifeq ($(CC),gcc)
    libs=$(libs_for_gcc)
else
    libs=$(normal_libs)
endif

foo: $(objects)
    $(CC) -o foo $(objects) $(libs)

#+END_SRC
*** 语法
条件表达式的语法为:
#+begin_src makefile
<conditional-directive>
<text-if-true>
endif

#+END_SRC
以及:
#+begin_src makefile
<conditional-directive>
<text-if-true>
else
<text-if-false>
endif

#+END_SRC
其中 <conditional-directive> 表示条件关键字，如 ifeq 。这个关键字有四个。

第一个是我们前面所见过的 ifeq
#+begin_src makefile
ifeq (<arg1>, <arg2>)
ifeq '<arg1>' '<arg2>'
ifeq "<arg1>" "<arg2>"
ifeq "<arg1>" '<arg2>'
ifeq '<arg1>' "<arg2>"

#+END_SRC
比较参数 arg1 和 arg2 的值是否相同。当然，参数中我们还可以使用make的函数。如:
#+begin_src makefile
ifeq ($(strip $(foo)),)
<text-if-empty>
endif

#+END_SRC
这个示例中使用了 strip 函数，如果这个函数的返回值是空（Empty），那么 <text-if-empty> 就生效。

第二个条件关键字是 ifneq 。语法是：
#+begin_src makefile
ifneq (<arg1>, <arg2>)
ifneq '<arg1>' '<arg2>'
ifneq "<arg1>" "<arg2>"
ifneq "<arg1>" '<arg2>'
ifneq '<arg1>' "<arg2>"

#+END_SRC
其比较参数 arg1 和 arg2 的值是否相同，如果不同，则为真。和 ifeq 类似。

第三个条件关键字是 ifdef 。语法是：
#+begin_src makefile
ifdef <variable-name>

#+END_SRC
如果变量 <variable-name> 的值非空，那到表达式为真。否则，表达式为假。当然， <variable-name> 同样可以是一个函数的返回值。注意， ifdef 只是测试一个变量是否有值，其并不会把变量扩展到当前位置。还是来看两个例子：

示例一：
#+begin_src makefile
bar =
foo = $(bar)
ifdef foo
    frobozz = yes
else
    frobozz = no
endif

#+END_SRC
示例二：
#+begin_src makefile
foo =
ifdef foo
    frobozz = yes
else
    frobozz = no
endif

#+END_SRC
第一个例子中， $(frobozz) 值是 yes ，第二个则是 no。

第四个条件关键字是 ifndef 。其语法是：
#+begin_src makefile
ifndef <variable-name>

#+END_SRC
这个我就不多说了，和 ifdef 是相反的意思。

在 <conditional-directive> 这一行上，多余的空格是被允许的，但是不能以 Tab 键作为开始（不然就被认为是命令）。而注释符 # 同样也是安全的。 else 和 endif 也一样，只要不是以 Tab 键开始就行了。

特别注意的是，make是在读取Makefile时就计算条件表达式的值，并根据条件表达式的值来选择语句，所以，你最好不要把自动化变量（如 $@ 等）放入条件表达式中，因为自动化变量是在运行时才有的。

而且为了避免混乱，make不允许把整个条件语句分成两部分放在不同的文件中。
** 隐含规则
*** 使用隐含规则
如果要使用隐含规则生成你需要的目标，你所需要做的就是不要写出这个目标的规则。那么，make会试图去自动推导产生这个目标的规则和命令，如果 make可以自动推导生成这个目标的规则和命令，那么这个行为就是隐含规则的自动推导。当然，隐含规则是make事先约定好的一些东西。例如，我们有下面的一个Makefile：
#+begin_src makefile
foo : foo.o bar.o
    cc –o foo foo.o bar.o $(CFLAGS) $(LDFLAGS)

#+END_SRC
我们可以注意到，这个Makefile中并没有写下如何生成 foo.o 和 bar.o 这两目标的规则和命令。因为make的“隐含规则”功能会自动为我们自动去推导这两个目标的依赖目标和生成命令。

make会在自己的“隐含规则”库中寻找可以用的规则，如果找到，那么就会使用。如果找不到，那么就会报错。在上面的那个例子中，make调用的隐含规则是，把 .o 的目标的依赖文件置成 .c ，并使用C的编译命令 cc –c $(CFLAGS)  foo.c 来生成 foo.o 的目标。也就是说，我们完全没有必要写下下面的两条规则：
#+begin_src makefile
foo.o : foo.c
    cc –c foo.c $(CFLAGS)
bar.o : bar.c
    cc –c bar.c $(CFLAGS)

#+END_SRC
因为，这已经是“约定”好了的事了，make和我们约定好了用C编译器 cc 生成 .o 文件的规则，这就是隐含规则。

当然，如果我们为 .o 文件书写了自己的规则，那么make就不会自动推导并调用隐含规则，它会按照我们写好的规则忠实地执行。

还有，在make的“隐含规则库”中，每一条隐含规则都在库中有其顺序，越靠前的则是越被经常使用的，所以，这会导致我们有些时候即使我们显示地指定了目标依赖，make也不会管。如下面这条规则（没有命令）：
#+begin_src makefile
foo.o : foo.p

#+END_SRC
依赖文件 foo.p （Pascal程序的源文件）有可能变得没有意义。如果目录下存在了 foo.c 文件，那么我们的隐含规则一样会生效，并会通过 foo.c 调用C的编译器生成 foo.o 文件。因为，在隐含规则中，Pascal的规则出现在C的规则之后，所以，make找到可以生成 foo.o 的C的规则就不再寻找下一条规则了。如果你确实不希望任何隐含规则推导，那么，你除了写依赖规则，还要吧把命令也写出来、
*** 隐含规则一览
这里我们将讲述所有预先设置（也就是make内建）的隐含规则，如果我们不明确地写下规则，那么，make就会在这些规则中寻找所需要规则和命令。
当然，我们也可以使用make的参数 -r 或 --no-builtin-rules 选项来取消所有的预设置的隐含规则。

当然，即使是我们指定了 -r 参数，某些隐含规则还是会生效，因为有许多的隐含规则都是使用了“后缀规则”来定义的，所以，只要隐含规则中有 “后缀列表”（也就是系统定义在目标 .SUFFIXES 的依赖目标），那么隐含规则就会生效。
默认的后缀列表是：.out, .a, .ln, .o, .c, .cc, .C, .p, .f, .F, .r, .y, .l, .s, .S, .mod, .sym, .def, .h, .info, .dvi, .tex, .texinfo, .texi, .txinfo, .w, .ch .web, .sh, .elc, .el。

还是先来看一看常用的隐含规则吧。
**** 编译C程序的隐含规则

<n>.o 的目标的依赖目标会自动推导为 <n>.c ，并且其生成命令是 $(CC) –c $(CPPFLAGS) $(CFLAGS)
**** 编译C++程序的隐含规则

<n>.o 的目标的依赖目标会自动推导为 <n>.cc 或是 <n>.C ，并且其生成命令是 $(CXX) –c $(CPPFLAGS) $(CXXFLAGS) 。（建议使用 .cc 作为C++源文件的后缀，而不是 .C ）
**** 编译Pascal程序的隐含规则
**** <n>.o 的目标的依赖目标会自动推导为 <n>.p ，并且其生成命令是 $(PC) –c  $(PFLAGS) 
**** 编译Fortran/Ratfor程序的隐含规则

<n>.o 的目标的依赖目标会自动推导为 <n>.r 或 <n>.F 或 <n>.f ，并且其生成命令是:

.f $(FC) –c  $(FFLAGS)

.F $(FC) –c  $(FFLAGS) $(CPPFLAGS)

.f $(FC) –c  $(FFLAGS) $(RFLAGS)
**** 预处理Fortran/Ratfor程序的隐含规则

<n>.f 的目标的依赖目标会自动推导为 <n>.r 或 <n>.F 。这个规则只是转换Ratfor 或有预处理的Fortran程序到一个标准的Fortran程序。其使用的命令是：

.F $(FC) –F $(CPPFLAGS) $(FFLAGS)

.r $(FC) –F $(FFLAGS) $(RFLAGS)
**** 编译Modula-2程序的隐含规则

<n>.sym 的目标的依赖目标会自动推导为 <n>.def ，并且其生成命令是： $(M2C) $(M2FLAGS) $(DEFFLAGS) 。 <n>.o 的目标的依赖目标会自动推导为 <n>.mod ，并且其生成命令是： $(M2C) $(M2FLAGS) $(MODFLAGS) 。
**** 汇编和汇编预处理的隐含规则

<n>.o 的目标的依赖目标会自动推导为 <n>.s ，默认使用编译器 as ，并且其生成命令是： $ (AS) $(ASFLAGS) 。 <n>.s 的目标的依赖目标会自动推导为 <n>.S ，默认使用C预编译器 cpp ，并且其生成命令是： $(AS) $(ASFLAGS) 。
**** 链接Object文件的隐含规则

<n> 目标依赖于 <n>.o ，通过运行C的编译器来运行链接程序生成（一般是 ld ），其生成命令是： $(CC) $(LDFLAGS) <n>.o $(LOADLIBES) $(LDLIBS) 。这个规则对于只有一个源文件的工程有效，同时也对多个Object文件（由不同的源文件生成）的也有效。
例如如下规则:
#+begin_src makefile
x : y.o z.o
#+END_SRC
并且 x.c 、 y.c 和 z.c 都存在时，隐含规则将执行如下命令:
#+begin_src makefile
cc -c x.c -o x.o
cc -c y.c -o y.o
cc -c z.c -o z.o
cc x.o y.o z.o -o x
rm -f x.o
rm -f y.o
rm -f z.o

#+END_SRC
如果没有一个源文件（如上例中的x.c）和你的目标名字（如上例中的x）相关联，那么，你最好写出自己的生成规则，不然，隐含规则会报错的。
**** Yacc C程序时的隐含规则

<n>.c 的依赖文件被自动推导为 n.y （Yacc生成的文件），其生成命令是： $(YACC) $(YFALGS) 。（“Yacc”是一个语法分析器，关于其细节请查看相关资料）
**** Lex C程序时的隐含规则

<n>.c 的依赖文件被自动推导为 n.l （Lex生成的文件），其生成命令是： $(LEX) $(LFALGS) 。（关于“Lex”的细节请查看相关资料）
**** Lex Ratfor程序时的隐含规则

<n>.r 的依赖文件被自动推导为 n.l （Lex生成的文件），其生成命令是： $(LEX) $(LFALGS) 。
**** 从C程序、Yacc文件或Lex文件创建Lint库的隐含规则

<n>.ln （lint生成的文件）的依赖文件被自动推导为 n.c ，其生成命令是： $(LINT) $(LINTFALGS) $(CPPFLAGS) -i 。对于 <n>.y 和 <n>.l 也是同样的规则。
*** 隐含规则使用的变量
在隐含规则中的命令中，基本上都是使用了一些预先设置的变量。你可以在你的makefile中改变这些变量的值，或是在make的命令行中传入这些值，或是在你的环境变量中设置这些值，无论怎么样，只要设置了这些特定的变量，那么其就会对隐含规则起作用。当然，你也可以利用make的 -R 或 --no–builtin-variables 参数来取消你所定义的变量对隐含规则的作用。

例如，第一条隐含规则——编译C程序的隐含规则的命令是 $(CC) –c $(CFLAGS) $(CPPFLAGS) 。Make默认的编译命令是 cc ，如果你把变量 $(CC) 重定义成 gcc ，把变量 $(CFLAGS) 重定义成 -g ，那么，隐含规则中的命令全部会以 gcc –c -g $(CPPFLAGS) 的样子来执行了。

我们可以把隐含规则中使用的变量分成两种：一种是命令相关的，如 CC ；一种是参数相的关，如 CFLAGS 。下面是所有隐含规则中会用到的变量：

**** 关于命令的变量
AR : 函数库打包程序。默认命令是 ar

AS : 汇编语言编译程序。默认命令是 as

CC : C语言编译程序。默认命令是 cc

CXX : C++语言编译程序。默认命令是 g++

CO : 从 RCS文件中扩展文件程序。默认命令是 co

CPP : C程序的预处理器（输出是标准输出设备）。默认命令是 $(CC) –E

FC : Fortran 和 Ratfor 的编译器和预处理程序。默认命令是 f77

GET : 从SCCS文件中扩展文件的程序。默认命令是 get

LEX : Lex方法分析器程序（针对于C或Ratfor）。默认命令是 lex

PC : Pascal语言编译程序。默认命令是 pc

YACC : Yacc文法分析器（针对于C程序）。默认命令是 yacc

YACCR : Yacc文法分析器（针对于Ratfor程序）。默认命令是 yacc –r

MAKEINFO : 转换Texinfo源文件（.texi）到Info文件程序。默认命令是 makeinfo

TEX : 从TeX源文件创建TeX DVI文件的程序。默认命令是 tex

TEXI2DVI : 从Texinfo源文件创建军TeX DVI 文件的程序。默认命令是 texi2dvi

WEAVE : 转换Web到TeX的程序。默认命令是 weave

CWEAVE : 转换C Web 到 TeX的程序。默认命令是 cweave

TANGLE : 转换Web到Pascal语言的程序。默认命令是 tangle

CTANGLE : 转换C Web 到 C。默认命令是 ctangle

RM : 删除文件命令。默认命令是 rm –f

**** 关于命令参数的变量
下面的这些变量都是相关上面的命令的参数。如果没有指明其默认值，那么其默认值都是空。

ARFLAGS : 函数库打包程序AR命令的参数。默认值是 rv

ASFLAGS : 汇编语言编译器参数。（当明显地调用 .s 或 .S 文件时）

CFLAGS : C语言编译器参数。

CXXFLAGS : C++语言编译器参数。

COFLAGS : RCS命令参数。

CPPFLAGS : C预处理器参数。（ C 和 Fortran 编译器也会用到）。

FFLAGS : Fortran语言编译器参数。

GFLAGS : SCCS “get”程序参数。

LDFLAGS : 链接器参数。（如： ld ）

LFLAGS : Lex文法分析器参数。

PFLAGS : Pascal语言编译器参数。

RFLAGS : Ratfor 程序的Fortran 编译器参数。

YFLAGS : Yacc文法分析器参数。

*** 隐含规则链
有些时候，一个目标可能被一系列的隐含规则所作用。
例如，一个 .o 的文件生成，可能会是先被 Yacc的[.y]文件先成 .c ，然后再被C的编译器生成。我们把这一系列的隐含规则叫做“隐含规则链”。

在上面的例子中，如果文件 .c 存在，那么就直接调用C的编译器的隐含规则，如果没有 .c 文件，但有一个 .y 文件，那么Yacc的隐含规则会被调用，生成 .c 文件，然后，再调用C编译的隐含规则最终由 .c 生成 .o 文件，达到目标。

我们把这种 .c 的文件（或是目标），叫做中间目标。不管怎么样，make会努力自动推导生成目标的一切方法，不管中间目标有多少，其都会执着地把所有的隐含规则和你书写的规则全部合起来分析，努力达到目标，所以，有些时候，可能会让你觉得奇怪，怎么我的目标会这样生成？怎么我的 makefile发疯了？

在默认情况下，对于中间目标，它和一般的目标有两个地方所不同：第一个不同是除非中间的目标不存在，才会引发中间规则。第二个不同的是，只要目标成功产生，那么，产生最终目标过程中，所产生的中间目标文件会被以 rm -f 删除。

通常，一个被makefile指定成目标或是依赖目标的文件不能被当作中介。然而，你可以明显地说明一个文件或是目标是中介目标，你可以使用伪目标 .INTERMEDIATE 来强制声明。（如： .INTERMEDIATE : mid ）

你也可以阻止make自动删除中间目标，要做到这一点，你可以使用伪目标 .SECONDARY 来强制声明（如： .SECONDARY : sec ）。你还可以把你的目标，以模式的方式来指定（如： %.o ）成伪目标 .PRECIOUS 的依赖目标，以保存被隐含规则所生成的中间文件。

在“隐含规则链”中，禁止同一个目标出现两次或两次以上，这样一来，就可防止在make自动推导时出现无限递归的情况。

Make会优化一些特殊的隐含规则，而不生成中间文件。如，从文件 foo.c 生成目标程序 foo ，按道理，make会编译生成中间文件 foo.o ，然后链接成 foo ，但在实际情况下，这一动作可以被一条 cc 的命令完成（ cc –o foo foo.c ），于是优化过的规则就不会生成中间文件。

*** 定义模式规则
你可以使用模式规则来定义一个隐含规则。一个模式规则就好像一个一般的规则，只是在规则中，目标的定义需要有 % 字符。 % 的意思是表示一个或多个任意字符。在依赖目标中同样可以使用 % ，只是依赖目标中的 % 的取值，取决于其目标。

有一点需要注意的是， % 的展开发生在变量和函数的展开之后，变量和函数的展开发生在make载入 Makefile时，而模式规则中的 % 则发生在运行时。

**** 模式规则介绍
模式规则中，至少在规则的目标定义中要包含 % ，否则，就是一般的规则。目标中的 % 定义表示对文件名的匹配， % 表示长度任意的非空字符串。例如： %.c 表示以 .c 结尾的文件名（文件名的长度至少为3），而 s.%.c 则表示以 s. 开头， .c 结尾的文件名（文件名的长度至少为5）。

如果 % 定义在目标中，那么，目标中的 % 的值决定了依赖目标中的 % 的值，也就是说，目标中的模式的 % 决定了依赖目标中 % 的样子。例如有一个模式规则如下：
#+begin_src makefile
%.o : %.c ; <command ......>;

#+END_SRC
其含义是，指出了怎么从所有的 .c 文件生成相应的 .o 文件的规则。如果要生成的目标是 a.o b.o ，那么 %c 就是 a.c b.c 。

一旦依赖目标中的 % 模式被确定，那么，make会被要求去匹配当前目录下所有的文件名，一旦找到，make就会规则下的命令，所以，在模式规则中，目标可能会是多个的，如果有模式匹配出多个目标，make就会产生所有的模式目标，此时，make关心的是依赖的文件名和生成目标的命令这两件事。

**** 模式规则示例
下面这个例子表示了,把所有的 .c 文件都编译成 .o 文件.
#+begin_src makefile
%.o : %.c
    $(CC) -c $(CFLAGS) $(CPPFLAGS) $< -o $@

#+END_SRC
其中， $@ 表示所有的目标的挨个值， $< 表示了所有依赖目标的挨个值。这些奇怪的变量我们叫“自动化变量”，后面会详细讲述。

下面的这个例子中有两个目标是模式的：
#+begin_src makefile
%.tab.c %.tab.h: %.y
    bison -d $<

#+END_SRC
这条规则告诉make把所有的 .y 文件都以 bison -d <n>.y 执行，然后生成 <n>.tab.c 和 <n>.tab.h 文件。（其中， <n> 表示一个任意字符串）。
如果我们的执行程序 foo 依赖于文件 parse.tab.o 和 scan.o ，并且文件 scan.o 依赖于文件 parse.tab.h 。
如果 parse.y 文件被更新了，那么根据上述的规则， bison -d parse.y 就会被执行一次，于是， parse.tab.o 和 scan.o 的依赖文件就齐了。
（假设， parse.tab.o 由 parse.tab.c 生成，和 scan.o 由 scan.c 生成，而 foo 由 parse.tab.o 和 scan.o 链接生成，而且 foo 和其 .o 文件的依赖关系也写好，那么，所有的目标都会得到满足）

**** 自动化变量
在上述的模式规则中，目标和依赖文件都是一系例的文件，那么我们如何书写一个命令来完成从不同的依赖文件生成相应的目标？因为在每一次的对模式规则的解析时，都会是不同的目标和依赖文件。

自动化变量就是完成这个功能的。在前面，我们已经对自动化变量有所提涉，相信你看到这里已对它有一个感性认识了。所谓自动化变量，就是这种变量会把模式中所定义的一系列的文件自动地挨个取出，直至所有的符合模式的文件都取完了。这种自动化变量只应出现在规则的命令中。

下面是所有的自动化变量及其说明：

$@ : 表示规则中的目标文件集。在模式规则中，如果有多个目标，那么， $@ 就是匹配于目标中模式定义的集合。

$% : 仅当目标是函数库文件中，表示规则中的目标成员名。例如，如果一个目标是 foo.a(bar.o) ，那么， $% 就是 bar.o ， $@ 就是 foo.a 。如果目标不是函数库文件（Unix下是 .a ，Windows下是 .lib ），那么，其值为空。

$< : 依赖目标中的第一个目标名字。如果依赖目标是以模式（即 % ）定义的，那么 $< 将是符合模式的一系列的文件集。注意，其是一个一个取出来的。

$? : 所有比目标新的依赖目标的集合。以空格分隔。

$^ : 所有的依赖目标的集合。以空格分隔。如果在依赖目标中有多个重复的，那么这个变量会去除重复的依赖目标，只保留一份。

$+ : 这个变量很像 $^ ，也是所有依赖目标的集合。只是它不去除重复的依赖目标。

$* : 这个变量表示目标模式中 % 及其之前的部分。如果目标是 dir/a.foo.b ，并且目标的模式是 a.%.b ，那么， $* 的值就是 dir/foo 。这个变量对于构造有关联的文件名是比较有效。如果目标中没有模式的定义，那么 $* 也就不能被推导出，但是，如果目标文件的后缀是make所识别的，那么 $* 就是除了后缀的那一部分。例如：如果目标是 foo.c ，因为 .c 是make所能识别的后缀名，所以， $* 的值就是 foo 。这个特性是GNU make的，很有可能不兼容于其它版本的make，所以，你应该尽量避免使用 $* ，除非是在隐含规则或是静态模式中。如果目标中的后缀是make所不能识别的，那么 $* 就是空值。

当你希望只对更新过的依赖文件进行操作时， $? 在显式规则中很有用，例如，假设有一个函数库文件叫 lib ，其由其它几个object文件更新。那么把object文件打包的比较有效率的Makefile规则是：
#+begin_src makefile
lib : foo.o bar.o lose.o win.o
    ar r lib $?

#+END_SRC
在上述所列出来的自动量变量中。四个变量（ $@ 、 $< 、 $% 、 $* ）在扩展时只会有一个文件，而另三个的值是一个文件列表。这七个自动化变量还可以取得文件的目录名或是在当前目录下的符合模式的文件名，只需要搭配上 D 或 F 字样。这是GNU make中老版本的特性，在新版本中，我们使用函数 dir 或 notdir 就可以做到了。 D 的含义就是Directory，就是目录， F 的含义就是File，就是文件。

下面是对于上面的七个变量分别加上 D 或是 F 的含义：

$(@D)
表示 $@ 的目录部分（不以斜杠作为结尾），如果 $@ 值是 dir/foo.o ，那么 $(@D) 就是 dir ，而如果 $@ 中没有包含斜杠的话，其值就是 . （当前目录）。

$(@F)
表示 $@ 的文件部分，如果 $@ 值是 dir/foo.o ，那么 $(@F) 就是 foo.o ， $(@F) 相当于函数 $(notdir $@) 。

$(*D), $(*F)
和上面所述的同理，也是取文件的目录部分和文件部分。对于上面的那个例子， $(*D) 返回 dir ，而 $(*F) 返回 foo

$(%D), $(%F)
分别表示了函数包文件成员的目录部分和文件部分。这对于形同 archive(member) 形式的目标中的 member 中包含了不同的目录很有用。

$(<D), $(<F)
分别表示依赖文件的目录部分和文件部分。

$(^D), $(^F)
分别表示所有依赖文件的目录部分和文件部分。（无相同的）

$(+D), $(+F)
分别表示所有依赖文件的目录部分和文件部分。（可以有相同的）

$(?D), $(?F)
分别表示被更新的依赖文件的目录部分和文件部分。

最后想提醒一下的是，对于 $< ，为了避免产生不必要的麻烦，我们最好给 $ 后面的那个特定字符都加上圆括号，比如， $(<) 就要比 $< 要好一些。

还得要注意的是，这些变量只使用在规则的命令中，而且一般都是“显式规则”和“静态模式规则”（参见前面“书写规则”一章）。其在隐含规则中并没有意义。

**** 模式的匹配
一般来说，一个目标的模式有一个有前缀或是后缀的 % ，或是没有前后缀，直接就是一个 % 。因为 % 代表一个或多个字符，所以在定义好了的模式中，我们把 % 所匹配的内容叫做“茎”，例如 %.c 所匹配的文件“test.c”中“test”就是“茎”。因为在目标和依赖目标中同时有 % 时，依赖目标的“茎”会传给目标，当做目标中的“茎”。

当一个模式匹配包含有斜杠（实际也不经常包含）的文件时，那么在进行模式匹配时，目录部分会首先被移开，然后进行匹配，成功后，再把目录加回去。在进行“茎”的传递时，我们需要知道这个步骤。例如有一个模式 e%t ，文件 src/eat 匹配于该模式，于是 src/a 就是其“茎”，如果这个模式定义在依赖目标中，而被依赖于这个模式的目标中又有个模式 c%r ，那么，目标就是 src/car 。（“茎”被传递）

**** 重载内建隐含规则
你可以重载内建的隐含规则（或是定义一个全新的），例如你可以重新构造和内建隐含规则不同的命令，如：

%.o : %.c
    $(CC) -c $(CPPFLAGS) $(CFLAGS) -D$(date)
你可以取消内建的隐含规则，只要不在后面写命令就行。如：

%.o : %.s
同样，你也可以重新定义一个全新的隐含规则，其在隐含规则中的位置取决于你在哪里写下这个规则。朝前的位置就靠前。

*** 老式风格的“后缀规则”
后缀规则是一个比较老式的定义隐含规则的方法。后缀规则会被模式规则逐步地取代。因为模式规则更强更清晰。为了和老版本的Makefile兼容，GNU make同样兼容于这些东西。后缀规则有两种方式：“双后缀”和“单后缀”。

双后缀规则定义了一对后缀：目标文件的后缀和依赖目标（源文件）的后缀。如 .c.o 相当于 %o : %c 。单后缀规则只定义一个后缀，也就是源文件的后缀。如 .c 相当于 % : %.c 。

后缀规则中所定义的后缀应该是make所认识的，如果一个后缀是make所认识的，那么这个规则就是单后缀规则，而如果两个连在一起的后缀都被make所认识，那就是双后缀规则。例如： .c 和 .o 都是make所知道。因而，如果你定义了一个规则是 .c.o 那么其就是双后缀规则，意义就是 .c 是源文件的后缀， .o 是目标文件的后缀。如下示例：

.c.o:
    $(CC) -c $(CFLAGS) $(CPPFLAGS) -o $@ $<
后缀规则不允许任何的依赖文件，如果有依赖文件的话，那就不是后缀规则，那些后缀统统被认为是文件名，如：

.c.o: foo.h
    $(CC) -c $(CFLAGS) $(CPPFLAGS) -o $@ $<
这个例子，就是说，文件 .c.o 依赖于文件 foo.h ，而不是我们想要的这样：

%.o: %.c foo.h
    $(CC) -c $(CFLAGS) $(CPPFLAGS) -o $@ $<
后缀规则中，如果没有命令，那是毫无意义的。因为他也不会移去内建的隐含规则。

而要让make知道一些特定的后缀，我们可以使用伪目标 .SUFFIXES 来定义或是删除，如：

.SUFFIXES: .hack .win
把后缀 .hack 和 .win 加入后缀列表中的末尾。

.SUFFIXES:              # 删除默认的后缀
.SUFFIXES: .c .o .h   # 定义自己的后缀
先清除默认后缀，后定义自己的后缀列表。

make的参数 -r 或 -no-builtin-rules 也会使用得默认的后缀列表为空。而变量 SUFFIXE 被用来定义默认的后缀列表，你可以用 .SUFFIXES 来改变后缀列表，但请不要改变变量 SUFFIXE 的值。

*** 隐含规则搜索算法
比如我们有一个目标叫 T。下面是搜索目标T的规则的算法。请注意，在下面，我们没有提到后缀规则，原因是，所有的后缀规则在Makefile被载入内存时，会被转换成模式规则。如果目标是 archive(member) 的函数库文件模式，那么这个算法会被运行两次，第一次是找目标T，如果没有找到的话，那么进入第二次，第二次会把 member 当作T来搜索。

把T的目录部分分离出来。叫D，而剩余部分叫N。（如：如果T是 src/foo.o ，那么，D就是 src/ ，N就是 foo.o ）

创建所有匹配于T或是N的模式规则列表。

如果在模式规则列表中有匹配所有文件的模式，如 % ，那么从列表中移除其它的模式。

移除列表中没有命令的规则。

对于第一个在列表中的模式规则：

推导其“茎”S，S应该是T或是N匹配于模式中 % 非空的部分。

计算依赖文件。把依赖文件中的 % 都替换成“茎”S。如果目标模式中没有包含斜框字符，而把D加在第一个依赖文件的开头。

测试是否所有的依赖文件都存在或是理当存在。（如果有一个文件被定义成另外一个规则的目标文件，或者是一个显式规则的依赖文件，那么这个文件就叫“理当存在”）

如果所有的依赖文件存在或是理当存在，或是就没有依赖文件。那么这条规则将被采用，退出该算法。

如果经过第5步，没有模式规则被找到，那么就做更进一步的搜索。对于存在于列表中的第一个模式规则：

如果规则是终止规则，那就忽略它，继续下一条模式规则。

计算依赖文件。（同第5步）

测试所有的依赖文件是否存在或是理当存在。

对于不存在的依赖文件，递归调用这个算法查找他是否可以被隐含规则找到。

如果所有的依赖文件存在或是理当存在，或是就根本没有依赖文件。那么这条规则被采用，退出该算法。

如果没有隐含规则可以使用，查看 .DEFAULT 规则，如果有，采用，把 .DEFAULT 的命令给T使用。

一旦规则被找到，就会执行其相当的命令，而此时，我们的自动化变量的值才会生成。
** 使用make更新函数库文件
函数库文件也就是对Object文件（程序编译的中间文件）的打包文件。在Unix下，一般是由命令 ar 来完成打包工作。

*** 函数库文件的成员
一个函数库文件由多个文件组成。你可以用如下格式指定函数库文件及其组成:

archive(member)
这个不是一个命令，而一个目标和依赖的定义。一般来说，这种用法基本上就是为了 ar 命令来服务的。如:

foolib(hack.o) : hack.o
    ar cr foolib hack.o
如果要指定多个member，那就以空格分开，如:

foolib(hack.o kludge.o)
其等价于:

foolib(hack.o) foolib(kludge.o)
你还可以使用Shell的文件通配符来定义，如:

foolib(*.o)
*** 函数库成员的隐含规则
当make搜索一个目标的隐含规则时，一个特殊的特性是，如果这个目标是 a(m) 形式的，其会把目标变成 (m) 。于是，如果我们的成员是 %.o 的模式定义，并且如果我们使用 make foo.a(bar.o) 的形式调用Makefile时，隐含规则会去找 bar.o 的规则，如果没有定义 bar.o 的规则，那么内建隐含规则生效，make会去找 bar.c 文件来生成 bar.o ，如果找得到的话，make执行的命令大致如下:

cc -c bar.c -o bar.o
ar r foo.a bar.o
rm -f bar.o
还有一个变量要注意的是 $% ，这是专属函数库文件的自动化变量，有关其说明请参见“自动化变量”一节。
*** 函数库文件的后缀规则
你可以使用“后缀规则”和“隐含规则”来生成函数库打包文件，如：

.c.a:
    $(CC) $(CFLAGS) $(CPPFLAGS) -c $< -o $*.o
    $(AR) r $@ $*.o
    $(RM) $*.o
其等效于：

(%.o) : %.c
    $(CC) $(CFLAGS) $(CPPFLAGS) -c $< -o $*.o
    $(AR) r $@ $*.o
    $(RM) $*.o
*** 注意事项
在进行函数库打包文件生成时，请小心使用make的并行机制（ -j 参数）。如果多个 ar 命令在同一时间运行在同一个函数库打包文件上，就很有可以损坏这个函数库文件。所以，在make未来的版本中，应该提供一种机制来避免并行操作发生在函数打包文件上。

但就目前而言，你还是应该不要尽量不要使用 -j 参数。
** 注释
井号（#）在Makefile中表示注释。
#+begin_src 
# 这是注释
result.txt: source.txt
    # 这是注释
    cp source.txt result.txt # 这也是注释
#+end_src
** 回声（echoing）
正常情况下，make会打印每条命令，然后再执行，这就叫做回声（echoing）。
#+begin_src 
test:
    # 这是测试
#+end_src
执行上面的规则，会得到下面的结果。
#+begin_src 
$ make test
# 这是测试
#+end_src
在命令的前面加上@，就可以关闭回声。
#+begin_src 
test:
    @# 这是测试
#+end_src
现在再执行make test，就不会有任何输出。

由于在构建过程中，需要了解当前在执行哪条命令，所以通常只在注释和纯显示的echo命令前面加上@。
#+begin_src 
test:
    @# 这是测试
    @echo TODO
#+end_src
** 参考文献
[[https://seisman.github.io/how-to-write-makefile/introduction.html][跟我一起写Makefile]]
[[https://www.ruanyifeng.com/blog/2015/02/make.html][Make 命令教程]]
* mkdir
Linux mkdir（英文全拼：make directory）命令用于创建目录。

语法:
mkdir [-p] dirName

参数说明：
-p 确保目录名称存在，不存在的就建一个。

* mount
#+begin_src bash
mount [-t vfstype] [-o options] device dir
#+END_SRC
1.-t vfstype 指定文件系统的类型，通常不必指定。mount 会自动选择正确的类型。
常用类型有：
- 光盘或光盘镜像：iso9660
- DOS fat16文件系统：msdos
- Windows 9x fat32文件系统：vfat
- Windows NT ntfs文件系统：ntfs
- Mount Windows文件网络共享：smbfs
- UNIX(LINUX) 文件网络共享：nfs

2.-o options 主要用来描述设备或档案的挂接方式。
常用的参数有：
- loop：用来把一个文件当成硬盘分区挂接上系统
- ro：采用只读方式挂接设备
- rw：采用读写方式挂接设备
- iocharset：指定访问文件系统所用字符集

3.device 要挂接(mount)的设备。

4.dir设备在系统上的挂接点(mount point)。
* minGW
** 安装
1) 打开 MinGW 官网（点击即可进入官网），下载 MinGW 安装包。

2) 下载完成后，会得到一个名为 mingw-get-setup.exe 的安装包，双击打开它，可以看到如下的对话框：
   #+DOWNLOADED: screenshot @ 2023-09-03 15:10:36
   [[file:images/linux笔记/minGW/2023-09-03_15-10-36_screenshot.png]]
3) 直接点击“Install”，进入下面的对话框：
   #+DOWNLOADED: screenshot @ 2023-09-03 15:10:49
   [[file:images/linux笔记/minGW/2023-09-03_15-10-49_screenshot.png]]
4) 读者可根据自己操作系统的实际情况，自定义 MinGW 的安装位置（例如我选择将其安装到 E 盘），然后点击“continue”，进入下面的对话框：
   #+DOWNLOADED: screenshot @ 2023-09-03 15:11:06
   [[file:images/linux笔记/minGW/2023-09-03_15-11-06_screenshot.png]]
5) 进入安装 MinGW 配置器的界面，读者耐心等待安装完成（显示 100%）即可。安装完成之后，我们会得到一个名为 "MinGW Installer Manager" 的软件，借助它，我们可以随时根据需要修改 GCC 编译器的配置。点击“continue”,会自动弹出配置界面，如下所示：
   #+DOWNLOADED: screenshot @ 2023-09-03 15:11:24
   [[file:images/linux笔记/minGW/2023-09-03_15-11-24_screenshot.png]]
勾选完成后，在菜单栏中选择Installation -> Apply Changes，弹出如下对话框：

#+DOWNLOADED: screenshot @ 2023-09-03 15:11:39
[[file:images/linux笔记/minGW/2023-09-03_15-11-39_screenshot.png]]
选择“Apply”。然后耐心等待，直至安装成功，即可关闭此界面。注意，整个安装过程中可能会提示某些组件下载失败，但没关系，后续需要时，可以通过 MinGw Installer（图 4 所示）安装界面中的 “All Packages”选项中，手动选择指定的安装包进行安装。

6) 在安装完成的基础上，我们需要手动配置 PATH 环境变量。依次右击计算机（我的电脑） -> 属性 -> 高级系统设置 -> 环境变量，建议读者在当前用户的 PATH 环境变量中增加 MinGW 的安装路径，例如我将其安装到了E:\MinGW文件夹中，因此 PATH 环境变量的设置如下：

#+DOWNLOADED: screenshot @ 2023-09-03 15:11:56
[[file:images/linux笔记/minGW/2023-09-03_15-11-56_screenshot.png]]

7) 由此，打开命令行窗口（通过在搜索栏中执行 cmd 指令即可），输入gcc -v指令，如果输出 GCC 编译器的具体信息，则表示安装成功.

* objdump
objdump命令是Linux下的反汇编目标文件或者可执行文件的命令，它以一种可阅读的格式让你更多地了解二进制文件可能带有的附加信息。

参数选项

--archive-headers 
-a 
显示档案库的成员信息,类似ls -l将lib*.a的信息列出。 

-b bfdname 
--target=bfdname 
指定目标码格式。这不是必须的，objdump能自动识别许多格式，比如： 

objdump -b oasys -m vax -h fu.o 
显示fu.o的头部摘要信息，明确指出该文件是Vax系统下用Oasys编译器生成的目标文件。objdump -i将给出这里可以指定的目标码格式列表。 

-C 
--demangle 
将底层的符号名解码成用户级名字，除了去掉所开头的下划线之外，还使得C++函数名以可理解的方式显示出来。 

--debugging 
-g 
显示调试信息。企图解析保存在文件中的调试信息并以C语言的语法显示出来。仅仅支持某些类型的调试信息。有些其他的格式被readelf -w支持。 

-e 
--debugging-tags 
类似-g选项，但是生成的信息是和ctags工具相兼容的格式。 

--disassemble 
-d 
从objfile中反汇编那些特定指令机器码的section。 

-D 
--disassemble-all 
与 -d 类似，但反汇编所有section. 

--prefix-addresses 
反汇编的时候，显示每一行的完整地址。这是一种比较老的反汇编格式。 

-EB 
-EL 
--endian={big|little} 
指定目标文件的小端。这个项将影响反汇编出来的指令。在反汇编的文件没描述小端信息的时候用。例如S-records.

-f 
--file-headers 
显示objfile中每个文件的整体头部摘要信息。 

-h 
--section-headers 
--headers 
显示目标文件各个section的头部摘要信息。 

-H 
--help 
简短的帮助信息。 

-i 
--info 
显示对于 -b 或者 -m 选项可用的架构和目标格式列表。 

-j name
--section=name 
仅仅显示指定名称为name的section的信息 

-l
--line-numbers 
用文件名和行号标注相应的目标代码，仅仅和-d、-D或者-r一起使用使用-ld和使用-d的区别不是很大，在源码级调试的时候有用，要求编译时使用了-g之类的调试编译选项。 

-m machine 
--architecture=machine 
指定反汇编目标文件时使用的架构，当待反汇编文件本身没描述架构信息的时候(比如S-records)，这个选项很有用。可以用-i选项列出这里能够指定的架构.

--reloc 
-r 
显示文件的重定位入口。如果和-d或者-D一起使用，重定位部分以反汇编后的格式显示出来。 

--dynamic-reloc 
-R 
显示文件的动态重定位入口，仅仅对于动态目标文件意义，比如某些共享库。 

-s 
--full-contents 
显示指定section的完整内容。默认所有的非空section都会被显示。 

-S 
--source 
尽可能反汇编出源代码，尤其当编译的时候指定了-g这种调试参数时，效果比较明显。隐含了-d参数。 

--show-raw-insn 
反汇编的时候，显示每条汇编指令对应的机器码，如不指定--prefix-addresses，这将是缺省选项。 

--no-show-raw-insn 
反汇编时，不显示汇编指令的机器码，如不指定--prefix-addresses，这将是缺省选项。 

--start-address=address 
从指定地址开始显示数据，该选项影响-d、-r和-s选项的输出。 

--stop-address=address 
显示数据直到指定地址为止，该项影响-d、-r和-s选项的输出。 

-t 
--syms 
显示文件的符号表入口。类似于nm -s提供的信息 

-T 
--dynamic-syms 
显示文件的动态符号表入口，仅仅对动态目标文件意义，比如某些共享库。它显示的信息类似于 nm -D|--dynamic 显示的信息。 

-V 
--version 
版本信息 

--all-headers 
-x 
显示所可用的头信息，包括符号表、重定位入口。-x 等价于-a -f -h -r -t 同时指定。 

-z 
--disassemble-zeroes 
一般反汇编输出将省略大块的零，该选项使得这些零块也被反汇编。 

@file 
可以将选项集中到一个文件中，然后使用这个@file选项载入。

复制
关于符号表字段下面直接只介绍部分常用的：

.text：已编译程序的机器代码。

.rodata：只读数据，比如printf语句中的格式串和开关（switch）语句的跳转表。

.data：已初始化的全局C变量。局部C变量在运行时被保存在栈中，既不出现在.data中，也不出现在.bss节中。

.bss：未初始化的全局C变量。在目标文件中这个节不占据实际的空间，它仅仅是一个占位符。目标文件格式区分初始化和未初始化变量是为了空间效率在：在目标文件中，未初始化变量不需要占据任何实际的磁盘空间。

.symtab：一个符号表（symbol table），它存放在程序中被定义和引用的函数和全局变量的信息。一些程序员错误地认为必须通过-g选项来编译一个程序，得到符号表信息。实际上，每个可重定位目标文件在.symtab中都有一张符号表。然而，和编译器中的符号表不同，.symtab符号表不包含局部变量的表目。

.rel.text：当链接噐把这个目标文件和其他文件结合时，.text节中的许多位置都需要修改。一般而言，任何调用外部函数或者引用全局变量的指令都需要修改。另一方面调用本地函数的指令则不需要修改。注意，可执行目标文件中并不需要重定位信息，因此通常省略，除非使用者显式地指示链接器包含这些信息。

.rel.data：被模块定义或引用的任何全局变量的信息。一般而言，任何已初始化全局变量的初始值是全局变量或者外部定义函数的地址都需要被修改。

.debug：一个调试符号表，其有些表目是程序中定义的局部变量和类型定义，有些表目是程序中定义和引用的全局变量，有些是原始的C源文件。只有以-g选项调用编译驱动程序时，才会得到这张表。

.line：原始C源程序中的行号和.text节中机器指令之间的映射。只有以-g选项调用编译驱动程序时，才会得到这张表。

.strtab：一个字符串表，其内容包括.symtab和.debug节中的符号表，以及节头部中的节名字。字符串表就是以null结尾的字符串序列。

使用举例：

反汇编应用程序

objdump -d  main.o  

显示文件头信息 

objdump -f main.o

显示制定section段信息(comment段)

objdump -s -j .comment main.o
** 参考文献
[[https://cloud.tencent.com/developer/article/1494510][objdump命令解析- 云+社区 - 腾讯云]]
* OpenCV
** C++接口
先安装依赖
#+BEGIN_SRC bash
sudo apt-get install build-essential
sudo apt-get install cmake git libgtk2.0-dev pkg-config libavcodec-dev libavformat-dev libswscale-dev
sudo apt-get install python-dev python-numpy libtbb2 libtbb-dev libjpeg-dev libpng-dev libtiff-dev libjasper-dev libdc1394-22-dev
#+END_SRC
然后，将压缩包解压，我下载我是opencv3.4.3版本，所以最后解压出来的文件夹就是opencv-3.4.3，接着，先用命令行进入该文件夹，然后执行命令，如下所示：
#+BEGIN_SRC bash
cd ~/opencv-3.4.3  # 进入opencv文件夹
mkdir build # 创建build文件夹
cd build # 进入build文件夹

#cmake指令，如果没有特殊要求建议就选择默认的就可以
#注意，后面的两个点千万不能省，代表了上级目录
cmake -D CMAKE_BUILD_TYPE=Release -D CMAKE_INSTALL_PREFIX=/usr/local ..  
make -j7 # 多线程执行make任务

# 最后一步，安装库文件
sudo make install

#安装完成
#+END_SRC
** python接口
方法一：用pip命令即可
#+BEGIN_SRC bash
pip install opencv-python #安装opencv
pip install opencv-contrib-python #安装opencv的contrib扩展包
#+END_SRC

方法二：用conda安装
#+BEGIN_SRC bash
conda search opencv #查询一下conda里面可以安装的opencv
conda install opencv=3.1.0 #根据你想要安装的opencv版本（以3.1.0为例），输入指令
#+END_SRC
* od 命令
od（Octal Dump）命令用于将指定文件内容以八进制、十进制、十六进制、浮点格式或 ASCII 编码字符方式显示，通常用于显示或查看文件中不能直接显示在终端的字符。od 命令系统默认的显示方式是八进制。

常见的文件为文本文件和二进制文件。od 命令主要用来查看保存在二进制文件中的值，按照指定格式解释文件中的数据并输出，不管是 IEEE754 格式的浮点数还是 ASCII 码，od 命令都能按照需求输出它们的值。

命令格式: od [OPTION]... [FILE]...

参数：
#+BEGIN_EXAMPLE
-A RADIX
--address-radix=RADIX
	选择以何种基数表示地址偏移
-j BYTES
--skip-bytes=BYTES
	跳过指定数目的字节
-N BYTES
--read-bytes=BYTES
	输出指定字节数
-S [BYTES]
--strings[=BYTES]
	输出长度不小于指定字节数的字符串，BYTES 缺省为 3
-v
--output-duplicates
	输出时不省略重复的数据
-w [BYTES]
--width[=BYTES]
	设置每行显示的字节数，BYTES 缺省为 32 字节
-t TYPE
--format=TYPE
	指定输出格式，格式包括 a、c、d、f、o、u 和 x，各含义如下：
  	a：具名字符；比如换行符显示为 nl
  	c：可打印字符或反斜杠表示的转义字符；比如换行符显示为 \n
 	d[SIZE]：SIZE 字节组成一个有符号十进制整数。SIZE 缺省为 sizeof(int)
 	f[SIZE]：SIZE 字节组成一个浮点数。SIZE 缺省为 sizeof(double)
  	o[SIZE]：SIZE 字节组成一个八进制整数。SIZE 缺省为 sizeof(int)
  	u[SIZE]：SIZE 字节组成一个无符号十进制整数。SIZE 缺省为 sizeof(int)
  	x[SIZE]：SIZE 字节组成一个十六进制整数。SIZE 缺省为 sizeof(int)
  	SIZE 可以为数字，也可以为大写字母。如果 TYPE 是 [doux] 中的一个，那么 SIZE 可以为 C  = sizeof(char)，S = sizeof(short)，I = sizeof(int)，L = sizeof(long)。如果 TYPE 是 f，那么 SIZE 可以为 F = sizeof(float)，D = sizeof(double) ，L = sizeof(long double)
--help
	在线帮助
--version
	显示版本信息
#+END_EXAMPLE

* Pytorch安装
首先安装Anaconda.

然后进入pytorch官网,根据自己的情况进行选择,之后最下方红线位置就会显示你应该输入的安装命令

#+DOWNLOADED: file:F:/org/图片/Snipaste_2020-06-02_17-33-39.png @ 2020-06-02 17:33:46
[[file:安装Pytorch/2020-06-02_17-33-46_Snipaste_2020-06-02_17-33-39.png]]


将得到的命令粘贴到终端窗口中运行即可.

#+DOWNLOADED: file:F:/org/图片/20180117102533147.png @ 2020-06-02 17:28:16
[[file:安装Pytorch/2020-06-02_17-28-16_20180117102533147.png]]

验证pytorch是否安装成功:

terminal内输入python，进入python环境
然后输入下面的命令:
#+BEGIN_SRC bash
import torch
import torchvision
#+END_SRC

不报错的话就说明pytorch安装成功了，如图所示
#+DOWNLOADED: file:F:/org/图片/Snipaste_2020-06-02_17-29-56.png @ 2020-06-02 17:30:06
[[file:安装Pytorch/2020-06-02_17-30-06_Snipaste_2020-06-02_17-29-56.png]]

如果下载速度很慢的话，可以选择pip方式下载安装,如下图所示

#+DOWNLOADED: file:F:/org/图片/Snipaste_2020-06-02_17-26-40.png @ 2020-06-02 17:31:43
[[file:安装Pytorch/2020-06-02_17-31-43_Snipaste_2020-06-02_17-26-40.png]]

一般这个pip方式会比较快吧，但如果很不幸，你的pip方式也遇到网络很差的问题，那就下载文件吧……

在浏览器里新建任务，下载链接就是图中命令位置里的链接: [[https://download.............]]  把这个文件下载下来，实在不行去windows上面用迅雷下载这个文件，下载好了之后copy到你的Linux系统上去，然后找到文件位置，直接pip install 文件名

* python安装
以下为在 Unix & Linux 平台上安装 Python 的简单步骤：
- 打开 WEB 浏览器访问 https://www.python.org/downloads/source/
- 选择适用于 Unix/Linux 的源码压缩包。
- 下载及解压压缩包 Python-3.x.x.tgz，3.x.x 为你下载的对应版本号。
- 如果你需要自定义一些选项修改 Modules/Setup

以 Python3.6.1 版本为例：
#+begin_src bash
tar -zxvf Python-3.6.1.tgz
cd Python-3.6.1
./configure
make && make install
#+END_SRC
检查 Python3 是否正常可用：
#+begin_src python
>>> python3 -V
Python 3.6.1
#+END_SRC
** no module named zlib错误的解决方法
#+begin_src bash
sudo apt-get install zlib1g-dev
#+END_SRC
* pip的用法
#+BEGIN_SRC bash
sudo pip3 --no-cache-dir --default-timeout=100 install -i https://pypi.tuna.tsinghua.edu.cn/simple torch
#+END_SRC
--no-cache-dir：pip下载库时会占用缓存，当文件过大会导致错误，这个选项可以避免该错误
#+BEGIN_SRC bash
pip install -r requirements.txt
#+END_SRC
-r表示从requirements.txt读取安装列表
浙大内部镜像：http://mirrors.aliyun.com/
** 换源
清华源

临时使用
#+begin_src bash
pip install -i https://pypi.tuna.tsinghua.edu.cn/simple some-package
#+END_SRC
注意，simple 不能少, 是 https 而不是 http

设为默认
升级 pip 到最新的版本 (>=10.0.0) 后进行配置：
#+begin_src bash
pip install pip -U
pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple
#+END_SRC
如果您到 pip 默认源的网络连接较差，临时使用本镜像站来升级 pip：
#+begin_src bash
pip install -i https://pypi.tuna.tsinghua.edu.cn/simple pip -U
#+END_SRC

** 安装包
#+begin_src bash
pip install SomePackage              # 最新版本
pip install SomePackage==1.0.4       # 指定版本
pip install 'SomePackage>=1.0.4'     # 最小版本
#+END_SRC
比如我要安装 Django。用以下的一条命令就可以，方便快捷。

pip install Django==1.7

** 升级包
pip install --upgrade SomePackage

升级指定的包，通过使用==, >=, <=, >, < 来指定一个版本号。
** 卸载包
pip uninstall SomePackage
** 搜索包
pip search SomePackage
** 显示安装包信息
pip show 
** 查看指定包的详细信息
pip show -f SomePackage
** 列出已安装的包
pip list
** 查看可升级的包
pip list -o
** 显示版本和路径
pip --version
** 获取帮助
pip --help
** 升级 pip
#+BEGIN_EXAMPLE
如果升级命令出现问题 ，可以使用以下命令：
sudo easy_install --upgrade pip
#+END_EXAMPLE
*** Linux 或 macOS
#+begin_src bash
pip install --upgrade pip    # python2.x
pip3 install --upgrade pip   # python3.x
#+END_SRC 
*** Windows 平台升级：
#+begin_src bash
python -m pip install -U pip   # python2.x
python -m pip3 install -U pip    # python3.x
#+END_SRC
** socket.timeout: The read operation timed out解决方案
解决方法：pip --default-timeout=100 install -U tensorflow
* page cache
** Free命令显示内存
#+DOWNLOADED: screenshot @ 2023-07-25 23:09:13
[[file:images/linux笔记/page_cache/2023-07-25_23-09-13_screenshot.png]]
- Mem：表示物理内存统计。
- total：表示物理内存总量(total = used + free)。
- used：表示总计分配给缓存（包含buffers 与cache ）使用的数量，但其中可能部分缓存并未实际使用。
- free：未被分配的内存。
- shared：共享内存。
- buffers：系统分配但未被使用的buffers数量。
- cached：系统分配但未被使用的cache数量。
- -/+ buffers/cache：表示物理内存的缓存统计。
- used2：也就是第一行中的used – buffers - cached也是实际使用的内存总量。 // used2为第二行
- free2 = buffers1 + cached1 + free1 // free2为第二行，buffers1等为第一行
- free2：未被使用的buffers与cache和未被分配的内存之和，这就是系统当前实际可用内存。
- Swap：表示硬盘上交换分区的使用情况。

在Free命令中显示的buffer和cache，它们都是占用内存：

buffer : 作为buffer cache的内存，是块设备的读写缓冲区，更靠近存储设备，或者直接就是disk的缓冲区。

cache: 作为page cache的内存, 文件系统的cache，是memory的缓冲区 。

如果cache 的值很大，说明cache住的文件数很多。如果频繁访问到的文件都能被cache住，那么磁盘的读IO 必会非常小 。

** Page cache（页面缓存）
Page cache 也叫页缓冲或文件缓冲，是由好几个磁盘块构成，大小通常为4k，在64位系统上为8k，构成的几个磁盘块在物理磁盘上不一定连续，文件的组织单位为一页， 也就是一个page cache大小.

page cache由多个buffer cache组成.

Page cache在linux读写文件时，它用于缓存文件的逻辑内容，从而加快对磁盘上映像和数据的访问。具体说是加速对文件内容的访问，buffer cache缓存文件的具体内容——物理磁盘上的磁盘块，这是加速对磁盘的访问。

** Buffer cache（块缓存）
Buffer cache 也叫块缓冲，是对物理磁盘上的一个磁盘块进行的缓冲，其大小为通常为1k，磁盘块也是磁盘的组织单位。设立buffer cache的目的是为在程序多次访问同一磁盘块时，减少访问时间。系统将磁盘块首先读入buffer cache，如果cache空间不够时，会通过一定的策略将一些过时或多次未被访问的buffer cache清空。程序在下一次访问磁盘时首先查看是否在buffer cache找到所需块，命中可减少访问磁盘时间。不命中时需重新读入buffer cache。对buffer cache的写分为两种，一是直接写，这是程序在写buffer cache后也写磁盘，要读时从buffer cache上读，二是后台写，程序在写完buffer cache后并不立即写磁盘，因为有可能程序在很短时间内又需要写文件，如果直接写，就需多次写磁盘了。这样效率很低，而是过一段时间后由后台写，减少了多次访磁盘的时间。

Buffer cache是由物理内存分配，Linux系统为提高内存使用率，会将空闲内存全分给buffer cache ，当其他程序需要更多内存时，系统会减少cache大小。

** 参考文章
[[https://zhuanlan.zhihu.com/p/35277219][Linux系统中的Page cache和Buffer cache]]
* paste 命令
Linux paste 命令用于合并文件的列。

paste 指令会把每个文件以列对列的方式，一列列地加以合并。

语法
paste [-s][-d <间隔字符>][--help][--version][文件...]
参数：
- -d<间隔字符>或--delimiters=<间隔字符> 　用指定的间隔字符取代跳格字符。
- -s或--serial 　串列进行而非平行处理。
- --help 　在线帮助。
- --version 　显示帮助信息。
- [文件…] 指定操作的文件路径

** 实例
使用paste指令将文件"file"、"testfile"、"testfile1"进行合并，输入如下命令：
#+begin_src bash
paste file testfile testfile1 #合并指定文件的内容 
#+END_SRC
但是，在执行以上命令之前，首先使用"cat"指令对3个文件内容进行查看，显示如下所示：
#+begin_src bash
$ cat file                  #file文件的内容  
xiongdan 200  
lihaihui 233  
lymlrl 231  
$ cat testfile              #testfile文件的内容  
liangyuanm  ss  
$ cat testfile1             #testfile1文件的内容  
huanggai 56  
zhixi 73 
#+END_SRC
当合并指令"$ paste file testfile testfile1"执行后，程序界面中将显示合并后的文件内容，如下所示：
#+BEGIN_EXAMPLE
xiongdan 200  
lihaihui 233  
lymlrl 231  
liangyuanm  ss  
huanggai 56  
zhixi 73  
#+END_EXAMPLE

若使用paste指令的参数"-s"，则可以将一个文件中的多行数据合并为一行进行显示。例如，将文件"file"中的3行数据合并为一行数据进行显示，输入如下命令
#+begin_src bash
$ paste -s file             #合并指定文件的多行数据
#+END_SRC
上面的命令执行后，显示的数据内容如下所示：
#+BEGIN_EXAMPLE
xiongdan 200 lihaihui 233 lymlrl 231 
#+END_EXAMPLE

注意：参数"-s"只是将testfile文件的内容调整显示方式，并不会改变原文件的内容格式。
* PS1设置
** bash
#+BEGIN_EXAMPLE
\d ：代表日期，格式为weekday month date，例如："Mon Aug1"
\H：完整的主机名称。例如：我的机器名称为：fc4.linux，则这个名称就是fc4.linux
\h ：仅取主机的第一个名字，如上例，则为fc4，.linux则被省略 
\t ：显示时间为24小时格式，如：HH：MM：SS 
\T ：显示时间为12小时格式 
\A ：显示时间为24小时格式：HH：MM 
\u ：当前用户的账号名称
\v ：BASH的版本信息
\w ：完整的工作目录名称。家目录会以 ~代替
\W ：利用basename取得工作目录名称，所以只会列出最后一个目录
\# ：下达的第几个命令
\$ ：提示字符，如果是root时，提示符为：# ，普通用户则为：$
#+END_EXAMPLE
*** 颜色
 颜色代码格式：\[\e[F;Bm\]，F表示字体颜色，B表示背景颜色

 We will use the \e special character at the beginning and an m at the end to indicate that what follows is a color sequence.

 For example, the following PS1 will cause the prompt to appear in yellow underlined text with red background:
 #+begin_src bash
 PS1="\e[41;4;33m[\u@\h \W]$ "
 #+END_SRC

 #+DOWNLOADED: screenshot @ 2021-12-10 16:58:01
 [[file:images/linux%E7%AC%94%E8%AE%B0/PS1%E8%AE%BE%E7%BD%AE/2021-12-10_16-58-01_screenshot.png]]

 注意在$符号输出之后，我们还要重置颜色为透明，也就是\[\e[0m\]，这样你输入的命令就不会受之前颜色设置的影响。
 例如：PS1="\e[42;0;32m\u@\h:\w\$\e[0m"
 颜色表如下：
 | Text Format        | Foreground (text) color | Background color |
 |--------------------+-------------------------+------------------|
 | 0: normal text     | 30: Black               | 40: Black        |
 | 1: bold            | 31: Red                 | 41: Red          |
 | 4: Underlined text | 32: Green               | 42: Green        |
 |                    | 33: Yellow              | 43: Yellow       |
 |                    | 34: Blue                | 44: Blue         |
 |                    | 35: Purple              | 45: Purple       |
 |                    | 36: Cyan                | 46: Cyan         |
 |                    | 37: White               | 47: White        |
**** 参考文章
 [[https://www.tecmint.com/customize-bash-colors-terminal-prompt-linux/][How to Customize Bash Colors and Content in Linux Terminal Prompt]]
*** What does "${debian_chroot:+($debian_chroot)}" do in my terminal prompt?
 The important part to answer this question is this snippet from /etc/bash.bashrc:
 #+begin_src bash
 if [ -z "$debian_chroot" ] && [ -r /etc/debian_chroot ]; then
     debian_chroot=$(cat /etc/debian_chroot)
 fi
 #+END_SRC
 It means if the variable $debian_chroot is empty and the file /etc/debian_chroot exists and is readable the variable is set to the content of the file.

 Now what is this for? The file /etc/debian_chroot is when you have a chrooted debian system inside another debian system (ubuntu is based on debian). So this is for a better overview. To distinguish whether you are in the chroot or not.

 When you have a chroot of another system for example in /srv/nfs4/netboot/ you can set a name for this chroot in /srv/nfs4/netboot/etc/debian_chroot (in my case it's a nfs4 pxe netboot drive):
 #+begin_src bash
 user@host:~# echo "netboot" >/srv/nfs4/netboot/etc/debian_chroot
 #+END_SRC
 And then when you chroot inside:
 #+begin_src bash
 chroot /srv/nfs4/netboot/
 #+END_SRC

 Your prompt looks like this:
 #+begin_src bash
 (netboot)user@host:~#
 #+END_SRC

** zsh
oh-my-zsh终端用户名设置

先查看一下当前使用的主题：
#+begin_src bash
echo $ZSH_THEME
#+END_SRC
查看自己主题，我的是robbyrussell

之后进入oh-my-zsh的主题目录，修改主题设置
#+begin_src bash
cd ~/.oh-my-zsh/themes
vim robbyrussell.zsh-theme
#+END_SRC
可以看到
#+begin_src bash
local ret_status="%(?:%{$fg_bold[green]%}➜ :%{$fg_bold[red]%}➜ )"
PROMPT='${ret_status} %{$fg[cyan]%}%~%{$reset_color%} $(git_prompt_info)'

ZSH_THEME_GIT_PROMPT_PREFIX="%{$fg_bold[blue]%}git:(%{$fg[red]%}"
ZSH_THEME_GIT_PROMPT_SUFFIX="%{$reset_color%} "
ZSH_THEME_GIT_PROMPT_DIRTY="%{$fg[blue]%}) %{$fg[yellow]%}✗"
ZSH_THEME_GIT_PROMPT_CLEAN="%{$fg[blue]%})"
#+END_SRC
PROMPT就是设置显示的用户名

由于oh_my_zsh时常会有版本更新，为了避免我们修改的跟更新的版本有冲突，建议不要修改robbyrussell.zsh-theme，而是将其拷贝出来，命名为自己的主题文件，比如叫做myrobbyrussell.zsh-theme，然后只对myrobbyrussell.zsh-theme进行修改。

修改后将 ~/.zshrc 中的
#+begin_src bash
ZSH_THEME="robbyrussell"
#+END_SRC
改为
#+begin_src bash
ZSH_THEME="myrobbyrussell"
#+END_SRC
这样就能避免冲突了。

#+BEGIN_EXAMPLE
%T	系统时间（时：分）
%*	系统时间（时：分：秒）
%D	系统日期（年-月-日）
%n	用户名称（即：当前登陆终端的用户的名称，和whami命令输出相同）
%B - %b	开始到结束使用粗体打印
%U - %u	开始到结束使用下划线打印
%d	你当前的工作目录
%~	你目前的目录相对于～的相对路径
%M	计算机的主机名
%m	计算机的主机名（在第一个句号之前截断）
%l	你当前的tty
#+END_EXAMPLE
* QEMU
“Qemu”是一个广泛使用的开源计算机模拟器和虚拟机。"

当作为模拟器时，可以在一种架构（如x86 PC）下运行另一种架构（如ARM）下的操作系统和程序。通过使用动态转换，它可以获得非常好的性能。

作为虚拟机时，QEMU可以使用其他虚拟机管理程序（如 Xen 或 KVM）来使用CPU扩展（HVM）进行虚拟化，通过在主机CPU上直接执行客户机代码来获得接近于宿主机的性能。
** 参考文章
[[https://wiki.archlinux.org/title/QEMU_(%25E7%25AE%2580%25E4%25BD%2593%25E4%25B8%25AD%25E6%2596%2587)][QEMU (简体中文)]]
* rsync
** 简介
rsync 是一个常用的 Linux 应用程序，用于文件同步。

它可以在本地计算机与远程计算机之间，或者两个本地目录之间同步文件（但不支持两台远程计算机之间的同步）。它也可以当作文件复制工具，替代cp和mv命令。

它名称里面的r指的是 remote，rsync 其实就是"远程同步"（remote sync）的意思。与其他文件传输工具（如 FTP 或 scp）不同，rsync 的最大特点是会检查发送方和接收方已有的文件，仅传输有变动的部分（默认规则是文件大小或修改时间有变动）。
** 安装方法
如果本机或者远程计算机没有安装 rsync，可以用下面的命令安装。
#+begin_src bash
# Debian
$ sudo apt-get install rsync

# Red Hat
$ sudo yum install rsync

# Arch Linux
$ sudo pacman -S rsync
#+END_SRC
注意，传输的双方都必须安装 rsync。
** 参数
-a、--archive参数表示存档模式，保存所有的元数据，比如修改时间（modification time）、权限、所有者等，并且软链接也会同步过去。

--append参数指定文件接着上次中断的地方，继续传输。

--append-verify参数跟--append参数类似，但会对传输完成后的文件进行一次校验。如果校验失败，将重新发送整个文件。

-b、--backup参数指定在删除或更新目标目录已经存在的文件时，将该文件更名后进行备份，默认行为是删除。更名规则是添加由--suffix参数指定的文件后缀名，默认是~。

--backup-dir参数指定文件备份时存放的目录，比如--backup-dir=/path/to/backups。

--bwlimit参数指定带宽限制，默认单位是 KB/s，比如--bwlimit=100。

-c、--checksum参数改变rsync的校验方式。默认情况下，rsync 只检查文件的大小和最后修改日期是否发生变化，如果发生变化，就重新传输；使用这个参数以后，则通过判断文件内容的校验和，决定是否重新传输。

--delete参数删除只存在于目标目录、不存在于源目标的文件，即保证目标目录是源目标的镜像。

-e参数指定使用 SSH 协议传输数据。

--exclude参数指定排除不进行同步的文件，比如--exclude="*.iso"。

--exclude-from参数指定一个本地文件，里面是需要排除的文件模式，每个模式一行。

--existing、--ignore-non-existing参数表示不同步目标目录中不存在的文件和目录。

-h参数表示以人类可读的格式输出。

-h、--help参数返回帮助信息。

-i参数表示输出源目录与目标目录之间文件差异的详细情况。

--ignore-existing参数表示只要该文件在目标目录中已经存在，就跳过去，不再同步这些文件。

--include参数指定同步时要包括的文件，一般与--exclude结合使用。

--link-dest参数指定增量备份的基准目录。

-m参数指定不同步空目录。

--max-size参数设置传输的最大文件的大小限制，比如不超过200KB（--max-size='200k'）。

--min-size参数设置传输的最小文件的大小限制，比如不小于10KB（--min-size=10k）。

-n参数或--dry-run参数模拟将要执行的操作，而并不真的执行。配合-v参数使用，可以看到哪些内容会被同步过去。

-P参数是--progress和--partial这两个参数的结合。

--partial参数允许恢复中断的传输。不使用该参数时，rsync会删除传输到一半被打断的文件；使用该参数后，传输到一半的文件也会同步到目标目录，下次同步时再恢复中断的传输。一般需要与--append或--append-verify配合使用。

--partial-dir参数指定将传输到一半的文件保存到一个临时目录，比如--partial-dir=.rsync-partial。一般需要与--append或--append-verify配合使用。

--progress参数表示显示进展。

-r参数表示递归，即包含子目录。

--remove-source-files参数表示传输成功后，删除发送方的文件。

--size-only参数表示只同步大小有变化的文件，不考虑文件修改时间的差异。

--suffix参数指定文件名备份时，对文件名添加的后缀，默认是~。

-u、--update参数表示同步时跳过目标目录中修改时间更新的文件，即不同步这些有更新的时间戳的文件。

-v参数表示输出细节。-vv表示输出更详细的信息，-vvv表示输出最详细的信息。

--version参数返回 rsync 的版本。

-z参数指定同步时压缩数据。
** 参数详解
*** -r
本机使用 rsync 命令时，可以作为cp和mv命令的替代方法，将源目录同步到目标目录。
#+begin_src bash
$ rsync -r source destination
#+END_SRC
上面命令中，-r表示递归，即包含子目录。注意，-r是必须的，否则 rsync 运行不会成功。source目录表示源目录，destination表示目标目录。

如果有多个文件或目录需要同步，可以写成下面这样。
#+begin_src bash
$ rsync -r source1 source2 destination
#+END_SRC
上面命令中，source1、source2都会被同步到destination目录。
*** -a 参数
-a参数可以替代-r，除了可以递归同步以外，还可以同步元信息（比如修改时间、权限等）。由于 rsync 默认使用文件大小和修改时间决定文件是否需要更新，所以-a比-r更有用。下面的用法才是常见的写法。
#+begin_src bash
$ rsync -a source destination
#+END_SRC
目标目录destination如果不存在，rsync 会自动创建。执行上面的命令后，源目录source被完整地复制到了目标目录destination下面，即形成了destination/source的目录结构。

如果只想同步源目录source里面的内容到目标目录destination，则需要在源目录后面加上斜杠。
#+begin_src bash
$ rsync -a source/ destination
#+END_SRC
上面命令执行后，source目录里面的内容，就都被复制到了destination目录里面，并不会在destination下面创建一个source子目录。
*** -n 参数
如果不确定 rsync 执行后会产生什么结果，可以先用-n或--dry-run参数模拟执行的结果。
#+begin_src bash
$ rsync -anv source/ destination
#+END_SRC
上面命令中，-n参数模拟命令执行的结果，并不真的执行命令。
*** -v
-v参数是将结果输出到终端，这样就可以看到哪些内容会被同步。
*** --delete 参数
默认情况下，rsync 只确保源目录的所有内容（明确排除的文件除外）都复制到目标目录。它不会使两个目录保持相同，并且不会删除文件。如果要使得目标目录成为源目录的镜像副本，则必须使用--delete参数，这将删除只存在于目标目录、不存在于源目录的文件。
#+begin_src bash
$ rsync -av --delete source/ destination
#+END_SRC
上面命令中，--delete参数会使得destination成为source的一个镜像。
*** --exclude 参数
有时，我们希望同步时排除某些文件或目录，这时可以用--exclude参数指定排除模式。
#+begin_src bash
$ rsync -av --exclude='*.txt' source/ destination
# 或者
$ rsync -av --exclude '*.txt' source/ destination
#+END_SRC
上面命令排除了所有 TXT 文件。

注意，rsync 会同步以"点"开头的隐藏文件，如果要排除隐藏文件，可以这样写--exclude=".*"。

如果要排除某个目录里面的所有文件，但不希望排除目录本身，可以写成下面这样。
#+begin_src bash
$ rsync -av --exclude 'dir1/*' source/ destination
#+END_SRC
多个排除模式，可以用多个--exclude参数。
#+begin_src bash
$ rsync -av --exclude 'file1.txt' --exclude 'dir1/*' source/ destination
#+END_SRC
多个排除模式也可以利用 Bash 的大扩号的扩展功能，只用一个--exclude参数。
#+begin_src bash
$ rsync -av --exclude={'file1.txt','dir1/*'} source/ destination
#+END_SRC
如果排除模式很多，可以将它们写入一个文件，每个模式一行，然后用--exclude-from参数指定这个文件。
#+begin_src bash
$ rsync -av --exclude-from='exclude-file.txt' source/ destination
#+END_SRC
*** --include 参数
--include参数用来指定必须同步的文件模式，往往与--exclude结合使用。
#+begin_src bash
$ rsync -av --include="*.txt" --exclude='*' source/ destination
#+END_SRC
上面命令指定同步时，排除所有文件，但是会包括 TXT 文件。
** 远程同步
*** SSH 协议
rsync 除了支持本地两个目录之间的同步，也支持远程同步。它可以将本地内容，同步到远程服务器。
#+begin_src bash
$ rsync -av source/ username@remote_host:destination
#+END_SRC
也可以将远程内容同步到本地。
#+begin_src bash
$ rsync -av username@remote_host:source/ destination
#+END_SRC
rsync 默认使用 SSH 进行远程登录和数据传输。

由于早期 rsync 不使用 SSH 协议，需要用-e参数指定协议，后来才改的。所以，下面-e ssh可以省略。
#+begin_src bash
$ rsync -av -e ssh source/ user@remote_host:/destination
#+END_SRC
但是，如果 ssh 命令有附加的参数，则必须使用-e参数指定所要执行的 SSH 命令。
#+begin_src bash
$ rsync -av -e 'ssh -p 2234' source/ user@remote_host:/destination
#+END_SRC
上面命令中，-e参数指定 SSH 使用2234端口。
*** rsync 协议
除了使用 SSH，如果另一台服务器安装并运行了 rsync 守护程序，则也可以用rsync://协议（默认端口873）进行传输。具体写法是服务器与目标目录之间使用双冒号分隔::。
#+begin_src bash
$ rsync -av source/ 192.168.122.32::module/destination
#+END_SRC
注意，上面地址中的module并不是实际路径名，而是 rsync 守护程序指定的一个资源名，由管理员分配。

如果想知道 rsync 守护程序分配的所有 module 列表，可以执行下面命令。
#+begin_src bash
$ rsync rsync://192.168.122.32
#+END_SRC
rsync 协议除了使用双冒号，也可以直接用rsync://协议指定地址。
#+begin_src bash
$ rsync -av source/ rsync://192.168.122.32/module/destination
#+END_SRC

** 增量备份
rsync 的最大特点就是它可以完成增量备份，也就是默认只复制有变动的文件。

除了源目录与目标目录直接比较，rsync 还支持使用基准目录，即将源目录与基准目录之间变动的部分，同步到目标目录。

具体做法是，第一次同步是全量备份，所有文件在基准目录里面同步一份。以后每一次同步都是增量备份，只同步源目录与基准目录之间有变动的部分，将这部分保存在一个新的目标目录。这个新的目标目录之中，也是包含所有文件，但实际上，只有那些变动过的文件是存在于该目录，其他没有变动的文件都是指向基准目录文件的硬链接。

--link-dest参数用来指定同步时的基准目录。
#+begin_src bash
$ rsync -a --delete --link-dest /compare/path /source/path /target/path
#+END_SRC
上面命令中，--link-dest参数指定基准目录/compare/path，然后源目录/source/path跟基准目录进行比较，找出变动的文件，将它们拷贝到目标

目录/target/path。那些没变动的文件则会生成硬链接。这个命令的第一次备份时是全量备份，后面就都是增量备份了。

下面是一个脚本示例，备份用户的主目录。
#+begin_src bash
#!/bin/bash

# A script to perform incremental backups using rsync

set -o errexit
set -o nounset
set -o pipefail

readonly SOURCE_DIR="${HOME}"
readonly BACKUP_DIR="/mnt/data/backups"
readonly DATETIME="$(date '+%Y-%m-%d_%H:%M:%S')"
readonly BACKUP_PATH="${BACKUP_DIR}/${DATETIME}"
readonly LATEST_LINK="${BACKUP_DIR}/latest"

mkdir -p "${BACKUP_DIR}"

rsync -av --delete \
  "${SOURCE_DIR}/" \
  --link-dest "${LATEST_LINK}" \
  --exclude=".cache" \
  "${BACKUP_PATH}"

rm -rf "${LATEST_LINK}"
ln -s "${BACKUP_PATH}" "${LATEST_LINK}"
#+END_SRC
上面脚本中，每一次同步都会生成一个新目录${BACKUP_DIR}/${DATETIME}，并将软链接${BACKUP_DIR}/latest指向这个目录。下一次备份时，就将${BACKUP_DIR}/latest作为基准目录，生成新的备份目录。最后，再将软链接${BACKUP_DIR}/latest指向新的备份目录。
** 参考文章
[[https://www.ruanyifeng.com/blog/2020/08/rsync.html][rsync 用法教程]]
* rm
-f, --force    忽略不存在的文件，从不给出提示。
-i, --interactive 进行交互式删除
-r, -R, --recursive   指示rm将参数中列出的全部目录和子目录均递归地删除。
-v, --verbose    详细显示进行的步骤
   --help     显示此帮助信息并退出
   --version  输出版本信息并退出
* rz和sz命令使用
rz命令是方便从windows传文件到Linux，在windows下通过连接工具进入linux系统，cd到自己需要的目录，命令行输入rz，然后回车，之后会弹出一个选择框，选择我们需要上传的文件，然后add，最后上传就好了。

#: rz 

sz命令反过来，是从Linux传输文件到windows，同样Linux下我们需要传的文件所在目录，命令行输入sz，后面跟上需要传输的文件命，可以是一个文件，也可以跟多个文件名，同时传多个文件，然后回车，就可以传文件了。默认情况文件传到windows的用户下载目录下。

#: sz filename1 filename2 filename3

这两个命令传输传输小文件很方便也很快，但是遇到大文件经常需要很久，甚至传了一部分然后中断了，这时就需要nc命令出场了，传输大文件也非常快。
* scp
scp可以用于从远程复制文件到本地、从本地复制文件到服务器，也可以在两个远程服务器之间传输文件

（1）-c

-c参数用来指定文件拷贝数据传输的加密算法。

$ scp -c blowfish some_file your_username@remotehost.edu:~
上面代码指定加密算法为blowfish。

（2）-C

-C参数表示是否在传输时压缩文件。

$ scp -c blowfish -C local_file your_username@remotehost.edu:~
（3）-F

-F参数用来指定 ssh_config 文件，供 ssh 使用。

$ scp -F /home/pungki/proxy_ssh_config Label.pdf root@172.20.10.8:/root
（4）-i

-i参数用来指定密钥。

$ scp -vCq -i private_key.pem ~/test.txt root@192.168.1.3:/some/path/test.txt
（5）-l

-l参数用来限制传输数据的带宽速率，单位是 Kbit/sec。对于多人分享的带宽，这个参数可以留出一部分带宽供其他人使用。

$ scp -l 80 yourusername@yourserver:/home/yourusername/* .
上面代码中，scp命令占用的带宽限制为每秒 80K 比特位，即每秒 10K 字节。

（6）-p

-p参数用来保留修改时间（modification time）、访问时间（access time）、文件状态（mode）等原始文件的信息。

$ scp -p ~/test.txt root@192.168.1.3:/some/path/test.txt
（7）-P

-P参数用来指定远程主机的 SSH 端口。如果远程主机使用默认端口22，可以不用指定，否则需要用-P参数在命令中指定。

$ scp -P 2222 user@host:directory/SourceFile TargetFile
（8）-q

-q参数用来关闭显示拷贝的进度条。

$ scp -q Label.pdf mrarianto@202.x.x.x:.
（9）-r

-r参数表示是否以递归方式复制目录。

（10）-v

-v参数用来显示详细的输出。

$ scp -v ~/test.txt root@192.168.1.3:/root/help2356.txt
* sed
sed采用的是流编辑模式，最明显的特点是，在 sed 处理数据之前，需要预先提供一组规则，sed 会按照此规则来编辑数据。

sed 会根据脚本命令来处理文本文件中的数据，这些命令要么从命令行中输入，要么存储在一个文本文件中，此命令执行数据的顺序如下：
- 每次仅读取一行内容；
- 根据提供的规则命令匹配并修改数据。注意，sed 默认不会直接修改源文件数据，而是会将数据复制到缓冲区中，修改也仅限于缓冲区中的数据；
- 将执行结果输出。

当一行数据匹配完成后，它会继续读取下一行数据，并重复这个过程，直到将文件中所有数据处理完毕。

sed 命令的基本格式如下：
#+begin_src bash
[root@localhost ~]# sed [选项] [脚本命令] 文件名
#+END_SRC

该命令常用的选项及含义，如下表所示。
| 选项            | 含义                                                                                                                        |
|-----------------+-----------------------------------------------------------------------------------------------------------------------------|
| -e 脚本命令     | 该选项会将其后跟的脚本命令添加到已有的命令中。                                                                              |
| -f 脚本命令文件 | 该选项会将其后文件中的脚本命令添加到已有的命令中。                                                                          |
| -n              | 默认情况下，sed 会在所有的脚本指定执行完毕后，会自动输出处理后的内容，而该选项会屏蔽启动输出，需使用 print 命令来完成输出。 |
| -i              | 此选项会直接修改源文件，要慎用。                                                                                            |

** sed选项
*** -n
sed 会将模式空间里的行经过处理后输出到标准输出，这是默认的处理方式。也就是说，除非你使用“d”来删除此行，否则经过“模式空间”处理的行都是会被输出到标准输出（屏幕）上的。

使用-n 选项只输出处理成功的行
#+begin_src bash
#还是先来看看原文件的内容
[roc@roclinux ~]$ cat roc.txt
1
2
3
4
5
 
#仔细看, 输出中出现了两个“4”
[roc@roclinux ~]$ sed ‘/4/p’ roc.txt
1
2
3
4
4
5
[roc@roclinux ~]$ sed -n '/4/p' roc.txt
4
#+END_SRC

** 特殊符号
*** $
数据流末尾
*** &
& 字符，在 sed 命令中，它表示的是“之前被匹配的部分”
#+begin_src bash
#按照惯例, 先展示文件的内容
[roc@roclinux ~]$ cat mysed.txt
Beijing
London
 
#我们使用到了&符号, 大家试着猜一猜它的作用
[roc@roclinux ~]$ sed 's/B.*/&2008/' mysed.txt
Beijing2008
London

[roc@roclinux 20160229]$ sed 's/Bei/&2008/' mysed.txt
Bei2008jing
London
#+END_SRC
*** （）括号
“sed 的预存储技术”，也就是命令中被“（”和“）”括起来的内容会被依次暂存起来，存储到 \1、\2、...里面。这样你就可以使用‘\N’形式来调用这些预存储的内容了。
#+begin_src bash
[roc@roclinux ~]$ echo "hello world" | sed 's/\(hello\).*/world \1/'
world hello
#+END_SRC

来继续看一个例子，我们希望只在每行的第一个和最后一个 Beijing 后面加上 2008 字符串，言下之意就是，除了每行的第一个和最后一个 2008 之外，这一行中间出现的 Beijing 后面就不要加 2008 啦。这个需求，真的是很复杂很个性化，但 sed 命令仍然可以很好地满足：
#先看下文件内容, 第一行中出现了4个Beijing
#+begin_src bash
[roc@roclinux ~]$ cat mysed.txt
Beijing Beijing Beijing Beijing
London London London London
 
[roc@roclinux ~]$ sed 's/\(Beijing\)\(.*\)\(Beijing\)/\12008\2\32008/' mysed.txt
Beijing2008 Beijing Beijing Beijing2008
London London London London
#+END_SRC
这个例子中我们再次使用了预存储技术，存储了三项内容，分别代表第一个 Beijing、中间的内容、最后的 Beijing。而针对\1和\3，我们在其后面追加了 2008 这个字符串。
** sed脚本命令
*** sed s 寻找并替换
此命令的基本格式为：
#+begin_src bash
[address]s/pattern/replacement/flags
#+END_SRC
其中，address 表示指定要操作的具体行，pattern 指的是需要替换的内容，replacement 指的是要替换的新内容。

关于指定具体操作行（address）的用法，这里先不做解释，文章后续会对其做详细介绍。

此命令中常用的 flags 标记如表 2 所示。

表 2 sed s命令flags标记及功能
| flags 标记 | 功能                                                                                                                                |
|------------+-------------------------------------------------------------------------------------------------------------------------------------|
| n          | 1~512 之间的数字，表示指定要替换的字符串出现第几次时才进行替换，例如，一行中有 3 个 A，但用户只想替换第二个 A，这是就用到这个标记； |
| g          | 对数据中所有匹配到的内容进行替换，如果没有 g，则只会在第一次匹配成功时做替换操作。例如，一行数据中有 3 个 A，则只会替换第一个 A；   |
| p          | 会打印与替换命令中指定的模式匹配的行。此标记通常与 -n 选项一起使用。                                                                |
| w file     | 将缓冲区中的内容写到指定的 file 文件中；                                                                                            |
| &          | 用正则表达式匹配的内容进行替换；                                                                                                    |
| \n         | 匹配第 n 个子串，该子串之前在 pattern 中用 \(\) 指定。                                                                              |
| \          | 转义（转义替换部分包含：&、\ 等）。                                                                                                 |

比如，可以指定 sed 用新文本替换第几处模式匹配的地方：
#+begin_src bash
[root@localhost ~]# sed 's/test/trial/2' data4.txt
This is a test of the trial script.
This is the second test of the trial script.
#+END_SRC

可以看到，使用数字 2 作为标记的结果就是，sed 编辑器只替换每行中第 2 次出现的匹配模式。

如果要用新文件替换所有匹配的字符串，可以使用 g 标记：
#+begin_src bash
[root@localhost ~]# sed 's/test/trial/g' data4.txt
This is a trial of the trial script.
This is the second trial of the trial script.
#+END_SRC
我们知道，-n 选项会禁止 sed 输出，但 p 标记会输出修改过的行，将二者匹配使用的效果就是只输出被替换命令修改过的行，例如：
#+begin_src bash
[root@localhost ~]# cat data5.txt
This is a test line.
This is a different line.
[root@localhost ~]# sed -n 's/test/trial/p' data5.txt
This is a trial line.
#+END_SRC
w 标记会将匹配后的结果保存到指定文件中，比如：
#+begin_src bash
[root@localhost ~]# sed 's/test/trial/w test.txt' data5.txt
This is a trial line.
This is a different line.
[root@localhost ~]#cat test.txt
This is a trial line.
#+END_SRC
在使用 s 脚本命令时，替换类似文件路径的字符串会比较麻烦，需要将路径中的正斜线进行转义，例如：
#+begin_src bash
[root@localhost ~]# sed 's/\/bin\/bash/\/bin\/csh/' /etc/passwd
#+END_SRC
*** sed d 删除行
此命令的基本格式为：
[address]d

如果需要删除文本中的特定行，可以用 d 脚本命令，它会删除指定行中的所有内容。但使用该命令时要特别小心，如果你忘记指定具体行的话，文件中的所有内容都会被删除，举个例子：
#+begin_src bash
[root@localhost ~]# cat data1.txt
The quick brown fox jumps over the lazy dog
The quick brown fox jumps over the lazy dog
The quick brown fox jumps over the lazy dog
The quick brown fox jumps over the lazy dog
[root@localhost ~]# sed 'd' data1.txt
#什么也不输出，证明成了空文件
#+END_SRC
当和指定地址一起使用时，删除命令显然能发挥出大的功用。可以从数据流中删除特定的文本行。

address 的具体写法后续会做详细介绍，这里举几个例子：

- 通过行号指定，比如删除 data6.txt 文件内容中的第 3 行：
#+begin_src bash
[root@localhost ~]# cat data6.txt
This is line number 1.
This is line number 2.
This is line number 3.
This is line number 4.
[root@localhost ~]# sed '3d' data6.txt
This is line number 1.
This is line number 2.
This is line number 4.
#+END_SRC
- 或者通过特定行区间指定，比如删除 data6.txt 文件内容中的第 2、3行：
#+begin_src bash
[root@localhost ~]# sed '2,3d' data6.txt
This is line number 1.
This is line number 4.
#+END_SRC
- 也可以使用两个文本模式来删除某个区间内的行，但这么做时要小心，你指定的第一个模式会“打开”行删除功能，第二个模式会“关闭”行删除功能，因此，sed 会删除两个指定行之间的所有行（包括指定的行），例如：
#+begin_src bash
[root@localhost ~]#sed '/1/,/3/d' data6.txt
#删除第 1~3 行的文本数据
This is line number 4.
#+END_SRC
- 或者通过特殊的文件结尾字符，比如删除 data6.txt 文件内容中第 3 行开始的所有的内容：
#+begin_src bash
[root@localhost ~]# sed '3,$d' data6.txt
This is line number 1.
This is line number 2.
#+END_SRC
在此强调，在默认情况下 sed 并不会修改原始文件，这里被删除的行只是从 sed 的输出中消失了，原始文件没做任何改变。
*** sed a 和 i 插入行
a 命令表示在指定行的后面附加一行，i 命令表示在指定行的前面插入一行，这里之所以要同时介绍这 2 个脚本命令，因为它们的基本格式完全相同，如下所示：
#+begin_src bash
[address]a（或 i）\新文本内容
#+END_SRC
下面分别就这 2 个命令，给读者举几个例子。比如说，将一个新行插入到数据流第三行前，执行命令如下：
#+begin_src bash
[root@localhost ~]# sed '3i\
> This is an inserted line.' data6.txt
This is line number 1.
This is line number 2.
This is an inserted line.
This is line number 3.
This is line number 4.
#+END_SRC
再比如说，将一个新行附加到数据流中第三行后，执行命令如下：
#+begin_src bash
[root@localhost ~]# sed '3a\
> This is an appended line.' data6.txt
This is line number 1.
This is line number 2.
This is line number 3.
This is an appended line.
This is line number 4.
#+END_SRC
如果你想将一个多行数据添加到数据流中，只需对要插入或附加的文本中的每一行末尾（除最后一行）添加反斜线即可，例如：
#+begin_src bash
[root@localhost ~]# sed '1i\
> This is one line of new text.\
> This is another line of new text.' data6.txt
This is one line of new text.
This is another line of new text.
This is line number 1.
This is line number 2.
This is line number 3.
This is line number 4.
#+END_SRC
可以看到，指定的两行都会被添加到数据流中。
*** sed c 替换整行
c 命令表示将指定行中的所有内容，替换成该选项后面的字符串。该命令的基本格式为：
#+begin_src bash
[address]c\用于替换的新文本
#+END_SRC
举个例子：
#+begin_src bash
[root@localhost ~]# sed '3c\
> This is a changed line of text.' data6.txt
This is line number 1.
This is line number 2.
This is a changed line of text.
This is line number 4.
#+END_SRC
在这个例子中，sed 编辑器会修改第三行中的文本，其实，下面的写法也可以实现此目的：
#+begin_src bash
[root@localhost ~]# sed '/number 3/c\
> This is a changed line of text.' data6.txt
This is line number 1.
This is line number 2.
This is a changed line of text.
This is line number 4.
#+END_SRC
*** sed y 替换单个字符
y 转换命令是唯一可以处理单个字符的 sed 脚本命令，其基本格式如下：
#+begin_src bash
[address]y/inchars/outchars/
#+END_SRC
转换命令会对 inchars 和 outchars 值进行一对一的映射，即 inchars 中的第一个字符会被转换为 outchars 中的第一个字符，第二个字符会被转换成 outchars 中的第二个字符...这个映射过程会一直持续到处理完指定字符。如果 inchars 和 outchars 的长度不同，则 sed 会产生一条错误消息。

举个简单例子：
#+begin_src bash
[root@localhost ~]# sed 'y/123/789/' data8.txt
This is line number 7.
This is line number 8.
This is line number 9.
This is line number 4.
This is line number 7 again.
This is yet another line.
This is the last line in the file.
#+END_SRC
可以看到，inchars 模式中指定字符的每个实例都会被替换成 outchars 模式中相同位置的那个字符。

转换命令是一个全局命令，也就是说，它会文本行中找到的所有指定字符自动进行转换，而不会考虑它们出现的位置，再打个比方：
#+begin_src bash
[root@localhost ~]# echo "This 1 is a test of 1 try." | sed 'y/123/456/'
This 4 is a test of 4 try.
#+END_SRC
sed 转换了在文本行中匹配到的字符 1 的两个实例，我们无法限定只转换在特定地方出现的字符。
*** sed p 打印命令
p 命令表示搜索符号条件的行，并输出该行的内容，此命令的基本格式为：
#+begin_src bash
[address]p
#+END_SRC
p 命令常见的用法是打印包含匹配文本模式的行，例如：
#+begin_src bash
[root@localhost ~]# cat data6.txt
This is line number 1.
This is line number 2.
This is line number 3.
This is line number 4.
[root@localhost ~]# sed -n '/number 3/p' data6.txt
This is line number 3.
[root@localhost ~]# sed '/number 2/p' data6.txt 
This is line number 1.
This is line number 2.
This is line number 2.
This is line number 3.
This is line number 4.
#+END_SRC
可以看到，用 -n 选项和 p 命令配合使用，我们可以禁止输出其他行，只打印包含匹配文本模式的行。

如果不加-n 选项，原有的内容也会打印出来

如果需要在修改之前查看行，也可以使用打印命令，比如与替换或修改命令一起使用。可以创建一个脚本在修改行之前显示该行，如下所示：
#+begin_src bash
[root@localhost ~]# sed -n '/3/{
> p
> s/line/test/p
> }' data6.txt
This is line number 3.
This is test number 3.
#+END_SRC
sed 命令会查找包含数字 3 的行，然后执行两条命令。首先，脚本用 p 命令来打印出原始行；然后它用 s 命令替换文本，并用 p 标记打印出替换结果。输出同时显示了原来的行文本和新的行文本。
*** sed w 将当前文件指定行写入另一个文件
w 命令用来将文本中指定行的内容写入文件中，此命令的基本格式如下：
#+begin_src bash
[address]w filename
#+END_SRC
这里的 filename 表示文件名，可以使用相对路径或绝对路径，但不管是哪种，运行 sed 命令的用户都必须有文件的写权限。

下面的例子是将数据流中的前两行打印到一个文本文件中：
#+begin_src bash
[root@localhost ~]# sed '1,2w test.txt' data6.txt
This is line number 1.
This is line number 2.
This is line number 3.
This is line number 4.
[root@localhost ~]# cat test.txt
This is line number 1.
This is line number 2.
#+END_SRC
当然，如果不想让行直接输出，可以用 -n 选项，再举个例子：
#+begin_src bash
[root@localhost ~]# cat data11.txt
Blum, R       Browncoat
McGuiness, A  Alliance
Bresnahan, C  Browncoat
Harken, C     Alliance
[root@localhost ~]# sed -n '/Browncoat/w Browncoats.txt' data11.txt
cat Browncoats.txt
Blum, R       Browncoat
Bresnahan, C  Browncoat
#+END_SRC
可以看到，通过使用 w 脚本命令，sed 可以实现将包含文本模式的数据行写入目标文件。
*** sed r 将另一个文件的内容写入当前文件的指定位置
r 命令用于将一个独立文件的数据插入到当前数据流的指定位置，该命令的基本格式为：
#+begin_src bash
[address]r filename
#+END_SRC
sed 命令会将 filename 文件中的内容插入到 address 指定行的后面，比如说：
#+begin_src bash
[root@localhost ~]# cat data12.txt
This is an added line.
This is the second added line.
[root@localhost ~]# sed '3r data12.txt' data6.txt
This is line number 1.
This is line number 2.
This is line number 3.
This is an added line.
This is the second added line.
This is line number 4.
#+END_SRC
如果你想将指定文件中的数据插入到数据流的末尾，可以使用 $ 地址符，例如：
#+begin_src bash
[root@localhost ~]# sed '$r data12.txt' data6.txt
This is line number 1.
This is line number 2.
This is line number 3.
This is line number 4.
This is an added line.
This is the second added line.
#+END_SRC
*** sed q 停止sed操作
q 命令的作用是使 sed 命令在第一次匹配任务结束后，退出 sed 程序，不再进行对后续数据的处理。

比如：
#+begin_src bash
[root@localhost ~]# sed '2q' test.txt
This is line number 1.
This is line number 2.
#+END_SRC
可以看到，sed 命令在打印输出第 2 行之后，就停止了，是 q 命令造成的，再比如：
#+begin_src bash
[root@localhost ~]# sed '/number 1/{ s/number 1/number 0/;q; }' test.txt
This is line number 0.
#+END_SRC
使用 q 命令之后，sed 命令会在匹配到 number 1 时，将其替换成 number 0，然后直接退出。
*** sed n 将下一行内容移入缓存空间，替换当前内容
n 选项可以将下一行内容移入缓存空降，替换掉当前缓存空间的内容；而N 选项是将下一行内容添加进当前缓存空间，原有的缓存空间内容并不会清空
#+begin_src bash
cs144@cs144vm:~/test$ cat mysed.txt 
Beijing 2003
Beijing 2004
Beijing 2005
Beijing 2006
Beijing 2007
cs144@cs144vm:~/test$ sed -n '/200/{n;y/eijing/EIIJNG/;p}' mysed.txt 
BEIIING 2004
BEIIING 2006
cs144@cs144vm:~/test$ sed -n '/200/{N;y/eijing/EIIJNG/;p}' mysed.txt 
BEIIING 2003
BEIIING 2004
BEIIING 2005
BEIIING 2006

#+END_SRC

** sed 脚本命令的寻址方式
前面在介绍各个脚本命令时，我们一直忽略了对 address 部分的介绍。对各个脚本命令来说，address 用来表明该脚本命令作用到文本中的具体行。

默认情况下，sed 命令会作用于文本数据的所有行。如果只想将命令作用于特定行或某些行，则必须写明 address 部分，表示的方法有以下 2 种：
1. 以数字形式指定行区间；
2. 用文本模式指定具体行区间。

以上两种形式都可以使用如下这 2 种格式，分别是：
#+begin_src bash
[address]脚本命令
#+END_SRC
或者
#+begin_src bash
address {
    多个脚本命令
}
#+END_SRC
以上两种形式在前面例子中都有具体实例，因此这里不再做过多赘述。
*** 以数字形式指定行区间
当使用数字方式的行寻址时，可以用行在文本流中的行位置来引用。sed 会将文本流中的第一行编号为 1，然后继续按顺序为接下来的行分配行号。

在脚本命令中，指定的地址可以是单个行号，或是用起始行号、逗号以及结尾行号指定的一定区间范围内的行。这里举一个 sed 命令作用到指定行号的例子：
#+begin_src bash
[root@localhost ~]#sed '2s/dog/cat/' data1.txt
The quick brown fox jumps over the lazy dog
The quick brown fox jumps over the lazy cat
The quick brown fox jumps over the lazy dog
The quick brown fox jumps over the lazy dog
#+END_SRC
可以看到，sed 只修改地址指定的第二行的文本。下面的例子中使用了行地址区间：
#+begin_src bash
[root@localhost ~]# sed '2,3s/dog/cat/' data1.txt
The quick brown fox jumps over the lazy dog
The quick brown fox jumps over the lazy cat
The quick brown fox jumps over the lazy cat
The quick brown fox jumps over the lazy dog
#+END_SRC
在此基础上，如果想将命令作用到文本中从某行开始的所有行，可以用特殊地址——美元符（$）：
#+begin_src bash
[root@localhost ~]# sed '2,$s/dog/cat/' data1.txt
The quick brown fox jumps over the lazy dog
The quick brown fox jumps over the lazy cat
The quick brown fox jumps over the lazy cat
The quick brown fox jumps over the lazy cat
#+END_SRC
*** 用文本模式指定行区间
sed 允许指定文本模式来过滤出命令要作用的行，格式如下：
#+begin_src bash
/pattern/command
#+END_SRC
注意，必须用正斜线将要指定的 pattern 封起来，sed 会将该命令作用到包含指定文本模式的行上。

举个例子，如果你想只修改用户 demo 的默认 shell，可以使用 sed 命令，执行命令如下：
#+begin_src bash
[root@localhost ~]# grep demo /etc/passwd
demo:x:502:502::/home/Samantha:/bin/bash
[root@localhost ~]# sed '/demo/s/bash/csh/' /etc/passwd
root:x:0:0:root:/root:/bin/bash
...
demo:x:502:502::/home/demo:/bin/csh
...
#+END_SRC
虽然使用固定文本模式能帮你过滤出特定的值，就跟上面这个用户名的例子一样，但其作用难免有限，因此，sed 允许在文本模式使用正则表达式指明作用的具体行。正则表达式允许创建高级文本模式匹配表达式来匹配各种数据。这些表达式结合了一系列通配符、特殊字符以及固定文本字符来生成能够匹配几乎任何形式文本的简练模式。

关于正则表达式，本节不做过多介绍.这里仅给读者提供一个简单示例：
#+begin_src bash
[root@localhost ~]# cat test.txt
<html>
<title>First Wed</title>
<body>
h1Helloh1
h2Helloh2
h3Helloh3
</body>
</html>
#使用正则表示式给所有第一个的h1、h2、h3添加<>，给第二个h1、h2、h3添加</>
[root@localhost ~]# cat sed.sh
/h[0-9]/{
    s//\<&\>/1
    s//\<\/&\>/2
}
[root@localhost ~]# sed -f sed.sh test.txt
<h1>Hello</h1>
<h2>Hello</h2>
<h3>Hello</h3>
#+END_SRC
*** /xxx/,/yyy/定位行范围
#+begin_src bash
#文件内容展示一下
[roc@roclinux ~]$ cat mysed.txt
Beijing 2003
Beijing 2004
Beijing 2005
Beijing 2006
Beijing 2007
Beijing 2008
Beijing 2007
 
#我们想展示匹配了2005的行和2007的行之间的内容
[roc@roclinux ~]$ sed -n ’/2005/,/2007/p’ mysed.txt
Beijing 2005
Beijing 2006
Beijing 2007
#+END_SRC
我们使用/2005/来匹配行范围的首行，用/2008/来匹配行范围的尾行。可以看到，在匹配尾行时，只要遇到第一个符合要求的行，就会停止，而不会再继续向后匹配了。所以，sed 命令只是匹配到了第一个 2007，并没有匹配到第二个 2007。

** sed 多行命令
默认情况下，sed会基于换行符的位置，将数据分成行，sed 会根据定义好的脚本命令一次处理一行数据。

但是，有时我们需要对跨多行的数据执行特定操作。比如说，在文本中查找一串字符串"abcdergalskgjalskgjl" ，它很有可能出现在两行中，每行各包含其中一部分。这时，如果用普通的 sed 编辑器命令来处理文本，就不可能发现这种被分开的情况。

幸运的是，sed 命令的设计人员已经考虑到了这种情况，并设计了对应的解决方案。sed 包含了三个可用来处理多行文本的特殊命令，分别是：
- Next 命令（N）：将数据流中的下一行加进来创建一个多行组来处理。
- Delete（D）：删除多行组中的一行。
- Print（P）：打印多行组中的一行。

注意，以上命令的缩写，都为大写
*** N 多行操作命令
N 命令会将下一行文本内容添加到缓冲区已有数据之后（之间用换行符分隔），从而使前后两个文本行同时位于缓冲区中，sed 命令会将这两行数据当成一行来处理。

下面这个例子演示的 N 命令的功能：
#+begin_src bash
[root@localhost ~]# cat data2.txt
This is the header line.
This is the first data line.
This is the second data line.
This is the last line.
[root@localhost ~]# sed '/first/{ N ; s/\n/ / }' data2.txt
This is the header line.
This is the first data line. This is the second data line.
This is the last line.
#+END_SRC
在这个例子中，sed 命令查找含有单词 first 的那行文本。找到该行后，它会用 N 命令将下一行合并到那行，然后用替换命令 s 将换行符替换成空格。结果是，文本文件中的两行在 sed 的输出中成了一行。

如果要在数据文件中查找一个可能会分散在两行中的文本短语，如何实现呢？这里给大家一个实例：
#+begin_src bash
[root@localhost ~]# cat data3.txt
On Tuesday, the Linux System
Administrator's group meeting will be held.
All System Administrators should attend.
Thank you for your attendance.
[root@localhost ~]# sed 'N ; s/System Administrator/Desktop User/' data3.txt
On Tuesday, the Linux Desktop User's group meeting will be held.
All Desktop Users should attend.
Thank you for your attendance.
#+END_SRC
用 N 命令将发现第一个单词的那行和下一行合并后，即使短语内出现了换行，你仍然可以找到它，这是因为，替换命令在 System 和 Administrator之间用了通配符（.）来匹配空格和换行符这两种情况。但当它匹配了换行符时，它就从字符串中删掉了换行符，导致两行合并成一行。这可能不是你想要的。

要解决这个问题，可以在 sed 脚本中用两个替换命令，一个用来匹配短语出现在多行中的情况，一个用来匹配短语出现在单行中的情况，比如：
#+begin_src bash
[root@localhost ~]# sed 'N
> s/System\nAdministrator/Desktop\nUser/
> s/System Administrator/Desktop User/
> ' data3.txt
On Tuesday, the Linux Desktop
User's group meeting will be held.
All Desktop Users should attend.
Thank you for your attendance.
#+END_SRC
第一个替换命令专门查找两个单词间的换行符，并将它放在了替换字符串中。这样就能在第一个替换命令专门在两个检索词之间寻找换行符，并将其纳入替换字符串。这样就允许在新文本的同样位置添加换行符了。

但这个脚本中仍有个小问题，即它总是在执行 sed 命令前将下一行文本读入到缓冲区中，当它到了后一行文本时，就没有下一行可读了，此时 N 命令会叫 sed 程序停止，这就导致，如果要匹配的文本正好在最后一行中，sed 命令将不会发现要匹配的数据。

解决这个 bug 的方法是，将单行命令放到 N 命令前面，将多行命令放到 N 命令后面，像这样：
#+begin_src bash
[root@localhost ~]# sed '
> s/System\nAdministrator/Desktop\nUser/
> N
> s/System Administrator/Desktop User/
> ' data3.txt
On Tuesday, the Linux Desktop
User's group meeting will be held.
All Desktop Users should attend.
Thank you for your attendance.
#+END_SRC
现在，查找单行中短语的替换命令在数据流的后一行也能正常工作，多行替换命令则会负责短语出现在数据流中间的情况。
*** D 多行删除命令
sed 不仅提供了单行删除命令（d），也提供了多行删除命令 D，其作用是只删除缓冲区中的第一行，也就是说，D 命令将缓冲区中第一个换行符（包括换行符）之前的内容删除掉。

比如说：
#+begin_src bash
[root@localhost ~]# cat data4.txt
On Tuesday, the Linux System
Administrator's group meeting will be held.
All System Administrators should attend.
[root@localhost ~]# sed 'N ; /System\nAdministrator/D' data4.txt
Administrator's group meeting will be held.
All System Administrators should attend.
#+END_SRC
文本的第二行被 N 命令加到了缓冲区(如果不加N是匹配不到东西的)，因此 sed 命令第一次匹配就是成功，而 D 命令会将缓冲区中第一个换行符之前（也就是第一行）的数据删除，所以，得到了如上所示的结果。

下面的例子中，它会删除数据流中出现在第一行前的空白行：
#+begin_src bash
[root@localhost ~]# cat data5.txt

This is the header line.
This is a data line.

This is the last line.
[root@localhost ~]# sed '/^$/{N ; /header/D}' data5.txt
This is the header line.
This is a data line.

This is the last line.
#+END_SRC
sed会查找空白行，然后用 N 命令来将下一文本行添加到缓冲区。此时如果缓冲区的内容中含有单词 header，则 D 命令会删除缓冲区中的第一行。
*** P 多行打印命令
同 d 和 D 之间的区别一样，P（大写）命令和单行打印命令 p（小写）不同，对于具有多行数据的缓冲区来说，它只会打印缓冲区中的第一行，也就是首个换行符之前的所有内容。

例如，test.txt 文件中的内容如下：
#+begin_src bash
[root@localhost ~]# cat test.txt
aaa
bbb
ccc
ddd
eee
fff
#+END_SRC
下面对 test.txt 文件中的内容分别用 p 命令和 P 命令后，产生的输出信息的对比。
#+begin_src bash
[root@localhost ~]# sed '/.*/N;P' test.txt
aaa
aaa
bbb
ccc
ccc
ddd
eee
eee
fff

[root@localhost ~]# sed -n '/.*/N;P' test.txt
aaa
ccc
eee

[root@localhost ~]# sed '/.*/N;p' test.txt
aaa
bbb
aaa
bbb
ccc
ddd
ccc
ddd
eee
fff
eee
fff

[root@localhost ~]# sed -n '/.*/N;p' test.txt
aaa
bbb
ccc
ddd
eee
fff
#+END_SRC
注意：N 将后面行加入缓存区后就不会处理后面行了，处理完将直接处理第三行内容
** sed 保持空间
前面我们一直说，sed 命令处理的是缓冲区中的内容，其实这里的缓冲区，应称为模式空间。值得一提的是，模式空间并不是 sed 命令保存文件的唯一空间。sed 还有另一块称为保持空间的缓冲区域，它可以用来临时存储一些数据。

下表列出了 5 条可用来操作保持空间的命令。

| 命令 | 功能                             |
|------+----------------------------------|
| h    | 将模式空间中的内容复制到保持空间 |
| H    | 将模式空间中的内容附加到保持空间 |
| g    | 将保持空间中的内容复制到模式空间 |
| G    | 将保持空间中的内容附加到模式空间 |
| x    | 交换模式空间和保持空间中的内容   |
通常，在使用 h 或 H 命令将字符串移动到保持空间后，最终还要用 g、G 或 x 命令将保存的字符串移回模式空间。保持空间最直接的作用是，一旦我们将模式空间中所有的文件复制到保持空间中，就可以清空模式空间来加载其他要处理的文本内容。

由于有两个缓冲区域，下面的例子中演示了如何用 h 和 g 命令来将数据在 sed 缓冲区之间移动。
#+begin_src bash
[root@localhost ~]# cat data2.txt
This is the header line.
This is the first data line.
This is the second data line.
This is the last line.
[root@localhost ~]# sed -n '/first/ {h ; p ; n ; p ; g ; p }' data2.txt
This is the first data line.
This is the second data line.
This is the first data line.
#+END_SRC
这个例子的运行过程是这样的：
- sed脚本命令用正则表达式过滤出含有单词first的行；
- 当含有单词 first 的行出现时，h 命令将该行放到保持空间；
- p 命令打印模式空间也就是第一个数据行的内容；
- n 命令提取数据流中的下一行（This is the second data line），并将它放到模式空间；
- p 命令打印模式空间的内容，现在是第二个数据行；
- g 命令将保持空间的内容（This is the first data line）放回模式空间，替换当前文本；
- p 命令打印模式空间的当前内容，现在变回第一个数据行了。
** sed改变指定流程
*** b 分支命令
通常，sed 程序的执行过程会从第一个脚本命令开始，一直执行到最后一个脚本命令（D 命令是个例外，它会强制 sed 返回到脚本的顶部，而不读取新的行）。sed 提供了 b 分支命令来改变命令脚本的执行流程，其结果与结构化编程类似。

b 分支命令基本格式为：
#+begin_src bash
[address]b [label]
#+END_SRC
其中，address 参数决定了哪些行的数据会触发分支命令，label 参数定义了要跳转到的位置。

需要注意的是，如果没有加 label 参数，跳转命令会跳转到脚本的结尾，比如：
#+begin_src bash
[root@localhost ~]# cat data2.txt
This is the header line.
This is the first data line.
This is the second data line.
This is the last line.
[root@localhost ~]# sed '{2,3b ; s/This is/Is this/ ; s/line./test?/}' data2.txt
Is this the header test?
This is the first data line.
This is the second data line.
Is this the last test?
#+END_SRC
可以看到，因为 b 命令未指定 label 参数，因此数据流中的第2行和第3行并没有执行那两个替换命令。

如果我们不想直接跳到脚本的结尾，可以为 b 命令指定一个标签（也就是格式中的 label，最多为 7 个字符长度）。在使用此该标签时，要以冒号开始（比如 :label2），并将其放到要跳过的脚本命令之后。这样，当 sed 命令匹配并处理该行文本时，会跳过标签之前所有的脚本命令，但会执行标签之后的脚本命令。

比如说：
#+begin_src bash
[root@localhost ~]# sed '{/first/b jump1 ; s/This is the/No jump on/
> :jump1
> s/This is the/Jump here on/}' data2.txt
No jump on header line
Jump here on first data line
No jump on second data line
No jump on last line
#+END_SRC
在这个例子中，如果文本行中出现了 first，程序的执行会直接跳到 jump1 标签之后的脚本行。如果分支命令的模式没有匹配，sed 会继续执行所有的脚本命令。

b 分支命令除了可以向后跳转，还可以向前跳转，例如：
#+begin_src bash
[root@localhost ~]# echo "This, is, a, test, to, remove, commas." | sed -n '{
> :start
> s/,//1p
> /,/b start
> }'
This is, a, test, to, remove, commas.
This is a, test, to, remove, commas.
This is a test, to, remove, commas.
This is a test to, remove, commas.
This is a test to remove, commas.
This is a test to remove commas.
#+END_SRC
在这个例子中，当缓冲区中的行内容中有逗号时，脚本命令就会一直循环执行，每次迭代都会删除文本中的第一个逗号，并打印字符串，直至内容中没有逗号。
*** t 测试命令
类似于 b 分支命令，t 命令也可以用来改变 sed 脚本的执行流程。t 测试命令会根据 s 替换命令的结果，如果匹配并替换成功，则脚本的执行会跳转到指定的标签；反之，t 命令无效。

测试命令使用与分支命令相同的格式：
#+begin_src bash
[address]t [label]
#+END_SRC
跟分支命令一样，在没有指定标签的情况下，如果 s 命令替换成功，sed 会跳转到脚本的结尾（相当于不执行任何脚本命令）。例如：
#+begin_src bash
[root@localhost ~]# sed '{
> s/first/matched/
> t
> s/This is the/No match on/
> }' data2.txt
No match on header line
This is the matched data line
No match on second data line
No match on last line
#+END_SRC
此例中，第一个替换命令会查找模式文本 first，如果匹配并替换成功，命令会直接跳过后面的替换命令；反之，如果第一个替换命令未能匹配成功，第二个替换命令就会被执行。

再举个例子：
#+begin_src bash
[root@localhost ~]#  echo "This, is, a, test, to, remove, commas. " | sed -n '{
> :start
> s/,//1p
> t start
> }'
This is, a, test, to, remove, commas.
This is a, test, to, remove, commas.
This is a test, to, remove, commas.
This is a test to, remove, commas.
This is a test to remove, commas.
This is a test to remove commas.
#+END_SRC
** 给文件的行编号
#+begin_src bash
# 行号和内容分开
sed '=' data

# 行号和内容在同一行
sed '=' data | sed 'N;s/\n/: /'
#+END_SRC

* set命令
** set -e

* split
split 的作用很好描述，就是将文件按照一定规则进行拆分。一般情况下，我们可以按照文件大小来进行拆分，如果是文本文件的话，还可以按照行数来进行拆分，默认是 1000 行作为一个拆分单位。

默认情况下，分割后的文件的名称会以 x 作为前缀，以 aa、ab、ac 这样的双字母格式作为后缀，形成 xaa、xab 这样的名称格式。

我们来一起看看 split 的命令格式：
~split [-b ][-C ][-][-l ][要切割的文件][输出文件名前缀][-a ]~

最常用的选项，都在这里了：
- -b<字节>：指定按多少字节进行拆分，也可以指定 K、M、G、T 等单位。
- -<行数>或-l<行数>：指定每多少行要拆分成一个文件。
- 输出文件名前缀：设置拆分后的文件的名称前缀，split 会自动在前缀后加上编号，默认从 aa 开始。
- -a<后缀长度>：默认的后缀长度是 2，也就是按 aa、ab、ac 这样的格式依次编号。
** 例子
闲言少叙，我们现在就来介绍拆分的方法。先使用 dd 命令来生成一个 700MB 文件来作为我们的拆分对象：
#+BEGIN_SRC bash
[root@roclinux ~]$ dd if=/dev/zero bs=1024 count=700000 of=king_of_ring.avi
700000+0 records in
700000+0 records out
716800000 bytes (717 MB) copied, 12.9189 s, 55.5 MB/s
 
[root@roclinux ~]$  ls -l king_of_ring.avi
-rw-r--r-- 1 root root 716800000 Apr 12 13:01 king_of_ring.avi
#+END_SRC
美国大片的文件大小是 700MB，而我手边仅有的两个优盘，都是 512MB 大小的。我打算把文件以 400MB 作为一个拆分单位，来进行拆分。这里使用到了 split 的-b选项，来指定每个拆分文件的大小：
#+BEGIN_SRC bash
[root@roclinux ~]$ split -b 400M king_of_ring.avi
 
[root@roclinux ~]$ ls -l
total 1400008
-rw-r--r-- 1 root root 716800000 Apr 12 13:01 king_of_ring.avi
-rw-r--r-- 1 root root 419430400 Apr 12 13:04 xaa
-rw-r--r-- 1 root root 297369600 Apr 12 13:04 xab
#+END_SRC
看！分身完毕！咦，怎么多出了 xaa 和 xab 两个文件，这么奇怪的名字？

是的，你没看错，在没有明确指定拆分后文件的命名方式的情况下，split 会默认采用 x 字符作为文件前缀，采用类似 aa、ab、ac 的字符串依次作为文件后缀。于是，就出现了我们上面看到的 xaa、xab 了。

从文件大小来看，如我们所愿，电影文件的确被切割成了一个 400MB 的文件、一个 300MB 的文件，终于可以装到两个优盘里了。
** 切分后的合并
使用 cat 命令将拆分文件 xaa 和 xab 合并成一个文件，可以看出合并后的文件和源文件的大小是一致的：
#+BEGIN_SRC bash
[root@roclinux ~]$ cat xaa xab > king_of_ring_merge.avi
 
[root@roclinux ~]$ ls -l
total 2100012
-rw-r--r-- 1 root root 716800000 Apr 12 13:01 king_of_ring.avi
-rw-r--r-- 1 root root 716800000 Apr 12 13:07 king_of_ring_merge.avi
-rw-r--r-- 1 root root 419430400 Apr 12 13:04 xaa
-rw-r--r-- 1 root root 297369600 Apr 12 13:04 xab
#+END_SRC
对了，如果是在 Windows 下的话，我们要先运行 cmd，然后用 copy 命令来进行文件的合并：
#+BEGIN_SRC bash
copy /b xaa + xab king_of_ring.avi
#+END_SRC
格式上和 Linux 有些区别，但原理是一样的。
** 设置拆分文件的名称前缀
上面例子中，我们没有指定拆分文件的名称前缀，结果拆分后的文件名都是 aa、ab 这样的名称，这样的名称既不达意也不美观。

下面的例子，我们尝试以 king_of_ring_part_ 作为拆分后文件的名称前缀：
#+BEGIN_SRC bash
#我们指定了king_of_ring_part_前缀

[root@roclinux ~]$ split -b 400m king_of_ring.avi king_of_ring_part_
 
#可以看到, 文件名的可读性提高了很多
[root@roclinux ~]$ ls -l king*
-rw-r--r-- 1 root root 716800000 Feb 25 18:29 king_of_ring.avi
-rw-r--r-- 1 root root 419430400 Feb 25 19:24 king_of_ring_part_aa
-rw-r--r-- 1 root root 297369600 Feb 25 19:24 king_of_ring_part_ab
#+END_SRC

文件名的可读性是不是提高了不少，从文件名称就可以看出来是美国大片的拆分文件啦。
** 设置数字后缀
如果大家看不惯以 aa、ab 这种字母作为文件后缀，我们还可以通过-d选项来指定数字形式的文件后缀：
#+BEGIN_SRC bash
#使用了-d选项
[root@roclinux ~]$ split -b 400m -d king_of_ring.avi king_of_ring_part_
 
#后缀从原来的aa、ab变成了00、01
[root@roclinux ~]$ ls -l king*
-rw-r--r-- 1 root root 716800000 Feb 25 18:29 king_of_ring.avi
-rw-r--r-- 1 root root 419430400 Feb 25 19:24 king_of_ring_part_00
-rw-r--r-- 1 root root 297369600 Feb 25 19:24 king_of_ring_part_01
#+END_SRC
** 按照行数进行拆分
前面我们讲的是按照文件大小（如 400MB）进行文件拆分的方法，但是并非所有情况都适合于用文件大小作为拆分单元。比如，我们希望把 /etc/passwd 文件按照一个文件 10 行记录的方式进行拆分，又该怎么操作呢？
#+BEGIN_SRC bash
#使用-N来指定拆分的行数,本例中为-10
[root@roclinux ~]$ split -d -10 /etc/passwd my_passwd_
 
#可以看到拆分成功
[root@roclinux ~]$ wc -l my_passwd_*
  10 my_passwd_00
  10 my_passwd_01
   5 my_passwd_02
  25 total
#+END_SRC
** 合并后的校验
需要注意的是，在通过网络来传输大文件，或者在设备之间复制大文件的时候，可能会出现传输前后数据不一致的情况。

使用 split 来拆分大文件仅仅是故事的开始，操作完毕后化零为整、完璧归赵才是完美的结局。因此需要在合并文件后进行文件的完整性校验，推荐使用 md5sum 来计算和比对前后两个大文件的 md5 值。
#+BEGIN_SRC bash
#对原先的文件计算md5值
[root@roclinux ~]$ md5sum king_of_ring.avi
eacff27bf2db99c7301383b7d8c1c07c  king_of_ring.avi
 
#对合并后的文件计算md5值, 并与原值进行比较
[root@roclinux ~]$ md5sum king_of_ring_merge.avi
eacff27bf2db99c7301383b7d8c1c07c  king_of_ring_merge.avi
#+END_SRC
如果前后一致，那么恭喜你，文件合并成功！
* script（记录终端输出）
script这个命令很强大，可以记录终端的所有输出到相应的文件中

执行script就是启动了一个子shell，所以用exit即可退出script

看例子:
#+begin_src bash
[lhd@hongdi ~]$ script
Script. started, file is typescript
[lhd@hongdi ~]$ ls
1.gtkrc-2.0 c.tar kmess-2.0alpha2.tar.gz secpanel-0.5.3-1.noarch.rpm
2009 DownZipAction.php kmesslog secpanel-0.5.4-2.noarch.rpm
[lhd@hongdi ~]$ exit
exit
Script. done, file is typescript
 
 
[lhd@hongdi ~]$ cat typescript
Script. started on 2009年02月08日 星期日 18时56分52秒
[lhd@hongdi ~]$ ls
1.gtkrc-2.0 c.tar kmess-2.0alpha2.tar.gz secpanel-0.5.3-1.noarch.rpm
2009 DownZipAction.php kmesslog secpanel-0.5.4-2.noarch.rpm
[lhd@hongdi ~]$ exit
exit
Script. done on 2009年02月08日 星期日 18时57分00秒
#+END_SRC
我们在启动script时没有指定文件名，它会自动记录到当前目录下一个名为 typescript的文件中。也可以用 -a参数 指定文件名
* ssh 相关
** ubuntu开启SSH服务远程登录
 SSH分客户端openssh-client和openssh-server

 如果你只是想登陆别的机器的SSH只需要安装openssh-client（ubuntu有默认安装，如果没有则sudo apt-get install openssh-client），如果要使本机开放SSH服务就需要安装openssh-server。

  查看当前的ubuntu是否安装了ssh-server服务。默认只安装ssh-client服务
 dpkg -l | grep ssh

 安装ssh-server服务
 sudo apt-get install openssh-server

 再次查看安装的服务：
 dpkg -l | grep ssh

 然后确认ssh-server是否启动了：

 ps -e | grep ssh

 如果看到sshd那说明ssh-server已经启动了。
 如果没有则可以这样启动：sudo /etc/init.d/ssh start或sudo service ssh start
 配置相关：
 ssh-server配置文件位于/etc/ssh/sshd_config，在这里可以定义SSH的服务端口，默认端口是22，你可以自己定义成其他端口号，如222。（或把配置文件中的”PermitRootLogin without-password”加一个”#”号,把它注释掉，再增加一句”PermitRootLogin yes”）
 然后重启SSH服务：
 sudo /etc/init.d/ssh stop
 sudo /etc/init.d/ssh start
*** Unable to locate package openssh-server
  给一个docker的ubuntu容器安装openssh-server出现了这个问题
 #+BEGIN_SRC bash
 root@1c3148b444e2:/# apt-get install openssh-server
 Reading package lists... Done
 Building dependency tree       
 Reading state information... Done
 E: Unable to locate package openssh-server
 #+END_SRC
 原因解释：因为软件源出问题，导致无法找到或者下载软件，一般原因是刚安装的Ubuntu后没有更新软件源或者更新后但是没有sudo apt-get update，导致找不到软件。

 1 sudo apt-get update 
 （更新软件源）执行安装操作，如果不成功，执行2 

 2  sudo apt-get upgrade 
 （继续更新软件源）执行安装操作，应该能成功 
 最后执行sudo apt-get install -y openssh-server
** SSH、SCP和SFTP
*** SSH、SCP和SFTP都是SSH软件包的组成部分
 SSH 是 Secure Shell 的缩写，由 IETF 的网络小组（Network Working Group）所制定；SSH 为建立在应用层基础上的安全协议。SSH 是目前广泛采用的安全登录协议，专为远程登录会话和其他网络服务提供安全性的协议，替代以前不安全的Telnet协议。利用 SSH 协议可以有效防止远程管理过程中的信息泄露问题。

 SSH包括二个部分，服务端的SSHD（Secure Shell Daemon）和SSH客户端。我们通常所说的用SSH登录到某某主机，指的是用SSH客户端远程登录到某台主机（该主机运行了SSHD服务端程序）。

 SSH最初是UNIX系统上的一个程序，后来又迅速扩展到其他操作平台，目前几乎所有UNIX平台—包括HP-UX、Linux、AIX、Solaris、Digital UNIX、Irix，以及其他系统平台，都可运行SSH。
*** SCP和SFTP
 SCP是Secure Copy的简称，是用来与远程主机之间进行数据传输的协议，相当于经过加密的Copy命令。SCP数据传输使用 ssh协议，并且和ssh 使用相同的认证方式，提供相同的安全保证 。 根据实际需要，scp进行验证时会要求你输入密码或口令。

 SFTP=SSH File Transfer Protocol ，有时也被称作 Secure File Transfer Protocol 。SFTP是用SSH封装过的FTP协议，相当于经过加密的FTP协议，功能与FTP一样，只是传输数据经过加密。

 SFTP也有二个部分，服务端的SFTP-Server及SFTP Client。通常所说的用SFTP登录到某台主机，指的是用SFTP客户端登录到某台主机（该主机运行了SFTP-Server服务端程序）。
**** SCP和SFTP异同：

 不管SCP还是SFTP，都是SSH的功能之一，也都是使用SSH协议来传输文件的。

 不只是登录时的用户信息，相互传输的文件内容也是经过SSH加密的，所以说SCP和SFTP实现了安全的文件传输。

 SCP和CP命令相似，SFTP和FTP的使用方法也类似。SCP和SFTP的共同之处在于「使用SSH将文件加密才传输的」

 使用「WinSCP」或者「FileZilla」之类的客户端，还可以和Windows之间进行文件传输。

 SCP和SFTP的不同之处，首先就是之前提到的，SCP使用「SCP命令」，SFTP则类似「FTP处理文件」的使用方式。

 它们的不同之处还不止如此，还有「SCP比较简单，是轻量级的，SFTP的功能则比较多」。

 虽然还有很多不同之处，但二者的最大不同之处在于「SFTP在文件传输过程中中断的话，连接后还可以继续传输，但SCP不行」。

 由于各种原因导致的文件传输中断是经常讨论的话题，所以这个区别（SFTP支持断点续传，SCP则不支持）被认为是最大的区别。
*** 常见的SSH客户端
**** 图形化客户端：
 WinSCP，是一个Windows环境下使用SSH的开源图形化SFTP客户端。同时支持FTP、SCP、webdav协议。它的主要功能就是在本地与远程计算机间安全的复制文件。

 Xftp，是一个基于 MS windows 平台的功能强大的SFTP、FTP 文件传输软件。使用了 Xftp 以后，MS windows 用户能安全地在 UNIX/Linux 和 Windows PC 之间传输文件。

 FileZilla是一个免费开源的FTP软件，分为客户端版本和服务器版本，具备所有的FTP软件功能。支持FTP，SFTP(SSH File Transfer Protocol)， FTPS(FTP over SSL/TLS)等多种协议。

**** 终端工具类：
 PuTTY是一个Telnet、SSH、rlogin、纯TCP以及串行接口连接软件。PuTTY是一款开放源代码软件，使用MIT licence授权。

 Xshell 是一个强大的安全终端模拟软件，它支持SSH1, SSH2, SFTP以及Microsoft Windows 平台的TELNET 协议。
** 基本用法
ssh 最常见的用途就是登录服务器，这要求服务器安装并正在运行 SSH 服务器软件。

ssh 登录服务器的命令如下。
#+begin_src bash
$ ssh hostname
#+END_SRC
上面命令中，hostname是主机名，它可以是域名，也可能是 IP 地址或局域网内部的主机名。不指定用户名的情况下，将使用客户端的当前用户名，作为远程服务器的登录用户名。如果要指定用户名，可以采用下面的语法。
#+begin_src bash
$ ssh user@hostname
#+END_SRC
上面的命令中，用户名和主机名写在一起了，之间使用@分隔。

用户名也可以使用ssh的-l参数指定，这样的话，用户名和主机名就不用写在一起了。
#+begin_src bash
$ ssh -l username host
#+END_SRC
ssh 默认连接服务器的22端口，-p参数可以指定其他端口。
#+begin_src bash
$ ssh -p 8821 foo.com
#+END_SRC
上面命令连接服务器foo.com的8821端口。

** SSH 密钥
 基于密钥的验证机制使用了密码学中的公钥，我们只需要向服务器证明客户端持有对应的私钥，而不需要公开其私钥。
 这样您就可以避免每次登录都输入密码的麻烦了秘密就可以登录。
 不过，私钥(通常是 ~/.ssh/id_rsa 或者 ~/.ssh/id_ed25519) 等效于您的密码，所以一定要好好保存它。

 ssh秘钥登录特点：1.安全；2.免输密码。

 对于安全级别较高的服务器，建议配好ssh登录后禁掉密码登录。

 缺点：略繁琐。如果你的只是临时登录一次，那么还是密码吧。

*** 密钥登录的过程
SSH 密钥登录分为以下的步骤：

预备步骤，客户端通过ssh-keygen生成自己的公钥和私钥。

第一步，手动将客户端的公钥放入远程服务器的指定位置。

第二步，客户端向服务器发起 SSH 登录的请求。

第三步，服务器收到用户 SSH 登录的请求，发送一些随机数据给用户，要求用户证明自己的身份。

第四步，客户端收到服务器发来的数据，使用私钥对数据进行签名，然后再发还给服务器。

第五步，服务器收到客户端发来的加密签名后，使用对应的公钥解密，然后跟原始数据比较。如果一致，就允许用户登录。

*** 生成秘钥
秘钥对需要在你自己的机器上生成，然后把公钥放到服务器相应用户的~/.ssh目录

使用 ssh-keygen 命令可以生成一对密钥

执行下面命令,默认生成位置是~/.ssh

~ssh-keygen~

系统会询问你文件名和秘钥密码，可以一路回车过去，会生成两个文件：
- id_rsa 私钥
- id_rsa.pub 公钥
默认使用rsa算法，你也可以用比较详细的指令，如
~ssh-keygen -t rsa -b 1024 -f yourkeyname -C "备注"~

| 参数   | 解释                                                  |
|--------+-------------------------------------------------------|
| -b     | 采用长度1024bit的密钥对,b=bits,最长4096，不过没啥必要 |
| -t rsa | 采用rsa加密方式,t=type                                |
| -f     | 生成文件名(文件路径),f=output_keyfiles                     |
| -C     | 备注，C=comment                                       |


更多参数可运行 man ssh-keygen

输入上面的命令以后，ssh-keygen会要求用户回答一些问题。
#+begin_src bash
$ ssh-keygen -t dsa
Generating public/private dsa key pair.
Enter file in which to save the key (/home/username/.ssh/id_dsa):  press ENTER
Enter passphrase (empty for no passphrase): ********
Enter same passphrase again: ********
Your identification has been saved in /home/username/.ssh/id_dsa.
Your public key has been saved in /home/username/.ssh/id_dsa.pub.
The key fingerprint is:
14:ba:06:98:a8:98:ad:27:b5:ce:55:85:ec:64:37:19 username@shell.isp.com
#+END_SRC
上面示例中，执行ssh-keygen命令以后，会出现第一个问题，询问密钥保存的文件名，默认是~/.ssh/id_dsa文件，这个是私钥的文件名，对应的公钥文件~/.ssh/id_dsa.pub是自动生成的。用户的密钥一般都放在主目录的.ssh目录里面。

如果选择rsa算法，生成的密钥文件默认就会是~/.ssh/id_rsa（私钥）和~/.ssh/id_rsa.pub（公钥）。

接着，就会是第二个问题，询问是否要为私钥文件设定密码保护（passphrase）。这样的话，即使入侵者拿到私钥，还是需要破解密码。如果为了方便，不想设定密码保护，可以直接按回车键，密码就会为空。后面还会让你再输入一次密码，两次输入必须一致。注意，这里“密码”的英文单词是 passphrase，这是为了避免与 Linux 账户的密码单词 password 混淆，表示这不是用户系统账户的密码。

实际上这里的密码保护是为了防止别人复制私钥后拿去登录服务器。当别人用复制来的私钥在他的电脑上登录服务器时，ssh客户端会要求其输入密码来解开私钥。实际上，密码保护只能防止别人无法用私钥在他自己的电脑上登录，但他还是能够在你的电脑上登录服务器，因为你的ssh客户端已经在第一次登录的时候解开了私钥，之后登录不会再要求验证密码。参考下面的解释：
#+BEGIN_EXAMPLE
SSH uses private/public key pairs to protect your communication with the server. SSH passphrases protect your private key from being used by someone who doesn't know the passphrase. Without a passphrase, anyone who gains access to your computer has the potential to copy your private key. For example, family members, coworkers, system administrators, and hostile actors could gain access.

A secure passphrase helps keep your private key from being copied and used even if your computer is compromised.

The downside to passphrases is that you need to enter it every time you create a connection using SSH. You can temporarily cache your passphrase using ssh-agent so you don't have to enter it every time you connect.
#+END_EXAMPLE

最后，就会生成私钥和公钥，屏幕上还会给出公钥的指纹，以及当前的用户名和主机名作为注释，用来识别密钥的来源。

公钥文件和私钥文件都是文本文件，可以用文本编辑器看一下它们的内容。公钥文件的内容类似下面这样。
#+BEGIN_EXAMPLE
ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAIEAvpB4lUbAaEbh9u6HLig7amsfywD4fqSZq2ikACIUBn3GyRPfeF93l/
weQh702ofXbDydZAKMcDvBJqRhUotQUwqV6HJxqoqPDlPGUUyo8RDIkLUIPRyq
ypZxmK9aCXokFiHoGCXfQ9imUP/w/jfqb9ByDtG97tUJF6nFMP5WzhM= username@shell.isp.com
#+END_EXAMPLE
上面示例中，末尾的username@shell.isp.com是公钥的注释，用来识别不同的公钥，表示这是哪台主机（shell.isp.com）的哪个用户（username）的公钥，不是必需项。

注意，公钥只有一行。因为它太长了，所以上面分成三行显示。

生成密钥以后，建议修改它们的权限，防止其他人读取。
#+begin_src bash
$ chmod 600 ~/.ssh/id_rsa
$ chmod 600 ~/.ssh/id_rsa.pub
#+END_SRC
您可以使用 ssh-agent 或 gpg-agent ，这样就不需要每次都输入该密码了。
*** 在服务器上安装秘钥
ssh 会查询 .ssh/authorized_keys 来确认那些用户可以被允许登录。

把上一步生成的公钥发送到服务器(scp,FillZilla等)上，然后在服务器上执行下面命令

cat id_rsa.pub >> ~/.ssh/authorized_keys


或者直接在本地机器上执行命令： cat ~/.ssh/id_rsa.pub | ssh user@host "mkdir -p ~/.ssh && cat >> ~/.ssh/authorized_keys"

如果支持 ssh-copy-id 的话，可以使用下面这种更简单的解决方案：

ssh-copy-id -i .ssh/id_rsa.pub foobar@remote

如果ssh-copy-id不行的话，就打开远程主机的/etc/ssh/sshd_config这个文件，检查下面几行前面"#"注释是否取掉。
#+BEGIN_EXAMPLE
RSAAuthentication yes
PubkeyAuthentication yes
AuthorizedKeysFile .ssh/authorized_keys
#+END_EXAMPLE
然后，重启远程主机的ssh服务。

如此便完成了公钥安装，有个小坑值得一提：authenrized_keys的权限必须是600或更小，否则会连接失败。

保险起见，执行下面命令
#+BEGIN_SRC bash
chmod 600 ~/.ssh/authorized_keys
chmod 700 ~/.ssh
#+END_SRC
另外，.ssh目录的owner必须是ssh登录用户，不能是root
*** config 文件的配置
ssh 默认用~/.ssh/xxx下的id_rsa私钥进行验证，如果需要用别的私钥，需要用IdentityFile指定私钥位置

在.ssh/config 配置文件下中加个密钥文件的定义

注意：IdentityFile填的是私钥文件的位置
#+BEGIN_EXAMPLE
HOST w231
    HostName 192.168.1.231
    IdentityFile ~/.ssh/xxx
#+END_EXAMPLE
*** 服务器ssh配置

 修改服务器上的ssh配置文件，位置：/etc/ssh/sshd_config
 #+BEGIN_EXAMPLE
 RSAAuthentication yes
 PubkeyAuthentication yes

 PermitRootLogin no //禁止root登录
 PasswordAuthentication yes //允许密码登录，根据你的情况设置
 #+END_EXAMPLE
 然后重启ssh服务

 service sshd restart
** 通过SSH远程执行命令
 ssh 的一个经常被忽视的特性是它可以直接远程执行命令。

 ssh foobar@server ls 可以直接在用foobar的命令下执行 ls 命令。 

 想要配合管道来使用也可以， ssh foobar@server ls | grep PATTERN 会在本地查询远端 ls 的输出而 ls | ssh foobar@server grep PATTERN 会在远端对本地 ls 输出的结果进行查询。

采用这种语法执行命令时，ssh 客户端不会提供互动式的 Shell 环境，而是直接将远程命令的执行结果输出在命令行。但是，有些命令需要互动式的 Shell 环境，这时就要使用-t参数。
#+begin_src bash
# 报错
$ ssh remote.server.com emacs
emacs: standard input is not a tty

# 不报错
$ ssh -t server.example.com emacs
#+END_SRC
上面代码中，emacs命令需要一个互动式 Shell，所以报错。只有加上-t参数，ssh 才会分配一个互动式 Shell。
** 通过 SSH 复制文件
 使用 ssh 复制文件有很多方法：
 - ssh+tee, 最简单的方法是执行 ssh 命令，然后通过这样的方法利用标准输入实现 cat localfile | ssh remote_server tee serverfile。回忆一下，tee 命令会将标准输出写入到一个文件；
 - scp ：当需要拷贝大量的文件或目录时，使用scp 命令则更加方便，因为它可以方便的遍历相关路径。语法如下：scp path/to/local_file remote_host:path/to/remote_file；
 - rsync 对 scp 进行了改进，它可以检测本地和远端的文件以防止重复拷贝。它还可以提供一些诸如符号连接、权限管理等精心打磨的功能。甚至还可以基于 --partial标记实现断点续传。rsync 的语法和scp类似；
** SSH 客户端config
SSH config是Linux系统下针对SSH客户端的一个参数配置方案，可以将一些关于SSH命令的参数放到配置文件中去，执行ssh命令的时候从文件中读取，简化命令行的操作。这篇短博客记录ssh config相关的配置问题和使用方法。

SSH 参数配置有3个层次：
- 命令行参数，如-p 10086, -i /path/to/identity_file 等选项来设置SSH的端口号或认证证书位置
- 针对某个用户的配置文件，所在路径为~/.ssh/config，默认是不存在的，需要手动创建
- 针对系统所有用户的配置文件，所在路径为/etc/ssh/ssh_config

参数重要性的顺序也是1>2>3，即越近的配置重要性越高。

除了配置文件，~/.ssh目录还有一些用户个人的密钥文件和其他文件。下面是其中一些常见的文件。
- ~/.ssh/id_ecdsa：用户的 ECDSA 私钥。
- ~/.ssh/id_ecdsa.pub：用户的 ECDSA 公钥。
- ~/.ssh/id_rsa：用于 SSH 协议版本2 的 RSA 私钥。
- ~/.ssh/id_rsa.pub：用于SSH 协议版本2 的 RSA 公钥。
- ~/.ssh/identity：用于 SSH 协议版本1 的 RSA 私钥。
- ~/.ssh/identity.pub：用于 SSH 协议版本1 的 RSA 公钥。
- ~/.ssh/known_hosts：包含 SSH 服务器的公钥指纹。

这里针对~/.ssh/config文件的写法进行说明。

一个示例的文件如下：
#+BEGIN_EXAMPLE
# configuration 1
Host *
     Port 2222

# configuration 2
Host remoteserver
     HostName remote.example.com
     User neo
     Port 2112


# configuration 3
Host=aliyun
     Hostname=202.44.2.2
     User tom
#+END_EXAMPLE
主要的规则如下：
- 不同主机的配置通过Host参数来区分，一个配置文件里面可以有针对多个Host的配置
- 以#开头的是注释，会被忽略
- 同一个Host的配置内部，参数名 参数值和参数值=参数名的形式可以混用，如上例#2配置所示

Host命令的值可以使用通配符，比如Host *表示对所有主机都有效的设置，Host *.edu表示只对一级域名为.edu的主机有效的设置。它们的设置都可以被单个主机的设置覆盖。

上面代码中，Host *表示对所有主机生效，后面的Port 2222表示所有主机的默认连接端口都是2222，这样就不用在登录时特别指定端口了。这里的缩进并不是必需的，只是为了视觉上，易于识别针对不同主机的设置。

后面的Host remoteserver表示，下面的设置只对主机remoteserver生效。remoteserver只是一个别名，具体的主机由HostName命令指定，User和Port这两项分别表示用户名和端口。这里的Port会覆盖上面Host *部分的Port设置。

以后，登录remote.example.com时，只要执行ssh remoteserver命令，就会自动套用 config 文件里面指定的参数。

*** config文件常见参数
参数可以在命令行通过man ssh_config来查看
#+BEGIN_EXAMPLE
AddressFamily inet：表示只使用 IPv4 协议。如果设为inet6，表示只使用 IPv6 协议。
BindAddress 192.168.10.235：指定本机的 IP 地址（如果本机有多个 IP 地址）。
BatchMode no                              如果设为“yes”，passphrase/password（交互式输入口令）的提示将被禁止。当不能交互式输入口令的时候，这个选项对脚本文件和批处理任务十分有用
CheckHostIP yes：检查 SSH 服务器的 IP 地址是否跟公钥数据库吻合。
Ciphers blowfish,3des：指定加密算法。
Compression yes：是否压缩传输信号。
ConnectionAttempts 10：客户端进行连接时，最大的尝试次数。
ConnectTimeout 60：客户端进行连接时，服务器在指定秒数内没有回复，则中断连接尝试。
ControlMaster auto:SSH支持 ControlMaster 模式，可以复用之前已经建立的连接,所以开启这个功能之后，如果已经有一条到服务器的链接，那么再连接的时候，就不需要再输入密码了。It will look for the special file (a socket) in your ControlPath directory that is maintaining a connection to the cluster. If it already exists and is open, it’ll use it to create a connection without re-authenticating; if it doesn’t exist, it’ll authenticate and create the file for subsequent use.
ControlPath:指定ControlMaster查找连接的目录.
ControlPersist yes: 在最后一个连接关闭之后也不真正的关掉连接，这样后面再连接的时候就还是不用输入密码。
DynamicForward 1080：指定动态转发端口。
EscapeChar ~                              设置escape字符
ForwardAgent no                           设置连接是否经过验证代理（如果存在）转发给远程计算机。
ForwardX11 no                             设置X11连接是否被自动重定向到安全的通道和显示集（DISPLAY set）
FallBackToRsh no                      设置如果用ssh连接出现错误是否自动使用rsh
GlobalKnownHostsFile /users/smith/.ssh/my_global_hosts_file：指定全局的公钥数据库文件的位置。
Host server.example.com：指定连接的域名或 IP 地址，也可以是别名，支持通配符。Host命令后面的所有配置，都是针对该主机的，直到下一个Host命令为止。“*”表示所有的计算机。
HostKeyAlgorithms ssh-dss,ssh-rsa：指定密钥算法，优先级从高到低排列。
HostName myserver.example.com：在Host命令使用别名的情况下，HostName指定域名或 IP 地址。
IdentityFile keyfile：指定私钥文件。 默认位置是~/.ssh/id_rsa,~/ssh/id_dsa等，如果采用默认的证书，可以不用设置此参数，除非你的证书放在某个自定义的目录，那么你就需要设置该参数来指向你的证书
LocalForward 2001 localhost:143：指定本地端口转发。
LogLevel QUIET：指定日志详细程度。如果设为QUIET，将不输出大部分的警告和提示。
MACs hmac-sha1,hmac-md5：指定数据校验算法。
NumberOfPasswordPrompts 2：密码登录时，用户输错密码的最大尝试次数。
PasswordAuthentication no：指定是否支持密码登录。不过，这里只是客户端禁止，真正的禁止需要在 SSH 服务器设置。
Port 2035：指定客户端连接的 SSH 服务器端口。
PreferredAuthentications publickey,hostbased,password：指定各种登录方法的优先级。
Protocol 2：支持的 SSH 协议版本，多个版本之间使用逗号分隔。默认是22端口，同上，只有在非默认情况下才需要设置该值
PubKeyAuthentication yes：是否支持密钥登录。这里只是客户端设置，还需要在 SSH 服务器进行相应设置。
RemoteForward 2001 server:143：指定远程端口转发。
RhostsAuthentication no                   设置是否使用基于rhosts的安全验证
RhostsRSAAuthentication no            设置是否使用用RSA算法的基于rhosts的安全验证
RSAAuthentication yes                     设置是否使用RSA算法进行安全验证
SendEnv COLOR：SSH 客户端向服务器发送的环境变量名，多个环境变量之间使用空格分隔。环境变量的值从客户端当前环境中拷贝。
ServerAliveCountMax 3：如果没有收到服务器的回应，客户端连续发送多少次keepalive信号，才断开连接。该项默认值为3。
ServerAliveInterval 300：客户端建立连接后，如果在给定秒数内，没有收到服务器发来的消息，客户端向服务器发送keepalive消息。如果不希望客户端发送，这一项设为0。
StrictHostKeyChecking yes：yes表示严格检查，服务器公钥为未知或发生变化，则拒绝连接。no表示如果服务器公钥未知，则加入客户端公钥数据库，如果公钥发生变化，不改变客户端公钥数据库，输出一条警告，依然允许连接继续进行。ask（默认值）表示询问用户是否继续进行。
TCPKeepAlive yes：客户端是否定期向服务器发送keepalive信息。
User userName：指定远程登录的账户名。
UserKnownHostsFile /users/smith/.ssh/my_local_hosts_file：指定当前用户的known_hosts文件（服务器公钥指纹列表）的位置。
UseRsh no                             设置是否在这台计算机上使用“rlogin/rsh”
VerifyHostKeyDNS yes：是否通过检查 SSH 服务器的 DNS 记录，确认公钥指纹是否与known_hosts文件保存的一致。
#+END_EXAMPLE

*** /etc/ssh/sshd_config配置文件
#+BEGIN_EXAMPLE
参数选项                                                        说明
Port 22                                                         SSH 预设使用 22 这个 port，您也可以使用多的 port ！
Protocol 2,1                                                    选择的 SSH 协议版本，可以是 1 也可以是 2 ，如果要同时支持两者，就必须要使用 2,1 这个分隔了！
ListenAddress 0.0.0.0                                           监听的主机适配卡！举个例子来说，如果您有两个 IP，分别是 192.168.0.100 及 192.168.2.20 ，那么只想要开放 192.168.0.100 时，就可以写如同下面的样式：
ListenAddress 192.168.0.100                                     只监听来自 192.168.0.100 这个 IP 的SSH联机。如果不使用设定的话，则预设所有接口均接受 SSH
PidFile /var/run/sshd.pid                                       可以放置 SSHD 这个 PID 的档案！左列为默认值
LoginGraceTime 600                                              当使用者连上 SSH server 之后，会出现输入密码的画面，在该画面中，在多久时间内没有成功连上 SSH server ，就断线！时间为秒！
Compression yes                                                 是否可以使用压缩指令？
HostKey /etc/ssh/ssh_host_key                                   SSH version 1 使用的私钥
HostKey /etc/ssh/ssh_host_rsa_key                               SSH version 2 使用的 RSA 私钥
HostKey /etc/ssh/ssh_host_dsa_key                               SSH version 2 使用的 DSA 私钥
KeyRegenerationInterval 3600                                    由前面联机的说明可以知道， version 1 会使用 server 的 Public Key ，每隔一段时间来重新建立一次！时间为秒！
ServerKeyBits 768                                               Server key 的长度！
SyslogFacility AUTH                                             当有人使用 SSH 登入系统的时候，SSH会记录信息
LogLevel INFO                                                   登录记录的等级---》全部
PermitRootLogin no                                              是否允许 root 登入！预设是允许的，但是建议设定成 no！
UserLogin no                                                    在 SSH 底下本来就不接受 login 这个程序的登入！
StrictModes yes                                                 当使用者的 host key 改变之后，Server 就不接受联机
RSAAuthentication yes                                           是否使用纯的 RSA 认证！？仅针对 version 1 ！
PubkeyAuthentication yes                                        是否允许 Public Key ？只有 version 2
AuthorizedKeysFile   .ssh/authorized_keys                       设定若要使用不需要密码登入的账号时，那么那个账号的存放档案所在档名！
RhostsAuthentication no                                         本机系统不使用 .rhosts ， .rhosts 不安全！
IgnoreRhosts yes                                                是否取消使用 ~/.ssh/.rhosts 来做为认证！
RhostsRSAAuthentication no                                      针对 version 1 ，使用 rhosts 档案在/etc/hosts.equiv配合 RSA 演算方式来进行认证！
HostbasedAuthentication no                                      这个项目与上面的项目类似，不过是给 version 2 使用的！
IgnoreUserKnownHosts no                                         是否忽略家目录内的 ~/.ssh/known_hosts 这个档案所记录的主机内容
PasswordAuthentication yes                                      密码验证当然是需要的！
PermitEmptyPasswords no                                         上面那一项如果设定为 yes 的话，这一项就最好设定为 no ，这个项目在是否允许以空的密码登入！
ChallengeResponseAuthentication yes                             挑战任何的密码认证！所以，任何 login.conf 规定的认证方式，均可适用！
PAMAuthenticationViaKbdInt yes                                  是否启用其它的 PAM 模块！启用这个模块将会导致 PasswordAuthentication 设定失效！

与Kerberos 有关的参数设定！底下不用设定
KerberosAuthentication no
KerberosOrLocalPasswd yes
KerberosTicketCleanup yes
KerberosTgtPassing no

有关在 X-Window 底下使用的相关设定
X11Forwarding yes
X11DisplayOffset 10
X11UseLocalhost yes

PrintMotd no                                                    登入后是否显示出一些信息呢？例如上次登入的时间、地点等，预设是 yes ，但是，如果为了安全，可以考虑改为 no ！
PrintLastLog yes                                                显示上次登入的信息！预设也是 yes 
KeepAlive yes                                                   一般而言，如果设定这项目的话，那么 SSH Server 会传送KeepAlive 的讯息给 Client 端，以确保两者的联机正常！在这个情况下，任何一端死掉后， SSH 可以立刻知道！而不会有僵尸程序的发生！
UsePrivilegeSeparation yes                                      使用者的权限设定项目！
MaxStartups 10                                                  同时允许几个尚未登入的联机画面
DenyUsers *                                                     设定受抵挡的使用者名称
AllowUsers *                                                    设定允许的使用者名称
#+END_EXAMPLE
** ssh 命令行参数
ssh 命令有很多配置项，修改它的默认行为。
*** -c
-c参数指定加密算法。
#+begin_src bash
$ ssh -c blowfish,3des server.example.com
# 或者
$ ssh -c blowfish -c 3des server.example.com
#+END_SRC
上面命令指定使用加密算法blowfish或3des。

*** -C
-C参数表示压缩数据传输。
#+begin_src bash
$ ssh -C server.example.com
#+END_SRC

*** -D
-D参数指定本机的 Socks 监听端口，该端口收到的请求，都将转发到远程的 SSH 主机，又称动态端口转发，详见《端口转发》一章。
#+begin_src bash
$ ssh -D 1080 server
#+END_SRC
上面命令将本机 1080 端口收到的请求，都转发到服务器server。

*** -e
-e ch|^ch|none
设置 pty 会话的 escape 字符 (默认字符: `~' ) . escape 字符只在行首有效, escape 字符后面跟一个点 (`.' ) 表示结束连接, 跟一个 control-Z 表示挂起连接(suspend), 跟 escape 字符自己 表示输出这个字符. 把这个字符设为 ``none 则禁止 escape 功能, 使会话完全透明.
*** -f
-f参数表示 SSH 连接在后台运行。

*** -F
-F参数指定配置文件。
#+begin_src bash
$ ssh -F /usr/local/ssh/other_config
#+END_SRC
上面命令指定使用配置文件other_config。

*** -i
-i参数用于指定私钥，意为“identity_file”，默认值为~/.ssh/id_dsa（DSA 算法）和~/.ssh/id_rsa（RSA 算法）。注意，对应的公钥必须存放到服务器，详见《密钥登录》一章。
#+begin_src bash
$ ssh -i my-key server.example.com
#+END_SRC
*** -l
-l参数指定远程登录的账户名。
#+begin_src bash
$ ssh -l sally server.example.com
# 等同于
$ ssh sally@server.example.com
#+END_SRC
*** -L
-L参数设置本地端口转发，详见《端口转发》一章。
#+begin_src bash
$ ssh  -L 9999:targetServer:80 user@remoteserver
#+END_SRC
上面命令中，所有发向本地9999端口的请求，都会经过remoteserver发往 targetServer 的 80 端口，这就相当于直接连上了 targetServer 的 80 端口。

*** -m
-m参数指定校验数据完整性的算法（message authentication code，简称 MAC）。
#+begin_src bash
$ ssh -m hmac-sha1,hmac-md5 server.example.com
#+END_SRC
上面命令指定数据校验算法为hmac-sha1或hmac-md5。

*** -N
-N参数用于端口转发，表示建立的 SSH 只用于端口转发，不能执行远程命令，这样可以提供安全性，详见《端口转发》一章。

*** -o
-o参数用来指定一个配置命令。
#+begin_src bash
$ ssh -o "Keyword Value"
#+END_SRC
举例来说，配置文件里面有如下内容。
#+BEGIN_EXAMPLE
User sally
Port 220
#+END_EXAMPLE
通过-o参数，可以把上面两个配置命令从命令行传入。
#+begin_src bash
$ ssh -o "User sally" -o "Port 220" server.example.com
#+END_SRC
使用等号时，配置命令可以不用写在引号里面，但是等号前后不能有空格。
#+begin_src bash
$ ssh -o User=sally -o Port=220 server.example.com
#+END_SRC

*** -p
-p参数指定 SSH 客户端连接的服务器端口。
#+begin_src bash
$ ssh -p 2035 server.example.com
#+END_SRC
上面命令连接服务器的2035端口。

*** -q

-q参数表示安静模式（quiet），不向用户输出任何警告信息。
#+begin_src bash
$ ssh –q foo.com
root’s password:
#+END_SRC
上面命令使用-q参数，只输出要求用户输入密码的提示。

*** -R

-R参数指定远程端口转发，详见《端口转发》一章。

$ ssh -R 9999:targetServer:902 local

上面命令需在跳板服务器执行，指定本地计算机local监听自己的 9999 端口，所有发向这个端口的请求，都会转向 targetServer 的 902 端口。

*** -t

-t参数在 ssh 直接运行远端命令时，提供一个互动式 Shell。

$ ssh -t server.example.com emacs

*** -v

-v参数显示详细信息。

$ ssh -v server.example.com

-v可以重复多次，表示信息的详细程度，比如-vv和-vvv。

$ ssh -vvv server.example.com
# 或者
$ ssh -v -v -v server.example.com
上面命令会输出最详细的连接信息。

*** -V

-V参数输出 ssh 客户端的版本。

$ ssh –V
ssh: SSH Secure Shell 3.2.3 (non-commercial version) on i686-pc-linux-gnu

*** -X

-X参数表示打开 X 窗口转发。

$ ssh -X server.example.com

*** -1，-2

-1参数指定使用 SSH 1 协议。

-2参数指定使用 SSH 2 协议。

$ ssh -2 server.example.com

*** -4，-6

-4指定使用 IPv4 协议，这是默认值。

$ ssh -4 server.example.com
-6指定使用 IPv6 协议。

$ ssh -6 server.example.com
** ssh 服务端配置
*** sshd简介
SSH 的架构是服务器/客户端模式，两端运行的软件是不一样的。OpenSSH 的客户端软件是 ssh，服务器软件是 sshd。本章介绍 sshd 的各种知识。

如果没有安装 sshd，可以用下面的命令安装。

#+begin_src bash
# Debian
$ sudo aptitude install openssh-server

# Red Hat
$ sudo yum install openssh-server
#+END_SRC

一般来说，sshd 安装后会跟着系统一起启动。如果当前 sshd 没有启动，可以用下面的命令启动。

#+begin_src bash
$ sshd
#+END_SRC

上面的命令运行后，如果提示“sshd re-exec requires execution with an absolute path”，就需要使用绝对路径来启动。这是为了防止有人出于各种目的，放置同名软件在$PATH变量指向的目录中，代替真正的 sshd。

#+begin_src bash
# Centos、Ubuntu、OS X
$ /usr/sbin/sshd
#+END_SRC

上面的命令运行以后，sshd 自动进入后台，所以命令后面不需要加上&。

除了直接运行可执行文件，也可以通过 Systemd 启动 sshd。

#+begin_src bash
# 启动
$ sudo systemctl start sshd.service

# 停止
$ sudo systemctl stop sshd.service

# 重启
$ sudo systemctl restart sshd.service
#+END_SRC

下面的命令让 sshd 在计算机下次启动时自动运行。

#+begin_src bash
$ sudo systemctl enable sshd.service
#+END_SRC

*** sshd 配置文件

sshd 的配置文件在/etc/ssh目录，主配置文件是sshd_config，此外还有一些安装时生成的密钥。

- /etc/ssh/sshd_config：配置文件
- /etc/ssh/ssh_host_ecdsa_key：ECDSA 私钥。
- /etc/ssh/ssh_host_ecdsa_key.pub：ECDSA 公钥。
- /etc/ssh/ssh_host_key：用于 SSH 1 协议版本的 RSA 私钥。
- /etc/ssh/ssh_host_key.pub：用于 SSH 1 协议版本的 RSA 公钥。
- /etc/ssh/ssh_host_rsa_key：用于 SSH 2 协议版本的 RSA 私钥。
- /etc/ssh/ssh_host_rsa_key.pub：用于 SSH 2 协议版本的 RSA 公钥。
- /etc/pam.d/sshd：PAM 配置文件。

注意，如果重装 sshd，上面这些密钥都会重新生成，导致客户端重新连接 ssh 服务器时，会跳出警告，拒绝连接。为了避免这种情况，可以在重装 sshd 时，先备份/etc/ssh目录，重装后再恢复这个目录。

配置文件sshd_config的格式是，每个命令占据一行。每行都是配置项和对应的值，配置项的大小写不敏感，与值之间使用空格分隔。

#+begin_src bash
Port 2034
#+END_SRC

上面的配置命令指定，配置项Port的值是2034。Port写成port也可。

配置文件还有另一种格式，就是配置项与值之间有一个等号，等号前后的空格可选。

#+begin_src bash
#Port指定 sshd 监听的端口，即客户端连接的端口，默认是22（Port 22）。出于安全考虑，可以改掉这个端口（比如Port 8822）。
Port = 2034
#+END_SRC

配置文件里面，#开头的行表示注释。

注意，注释只能放在一行的开头，不能放在一行的结尾。

#+begin_src bash
Port 2034 # 此处不允许注释
#+END_SRC

上面的写法是错误的。

另外，空行等同于注释。

sshd 启动时会自动读取默认的配置文件。如果希望使用其他的配置文件，可以用 sshd 命令的-f参数指定。

#+begin_src bash
$ sshd -f /usr/local/ssh/my_config
#+END_SRC

上面的命令指定 sshd 使用另一个配置文件my_config。

修改配置文件以后，可以用 sshd 命令的-t（test）检查有没有语法错误。

#+begin_src bash
$ sshd -t
#+END_SRC

配置文件修改以后，并不会自动生效，必须重新启动 sshd。

#+begin_src bash
$ sudo systemctl restart sshd.service
#+END_SRC

*** sshd 密钥

sshd 有自己的一对或多对密钥。它使用密钥向客户端证明自己的身份。所有密钥都是公钥和私钥成对出现，公钥的文件名一般是私钥文件名加上后缀.pub。

DSA 格式的密钥文件默认为/etc/ssh/ssh_host_dsa_key（公钥为ssh_host_dsa_key.pub），RSA 格式的密钥为/etc/ssh/ssh_host_rsa_key（公钥为ssh_host_rsa_key.pub）。如果需要支持 SSH 1 协议，则必须有密钥/etc/ssh/ssh_host_key。

如果密钥不是默认文件，那么可以通过配置文件sshd_config的HostKey配置项指定。默认密钥的HostKey设置如下。

#+begin_src bash
# HostKey for protocol version 1
# HostKey /etc/ssh/ssh_host_key

# HostKeys for protocol version 2
# HostKey /etc/ssh/ssh_host_rsa_key
# HostKey /etc/ssh/ssh_host_dsa_ke
#+END_SRC

上面命令前面的#表示这些行都是注释，因为这是默认值，有没有这几行都一样。

如果要修改密钥，就要去掉行首的#，指定其他密钥。

#+begin_src bash
HostKey /usr/local/ssh/my_dsa_key
HostKey /usr/local/ssh/my_rsa_key
HostKey /usr/local/ssh/my_old_ssh1_key
#+END_SRC

*** sshd 配置项

以下是/etc/ssh/sshd_config文件里面的配置项。

**AcceptEnv**

AcceptEnv指定允许接受客户端通过SendEnv命令发来的哪些环境变量，即允许客户端设置服务器的环境变量清单，变量名之间使用空格分隔（AcceptEnv PATH TERM）。

**AllowGroups**

AllowGroups指定允许登录的用户组（AllowGroups groupName，多个组之间用空格分隔。如果不使用该项，则允许所有用户组登录。

**AllowUsers**

AllowUsers指定允许登录的用户，用户名之间使用空格分隔（AllowUsers user1 user2），也可以使用多行AllowUsers命令指定，用户名支持使用通配符。如果不使用该项，则允许所有用户登录。该项也可以使用用户名@域名的格式（比如AllowUsers jones@example.com）。

**AllowTcpForwarding**

AllowTcpForwarding指定是否允许端口转发，默认值为yes（AllowTcpForwarding yes），local表示只允许本地端口转发，remote表示只允许远程端口转发。

**AuthorizedKeysFile**

AuthorizedKeysFile指定储存用户公钥的目录，默认是用户主目录的ssh/authorized_keys目录（AuthorizedKeysFile .ssh/authorized_keys）。

**Banner**

Banner指定用户登录后，sshd 向其展示的信息文件（Banner /usr/local/etc/warning.txt），默认不展示任何内容。

**ChallengeResponseAuthentication**

ChallengeResponseAuthentication指定是否使用“键盘交互”身份验证方案，默认值为yes（ChallengeResponseAuthentication yes）。

从理论上讲，“键盘交互”身份验证方案可以向用户询问多重问题，但是实践中，通常仅询问用户密码。如果要完全禁用基于密码的身份验证，请将PasswordAuthentication和ChallengeResponseAuthentication都设置为no。

**Ciphers**

Ciphers指定 sshd 可以接受的加密算法（Ciphers 3des-cbc），多个算法之间使用逗号分隔。

**ClientAliveCountMax**

ClientAliveCountMax指定建立连接后，客户端失去响应时，服务器尝试连接的次数（ClientAliveCountMax 8）。

**ClientAliveInterval**

ClientAliveInterval指定允许客户端发呆的时间，单位为秒（ClientAliveInterval 180）。如果这段时间里面，客户端没有发送任何信号，SSH 连接将关闭。

**Compression**

Compression指定客户端与服务器之间的数据传输是否压缩。默认值为yes（Compression yes）

**DenyGroups**

DenyGroups指定不允许登录的用户组（DenyGroups groupName）。

**DenyUsers**

DenyUsers指定不允许登录的用户（DenyUsers user1），用户名之间使用空格分隔，也可以使用多行DenyUsers命令指定。

**FascistLogging**

SSH 1 版本专用，指定日志输出全部 Debug 信息（FascistLogging yes）。

**HostKey**

HostKey指定 sshd 服务器的密钥，详见前文。

**KeyRegenerationInterval**

KeyRegenerationInterval指定 SSH 1 版本的密钥重新生成时间间隔，单位为秒，默认是3600秒（KeyRegenerationInterval 3600）。

**ListenAddress**

ListenAddress指定 sshd 监听的本机 IP 地址，即 sshd 启用的 IP 地址，默认是 0.0.0.0（ListenAddress 0.0.0.0）表示在本机所有网络接口启用。可以改成只在某个网络接口启用（比如ListenAddress 192.168.10.23），也可以指定某个域名启用（比如ListenAddress server.example.com）。

如果要监听多个指定的 IP 地址，可以使用多行ListenAddress命令。

#+begin_src bash
ListenAddress 172.16.1.1
ListenAddress 192.168.0.1
#+END_SRC

**LoginGraceTime**

LoginGraceTime指定允许客户端登录时发呆的最长时间，比如用户迟迟不输入密码，连接就会自动断开，单位为秒（LoginGraceTime 60）。如果设为0，就表示没有限制。

**LogLevel**

LogLevel指定日志的详细程度，可能的值依次为QUIET、FATAL、ERROR、INFO、VERBOSE、DEBUG、DEBUG1、DEBUG2、DEBUG3，默认为INFO（LogLevel INFO）。

**MACs**

MACs指定sshd 可以接受的数据校验算法（MACs hmac-sha1），多个算法之间使用逗号分隔。

**MaxAuthTries**

MaxAuthTries指定允许 SSH 登录的最大尝试次数（MaxAuthTries 3），如果密码输入错误达到指定次数，SSH 连接将关闭。

**MaxStartups**

MaxStartups指定允许同时并发的 SSH 连接数量（MaxStartups）。如果设为0，就表示没有限制。

这个属性也可以设为A:B:C的形式，比如MaxStartups 10:50:20，表示如果达到10个并发连接，后面的连接将有50%的概率被拒绝；如果达到20个并发连接，则后面的连接将100%被拒绝。

**PasswordAuthentication**

PasswordAuthentication指定是否允许密码登录，默认值为yes（PasswordAuthentication yes），建议改成no（禁止密码登录，只允许密钥登录）。

**PermitEmptyPasswords**

PermitEmptyPasswords指定是否允许空密码登录，即用户的密码是否可以为空，默认为yes（PermitEmptyPasswords yes），建议改成no（禁止无密码登录）。

**PermitRootLogin**

PermitRootLogin指定是否允许根用户登录，默认为yes（PermitRootLogin yes），建议改成no（禁止根用户登录）。

还有一种写法是写成prohibit-password，表示 root 用户不能用密码登录，但是可以用密钥登录。

#+begin_src bash
PermitRootLogin prohibit-password
#+END_SRC

**PermitUserEnvironment**

PermitUserEnvironment指定是否允许 sshd 加载客户端的~/.ssh/environment文件和~/.ssh/authorized_keys文件里面的environment= options环境变量设置。默认值为no（PermitUserEnvironment no）。

**Port**

Port指定 sshd 监听的端口，即客户端连接的端口，默认是22（Port 22）。出于安全考虑，可以改掉这个端口（比如Port 8822）。

配置文件可以使用多个Port命令，同时监听多个端口。

#+begin_src bash
Port 22
Port 80
Port 443
Port 8080
#+END_SRC

上面的示例表示同时监听4个端口。

**PrintMotd**

PrintMotd指定用户登录后，是否向其展示系统的 motd（Message of the day）的信息文件/etc/motd。该文件用于通知所有用户一些重要事项，比如系统维护时间、安全问题等等。默认值为yes（PrintMotd yes），由于 Shell 一般会展示这个信息文件，所以这里可以改为no。

**PrintLastLog**

PrintLastLog指定是否打印上一次用户登录时间，默认值为yes（PrintLastLog yes）。

**Protocol**

Protocol指定 sshd 使用的协议。Protocol 1表示使用 SSH 1 协议，建议改成Protocol 2（使用 SSH 2 协议）。Protocol 2,1表示同时支持两个版本的协议。

**PubKeyAuthentication**

PubKeyAuthentication指定是否允许公钥登录，默认值为yes（PubKeyAuthentication yes）。

**QuietMode**

SSH 1 版本专用，指定日志只输出致命的错误信息（QuietMode yes）。

**RSAAuthentication**

RSAAuthentication指定允许 RSA 认证，默认值为yes（RSAAuthentication yes）。

**ServerKeyBits**

ServerKeyBits指定 SSH 1 版本的密钥重新生成时的位数，默认是768（ServerKeyBits 768）。

**StrictModes**

StrictModes指定 sshd 是否检查用户的一些重要文件和目录的权限。默认为yes（StrictModes yes），即对于用户的 SSH 配置文件、密钥文件和所在目录，SSH 要求拥有者必须是根用户或用户本人，用户组和其他人的写权限必须关闭。

**SyslogFacility**

SyslogFacility指定 Syslog 如何处理 sshd 的日志，默认是 Auth（SyslogFacility AUTH）。

**TCPKeepAlive**

TCPKeepAlive指定打开 sshd 跟客户端 TCP 连接的 keepalive 参数（TCPKeepAlive yes）。

**UseDNS**

UseDNS指定用户 SSH 登录一个域名时，服务器是否使用 DNS，确认该域名对应的 IP 地址包含本机（UseDNS yes）。打开该选项意义不大，而且如果 DNS 更新不及时，还有可能误判，建议关闭。

**UseLogin**

UseLogin指定用户认证内部是否使用/usr/bin/login替代 SSH 工具，默认为no（UseLogin no）。

**UserPrivilegeSeparation**

UserPrivilegeSeparation指定用户认证通过以后，使用另一个子线程处理用户权限相关的操作，这样有利于提高安全性。默认值为yes（UsePrivilegeSeparation yes）。

**VerboseMode**

SSH 2 版本专用，指定日志输出详细的 Debug 信息（VerboseMode yes）。

**X11Forwarding**

X11Forwarding指定是否打开 X window 的转发，默认值为 no（X11Forwarding no）。

修改配置文件以后，可以使用下面的命令验证，配置文件是否有语法错误。

#+begin_src bash
$ sshd -t
#+END_SRC

新的配置文件生效，必须重启 sshd。

#+begin_src bash
$ sudo systemctl restart sshd
#+END_SRC

*** sshd 的命令行配置项

sshd 命令有一些配置项。这些配置项在调用时指定，可以覆盖配置文件的设置。

-d

-d参数用于显示 debug 信息。

#+begin_src bash
$ sshd -d
#+END_SRC

-D

-D参数指定 sshd 不作为后台守护进程运行。

#+begin_src bash
$ sshd -D
#+END_SRC

-e

-e参数将 sshd 写入系统日志 syslog 的内容导向标准错误（standard error）。

-f

-f参数指定配置文件的位置。

-h

-h参数用于指定密钥。

#+begin_src bash
$ sshd -h /usr/local/ssh/my_rsa_key
#+END_SRC

-o

-o参数指定配置文件的一个配置项和对应的值。

#+begin_src bash
$ sshd -o "Port 2034"
#+END_SRC

配置项和对应值之间，可以使用等号。

#+begin_src bash
$ sshd -o "Port = 2034"
#+END_SRC

如果省略等号前后的空格，也可以不使用引号。

#+begin_src bash
$ sshd -o Port=2034
#+END_SRC

-o参数可以多个一起使用，用来指定多个配置关键字。

-p

-p参数指定 sshd 的服务端口。

#+begin_src bash
$ sshd -p 2034
#+END_SRC

上面命令指定 sshd 在2034端口启动。

-p参数可以指定多个端口。

#+begin_src bash
$ sshd -p 2222 -p 3333
#+END_SRC

-t

-t参数检查配置文件的语法是否正确。
** SSH 端口转发
SSH 端口转发功能能够将其他 TCP 端口的网络数据通过 SSH 链接来转发，并且自动提供了相应的加密及解密服务。其实这一技术就是我们常常听说的隧道(tunnel)技术，原因是 SSH 为其他 TCP 链接提供了一个安全的通道来进行传输。

SSH端口转发也被称作SSH隧道(SSH Tunnel)，因为它们都是通过SSH登陆之后，在SSH客户端与SSH服务端之间建立了一个隧道，从而进行通信。

我们知道，FTP 协议是以明文来传递数据的。但是我们可以让 FTP 客户端和服务器通过 SSH 隧道传输数据，从而实现安全的 FTP 数据传输。

更常见的情况是我们的应用经常被各种防火墙限制。常见的有禁止访问某些网站、禁用某类软件，同时你的所有网络行为都被监控并分析！同样的通过 SSH 隧道技术我们完全可以规避这些限制。

#+DOWNLOADED: file:E:/org/图片/Snipaste_2021-10-19_15-42-53.png @ 2021-10-19 15:43:34
[[file:ssh_相关/2021-10-19_15-43-34_Snipaste_2021-10-19_15-42-53.png]]
如上图所示，通过 SSH 的端口转发， 应用程序的客户端和应用程序的服务器端不再直接通讯，而是转发到了 SSH 客户端及 SSH 服务端来通讯。这样就可以同时实现两个目的：数据的加密传输和穿透防火墙！
在具体的使用场景中，端口转发又被细分为本地端口转发、远程端口转发、动态端口转发等。
*** 本地端口转发
[[https://unix.stackexchange.com/questions/115897/whats-ssh-port-forwarding-and-whats-the-difference-between-ssh-local-and-remot][StackOverflow 文章示意图]]：

#+DOWNLOADED: file:E:/org/图片/Snipaste_2021-10-19_16-38-33.png @ 2021-10-19 16:38:37
[[file:ssh_相关/2021-10-19_16-38-37_Snipaste_2021-10-19_16-38-33.png]]

顾名思义，本地端口转发是将应用【application client】对于本地主机A指定端口X的访问请求转发给主机B，交由主机B对另一指定主机C的指定端口Z发起访问。

命令如下：
#+begin_src bash
ssh -L 主机A端口X:主机C:主机C端口Z username@hostname
# 简单理解为：将对A:X的访问转变成对C:Z的访问
#+END_SRC
客户端在执行端口转发命令的同时，实际上也执行了基本的连接命令。多出来的部分中，「-L」旗标表示使用「本地端口转发」选项，之后是用冒号分隔开的三个需要指定的项。原理上，主机C可以是任何能够被主机B识别到的设备，也可以是主机B自身。

当主机C在其某端口提供某服务【application server】，主机A需要使用该服务却无法直接访问主机C或该端口时，如果发现有SSH：A→B的连接，且主机B能够直接访问主机C的该端口，本地端口转发就派上用场。

#+DOWNLOADED: file:E:/org/图片/Snipaste_2021-10-19_15-48-49.png @ 2021-10-19 15:48:54
[[file:ssh_相关/2021-10-19_15-48-54_Snipaste_2021-10-19_15-48-49.png]]

此时，访问请求在主机A一侧发生，可以来自于主机A自身，也可以是其他与A连接的设备。图中Host A或Host B的阴影指代主机A或主机B一侧的网络系统。

实际上ssh本地端口转发命令的「-L」旗标后可以填写四个参数，完整格式为：
#+begin_src bash
ssh -L [收听接口:]收听端口:目标主机:目标端口 username@hostname
#+END_SRC
username@hostname 是 SSH 服务器所在的主机

命令中方括号内的部分，即第一个参数可以不写；它的默认值一般是0.0.0.0，意味着SSH隧道会收听所有接口，接受来自任何地址的应用访问请求并进行转发。而如果在此处填写了绑定地址（bind address），SSH隧道连接就会只处理来自绑定地址的应用请求，而对其他地址发来的请求置之不理；如同在（真实世界的）隧道入口设立哨卡，只对白名单牌号的车辆放行。例如在此处填写127.0.0.1，即可实现只有来自主机A本机的应用请求才被SSH隧道转发的效果。

需留意，收听接口是站在主机A的视角上去规定允许与A连接的设备，解决「能够使用SSH端口转发的应用请求从何处来」的问题，类似防火墙的入站；收听端口则依旧是主机A上的那个端口X，不能够跑到别的主机上去。

类似地，远程端口转发和动态端口转发也具有「收听接口」这一可不指明的参数，下文不再赘述。从安全或控制流量的角度，规定绑定地址是一项实用的功能。
**** 实例场景
***** 场景1 
主机B与主机C处于同一内网中，主机B能够与外界联系而主机C不能。这时不处于内网中的主机A如果想要访问主机C，就可以通过SSH连接主机B＋端口转发来进行。

台式机B上运行着虚拟机C，虚拟机使用虚拟机软件搭建的虚拟网络与宿主主机B相连接，但在主机B以外无法直接访问该虚拟网络。想要通过SSH，用与台式机B处于同一WiFi下的笔记本A来远程控制虚拟机C，（在A上）执行端口转发命令：
#+begin_src bash
ssh -L 22022:10.0.2.15:22 desktop_user@192.168.1.11	# cmd.1-1
#+END_SRC
其中，22022号端口是随便选的一个没被占用的端口；192.168.1.11是台式机B在WiFi中的IP；desktop_user是主机B上的用户名；10.0.2.15是虚拟机C在主机B为其搭建的虚拟网络中的IP；22号端口是默认的SSH端口。已知virtual_user是虚拟机C上的用户名，这时在笔记本A上执行应用的访问请求命令：
#+begin_src bash
ssh -p 22022 virtual_user@localhost	# cmd.1-2
#+END_SRC
我们在笔记本A上以SSH协议访问本机（localhost）的22022号端口，这个请求就像通过了隧道（SSH隧道）一样抵达台式机B，台式机B则把这个请求变为对虚拟机C的22号端口的访问，并为A返回结果。其中，使用「-p」旗标是为了访问主机A的特定端口而不是SSH默认的22号端口；由于我们在主机A上执行命令，A管自己叫localhost，假如在其他主机上执行则需相应地改为主机A的域名或IP等他们对A的称呼。

cmd.1-2中我们是将SSH当作普通应用使用的。参考Fig.1，cmd.1-1在A与B之间建立SSH隧道，此时A上的SSH客户端和B上的SSH服务器对应图中的SSH Client和SSH Server；cmd.1-2则表达应用的访问请求，此时A上的SSH客户端和C上的SSH服务器对应图中的application client和application server。

以上cmd.1-1和cmd.1-2合起来实际是想（在A上）进行：
#+begin_src bash
ssh -p 22 virtual_user@10.0.2.15	# cmd.1-3
#+END_SRC
当然，如果这cmd.1-3能被成功执行的话，就不需要端口转发了。
***** 场景2
防火墙阻止了主机A对主机B一些端口的连接，但主机B仍有部分端口是对主机A开放的。这时主机A如果需要访问主机B上被防火墙阻挡的端口，就可以通过SSH连接主机B＋端口转发来进行。需注意，这时所谓的主机C就是主机B。
某某云的云服务器B默认的防火墙设置仅开放了22号端口，其他入方向的访问都被屏蔽了。我们为云服务器B安装了桌面环境，现在想要在自己的计算机A上，通过VNC远程控制云服务器B的桌面。（在A上）执行端口转发命令：

ssh -L 5920:localhost:5901 cloud_user@server.example.com	# cmd.2-1
因为C就是B自己，所以C的位置填localhost；5920随便选；5901是云服务器B上VNC服务进程收听的端口；cloud_user是B上的用户名；http://server.example.com 是B的域名，换成公网IP也行。

下面在计算机A上打开RealVNC VNC Viewer（VNC客户端），输入VNC服务器地址：
#+begin_src bash
localhost:20
#+END_SRC
20=5920−5900，这是采用5901到5999之间端口时RealVNC的特殊设定。开始使用优雅（或许吧）的GUI来操作云服务器吧！

*** 远程端口转发
#+DOWNLOADED: file:E:/org/图片/Snipaste_2021-10-19_16-44-15.png @ 2021-10-19 16:44:19
[[file:ssh_相关/2021-10-19_16-44-19_Snipaste_2021-10-19_16-44-15.png]]
当主机C在其某端口提供某服务，主机B需要使用该服务却无法直接访问主机C或该端口时，如果发现有SSH：A→B的连接，且主机A能够直接访问主机C的该端口，远程端口转发就派上用场。

远程端口转发的结构如下图所示：

#+DOWNLOADED: file:E:/org/图片/Snipaste_2021-10-19_16-45-42.png @ 2021-10-19 16:45:46
[[file:ssh_相关/2021-10-19_16-45-46_Snipaste_2021-10-19_16-45-42.png]]

需注意，此时访问请求在主机B一侧发生，而SSH连接的方向却没有变化，仍是由A到B的。因此「本地与远程端口转发互为镜像」的说法并不完全准确；严格意义上的镜像，SSH连接也要变为由B到A，那时则应该是在B上采用本地端口转发。可以看出，采取哪种端口转发主要取决于SSH连接建立的方向。

与本地端口转发的流动方向相反，远程端口转发是将对于远程主机B指定端口Y的访问请求转发给主机A，交由主机A对另一指定主机C的指定端口Z发起访问。命令如下：
#+begin_src bash
ssh -R 主机B端口Y:主机C:主机C端口Z username@hostname
# 简单理解为：将对B:Y的访问转变成对C:Z的访问
#+END_SRC
username@hostname不变，因为我们仍然以从主机A对主机B发起SSH连接为基础；「-R」旗标表示使用「远程端口转发」选项，之后是用冒号分隔开的三个需要指定的项。原理上，主机C可以是任何能够被主机A识别到的设备，也可以是主机A自身。

**** 示例场景

***** 场景1
主机A与主机C处于同一内网中，主机A能够与外界联系而主机C不能。这时（在主机A上）如果想让不处于内网中的主机B访问主机C，就可以通过SSH连接主机B＋端口转发来进行。
台式机A上运行着虚拟机C，虚拟机使用虚拟机软件搭建的虚拟网络与宿主主机A相连接，但在主机A以外无法直接访问该虚拟网络。想要通过SFTP，用与台式机A处于同一WiFi下的笔记本B来向虚拟机C传输文件，（在A上）执行端口转发命令：
#+begin_src bash
ssh -R 22122:10.0.2.16:22 laptop_user@192.168.1.233	# cmd.3-1
#+END_SRC
其中，22122号端口是随便选的一个没被占用的端口；192.168.1.233是笔记本B在WiFi中的IP；laptop_user是主机B上的用户名；10.0.2.16是虚拟机C在主机A为其搭建的虚拟网络中的IP；22号端口是默认的SFTP端口。已知virtual_user是虚拟机C上的用户名，这时在笔记本B上执行应用的访问请求命令：
#+begin_src bash
sftp -P 22122 virtual_user@localhost	# cmd.3-2
#+END_SRC
请注意这是一条运行在B上的应用命令；B上的SFTP客户端这时充当Fig.2中的application client。此处localhost是主机B对自己的称呼。对B的22122号端口的访问被转发至A，A访问C，即10.0.2.16的22号端口并将结果返回给B。于是B就通过远程端口转发成功访问了C上的SFTP服务器。

以上cmd.3-1和cmd.3-2合起来实际是想（在B上）进行：
#+begin_src bash
sftp -P 22 virtual_user@10.0.2.15	# cmd.3-3
#+END_SRC
当然，这cmd.3-3也是不能被直接成功执行的。

***** 场景2
处于内网之中的主机A可以访问公网，但不具有公网IP；公网中的主机B无法找到A，但为A开放各个端口的访问（A可以直接连接B，反之则不行）。这时A想要让B访问自己，就可以通过SSH连接主机B＋端口转发来进行。需注意，这时所谓的主机C就是主机A。

注意：OpenSSH服务器对于远程端口转发的设定，默认只接受远程主机B本机上的应用发起的请求。想要从其他连接到B的设备发起请求，需将「sshd_config」文件中「GatewayPorts」选项后的「no」修改为「yes」。

手头上计算机A运行着http服务，但A没有公网IP，其他设备不能使用该服务。恰好云服务器B有公网IP（甚至域名），便于被访问。在不将http服务迁移至云服务器B的前提下，可以使用SSH端口转发使其他设备通过访问B的方式访问A上的http服务。（在A上）执行端口转发命令：
#+begin_src bash
ssh -R 80:localhost:80 cloud_user@server.example.com	# cmd.4-1
#+END_SRC

这时C便是A自己（localhost）；80号端口是http默认端口，为简便两个都用默认；cloud_user还是B上的用户名；http://server.example.com 还是B的域名。

接下来在其他设备上打开浏览器，输入地址：
#+BEGIN_EXAMPLE
http://server.example.com/
#+END_EXAMPLE
于是大家可以通过访问 http://server.example.com 来访问本地计算机A提供的http服务了。

*** 动态端口转发
动态转发指的是，本机与 SSH 服务器之间创建了一个加密连接，然后本机内部针对某个端口的通信，都通过这个加密连接转发。它的一个使用场景就是，访问所有外部网站，都通过 SSH 转发。

动态转发需要把本地端口绑定到 SSH 服务器。至于 SSH 服务器要去访问哪一个网站，完全是动态的，取决于原始通信，所以叫做动态转发。

#+begin_src bash
ssh -D local-port username@hostname -N
#+END_SRC
上面命令中，-D表示动态转发，local-port是本地端口，username@hostname是 SSH 服务器，-N表示这个 SSH 连接只进行端口转发，不登录远程 Shell，不能执行远程命令，只能充当隧道。

举例来说，如果本地端口是2121，那么动态转发的命令就是下面这样。
#+begin_src bash
$ ssh -D 2121 tunnel-host -N
#+END_SRC
注意，这种转发采用了 SOCKS5 协议。访问外部网站时，需要把 HTTP 请求转成 SOCKS5 协议，才能把本地端口的请求转发出去。

下面是 SSH 隧道建立后的一个使用实例。
#+begin_src bash
$ curl -x socks5://localhost:2121 http://www.example.com
#+END_SRC
上面命令中，curl 的-x参数指定代理服务器，即通过 SOCKS5 协议的本地2121端口，访问http://www.example.com。

如果经常使用动态转发，可以将设置写入 SSH 客户端的用户个人配置文件（~/.ssh/config）。
#+BEGIN_EXAMPLE
DynamicForward tunnel-host:local-port
#+END_EXAMPLE

动态端口转发可以把本地主机A上运行的SSH客户端转变成一个SOCKS代理服务器；实际上它是一种特殊的本地端口转发，或者说叫它「动态本地端口转发」更科学。这个动态，就动在这种转发不规定目标地址（主机C）和目标端口（端口Z），而是去读取应用发起的请求，从请求中获取目标信息。

这里有一个问题：之前使用固定的端口转发时，应用的访问请求都是指向被转发的那个端口X的，但现在应用的访问请求必须指向目标，以指定动态端口转发的目标。可如果不指向端口X，如何让数据走SSH隧道呢？这就要求我们在系统或应用（浏览器等）中设置一个使用SOCKS5协议、服务器为localhost、端口为X的代理，利用代理使请求走端口X。

这样应用的请求就从X进入隧道，抵达B后其中的目标信息被解析出来，B访问目标后再将结果通过隧道返回给A。比如在开启代理的A上的浏览器中访问http://zhihu.com ，经过端口转发，相当于是B在帮A访问 http://zhihu.com。 

**** 端口转发的停止
SSH端口转发完全基于基本的SSH连接，因此，通过在远程终端上执行exit命令、暴力关闭本地终端窗口、远程主机B关机、本地主机A关机等可以切断SSH连接的方式，即可停止SSH端口转发。就是这样。
*** 参考文章
[[https://wangdoc.com/ssh/port-forwarding.html][SSH 端口转发]]
[[https://solitum.net/posts/an-illustrated-guide-to-ssh-tunnels/][An Illustrated Guide to SSH Tunnels]]
** 开机自启动ssh
这个方法对docker容器无效

设置开机自启动
#+begin_src bash
sudo systemctl enable ssh
#+END_SRC
关闭ssh开机自动启动命令
#+begin_src bash
sudo systemctl disable ssh
#+END_SRC

** 关于公钥指纹
如果是第一次登录对方主机，系统会出现如下图的提示
#+DOWNLOADED: file:E:/org/图片/Snipaste_2021-11-26_16-49-04.png @ 2021-11-26 16:49:17
[[file:ssh_相关/2021-11-26_16-49-17_Snipaste_2021-11-26_16-49-04.png]]

这段话的意思是，无法确认host主机的真实性，只知道它的公钥指纹，问你还想继续连接吗？

在上面这段文字后面，输入yes，就可以将当前服务器的指纹也储存在本机~/.ssh/known_hosts文件中，并显示下面的提示。以后再连接的时候，就不会再出现警告了。

#+BEGIN_EXAMPLE
Warning: Permanently added 'foo.com (192.168.121.111)' (RSA) to the list of known hosts
#+END_EXAMPLE

所谓"公钥指纹"，是指公钥长度较长（这里采用RSA算法，长达1024位），很难比对，所以对其进行MD5计算，将它变成一个128位的指纹。上例中是20:42:b3:d6:79:dc:79:ec:26:1a:54:8c:72:b7:a7:e3，再进行比较，就容易多了。

很自然的一个问题就是，用户怎么知道远程主机的公钥指纹应该是多少？回答是没有好办法，远程主机必须在自己的网站上贴出公钥指纹，以便用户自行核对。

下面的命令可以查看某个公钥的指纹:
#+begin_src bash
$ ssh-keygen -l -f /etc/ssh/ssh_host_ecdsa_key.pub
256 da:24:43:0b:2e:c1:3f:a1:84:13:92:01:52:b4:84:ff   (ECDSA)
#+END_SRC
上面的例子中，ssh-keygen -l -f命令会输出公钥/etc/ssh/ssh_host_ecdsa_key.pub的指纹。

ssh 会将本机连接过的所有服务器公钥的指纹，都储存在本机的~/.ssh/known_hosts文件中。每次连接服务器时，通过该文件判断是否为陌生主机（陌生公钥）。

服务器指纹可以防止有人恶意冒充远程主机。如果服务器的密钥发生变更（比如重装了 SSH 服务器），客户端再次连接时，就会发生公钥指纹不吻合的情况。这时，客户端就会中断连接，并显示一段警告信息。
#+BEGIN_EXAMPLE
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
@    WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!     @
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
IT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY!
Someone could be eavesdropping on you right now (man-in-the-middle attack)!
It is also possible that the RSA host key has just been changed.
The fingerprint for the RSA key sent by the remote host is
77:a5:69:81:9b:eb:40:76:7b:13:04:a9:6c:f4:9c:5d.
Please contact your system administrator.
Add correct host key in /home/me/.ssh/known_hosts to get rid of this message.
Offending key in /home/me/.ssh/known_hosts:36
#+END_EXAMPLE
上面这段文字的意思是，该主机的公钥指纹跟~/.ssh/known_hosts文件储存的不一样，必须处理以后才能连接。这时，你需要确认是什么原因，使得公钥指纹发生变更，到底是恶意劫持，还是管理员变更了 SSH 服务器公钥。

如果新的公钥确认可以信任，需要继续执行连接，你可以执行下面的命令，将原来的公钥指纹从~/.ssh/known_hosts文件删除。
#+begin_src bash
$ ssh-keygen -R hostname
#+END_SRC
上面命令中，hostname是发生公钥变更的主机名。

除了使用上面的命令，你也可以手工修改known_hosts文件，将公钥指纹删除。

删除了原来的公钥指纹以后，重新执行 ssh 命令连接远程服务器，将新的指纹加入known_hosts文件，就可以顺利连接了。
** ssh-keygen命令：生成密钥
密钥登录时，首先需要生成公钥和私钥。OpenSSH 提供了一个工具程序ssh-keygen命令，用来生成密钥。

ssh-keygen的命令行配置项，主要有下面这些。

*** -b

-b参数指定密钥的二进制位数。这个参数值越大，密钥就越不容易破解，但是加密解密的计算开销也会加大。

一般来说，-b至少应该是1024，更安全一些可以设为2048或者更高。

*** -C

-C参数可以为密钥文件指定新的注释，格式为username@host。

下面命令生成一个4096位 RSA 加密算法的密钥对，并且给出了用户名和主机名。

$ ssh-keygen -t rsa -b 4096 -C "your_email@domain.com"

*** -f

-f参数指定生成的私钥文件。

$ ssh-keygen -t dsa -f mykey
上面命令会在当前目录生成私钥文件mykey和公钥文件mykey.pub。

*** -F

-F参数检查某个主机名是否在known_hosts文件里面。

$ ssh-keygen -F example.com

*** -N

-N参数用于指定私钥的密码（passphrase）。

$ ssh-keygen -t dsa -N secretword

*** -p

-p参数用于重新指定私钥的密码（passphrase）。它与-N的不同之处在于，新密码不在命令中指定，而是执行后再输入。ssh 先要求输入旧密码，然后要求输入两遍新密码。

*** -R

-R参数将指定的主机公钥指纹移出known_hosts文件。

$ ssh-keygen -R example.com

*** -t

-t参数用于指定生成密钥的加密算法，一般为dsa或rsa
** ssh-copy-id 命令：自动上传公钥
OpenSSH 自带一个ssh-copy-id命令，可以自动将公钥拷贝到远程服务器的~/.ssh/authorized_keys文件。如果~/.ssh/authorized_keys文件不存在，ssh-copy-id命令会自动创建该文件。

用户在本地计算机执行下面的命令，就可以把本地的公钥拷贝到服务器。
#+begin_src bash
$ ssh-copy-id -i key_file user@host
#+END_SRC
上面命令中，-i参数用来指定公钥文件，user是所要登录的账户名，host是服务器地址。如果省略用户名，默认为当前的本机用户名。执行完该命令，公钥就会拷贝到服务器。

注意，公钥文件可以不指定路径和.pub后缀名，ssh-copy-id会自动在~/.ssh目录里面寻找。
#+begin_src bash
$ ssh-copy-id -i id_rsa user@host
#+END_SRC
上面命令中，公钥文件会自动匹配到~/.ssh/id_rsa.pub。

ssh-copy-id会采用密码登录，系统会提示输入远程服务器的密码。

注意，ssh-copy-id是直接将公钥添加到authorized_keys文件的末尾。如果authorized_keys文件的末尾不是一个换行符，会导致新的公钥添加到前一个公钥的末尾，两个公钥连在一起，使得它们都无法生效。所以，如果authorized_keys文件已经存在，使用ssh-copy-id命令之前，务必保证authorized_keys文件的末尾是换行符（假设该文件已经存在）。
** ssh-agent 命令和ssh-add 命令
*** 基本用法
私钥设置了密码以后，每次使用都必须输入密码，有时让人感觉非常麻烦。比如，连续使用scp命令远程拷贝文件时，每次都要求输入密码。

ssh-agent命令就是为了解决这个问题而设计的，它让用户在整个 Bash 对话（session）之中，只在第一次使用 SSH 命令时输入密码，然后将私钥保存在内存中，后面都不需要再输入私钥的密码了。

第一步，使用下面的命令新建一次命令行对话。
#+begin_src bash
$ ssh-agent bash
#+END_SRC
上面命令中，如果你使用的命令行环境不是 Bash，可以用其他的 Shell 命令代替。比如zsh和fish。

如果想在当前对话启用ssh-agent，可以使用下面的命令。
#+begin_src bash
$ eval `ssh-agent`
#+END_SRC
上面命令中，ssh-agent会先自动在后台运行，并将需要设置的环境变量输出在屏幕上，类似下面这样。
#+begin_src bash
$ ssh-agent
SSH_AUTH_SOCK=/tmp/ssh-barrett/ssh-22841-agent; export SSH_AUTH_SOCK;
SSH_AGENT_PID=22842; export SSH_AGENT_PID;
echo Agent pid 22842;
#+END_SRC
eval命令的作用，就是运行上面的ssh-agent命令的输出，设置环境变量。

第二步，在新建的 Shell 对话里面，使用ssh-add命令添加默认的私钥（比如~/.ssh/id_rsa，或~/.ssh/id_dsa，或~/.ssh/id_ecdsa，或~/.ssh/id_ed25519）。
#+begin_src bash
$ ssh-add
Enter passphrase for /home/you/.ssh/id_dsa: ********
Identity added: /home/you/.ssh/id_dsa (/home/you/.ssh/id_dsa)
#+END_SRC

上面例子中，添加私钥时，会要求输入密码。以后，在这个对话里面再使用密钥时，就不需要输入私钥的密码了，因为私钥已经加载到内存里面了。

如果添加的不是默认私钥，ssh-add命令需要显式指定私钥文件。
#+begin_src bash
$ ssh-add my-other-key-file
#+END_SRC
上面的命令中，my-other-key-file就是用户指定的私钥文件。

第三步，使用 ssh 命令正常登录远程服务器。
#+begin_src bash
$ ssh remoteHost
#+END_SRC
上面命令中，remoteHost是远程服务器的地址，ssh 使用的是默认的私钥。这时如果私钥设有密码，ssh 将不再询问密码，而是直接取出内存里面的私钥。

如果要使用其他私钥登录服务器，需要使用 ssh 命令的-i参数指定私钥文件。
#+begin_src bash
$ ssh –i OpenSSHPrivateKey remoteHost
#+END_SRC
最后，如果要退出ssh-agent，可以直接退出子 Shell（按下 Ctrl + d），也可以使用下面的命令。
#+begin_src bash
$ ssh-agent -k
#+END_SRC
*** ssh-add命令
ssh-add命令用来将私钥加入ssh-agent，它有如下的参数。

**** -d

-d参数从内存中删除指定的私钥。

$ ssh-add -d name-of-key-file

**** -D

-D参数从内存中删除所有已经添加的私钥。

$ ssh-add -D

**** -l

-l参数列出所有已经添加的私钥。

$ ssh-add -l
** 关闭ssh密码登录
为了安全性，启用密钥登录之后，最好关闭服务器的密码登录。

对于 OpenSSH，具体方法就是打开服务器 sshd 的配置文件/etc/ssh/sshd_config，将PasswordAuthentication这一项设为no。
#+BEGIN_EXAMPLE
PasswordAuthentication no
#+END_EXAMPLE

修改配置文件以后，不要忘了重新启动 sshd，否则不会生效。
** known_hosts文件
当远程主机的公钥被接受以后，它就会被保存在文件$HOME/.ssh/known_hosts之中。下次再连接这台主机，系统就会认出它的公钥已经保存在本地了，从而跳过警告部分，直接提示输入密码。

每个SSH用户都有自己的known_hosts文件，此外系统也有一个这样的文件，通常是/etc/ssh/ssh_known_hosts，保存一些对所有用户都可信赖的远程主机的公钥。

** authorized_keys文件
生成密钥以后，公钥必须上传到服务器，才能使用公钥登录。

OpenSSH 规定，用户公钥保存在服务器的~/.ssh/authorized_keys文件。你要以哪个用户的身份登录到服务器，密钥就必须保存在该用户主目录的~/.ssh/authorized_keys文件。只要把公钥添加到这个文件之中，就相当于公钥上传到服务器了。每个公钥占据一行。如果该文件不存在，可以手动创建。

用户可以手动编辑该文件，把公钥粘贴进去，也可以在本机计算机上，执行下面的命令。
#+begin_src bash
$ cat ~/.ssh/id_rsa.pub | ssh user@host "mkdir -p ~/.ssh && cat >> ~/.ssh/authorized_keys"
#+END_SRC
上面示例中，user@host要替换成你所要登录的用户名和主机名。

注意，authorized_keys文件的权限要设为644，即只有文件所有者才能写。如果权限设置不对，SSH 服务器可能会拒绝读取该文件。
#+begin_src bash
$ chmod 644 ~/.ssh/authorized_keys
#+END_SRC
只要公钥上传到服务器，下次登录时，OpenSSH 就会自动采用密钥登录，不再提示输入密码。
#+begin_src bash
$ ssh -l username shell.isp.com
Enter passphrase for key '/home/you/.ssh/id_dsa': ************
Last login: Mon Mar 24 02:17:27 2014 from ex.ample.com
shell.isp.com>
#+END_SRC
上面例子中，SSH 客户端使用私钥之前，会要求用户输入密码（passphrase），用来解开私钥。
** 加密参数
SSH 连接的握手阶段，客户端必须跟服务端约定加密参数集（cipher suite）。

加密参数集包含了若干不同的加密参数，它们之间使用下划线连接在一起，下面是一个例子。
#+BEGIN_EXAMPLE
TLS_RSA_WITH_AES_128_CBC_SHA
#+END_EXAMPLE
它的含义如下。
#+BEGIN_EXAMPLE
TLS：加密通信协议
RSA：密钥交换算法
AES：加密算法
128：加密算法的强度
CBC：加密算法的模式
SHA：数字签名的 Hash 函数
#+END_EXAMPLE
下面是一个例子，客户端向服务器发出的握手信息。
#+BEGIN_EXAMPLE
Handshake protocol: ClientHello
    Version: TLS 1.2
    Random
        Client time: May 22, 2030 02:43:46 GMT
        Random bytes: b76b0e61829557eb4c611adfd2d36eb232dc1332fe29802e321ee871
    Session ID: (empty)
    Cipher Suites
        Suite: TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256”
        Suite: TLS_DHE_RSA_WITH_AES_128_GCM_SHA256
        Suite: TLS_RSA_WITH_AES_128_GCM_SHA256
        Suite: TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA
        Suite: TLS_DHE_RSA_WITH_AES_128_CBC_SHA
        Suite: TLS_RSA_WITH_AES_128_CBC_SHA
        Suite: TLS_RSA_WITH_3DES_EDE_CBC_SHA
        Suite: TLS_RSA_WITH_RC4_128_SHA
    Compression methods
        Method: null
    Extensions
        Extension: server_name
            Hostname: www.feistyduck.com
        Extension: renegotiation_info
        Extension: elliptic_curves
            Named curve: secp256r1
            Named curve: secp384r1
        Extension: signature_algorithms
            Algorithm: sha1/rsa
            Algorithm: sha256/rsa
            Algorithm: sha1/ecdsa
            Algorithm: sha256/ecdsa”
#+END_EXAMPLE
上面的握手信息（ClientHello）之中，Cipher Suites字段就是客户端列出可选的加密参数集，服务器在其中选择一个自己支持的参数集。

服务器选择完毕之后，向客户端发出回应。
#+BEGIN_EXAMPLE
Handshake protocol: ServerHello
    Version: TLS 1.2
    Random
        Server time: Mar 10, 2059 02:35:57 GMT”
        Random bytes: 8469b09b480c1978182ce1b59290487609f41132312ca22aacaf5012
    Session ID: 4cae75c91cf5adf55f93c9fb5dd36d19903b1182029af3d527b7a42ef1c32c80
    Cipher Suite: TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256
    Compression method: null
    Extensions
        Extension: server_name
        Extension: renegotiation_info”
#+END_EXAMPLE
上面的回应信息（ServerHello）中，Cipher Suite字段就是服务器最终选定的加密参数。
** SSH 证书登录
SSH 是服务器登录工具，一般情况下都采用密码登录或密钥登录。

但是，SSH 还有第三种登录方法，那就是证书登录。某些情况下，它是更合理、更安全的登录方法，本文就介绍这种登录方法。
*** 非证书登录的缺点

密码登录和密钥登录，都有各自的缺点。

密码登录需要输入服务器密码，这非常麻烦，也不安全，存在被暴力破解的风险。

密钥登录需要服务器保存用户的公钥，也需要用户保存服务器公钥的指纹。这对于多用户、多服务器的大型机构很不方便，如果有员工离职，需要将他的公钥从每台服务器删除。

*** 证书登录是什么？

证书登录就是为了解决上面的缺点而设计的。它引入了一个证书颁发机构（Certificate Authority，简称 CA），对信任的服务器颁发服务器证书，对信任的用户颁发用户证书。

登录时，用户和服务器不需要提前知道彼此的公钥，只需要交换各自的证书，验证是否可信即可。

证书登录的主要优点有两个：（1）用户和服务器不用交换公钥，这更容易管理，也具有更好的可扩展性。（2）证书可以设置到期时间，而公钥没有到期时间。针对不同的情况，可以设置有效期很短的证书，进一步提高安全性。

*** 证书登录的流程

SSH 证书登录之前，如果还没有证书，需要生成证书。具体方法是：（1）用户和服务器都将自己的公钥，发给 CA；（2）CA 使用服务器公钥，生成服务器证书，发给服务器；（3）CA 使用用户的公钥，生成用户证书，发给用户。

有了证书以后，用户就可以登录服务器了。整个过程都是 SSH 自动处理，用户无感知。

第一步，用户登录服务器时，SSH 自动将用户证书发给服务器。

第二步，服务器检查用户证书是否有效，以及是否由可信的 CA 颁发。证实以后，就可以信任用户。

第三步，SSH 自动将服务器证书发给用户。

第四步，用户检查服务器证书是否有效，以及是否由信任的 CA 颁发。证实以后，就可以信任服务器。

第五步，双方建立连接，服务器允许用户登录。

*** 生成 CA 的密钥

证书登录的前提是，必须有一个 CA，而 CA 本质上就是一对密钥，跟其他密钥没有不同，CA 就用这对密钥去签发证书。

虽然 CA 可以用同一对密钥签发用户证书和服务器证书，但是出于安全性和灵活性，最好用不同的密钥分别签发。所以，CA 至少需要两对密钥，一对是签发用户证书的密钥，假设叫做user_ca，另一对是签发服务器证书的密钥，假设叫做host_ca。

使用下面的命令，生成user_ca。

#+begin_src bash
# 生成 CA 签发用户证书的密钥
$ ssh-keygen -t rsa -b 4096 -f ~/.ssh/user_ca -C user_ca
#+END_SRC

上面的命令会在~/.ssh目录生成一对密钥：user_ca（私钥）和user_ca.pub（公钥）。

这个命令的各个参数含义如下。

- -t rsa：指定密钥算法 RSA。
- -b 4096：指定密钥的位数是4096位。安全性要求不高的场合，这个值可以小一点，但是不应小于1024。
- -f ~/.ssh/user_ca：指定生成密钥的位置和文件名。
- -C user_ca：指定密钥的识别字符串，相当于注释，可以随意设置。

使用下面的命令，生成host_ca。

#+begin_src bash
# 生成 CA 签发服务器证书的密钥
$ ssh-keygen -t rsa -b 4096 -f host_ca -C host_ca
#+END_SRC

上面的命令会在~/.ssh目录生成一对密钥：host_ca（私钥）和host_ca.pub（公钥）。

现在，~/.ssh目录应该至少有四把密钥。

- ~/.ssh/user_ca
- ~/.ssh/user_ca.pub
- ~/.ssh/host_ca
- ~/.ssh/host_ca.pub

*** CA 签发服务器证书

有了 CA 以后，就可以签发服务器证书了。

签发证书，除了 CA 的密钥以外，还需要服务器的公钥。一般来说，SSH 服务器（通常是sshd）安装时，已经生成密钥/etc/ssh/ssh_host_rsa_key了。如果没有的话，可以用下面的命令生成。

#+begin_src bash
$ sudo ssh-keygen -f /etc/ssh/ssh_host_rsa_key -b 4096 -t rsa
#+END_SRC

上面命令会在/etc/ssh目录，生成ssh_host_rsa_key（私钥）和ssh_host_rsa_key.pub（公钥）。然后，需要把服务器公钥ssh_host_rsa_key.pub，复制或上传到 CA 所在的服务器。

上传以后，CA 就可以使用密钥host_ca为服务器的公钥ssh_host_rsa_key.pub签发服务器证书。

#+begin_src bash
$ ssh-keygen -s host_ca -I host.example.com -h -n host.example.com -V +52w ssh_host_rsa_key.pub
#+END_SRC

上面的命令会生成服务器证书ssh_host_rsa_key-cert.pub（服务器公钥名字加后缀-cert）。这个命令各个参数的含义如下。

- -s：指定 CA 签发证书的密钥。
- -I：身份字符串，可以随便设置，相当于注释，方便区分证书，将来可以使用这个字符串撤销证书。
- -h：指定该证书是服务器证书，而不是用户证书。
- -n host.example.com：指定服务器的域名，表示证书仅对该域名有效。如果有多个域名，则使用逗号分隔。用户登录该域名服务器时，SSH 通过证书的这个值，分辨应该使用哪张证书发给用户，用来证明服务器的可信性。
- -V +52w：指定证书的有效期，这里为52周（一年）。默认情况下，证书是永远有效的。建议使用该参数指定有效期，并且有效期最好短一点，最长不超过52周。
- ssh_host_rsa_key.pub：服务器公钥。

生成证书以后，可以使用下面的命令，查看证书的细节。

#+begin_src bash
$ ssh-keygen -L -f ssh_host_rsa_key-cert.pub
#+END_SRC

最后，为证书设置权限。

#+begin_src bash
$ chmod 600 ssh_host_rsa_key-cert.pub
#+END_SRC

*** CA 签发用户证书

下面，再用 CA 签发用户证书。这时需要用户的公钥，如果没有的话，客户端可以用下面的命令生成一对密钥。

#+begin_src bash
$ ssh-keygen -f ~/.ssh/user_key -b 4096 -t rsa
#+END_SRC

上面命令会在~/.ssh目录，生成user_key（私钥）和user_key.pub（公钥）。

然后，将用户公钥user_key.pub，上传或复制到 CA 服务器。接下来，就可以使用 CA 的密钥user_ca为用户公钥user_key.pub签发用户证书。

#+begin_src bash
$ ssh-keygen -s user_ca -I user@example.com -n user -V +1d user_key.pub
#+END_SRC

上面的命令会生成用户证书user_key-cert.pub（用户公钥名字加后缀-cert）。这个命令各个参数的含义如下。

- -s：指定 CA 签发证书的密钥
- -I：身份字符串，可以随便设置，相当于注释，方便区分证书，将来可以使用这个字符串撤销证书。
- -n user：指定用户名，表示证书仅对该用户名有效。如果有多个用户名，使用逗号分隔。用户以该用户名登录服务器时，SSH 通过这个值，分辨应该使用哪张证书，证明自己的身份，发给服务器。
- -V +1d：指定证书的有效期，这里为1天，强制用户每天都申请一次证书，提高安全性。默认情况下，证书是永远有效的。
- user_key.pub：用户公钥。

生成证书以后，可以使用下面的命令，查看证书的细节。

#+begin_src bash
$ ssh-keygen -L -f user_key-cert.pub
#+END_SRC

最后，为证书设置权限。

#+begin_src bash
$ chmod 600 user_key-cert.pub
#+END_SRC

*** 服务器安装证书

CA 生成服务器证书ssh_host_rsa_key-cert.pub以后，需要将该证书发回服务器，可以使用下面的scp命令，将证书拷贝过去。

#+begin_src bash
$ scp ~/.ssh/ssh_host_rsa_key-cert.pub root@host.example.com:/etc/ssh/
#+END_SRC

然后，将下面一行添加到服务器配置文件/etc/ssh/sshd_config。

#+begin_src bash
HostCertificate /etc/ssh/ssh_host_rsa_key-cert.pub
#+END_SRC

上面的代码告诉 sshd，服务器证书是哪一个文件。

重新启动 sshd。

#+begin_src bash
$ sudo systemctl restart sshd.service
# 或者
$ sudo service sshd restart
#+END_SRC

*** 服务器安装 CA 公钥

为了让服务器信任用户证书，必须将 CA 签发用户证书的公钥user_ca.pub，拷贝到服务器。

#+begin_src bash
$ scp ~/.ssh/user_ca.pub root@host.example.com:/etc/ssh/
#+END_SRC

上面的命令，将 CA 签发用户证书的公钥user_ca.pub，拷贝到 SSH 服务器的/etc/ssh目录。

然后，将下面一行添加到服务器配置文件/etc/ssh/sshd_config。

#+begin_src bash
TrustedUserCAKeys /etc/ssh/user_ca.pub
#+END_SRC

上面的做法是将user_ca.pub加到/etc/ssh/sshd_config，这会产生全局效果，即服务器的所有账户都会信任user_ca签发的所有用户证书。

另一种做法是将user_ca.pub加到服务器某个账户的~/.ssh/authorized_keys文件，只让该账户信任user_ca签发的用户证书。具体方法是打开~/.ssh/authorized_keys，追加一行，开头是@cert-authority principals="..."，然后后面加上user_ca.pub的内容，大概是下面这个样子。

#+begin_src bash
@cert-authority principals="user" ssh-rsa AAAAB3Nz...XNRM1EX2gQ==
#+END_SRC

上面代码中，principals="user"指定用户登录的服务器账户名，一般就是authorized_keys文件所在的账户。

重新启动 sshd。

#+begin_src bash
$ sudo systemctl restart sshd.service
# 或者
$ sudo service sshd restart
#+END_SRC

至此，SSH 服务器已配置为信任user_ca签发的证书。

*** 客户端安装证书

客户端安装用户证书很简单，就是从 CA 将用户证书user_key-cert.pub复制到客户端，与用户的密钥user_key保存在同一个目录即可。

*** 客户端安装 CA 公钥

为了让客户端信任服务器证书，必须将 CA 签发服务器证书的公钥host_ca.pub，加到客户端的/etc/ssh/ssh_known_hosts文件（全局级别）或者~/.ssh/known_hosts文件（用户级别）。

具体做法是打开ssh_known_hosts或known_hosts文件，追加一行，开头为@cert-authority *.example.com，然后将host_ca.pub文件的内容（即公钥）粘贴在后面，大概是下面这个样子。

#+begin_src bash
@cert-authority *.example.com ssh-rsa AAAAB3Nz...XNRM1EX2gQ==
#+END_SRC

上面代码中，*.example.com是域名的模式匹配，表示只要服务器符合该模式的域名，且签发服务器证书的 CA 匹配后面给出的公钥，就都可以信任。如果没有域名限制，这里可以写成*。如果有多个域名模式，可以使用逗号分隔；如果服务器没有域名，可以用主机名（比如host1,host2,host3）或者 IP 地址（比如11.12.13.14,21.22.23.24）。

然后，就可以使用证书，登录远程服务器了。

#+begin_src bash
$ ssh -i ~/.ssh/user_key user@host.example.com
#+END_SRC

上面命令的-i参数用来指定用户的密钥。如果证书与密钥在同一个目录，则连接服务器时将自动使用该证书。

*** 废除证书

废除证书的操作，分成用户证书的废除和服务器证书的废除两种。

服务器证书的废除，用户需要在known_hosts文件里面，修改或删除对应的@cert-authority命令的那一行。

用户证书的废除，需要在服务器新建一个/etc/ssh/revoked_keys文件，然后在配置文件sshd_config添加一行，内容如下。

#+begin_src bash
RevokedKeys /etc/ssh/revoked_keys
#+END_SRC

revoked_keys文件保存不再信任的用户公钥，由下面的命令生成。

#+begin_src bash
$ ssh-keygen -kf /etc/ssh/revoked_keys -z 1 ~/.ssh/user1_key.pub
#+END_SRC

上面命令中，-z参数用来指定用户公钥保存在revoked_keys文件的哪一行，这个例子是保存在第1行。

如果以后需要废除其他的用户公钥，可以用下面的命令保存在第2行。

#+begin_src bash
$ ssh-keygen -ukf /etc/ssh/revoked_keys -z 2 ~/.ssh/user2_key.pub
#+END_SRC

*** 参考链接

- [SSH Emergency Access](https://smallstep.com/blog/ssh-emergency-access/), Carl Tashian
- [Using OpenSSH Certificate Authentication](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/deployment_guide/sec-using_openssh_certificate_authentication), Red Hat Enterprise Linux Deployment Guide
- [How to SSH Properly](https://gravitational.com/blog/how-to-ssh-properly/), Gus Luxton
** 配置vscode 远程开发+ 免密登录
1. 先在window上安装ssh，然后在cmd上用命令ssh-keygen生成密钥对

2. 在vscode中安装remote development 插件

3. 将公钥添加到服务器上的~/.ssh/authorized_keys文件里

4. 在vscode中（或者直接在本地路径打开）打开.ssh/config文件

#+DOWNLOADED: file:E:/org/图片/Snipaste_2021-11-26_18-57-54.png @ 2021-11-26 18:57:59
[[file:ssh_相关/2021-11-26_18-57-59_Snipaste_2021-11-26_18-57-54.png]]
5. 修改.ssh/config文件：加入IdentityFile的路径（也就是私钥在本机的所在位置）,

注意这里的Windows路径要加双引号，如果是linux路径，则不用加双引号

#+DOWNLOADED: file:E:/org/图片/Snipaste_2021-11-26_18-58-21.png @ 2021-11-26 18:58:25
[[file:ssh_相关/2021-11-26_18-58-25_Snipaste_2021-11-26_18-58-21.png]]

** 获取SSH登陆用户的IP地址
一、找sshd进程
#+begin_src bash
ps -ef|grep sshd
root      1693     1  0 Aug13 ?        00:00:00 /usr/sbin/sshd   #父进程号是1的是系统服务进程
root     12598  1693  2 14:59 ?        00:00:00 /usr/sbin/sshd   #有这个进程说明有SSHD远程客户登录
root     12638  1693  0 15:02 ?        00:00:00 /usr/sbin/sshd   #这是第二个登录用户
root     12633 12600  0 14:59 pts/0    00:00:00 grep sshd
#+END_SRC

二、根据登录上来的进程号找到用户进程
#+begin_src bash
#ps -ef|grep 12598
root     12598  1693  0 14:59 ?        00:00:00 /usr/sbin/sshd
root     12600 12598  0 14:59 pts/0    00:00:00 -bash            #第一个用户，居然还是用root登录的。

#ps -ef|grep 12633
root     12638  1693  0 15:02 ?        00:00:00 /usr/sbin/sshd
root     12640 12638  0 15:02 pts/1    00:00:00 -bash            #第二个用户
#+END_SRC

三、根据bash进程的终端号pts/?来确定来源
#+begin_src bash
[root@redhat root]# who -a|grep pts/1
root     + pts/1        Aug 14 15:02 00:03       12640 (192.168.0.123)   #登录来源IP192.168.0.123
[root@redhat root]# who -a|grep pts/0
root     + pts/0        Aug 14 14:59   .         12600 (192.168.0.123)   #登录来源IP192.168.0.123
#+END_SRC
** ssh Connection refused的解决方法
 没装openssh_server 或者openssh_client，解决方法:sudo apt-get install openssh_server openssh_client
 #+BEGIN_EXAMPLE
 The ssh binary, the SSH client, is provided by the openssh-client package, which is installed on your system.

 The ssh service runs the SSH server, provided by the openssh-server package, which isn’t installed on your system.

 The ssh package is a meta-package which installs both the client and the server.
 #+END_EXAMPLE
 开启openssh服务: sudo /etc/init.d/ssh start

 验证是否开启服务: ps -e | grep ssh

 如果有输出 sshd 证明已经开启ssh服务

** git bash关于debug1: send_pubkey_test: no mutual signature algorithm 的解决方法
相关讨论：[[https://github.com/golang/go/issues/37278][x/crypto/ssh: support RSA SHA-2 host key signatures #37278]]
#+BEGIN_EXAMPLE
The new version of Git for Windows uses OpenSSH version 8.8, which uses THE RSA-SHA2 algorithm by default. However, the Golang SSH library used by Gitee uses the RSA-SHA1 algorithm, so the public key authentication fails.

Add the following information to the config file under ~/.ssh/ :

Host gitee.com 
HostkeyAlgorithms +ssh-rsa 
PubkeyAcceptedAlgorithms +ssh-rsa
#+END_EXAMPLE

** SSH连接报错:Permission denied, please try again.的解决方法
当使用 SSH 登录云服务器 ECS （Elastic Compute Server） Linux 服务器时，如果是 root 用户，即便正确输入了密码，也会出现类似如下错误信息。

Permission denied, please try again.

SSH 服务器拒绝了密码，请再试一次。

但非root用户可以正常登录，而且root用户通过 管理终端 登录也正常。

这是因为服务端SSH 服务配置了禁止root用户登录策略。

修改/etc/ssh/sshd_config 中:
PermitRootLogin no

为：PermitRootLogin yes

并重启ssh服务：service sshd restart
** SSH-Key authentication fails
root用户无法用密钥登录的解决方法

ssh -vvv root@10.0.12.28 查看连接详细信息，发现出现
#+begin_src bash
debug1: Offering public key: /c/Users/123/.ssh/id_rsa RSA SHA256:FBIuIq5fVuKYh0ncLnXiJryP/K+58ysh2fGdwVveU1I
debug3: send packet: type 50
debug2: we sent a publickey packet, wait for reply
debug3: receive packet: type 51
#+END_SRC
这个是root用户目录下的.ssh文件夹以及authorized_keys文件的权限没有正确设置的原因

*** 参考文章
[[https://superuser.com/questions/1137438/ssh-key-authentication-fails][SSH-Key authentication fails]]
** 重用SSH连接
平时需要经常用到 SSH，比如登录远程服务器，用 Git 推送和更新代码等。建立一次 SSH 连接可能并不需要多久长时间，但是如果要频繁登录同一台服务器，就未免显得有些繁琐和浪费时间。如果是用用户名和密码登录，每次都要输入密码就更加让人崩溃。还有使用 Git 的时候，短时间内可能需要经常 git pull 和 git push，如果每次操作都需要重新建立连接，等待过程就让人心生厌恶了。

实际上，SSH 有个「鲜为人知」的特性可以做到重用连接，只有在第一次登录的时候会创建新的连接，后续的会话都可以重用这个已经存在的连接。这样，后续的登录就会非常快，而且不需要输入密码认证。配置也很简单，直接上代码。

修改 ~/.ssh/config 文件，添加如下配置：
#+begin_example
Host *
    ControlMaster auto
    ControlPath /tmp/ssh_mux_%h_%p_%r
    ControlPersist 600

#+end_example
意思也很好理解：

Host * 这一行表示下面这些配置和规则影响到的 host，* 表示所有的远程 host 都生效。如果要指定某个（些）特定的 host，可以使用类似 Host *.example.com 的配置。

ControlMaster auto 这个选项告诉 SSH 客户端尝试重用现有的连接（master connection）。

ControlPath 指定了这个连接的 socket 保存的路径，这里配置的是在 /tmp 目录，实际上可以在任何有读写权限的路径下。/tmp/ssh_mux_%h_%p_%r 配置了 socket 文件名，%h 表示远程主机名（host），%p 表示远程 SSH 服务器的端口（port），%r 表示登录的远程用户名（remote user name）。这些 socket 可以随时删掉（rm），删除后首次会话又会创建新的 master 连接。曾经遇到过这种情况，本地断网了，打开的几个远程终端都卡死，网络恢复后也一直这样，甚至打开新的终端也登录不上。这个时候只需要把之前的 socket 文件都删掉，重新登录就可以了。

ControlPersist 这个选项比较重要，表示在创建首个连接（master connection）的会话退出后，master 连接仍然在后台保留，以便其他复用该连接的会话不会出现问题。这个特性在使用 Git 的时候就非常有用，在频繁提交和拉代码的时候，每次 SSH 会话都是很短暂的，如果 master 连接能保持在后台，后续的操作就会如丝般顺滑。

只需要添加上面几行配置，SSH 的体验就瞬间上升了好几个档次，简直是懒人必备。
** 参考文章
[[https://www.jianshu.com/p/1e793e386beb][ssh配置文件详解]]
[[https://wangdoc.com/ssh/client.html][ssh教程]]
[[https://www.jianshu.com/p/7e43fa159851][使用ssh 的ControlMaster实现不用每次ssh都输入密码]]
[[http://liyangliang.me/posts/2015/03/reuse-ssh-connection/][重用 SSH 连接]]
* stty命令
Linux环境下，在终端设备与进程之间的中间有一个终端驱动器，里面有终端驱动函数。

stty 命令的作用是修改或者显示终端驱动程序里面的设置。

stty的设置只存在于当前shell环境中，如果需要重启后自动设置终端，可以将修改加入到profile中。
** 参数
常用参数
stty 命令不带参数可以打印终端行设置，加上 -a 参数可以打印得更详细些。

stty size ：可以显示终端的大小，即行数和列数。

stty 命令还可以更改终端行的设置，格式如下：stty SETTING CHAR

其中，SETTING可以是如下：
- eof : 输入结束，文件结束，默认为Ctrl+D。比如：用cat >file来创建文件时，按Ctrl+D来结束输入。
- erase : 向后删除字符，擦除最后一个输入字符，默认为Ctrl+?。注意默认情况下退格键Backspace不是删除字符。
- intr : 中断当前程序，默认为Ctrl+C。
- kill : 删除整条命令，删除整行，默认为Ctrl+U。
- quit :退出当前程序，默认为Ctrl+\或Ctrl+|。
- start : 启动屏幕输出，默认为Ctrl+Q。
- stop :停止屏幕输出，默认为Ctrl+S。
- susp : terminal stop当前程序，默认为Ctrl+Z。这样当前进程就会变成后台进程了。
- werase：删除最后一个单词，默认为Ctrl+W。

stty 命令还有一些其他用法：
#+begin_src bash
#在命令行下，禁止输出大写的方法：
stty iuclc     #开启
stty -iuclc    #恢复

#在命令行下禁止输出小写：
stty olcuc    #开启
stty -olcuc   #恢复

#打印出终端的行数和列数：
stty size

#改变Ctrl+D的方法:
stty eof "string"
#系统默认是Ctrl+D来表示文件的结束，而通过这种方法，可以改变！

#屏蔽显示：
stty -echo   #禁止回显
stty echo    #打开回显
#测试方法:
stty -echo;read;stty echo;read

#忽略回车符：
stty igncr     #开启
stty -igncr    #恢复
#+END_SRC

** 使用示例
*** 打印终端行设置
#+begin_src bash
[oracle10g@linux]$ stty -a
speed 38400 baud; rows 66; columns 132; line = 0;
intr = ^C; quit = ^\; erase = ^H; kill = ^U; eof = ^D; eol = <undef>; eol2 = <undef>; start = ^Q; stop = ^S; susp = ^Z; rprnt = ^R;
werase = ^W; lnext = ^V; flush = ^O; min = 1; time = 0;
-parenb -parodd cs8 -hupcl -cstopb cread -clocal -crtscts
-ignbrk -brkint -ignpar -parmrk -inpck -istrip -inlcr -igncr icrnl ixon -ixoff -iuclc -ixany -imaxbel
opost -olcuc -ocrnl onlcr -onocr -onlret -ofill -ofdel nl0 cr0 tab0 bs0 vt0 ff0
isig icanon iexten echo echoe echok -echonl -noflsh -xcase -tostop -echoprt echoctl echoke
#+END_SRC
其中：
- eof : 输入结束
- erase : 向后删除字符，
- intr : 中断当前程序
- kill : 删除整条命令
- quit :退出当前程序
- start : 启动屏幕输出
- stop :停止屏幕输出；
- susp : terminal stop当前程序。
*** 打印当前终端的大小（行数和列数）
#+begin_src bash
[root@web ~]# stty size
24 80

#+END_SRC
*** 设置退格键Backspace的删除行为

在默认情况下，我们按退格键Backspace时，会在屏幕上回显^H，而不是把前一个字符删除。
比如使用sftp/ftp/sqlplus/ij等命令时，就会碰到这种情况。
当然，我们 可以同时按下ctrl+backspace键来删除，但对于习惯了用backspace来删除的用户，这样很不爽。
这可以通过修改tty终端的设置来实现 backspace删除功能。我们可以使用stty命令把Backspace的行为变成删除前一个字符。
#+begin_src bash
sftp> get abc^H^H^H^H

#设置backspace为删除键：
[root@web ~]# stty erase ^H
#改回使用ctrl+backspace为删除键
[root@web ~]# stty erase ^?
#+END_SRC
在设置backspace时，最好先在shell提示符下按一下backspace键试一下，如果显示^h就设置成stty erase ^h, 如果^?就用stty erease ^?
*** 在vi编辑文件时按Ctrl+Q来结束终端僵死的局面
#+begin_src bash
[root@web ~]# vi 1.txt
1
2
3
Ctrl+S
~
#+END_SRC

注：按了Ctrl+S之后，就会禁止屏幕输出，从而出现终端僵死的情况。
这个时候，只要按Ctrl+Q就会结束这种局面，因为它会允许屏幕输出。
Ctrl+Q
** 参考文章
[[https://www.cnblogs.com/goloving/p/15170646.html][浅析Linux中stty命令的作用、常用用法及案例使用]]
[[https://www.cnblogs.com/the-tops/p/5621207.html][使用stty修改终端设置 stty 用法！]]
* string命令
strings [-a] [-] [-o] [-t Format] [-n Number] [-Number] [File ...]

strings 命令在对象文件或二进制文件中查找可打印的字符串。这个文件可以是文本文件（test.c）, 可执行文件(test),  动态链接库(test.o), 静态链接库(test.a).
字符串是 4 个或更多可打印字符的任意序列，以换行符或空字符结束。
strings 命令对识别随机对象文件很有用。

** 参数
-a 或 - 搜索整个文件，而不仅仅是数据段，以寻找可打印的字符串。如果省略这个标志，则 strings 命令只在对象文件的初始化数据空间内寻找。
-n Number 指定最小的字符串长度（除了缺省的 4 个字符以外）。字符串长度的最大值是 4096。这个标志与 -Number 标志相同。
-o 列出文件中每个跟随在其八进制偏移量之后的字符串。这个标志与 -t o 标志相同。
-t Format 列出从文件最开始起，每个跟随在其偏移量之后的字符串。该格式取决于用作 Format 变量的字符。
d
以十进制写下偏移量。
o
以八进制写下偏移量。
x
以十六进制写下偏移量。
 

注：当 -o 和 -t Format 标志在一个命令行上多次定义，则最后指定的标志控制 strings 命令的行为。
-Number 指定最小的字符串长度（除了缺省的 4 个字符以外）。字符串长度的最大值是 4096。这个标志与 -n Number 标志相同。
File 要搜索的二进制文件或对象文件。

** 返回值
0 表示命令成功运行。
>0 表示出错。

** 示例
在大型的软件开发中， 假设有100个.c/.cpp文件， 这个.cpp文件最终生成10个.so库， 那么怎样才能快速知道某个.c/.cpp文件编译到那个.so库中去了呢？ 当然， 你可能要说， 看makefile不就知道了。 对， 看makefile肯定可以， 但如下方法更好， 直接用命令：
      strings -f "*.so" | grep "xxxxxx"
 
      如果还不明白， 那就就以上面的小程序为例为说明， 不过， 此处我们考虑所有的文件， 如下：
#+begin_src bash
1 [taoge@localhost learn_c]$ strings -f * | grep "my dear"
2 a.out: oh, my dear, c is %d
3 test.c:     printf("oh, my dear, c is %d\n", c);
4 [taoge@localhost learn_c]$
#+end_src
可以看到， 源文件test.c和可执行文件中皆有"my dear"串， 一下子就找到了对应的文件，清楚了吧。如果某.c/.cpp文件编译进了.so库， 那么，strings -f * | grep "my dear"必定可以找到对应的.so文件， 其中"my dear"为该.c/.cpp文件中的某个日志串（比如以printf为打印）。

** 参考文章
[[https://www.cnblogs.com/klb561/p/10765464.html][linux中的strings命令]]
* sftp
sftp是 SSH 提供的一个客户端应用程序，主要用来安全地访问 FTP。因为 FTP 是不加密协议，很不安全，sftp就相当于将 FTP 放入了 SSH。

下面的命令连接 FTP 主机。
#+begin_src bash
$ sftp username@hostname
#+END_SRC
执行上面的命令，会要求输入 FTP 的密码。密码验证成功以后，就会出现 FTP 的提示符sftp>，下面是一个例子。
#+begin_src bash
$ sftp USER@penguin.example.com
USER@penguin.example.com's password:
Connected to penguin.example.com.
sftp>
#+END_SRC
FTP 的提示符下面，就可以输入各种 FTP 命令了，这部分完全跟传统的 FTP 用法完全一样。
- ls [directory]：列出一个远程目录的内容。如果没有指定目标目录，则默认列出当前目录。
- cd directory：从当前目录改到指定目录。
- mkdir directory：创建一个远程目录。
- rmdir path：删除一个远程目录。
- put localfile [remotefile]：本地文件传输到远程主机。
- get remotefile [localfile]：远程文件传输到本地。
- help：显示帮助信息。
- bye：退出 sftp。
- quit：退出 sftp。
- exit：退出 sftp。
* tar命令
- *.Z compress 程序压缩的文件；
- *.zip zip 程序压缩的文件；
- *.gz gzip 程序压缩的文件；
- *.bz2 bzip2 程序压缩的文件；
- *.xz xz 程序压缩的文件；
- *.tar tar 程序打包的数据，并没有压缩过；
- *.tar.gz tar 程序打包的文件，其中并且经过 gzip 的压缩
- *.tar.bz2 tar 程序打包的文件，其中并且经过 bzip2 的压缩
- *.tar.xz tar 程序打包的文件，其中并且经过 xz 的压缩

** 常见的压缩指令
*** gzip, zcat/zmore/zless/zgrep
 目前 gzip 可以解开 compress, zip 与 gzip 等软件所压缩的文件

 当你使用 gzip 进行压缩时，在预设的状态下原本的文件会被压缩成为 .gz 的档名，源文件就不再存在了。
*** bzip2, bzcat/bzmore/bzless/bzgrep
*** xz, xzcat/xzmore/xzless/xzgrep

** 命令格式
#+begin_src bash
tar [-z|-j|-J] [cv] [-f 待建立的新檔名] filename... <==打包与压缩
tar [-z|-j|-J] [tv] [-f 既有的 tar 檔名] <==察看檔名
tar [-z|-j|-J] [xv] [-f 既有的 tar 檔名] [-C 目录] <==解压缩
#+END_SRC
-z:gz
-j:bz2
-J:xz
** 选项与参数：
- -c ：建立打包文件，可搭配 -v 来察看过程中被打包的档名(filename)
- -t ：察看打包文件的内容含有哪些档名，重点在察看『档名』就是了；
- -x ：解打包或解压缩的功能，可以搭配 -C (大写) 在特定目录解开。 

特别留意的是， -c, -t, -x 不可同时出现在一串指令列中。

- -z ：透过 gzip 的支持进行压缩/解压缩：此时档名最好为 *.tar.gz
- -j ：透过 bzip2 的支持进行压缩/解压缩：此时档名最好为 *.tar.bz2
- -J ：透过 xz 的支持进行压缩/解压缩：此时档名最好为 *.tar.xz。 

特别留意， -z, -j, -J 不可以同时出现在一串指令列中

- -v ：在压缩/解压缩的过程中，将正在处理的文件名显示出来！用-tv 选项查看打包文件时，详细的文件权限/属性都会被列出来。
- -f filename：-f 后面要立刻接要被处理的档名！建议 -f 单独写一个选项啰！(比较不会忘记) 。如果把-jcvf filename写成-jvfc filename ，会导致产生的档名变成 c 
- -C 目录 ：指定解压目录。这个选项用在解压缩，若要在特定目录解压缩，可以使用这个选项。
- -p(小写) ：保留备份数据的原本权限与属性，常用于备份(-c)重要的配置文件
- -P(大写) ：保留绝对路径，亦即允许备份数据中含有根目录存在之意；
- --exclude=FILE：在压缩的过程中，不要将 FILE 打包！
** 仅解开单一文件的方法
#+begin_src bash
# 1. 先找到我们要的档名，假设解开 shadow 文件好了：
[root@study ~]# tar -jtv -f /root/etc.tar.bz2 | grep 'shadow'
---------- root/root 721 2015-06-17 00:20 etc/gshadow
---------- root/root 1183 2015-06-17 00:20 etc/shadow-
---------- root/root 1210 2015-06-17 00:20 etc/shadow <==这是我们要的！
---------- root/root 707 2015-06-17 00:20 etc/gshadow-
# 先搜寻重要的档名！其中那个 grep 是『撷取』关键词的功能！我们会在第三篇说明！
# 这里您先有个概念即可！那个管线 | 配合 grep 可以撷取关键词的意思！
# 2. 将该文件解开！语法与实际作法如下：
[root@study ~]# tar -jxv -f 打包檔.tar.bz2 待解开档名
[root@study ~]# tar -jxv -f /root/etc.tar.bz2 etc/shadow
etc/shadow
[root@study ~]# ll etc
total 4
----------. 1 root root 1210 Jun 17 00:20 shadow
# 很有趣！此时只会解开一个文件而已！不过，重点是那个档名！你要找到正确的档名。
# 在本例中，你不能写成 /etc/shadow ！因为记录在 etc.tar.bz2 内的并没有 / 之故！
#+END_SRC
** tar命令解压时去除目录结构
指定去除目录结构，使用--strip-components N

如：压缩文件 file.tar 中文件信息为 three/two/one/file.txt

1、（去除第一层目录 three）运行以下命令：
tar -xvf file.tar --strip-components 1

最终结果为：
two/one/file.txt

2、（去除三层目录 three、two、one、）运行以下命令：
tar -xvf file.tar --strip-components 3

解压结果为：
file.txt
* TensorFlow
用pip命令
#+BEGIN_SRC bash
pip install tensorflow
#+END_SRC
* tee命令
Linux tee命令用于读取标准输入的数据，并将其内容输出成文件。

tee指令会从标准输入设备读取数据，将其内容输出到标准输出设备，同时保存成文件。

语法：
tee [-ai][--help][--version][文件...]

参数：
- -a或--append 　附加到既有文件的后面，而非覆盖它．
- -i或--ignore-interrupts 　忽略中断信号。
- --help 　在线帮助。
- --version 　显示版本信息。
** 实例
使用指令"tee"将用户输入的数据同时保存到文件"file1"和"file2"中，输入如下命令：
#+begin_src bash
$ tee file1 file2                   #在两个文件中复制内容 
#+END_SRC
以上命令执行后，将提示用户输入需要保存到文件的数据，如下所示：
#+BEGIN_EXAMPLE
My Linux                        #提示用户输入数据  
My Linux                        #输出数据，进行输出反馈  
#+END_EXAMPLE
此时，可以分别打开文件"file1"和"file2"，查看其内容是否均是"My Linux"即可判断指令"tee"是否执行成功。
* tmp目录
** /tmp临时目录
inux的/tmp目录中保存了linux操作系统和其他正在执行的应用层软件需要的一些临时文件。
比如，当你编写某个文档的时候，文档的内容实际上是先以临时文件的方式保存在/tmp目录中的。当你将文档保存之后，它才以文件的方式保存到你制定的位置里，而/tmp目录中的临时文件，在你关闭这片文档的时候，就会被移除。
** /tmp目录和/var/tmp目录的区别
Ubuntu的临时文件目录，更多规则参考这里：https://manpages.ubuntu.com/manpages/lunar/en/man5/tmpfiles.d.5.html
*** 有效期不同
/tmp目录和/var/tmp目录都被操作系统和应用软件存储临时文件，最大的不同是两个目录中临时文件的有效期不同。
保存在/var/tmp目录中的临时文件，有效期更久。
默认情况下，/var/tmp目录中临时文件的有效期为30天，/tmp目录中的临时文件有效期为10天。
*** 重启清理
还有就是，/tmp目录中的临时文件，当系统重启的时候就会被清理一次。而/var/tmp目录中的临时文件，在系统重启的时候不会被清理。

* tmux
** sessions, windows and panes介绍
摘抄 github 上 tmux 项目的 wiki 之 Getting-Started#summary-of-terms 属于解释表，如下：
| Term           | Description                                                                          |
|----------------+--------------------------------------------------------------------------------------|
| Client         | Attaches a tmux session from an outside terminal such as xterm(1)                    |
| Session        | Groups one or more windows together                                                  |
| Window         | Groups one or more panes together, linked to one or more sessions                    |
| Pane           | Contains a terminal and running program, appears in one window                       |
| Active pane    | The pane in the current window where typing is sent; one per window                  |
| Current window | The window in the attached session where typing is sent; one per session             |
| Last window    | The previous current window                                                          |
| Session name   | The name of a session, defaults to a number starting from zero                       |
| Window list    | The list of windows in a session in order by number                                  |
| Window name    | The name of a window, defaults to the name of the running program in the active pane |
| Window index   | The number of a window in a session’s window list                                    |
| Window layout  | The size and position of the panes in a window                                       |
*** pane
每一个运行在 tmux 里的终端都属于一个 pane，它是一个矩形区域。

因为 tmux 里一个终端仅仅被显示在一个 pane 里，术语 pane 常常用于表示 tmux 里所有的 pane。

一个 pane 仅属于一个 window ，一个 window 可以有多个 pane，多个 pane 共同填满整个 window 区域，达到多个 pane 允许同时被看到。

pane 间用线分隔，这条线叫 pane border 。

每个 window 里有一个 active pane，active pane 是输入的文本发送的地方，是用指令定位到 window 后默认的 pane 。

active pane 的 pane border 是绿色的。
*** window
一个 window 通常会占据整个 tmux 终端，不过 window 大小是可以设置的。

一个 window 里的所有 pane 的大小、位置信息叫做 window layout。

每个 window 都有一个名称，默认情况 tmux 会自动命名一个，用户可以修改。

window 名称不用全局唯一，鉴定出一个 window 用的是 session 和 window index，不是用 window 名称。
*** session
一个 session 可以包含多个 window，一个 window 也可以属于多个 session，大多数时候一个 window 仅属于一个 session 。

一个 window 是某个 session 的一部分，那么可以说此 window 链接到这个 session。

同属一个 session 的 window 有个数字，叫做 window index 。当一个 window 属于多个 session 时，同样的 window 有多个不同的 window index 值。

一个 session 的 window 列表是此 session 下所有 window 的列表，并且 window 按照 window index 排序。

每个 session 有个 current window 。当依附到 session 时展现的 window 叫 current window，也是用指定选中 session 时默认的 window 。

如果 current window 改变了，前一个 current window 改叫做 last window 。

多个客户端可以依附到同一个 session 上，

session 没有 index 但是有名次，session 的名称必须唯一。
** 会话
每个会话都是一个独立的工作区，其中包含一个或多个窗口
#+BEGIN_EXAMPLE
tmux 开始一个新的会话
tmux new -s NAME -n window_name 以指定名称开始一个新的会话,-s指定会话名，-n指定窗口名
tmux new 'emacs ~/.tmux.conf' 或者 tmux new -- emacs ~/.tmux.conf 启动其他程序替代启动 shell
tmux ls 列出当前所有会话
tmux kill-session -t <session_name> 删除指定名字的会话
tmux list-keys 列出您拥有的所有自定义键绑定。
tmux a 重新连接最后一个会话。您也可以通过 -t 来指定具体的会话（例如tmux attach -t 0）
tmux rename-session -t 0 database 对指定的会话由0改名为database
tmux attach -d -t <session_name>. The “-d” option causes the session to be detached from its previous terminal. Without this option, the session will be attached to both its previous terminal and the new terminal
<C-b> d 将当前会话分离
<C-b> $ 重命名会话
<C-b> s 会话切换
<C-b> w 会显示 session 和 session 下的 window ，并选中 session 下的 current window 。
exit 退出会话
#+END_EXAMPLE
** 窗口 
相当于编辑器或是浏览器中的标签页，从视觉上将一个会话分割为多个部分
#+BEGIN_EXAMPLE
<C-b> c 创建一个新的窗口，使用 <C-d>关闭
tmux neww -n Window1 创建一个新的名为Window1的窗口
<C-b> N 跳转到第 N 个窗口，注意每个窗口都是有编号的
<C-b> p 切换到前一个窗口
<C-b> n 切换到下一个窗口
<C-b> , 重命名当前窗口
<C-b> 0	切换到0号窗口. 窗口1-9操作类似.
<C-b> w 列出当前所有窗口
<C-b> ? 列出所有快捷键
#+END_EXAMPLE

** 面板
像 vim 中的分屏一样，面板使我们可以在一个屏幕里显示多个 shell
#+BEGIN_EXAMPLE
<C-b> " 水平分割
<C-b> % 垂直分割
<C-b> <方向> 切换到指定方向的面板，<方向> 指的是键盘上的方向键
<C-b> z 切换当前面板的缩放（即切换全屏）
<C-b> [ 开始往回卷动屏幕。您可以按下空格键来开始选择，回车键复制选中的部分。type Ctrl-space to begin selection, then move the cursor to make our selection. Finally, we type Alt-w to copy the selected text.
<C-b> ] 粘贴
<C-b> <C-arrow> Resize pane by 1 character
<C-b> <Alt-arrow> Resize pane by 5 characters
<C-b> x	Destroy current pane
<C-b> <空格> 在不同的面板排布间切换
exit or <C-b> d 退出面板
<C-b> t 在当前面板显示一个数字时钟，按q可以退出
<C-b> ! 将当前面板变成一个新的窗口
#+END_EXAMPLE
** 状态栏
当一个客户端依附到 session 时，客户端会在屏幕底部显示一个状态栏，默认是绿色的，并展示下面信息：
- 左边是依附到的 session 名称
- 中间是依附到 session 的 window 列表，有 window 的 index，比如 0:ksh 。
- 右边是用引号括起 pane 的 title （默认情况是运行 tmux 的主机名）和时间日期。
- 如果打开的 window 太多，< 和 > 符号会加在 window 列表的两边。
- window 列表里，current window 会加 * ，last window 会加 - 。
#+DOWNLOADED: screenshot @ 2021-12-10 09:37:39
[[file:images/linux笔记/tmux/2021-12-10_09-37-39_screenshot.png]]
** 帮助键
每个默认的 tmux 快捷键都有个简单的描述来帮助记忆这些快捷键用来做什么的。

C-b ? 键可以查看快捷键列表。

C-b ? 进入 view 模式，显示文本。pane 进入 view 模式后有自己独立的快捷键就不需要使用前缀键了。pane view 模式的快捷键和 emacs 很像。Up、Down、C-Up，C-Down 用于上下滚动，q 退出 pane 的 view 模式；右上角显示总行数和当前行数。

或者，tmux lsk -N | more 也可以查看相同的快捷键列表。

C-b / 查看单个键的描述信息，按下 C-b / 之后，一个提示符出现在终端底部，输入要查看的 key 就会显示它的描述，比如按下 C-b / 在按下 ? 会显示 “C-b ? List key bindings” 。
** 完全的退出 tmux
当 tmux 里没有 session 、window、pane 时 tmux server 自动退出。

也可以手动退出正在运行的 tmux server，进入命令提示符（C-b :）输入 :kill-server 即可。
** tree mode(选择 session, window, panen)
tmux 有种模式叫 tree mode，允许在一个 tree 上浏览、依附、杀掉、选择 session 、window 、pane ；允许选择多个 session 、window 、pane 打上标签，然后同时向它们发送命令。

有两种进入 tree mode 的快捷键：
- C-b s 仅显示 session，并选中依附上的 session 。
- C-b w 会显示 session 和 session 下的 window ，并选中 session 下的 current window 。

tree mode 把窗口分割成两部分，上半部分是列出 session 、window 、pane 信息的 tree ，下半部分是光标选中部分的预览。对于选中的 session 会尽可能显示每个 window 的 active pane ，选中的 window 会尽可能显示每个 pane ，选中的 pane 会只显示选中的 pane 。

控制 tree mode 的按键不需要前缀键。
- Up ，Down 上下移动。
- Enter 改成选中的项，变成依附的 session ，current window ，active pane ，并退出 tree mode。
- Right 展开选中的项，session 展开显示 window ，window 展开显示 pane 。
- Left 收起选中的项。
- q 退出 tree mode 。
- t 键给项打标签，再按一次 t 取消标签。被打上标签的项加粗显示，名称后面有 * 号。
- T 一次取消所有项的标签。
- X 一次性杀掉所有打上标签的项。
- : 进入提示符模式，输入的命令会一次性应用到所有被打标签的项上。
- tree 里的每项前面都有个序号，在行首，用括号包围着。按下序号对应的按键会立即选中此项，相当于按下 enter 键。前十个项是 0-9 按键，后面的使用 M-a 到 M-z 。
** client mode(分离其他客户端)
C-b D (C-b S-d) 快捷键可以获得客户端列表，进入 client mode 。

每个 client 会显示在上半部分的列表里，会显示客户端的名字、依附到的 session 、大小、最后使用的时间和日期。下半部分会预览选中的客户端。

在 client mode 里移动和打标签的快捷键和 tree mode 一样。但是有区别：
- Enter 分离选中的 client 。
- d 分离选中的 client 和 enter 一样。
- D 分离被打标签了的 clients 。
- x 分离选中的 client 并尝试 kill 启动此 client 的 shell 。
- X 分离被打标签的 clients 并尝试 kill 启动这些 client 的 shell 们。
** 配置文件
位置文件位置在：
/etc/tmux.conf and ~/.tmux.conf

加载配置文件：在 tmux 窗口中，先按下 Ctrl+b 指令前缀，然后按下系统指令:，进入到命令模式后输入 source-file ~/.tmux.conf
*** 修改指令前缀
#+begin_src bash
unbind C-f # C-b 即 Ctrl+b 键，unbind 意味着解除绑定
set -g prefix C-f #
bind C-f send-prefix # 绑定 Ctrl+f 为新的指令前缀

# 从tmux v1.6版起，支持设置第二个指令前缀
set-option -g prefix2 ` # 设置一个不常用的`键作为指令前缀，按键更快些
#+END_SRC
*** 添加加载配置文件快捷指令 r
#+begin_src bash
bind r source-file ~/.tmux.conf \; display-message "Config reloaded.."
#+END_SRC
*** 支持鼠标
- 选取文本
- 调整面板大小
- 选中并切换面板
#+begin_src bash
# 老版本：
setw -g mode-mouse on # 支持鼠标选取文本等
setw -g mouse-resize-pane on # 支持鼠标拖动调整面板的大小(通过拖动面板间的分割线)
setw -g mouse-select-pane on # 支持鼠标选中并切换面板
setw -g mouse-select-window on # 支持鼠标选中并切换窗口(通过点击状态栏窗口名称)

# v2.1及以上的版本
set-option -g mouse on
#+END_SRC
但在以上设置下，会发现无法用中键向 tmux 中复制文本，也无法将 tmux 中选择好的文本中键复制到系统其他应用程序中。

这里有一个 trick，那就是在 tmux 中不论选择还是复制时，都按住 Shift 键，你会发现熟悉的中键又回来了 ? 此外，还可以使用 Shift+Insert 快捷键将系统剪切板中的内容输入 tmux 中。 相对于 tmux 原生的选择模式（不加 shift 键），使用系统选择有个缺陷，即当一行内存在多个面板时，无法选择单个面板中的内容，这时就必须使用 tmux 自带的复制粘贴系统了。
*** 更改新增面板键
- 垂直新增面板
- 水平新增面板
#+begin_src bash
unbind '"'
bind - splitw -v -c '#{pane_current_path}' # 垂直方向新增面板，默认进入当前目录
unbind %
bind =  splitw -h -c '#{pane_current_path}' # 水平方向新增面板，默认进入当前目录
#+END_SRC
*** 面板调整大小
绑定Ctrl+hjkl键为面板上下左右调整边缘的快捷指令
#+begin_src bash
bind -r ^k resizep -U 10 # 绑定Ctrl+k为往↑调整面板边缘10个单元格
bind -r ^j resizep -D 10 # 绑定Ctrl+j为往↓调整面板边缘10个单元格
bind -r ^h resizep -L 10 # 绑定Ctrl+h为往←调整面板边缘10个单元格
bind -r ^l resizep -R 10 # 绑定Ctrl+l为往→调整面板边缘10个单元格
#+END_SRC
*** 快速面板切换
鼠标支持确实能带来很大的便捷性，特别是对于习惯了鼠标操作的tmux新手，但对于键盘爱好者而言，这不是什么好消息，对他们而言，双手不离键盘是基本素质。

虽然指令前缀加方向键可以切换面板，但方向键太远，不够快，不够Geek。没关系，我们可以将面板切换升级为熟悉的h、j、k、l键位。
#+begin_src bash
# 绑定hjkl键为面板切换的上下左右键
bind -r k select-pane -U # 绑定k为↑
bind -r j select-pane -D # 绑定j为↓
bind -r h select-pane -L # 绑定h为←
bind -r l select-pane -R # 绑定l为→
#+END_SRC
-r表示可重复按键，大概500ms之内，重复的h、j、k、l按键都将有效，完美支持了快速切换的Geek需求。

除了上下左右外， 还有几个快捷指令可以设置。
#+begin_src bash
bind -r e lastp # 选择最后一个面板
bind -r ^e last # 选择最后一个窗口

bind -r ^u swapp -U # 与前一个面板交换位置
bind -r ^d swapp -D # 与后一个面板交换位置
#+END_SRC
*** 复制模式
复制模式更改为 vi 风格
#+begin_src bash
setw -g mode-keys vi # 开启vi风格后，支持vi的C-d、C-u、hjkl等快捷键
#+END_SRC
复制模式向 vi 靠拢
- v 开始选择文本
- y 复制选中文本
- p 粘贴文本
#+begin_src bash
bind -t vi-copy v begin-selection # 绑定v键为开始选择文本
bind -t vi-copy y copy-selection # 绑定y键为复制选中文本
bind p pasteb # 绑定p键为粘贴文本（p键默认用于进入上一个窗口，不建议覆盖）
#+END_SRC

*** 设置窗口面板起始序
#+begin_src bash
set -g base-index 1 # 设置窗口的起始下标为1
set -g pane-base-index 1 # 设置面板的起始下标为1
#+END_SRC

*** 自定义状态栏
#+begin_src bash
set -g status-utf8 on # 状态栏支持utf8
set -g status-interval 1 # 状态栏刷新时间
set -g status-justify left # 状态栏列表左对齐
setw -g monitor-activity on # 非当前窗口有内容更新时在状态栏通知

set -g status-bg black # 设置状态栏背景黑色
set -g status-fg yellow # 设置状态栏前景黄色
set -g status-style "bg=black, fg=yellow" # 状态栏前景背景色

set -g status-left "#[bg=#FF661D] ❐ #S " # 状态栏左侧内容
set -g status-right 'Continuum status: #{continuum_status}' # 状态栏右侧内容
set -g status-left-length 300 # 状态栏左边长度300
set -g status-right-length 500 # 状态栏左边长度500

set -wg window-status-format " #I #W " # 状态栏窗口名称格式
set -wg window-status-current-format " #I:#W#F " # 状态栏当前窗口名称格式(#I：序号，#w：窗口名称，#F：间隔符)
set -wg window-status-separator "" # 状态栏窗口名称之间的间隔
set -wg window-status-current-style "bg=red" # 状态栏当前窗口名称的样式
set -wg window-status-last-style "fg=red" # 状态栏最后一个窗口名称的样式

set -g message-style "bg=#202529, fg=#91A8BA" # 指定消息通知的前景、后景色
#+END_SRC
状态栏包含 3 个组件：一个左面板，窗口列表和一个右面板。我们可以改变状态栏里左侧或右侧面板的内容，这需要使用一个文本和变量的组合。表1（状态栏变量）列出了状态栏里可能用到的变量。

表1 - 状态栏变量
| 变量             | 描述                          |
| #H               | 本地主机的主机名              |
| #h               | 本地主机的主机名，没有 domain |
| #F               | 当前窗口的标签                |
| #I               | 当前窗口的索引                |
| #P               | 当前面板的索引                |
| #S               | 当前会话的名称                |
| #T               | 当前窗口的标题                |
| #W               | 当前窗口的名称                |
| ##               | 一个 # 符号                   |
| #(shell-command) | shell 命令的第一行输出        |
| #[attributes]    | 要改变的颜色或属性            |

例如，如果想要在左侧显示当前 tmux 会话的名称，就需要使用 set-option -g status-left 选项，后面跟着 #S 值，就像这样：
#+begin_src bash
set -g status-left "#S"
#+END_SRC
还可以通过设置前景色让它显示地更明显，像这样：
#+begin_src bash
set -g status-left "#[fg=green]#S"
#+END_SRC
可以向状态栏里添加任何想要的属性和条目。为了便于展示，我们修改了左侧的状态栏，让它显示绿色的会话名称，黄色的窗口编号，以及蓝绿色的当前面板。配置如下：
#+begin_src bash
set -g status-left "#[fg=green]#S #[fg=yellow]#I #[fg=cyan]#P"
#+END_SRC
也可以向状态栏里添加任意文字。我们现在添加一些文字，让会话、窗口和面板显示地更突出，像这样：
#+begin_src bash
set -g status-left-length 40
set -g status-left "#[fg=green]Session: #S #[fg=yellow]#I #[fg=cyan]#P"
#+END_SRC
我们设置了 status-left-length 选项因为指定的输出对默认长度来说太长了，所以我们让那个区域更宽一些。

还可以配置右侧的状态栏。现在我们向它添加当前日期和时间：
#+begin_src bash
set -g status-right "#[fg=cyan]%d %b %R"
#+END_SRC
这样配置的日期格式是“13-Jan 13:45”，你可以让它显示任意你想要的格式，可以使用许多编程语言通用的 strftime() 时间格式化机制。

在状态栏里开启 UTF-8 支持是个不错的注意，尤其是如果你特别喜欢使用这些字符。
#+begin_src bash
set -g status-utf8 on
#+END_SRC
还可以更进一步，通过使用 #(shell-command) 变量把 shell 命令加入到状态栏中，在状态栏显示该命令的返回结果。

**** 让状态栏实时更新信息
我们已经把当前时间和一些其它动态信息添加到了状态栏，这时需要告诉 tmux 这些信息的刷新周期。默认配置下，tmux 会每 15 秒刷新一次状态栏。可以通过使用 set-option -g status-interval 命令后面加上刷新周期（以秒为单位，译者注）来指定 tmux 的刷新时间，就像这样：
#+begin_src bash
set -g status-interval 60
#+END_SRC
这样就会让 tmux 每 60 秒刷新一次状态栏。注意，如果你在状态栏里添加了 shell 命令，这些命令也会在每次状态栏刷新时执行一遍，所以要注意不要加载太多资源密集型的脚本。

**** 让窗口列表居中显示
我们还能控制窗口列表显示的位置。默认的，窗口列表是靠左对齐的，通过简单的配置就可以让窗口列表在左右面板之间居中显示：
#+begin_src bash
set -g status-justify centre
#+END_SRC
这样配置就会让窗口列表居中显示。创建新窗口时，窗口列表会相应地变换位置，让整个窗口列表显示在状态栏正中间。

**** 窗口活动通知
同样的，我们希望如果当前会话的其他窗口里有一些事件发生时我们能够注意到这些事件，那么我们就可以快速响应那个窗口。可以通过增加一个可视化的通知（visual notification）实现这个功能，像这样：
#+begin_src bash
setw -g monitor-activity on
set -g visual-activity on
#+END_SRC
现在呢，如果其它窗口里有一些活动，它就会使用蓝绿色的背景色突出显示，就像这里的 webserver 窗口：

#+DOWNLOADED: screenshot @ 2021-12-09 16:02:25
[[file:images/linux笔记/tmux/2021-12-09_16-02-25_screenshot.png]]

*** 参考文章
[[https://www.cnblogs.com/zuoruining/p/11074367.html][Tmux 配置：打造最适合自己的终端复用工具]]
[[http://louiszhai.github.io/2017/09/30/tmux/#%25E8%2587%25AA%25E5%25AE%259A%25E4%25B9%2589%25E7%258A%25B6%25E6%2580%2581%25E6%25A0%258F][Tmux使用手册]]
[[https://www.kancloud.cn/kancloud/tmux/62463][《tmux: Productive Mouse-Free Development》中文翻译]]
** tmux 选项
tmux 的选项有几种类型，如下：
- server options，影响整个 tmux server 。
- session options，影响一个或者所有的 session 。
- window options，影响一个或者所有 window 。
- pane options，影响一个或者所有 pane 。
- user options，tmux 没有使用这个类型的选项，但是保留了这个选项。

session 和 window 的选项由 2 部分组成，一部分是全局的，另一部分每个 session 、window 独有的，全局的叫 global set，独有的叫 session set 和 window set 。若一个选项没有在 session set 或者 window set 里出现，那么会用 global set 里项。pane 的选项和它们很相似，除非 window 的项也被检查时。（最后一句话原文是 Pane options are similar except the window options are also checked，我没深究 window options are also checked 时 pane option 会怎么样，猜测可能是以 window 的 option 项为主）
*** 显示选项
选项可以用 show-options 指令列出。
- -g 标志参数列出 global options 。
- -s 标志参数列出 server options.tmux show -s
- -g -w 列出 global window options 。tmux show -wg
- 单个 option 的值可以用 show-option 指令加上此 option 的名字显示出来。给了 option 的名字时，就不用加 -s、-w 标志参数了。tmux show -g status 列出 status 选项的值。
*** 改变选项
set-option 指令用来设置和取消设置选项。set-option 指令不用指定 -s -w 标志参数，它可以根据 option name 找到 option 。-g 参数是需要的，用来设置 global session 或者 global window 的选项，对于 server 选项它不起作用。
- set -g status off 关闭 status 。
- set -s default-terminal 'tmux-256color' 设置 default-terminal 值。
- -u 标志参数 unset option，取消某个设置会恢复它的默认值。set -gu status
*** 内嵌的 style
内嵌的 style 包含在 #[] 里面。每个内嵌的 style 会改变接下来的文本风格，直到遇到下一个内嵌的 style 或者文本结尾。

例如，在 status-left 里把文本 foreground 改成 red 把 background 改成 blue ，set -g status-left 'default #[fg=red] red #[fg=blue] blue' 。这样设置也需要增加 status-left-length 值，set -g status-left-length 100 。

内嵌的 style 可以使用条件判断。下面设置 status-left 在按下前缀键时 P 用红色显示，否则是默认的 style 。
#+begin_src bash
set -g status-left '#{?client_prefix,#[bg=red],}P#[default] [#{session_name}] '
#+END_SRC

*** set-option [-aFgopqsuUw] [-t target-pane] option value
(alias: set)
Set a pane option with -p, a window option with -w, a server option with -s, otherwise a session option. If the option is not a user option, -w or -s may be unnecessary - tmux will infer the type from the option name, assuming -w for pane options. If -g is given, the global session or window option is set.
-F expands formats in the option value. The -u flag unsets an option, so a session inherits the option from the global options (or with -g, restores a global option to the default). -U unsets an option (like -u) but if the option is a pane option also unsets the option on any panes in the window. value depends on the option and may be a number, a string, or a flag (on, off, or omitted to toggle).

The -o flag prevents setting an option that is already set and the -q flag suppresses errors about unknown or ambiguous options.

With -a, and if the option expects a string or a style, value is appended to the existing setting. For example:
#+begin_src bash
set -g status-left "foo"
set -ag status-left "bar"
#+END_SRC
Will result in ‘foobar’. And:
#+begin_src bash
set -g status-style "bg=red"
set -ag status-style "fg=blue"
#+END_SRC
Will result in a red background and blue foreground. Without -a, the result would be the default background and a blue foreground.
*** show-options [-AgHpqsvw] [-t target-pane] [option]
(alias: show)
Show the pane options (or a single option if option is provided) with -p, the window options with -w, the server options with -s, otherwise the session options. If the option is not a user option, -w or -s may be unnecessary - tmux will infer the type from the option name, assuming -w for pane options. Global session or window options are listed if -g is used. -v shows only the option value, not the name. If -q is set, no error will be returned if option is unset. -H includes hooks (omitted by default). -A includes options inherited from a parent set of options, such options are marked with an asterisk.
*** 参考文章
[[http://man.openbsd.org/cgi-bin/man.cgi/OpenBSD-current/man1/tmux.1?query=tmux%2526sec=1][官方文档]]
** 退出 session, window, pane
退出 window
- C-b & 会出现提示符让确认是否退出 window ，所有的 pane 也同时退出。
- C-b : 和 kill-window 组合使用退出 window 。

退出 pane
- C-b x 退出 active pane 。
- C-b : 和 kill-pane ，用命令退出 pane 。

退出 session
- C-b : 和 kill-session ，退出 session ，window 同时退出，客户端分离。
** 重命名 session 和 window
重命名 session
- 快捷键使用 C-b $ 出现提示符，为依附的 session 重命名。
- 命令使用 C-b : 和 rename-session 。

重命名 window
- 快捷键使用 C-b , 出现提示符，为 current window 重命名。
- 命令使用 C-b : 和 rename-window 。
** 快捷键
tmux 里绑定快捷键使用 bind-key 命令，解除快捷键使用 unbind-key 命令。每个快捷键都属于有名称的表里，默认有 4 张被命名的表。
- root 表，表里的快捷键不需要和前缀键一起使用。
- prefix 表，表里的键需要和前缀键使用。
- copy-mode 表，copy mode 里使用的快捷键，emacs 风格。
- copy-mode-vi 表，copy mode 里使用的快捷键，vi 风格。

所有的快捷键，或者单个表里的快捷键都可以使用 list-keys 来列出。默认展示 bind-key 的一系列键。
- -T 参数指定表名。
    - tmux lsk -Tprefix
- -N 参数列出帮助信息。
    - tmux lsk -Tprefix -N

unbind-key 用来删除一个快捷键，和 bind-key 一样，有 -T 、-n 标志参数。重新设置快捷键动作时，无需删除此快捷键，bind-key 会自动覆盖已有的快捷键。只有在完全删除一个快捷键时才使用 unbind-key 。
** 自动保存tmux会话 关机重启再也不怕
参考文章：https://zhuanlan.zhihu.com/p/146544540
** Tmux不管怎么改配置文件，都不产生变化的解决方法
这个主要是由于Tmux的后台缓存机制造成的。我就犯了个大错误：甚至删了Tmux、重装Tmux、重启电脑，都没达成。
Tmux会有一个叫Tmux-server的东西。只要把它kill，重启tmux就OK了：
#+begin_src bash
tmux kill-server -a
#+END_SRC
** 复制模式
tmux中操作文本，自然离不开复制模式，通常使用复制模式的步骤如下：
- 输入 `+[ 进入复制模式
- 按下 空格键 开始复制，移动光标选择复制区域
- 按下 回车键 复制选中文本并退出复制模式
- 按下 `+] 粘贴文本

查看复制模式默认的快捷键风格：
#+begin_src bash
tmux show-window-options -g mode-keys # mode-keys emacs
#+END_SRC
默认情况下，快捷键为emacs风格。

为了让复制模式更加方便，我们可以将快捷键设置为熟悉的vi风格，如下：
#+begin_src bash
setw -g mode-keys vi # 开启vi风格后，支持vi的C-d、C-u、hjkl等快捷键

set-window-option -g mode-keys vi #可以设置为vi或emacs
#+END_SRC
tmux复制模式的命令表：
| Command                     | emacs(1) | vi(1)  | Description                                                                     |
|-----------------------------+----------+--------+---------------------------------------------------------------------------------|
| begin-selection             | C-Space  | Space  | Start selection                                                                 |
| cancel                      | q        | q      | Exit copy mode                                                                  |
| clear-selection             | C-g      | Escape | Clear selection                                                                 |
| copy-pipe                   |          |        | Copy and pipe to the command in the first argument                              |
| copy-selection-and-cancel   | M-w      | Enter  | Copy the selection and exit copy mode                                           |
| cursor-down                 | Down     | j      | Move the cursor down                                                            |
| cursor-left                 | Left     | h      | Move the cursot left                                                            |
| cursor-right                | Right    | l      | Move the cursor right                                                           |
| cursor-up                   | Up       | k      | Move the cursor up                                                              |
| end-of-line                 | C-e      | $      | Move the cursor to the end of the line                                          |
| history-bottom              | M->      | G      | Move to the bottom of the history                                               |
| history-top                 | M-<      | g      | Move to the top of the history                                                  |
| middle-line                 | M-r      | M      | Move to middle line                                                             |
| next-word-end               | M-f      | e      | Move to the end of the next word                                                |
| page-down                   | PageDown | C-f    | Page down                                                                       |
| page-up                     | PageUp   | C-b    | Page up                                                                         |
| previous-word               | M-b      | b      | Move to the previous word                                                       |
| rectangle-toggle            | R        | v      | Toggle rectangle selection                                                      |
| search-again                | n        | n      | Repeat the last search                                                          |
| search-backward             |          | ?      | Search backwards, the first argument is the search term                         |
| search-backward-incremental | C-r      |        | Search backwards incrementally, usually used with the -i flag to command-prompt |
| search-forward              |          | /      | Search forwards, the first argument is the search term                          |
| search-forward-incremental  | C-s      |        | Search forwards incrementally                                                   |
| search-reverse              | N        | N      | Repeat the last search but reverse the direction                                |
| start-of-line               | C-a      | 0      | Move to the start of the line                                                   |
*** 自定义复制和选择快捷键了快捷键外，复制模式的启用、选择、复制、粘贴等按键也可以向vi风格靠拢。
#+begin_src bash
bind Escape copy-mode # 绑定esc键为进入复制模式
bind -t vi-copy v begin-selection # 绑定v键为开始选择文本
bind -t vi-copy y copy-selection # 绑定y键为复制选中文本
bind p pasteb # 绑定p键为粘贴文本（p键默认用于进入上一个窗口，不建议覆盖）
#+END_SRC
以上，绑定 v、y两键的设置只在tmux v2.4版本以下才有效，对于v2.4及以上的版本，绑定快捷键需要使用 -T 选项，发送指令需要使用 -X 选项，请参考如下设置：
#+begin_src bash
bind -T copy-mode-vi v send-keys -X begin-selection
bind -T copy-mode-vi y send-keys -X copy-selection-and-cancel
#+END_SRC
** 启动shell时自动启动tmux
Bash
对bash用户, 只需要将下面命令添加到自己家目录下的.bashrc, 要注意这句命令需要在alias配置之前.对其它shell的配置也是类似的
#+begin_src bash
~/.bashrc
# If not running interactively, do not do anything
[[ $- != *i* ]] && return
[[ -z "$TMUX" ]] && exec tmux
#+END_SRC
注意: 这些代码确保tmux不会在tmux中启动(tmux嵌套于tmux中). tmux 通过设置环境变量$TMUX 来设置tmux启动所用的socket, 如果$TMUX不存在,或者长度为0那么就可以知道当前没有运行tmux.
下面的配置会尝试只启动一个会话, 当你登录时, 如果之前启动过会话, 那么它会直接attach, 而不是新开一个. 想要新开一个session要么是因为之前没有会话, 要么是你手动启动一个新的会话.
#+begin_src bash
# TMUX
if which tmux >/dev/null 2>&1; then
    #if not inside a tmux session, and if no session is started, start a new session
    test -z "$TMUX" && (tmux attach || tmux new-session)
fi
#+END_SRC
下面的配置实现的功能相似, 但是他会在启动tmux之前先检查一下tmux是否已经安装. 它也会在你登出之前帮你重新连接上未关闭的session, 这样可以让你手动关闭会话并保存相应的工作,避免数据丢失,进程异常中断.
#+begin_src bash
# TMUX
if which tmux >/dev/null 2>&1; then
    # if no session is started, start a new session
    test -z ${TMUX} && tmux

    # when quitting tmux, try to attach
    while test -z ${TMUX}; do
        tmux attach || break
    done
fi
#+END_SRC
另外一种配置, 一样可以实现自动连接已存在的会话,否则会新开一个:
#+begin_src bash
if [[ -z "$TMUX" ]] ;then
    ID="`tmux ls | grep -vm1 attached | cut -d: -f1`" # get the id of a deattached session
    if [[ -z "$ID" ]] ;then # if not available create a new one
        tmux new-session
    else
        tmux attach-session -t "$ID" # if available attach to it
    fi
fi
#+END_SRC
*** 参考文章
[[https://www.cnblogs.com/yangjig/p/10070178.html][启动shell时自动启动tmux]]
** 屏幕比例不协调问题（很多点号）
有时候 tmux 突然中断之后，再次进入时，会发现屏幕被限制在了一个很小的范围内，其他的地方全部变成了点 “.”, 或者“烫”

解决办法：

再次进入时使用  -d 参数：

tmux a -d -t [YOUR TMUX NAME]
*** 参考文章
[[https://blog.csdn.net/CSDN_71560364126/article/details/99821058][tmux 解决屏幕比例不协调问题]]
** 参考文章
[[https://missing.csail.mit.edu/2020/command-line/][Command-line Environment]]
[[http://linuxcommand.org/lc3_adv_termmux.php][Terminal Multiplexers]]
[[https://www.ruanyifeng.com/blog/2019/10/tmux.html][Tmux 使用教程]]
[[http://longed.top/index.php/2020/10/11/tmux-tutorial/#fu_zhi_zhan_tie][走进神奇的 TMUX]]
* tr命令
Linux tr 命令用于转换或删除文件中的字符。

tr 指令从标准输入设备读取数据，经过字符串转译后，将结果输出到标准输出设备。

语法
#+begin_src bash
tr [-cdst][--help][--version][第一字符集][第二字符集]  
tr [OPTION]…SET1[SET2] 
#+END_SRC
参数说明：
- -c, --complement：反选设定字符。也就是符合 SET1 的部份不做处理，不符合的剩余部份才进行转换
- -d, --delete：删除指令字符
- -s, --squeeze-repeats：缩减连续重复的字符成指定的单个字符
- -t, --truncate-set1：削减 SET1 指定范围，使之与 SET2 设定长度相等
- --help：显示程序用法信息
- --version：显示程序本身的版本信息

字符集合的范围：
- \NNN 八进制值的字符 NNN (1 to 3 为八进制值的字符)
- \\ 反斜杠
- \a Ctrl-G 铃声
- \b Ctrl-H 退格符
- \f Ctrl-L 走行换页
- \n Ctrl-J 新行
- \r Ctrl-M 回车
- \t Ctrl-I tab键
- \v Ctrl-X 水平制表符
- CHAR1-CHAR2 ：字符范围从 CHAR1 到 CHAR2 的指定，范围的指定以 ASCII 码的次序为基础，只能由小到大，不能由大到小。
- [CHAR*] ：这是 SET2 专用的设定，功能是重复指定的字符到与 SET1 相同长度为止
- [CHAR*REPEAT] ：这也是 SET2 专用的设定，功能是重复指定的字符到设定的 REPEAT 次数为止(REPEAT 的数字采 8 进位制计算，以 0 为开始)
- [:alnum:] ：所有字母字符与数字
- [:alpha:] ：所有字母字符
- [:blank:] ：所有水平空格
- [:cntrl:] ：所有控制字符
- [:digit:] ：所有数字
- [:graph:] ：所有可打印的字符(不包含空格符)
- [:lower:] ：所有小写字母
- [:print:] ：所有可打印的字符(包含空格符)
- [:punct:] ：所有标点字符
- [:space:] ：所有水平与垂直空格符
- [:upper:] ：所有大写字母
- [:xdigit:] ：所有 16 进位制的数字
- [=CHAR=] ：所有符合指定的字符(等号里的 CHAR，代表你可自订的字符)
** 实例
将文件testfile中的小写字母全部转换成大写字母，此时，可使用如下命令：
#+begin_src bash
cat testfile |tr a-z A-Z 
#+END_SRC
testfile文件中的内容如下：
#+begin_src bash
$ cat testfile         #testfile原来的内容  
Linux networks are becoming more and more common, 
but scurity is often an overlooked  
issue. Unfortunately, in today’s environment all networks 
are potential hacker targets,  
fro0m tp-secret military research networks to small home LANs.  
Linux Network Securty focuses on securing Linux in a 
networked environment, where the  
security of the entire network needs to be considered
rather than just isolated machines.  
It uses a mix of theory and practicl techniques to 
teach administrators how to install and  
use security applications, as well as how the 
applcations work and why they are necesary. 
#+END_SRC
使用 tr 命令大小写转换后，得到如下输出结果：
#+begin_src bash
$ cat testfile | tr a-z A-Z #转换后的输出  
LINUX NETWORKS ARE BECOMING MORE AND MORE COMMON, BUT SCURITY IS OFTEN AN OVERLOOKED  
ISSUE. UNFORTUNATELY, IN TODAY’S ENVIRONMENT ALL NETWORKS ARE POTENTIAL HACKER TARGETS,  
FROM TP-SECRET MILITARY RESEARCH NETWORKS TO SMALL HOME LANS.  
LINUX NETWORK SECURTY FOCUSES ON SECURING LINUX IN A NETWORKED ENVIRONMENT, WHERE THE  
SECURITY OF THE ENTIRE NETWORK NEEDS TO BE CONSIDERED RATHER THAN JUST ISOLATED MACHINES.  
IT USES A MIX OF THEORY AND PRACTICL TECHNIQUES TO TEACH ADMINISTRATORS HOW TO INSTALL AND  
USE SECURITY APPLICATIONS, AS WELL AS HOW THE APPLCATIONS WORK AND WHY THEY ARE NECESARY. 
#+END_SRC
大小写转换，也可以通过[:lower][:upper]参数来实现。例如使用如下命令：
#+begin_src bash
capt testfile |tr [:lower:] [:upper:] 
#+END_SRC
输出结果如下：
#+begin_src bash
$ cat testfile | tr [:lower:] [:upper:] #转换后的输出  
LINUX NETWORKS ARE BECOMING MORE AND MORE COMMON, BUT SCURITY IS OFTEN AN OVERLOOKED  
ISSUE. UNFORTUNATELY, IN TODAY’S ENVIRONMENT ALL NETWORKS ARE POTENTIAL HACKER TARGETS,  
FROM TP-SECRET MILITARY RESEARCH NETWORKS TO SMALL HOME LANS.  
LINUX NETWORK SECURTY FOCUSES ON SECURING LINUX IN A NETWORKED ENVIRONMENT, WHERE THE  
SECURITY OF THE ENTIRE NETWORK NEEDS TO BE CONSIDERED RATHER THAN JUST ISOLATED MACHINES.  
IT USES A MIX OF THEORY AND PRACTICL TECHNIQUES TO TEACH ADMINISTRATORS HOW TO INSTALL AND  
USE SECURITY APPLICATIONS, AS WELL AS HOW THE APPLCATIONS WORK AND WHY THEY ARE NECESARY. 
#+END_SRC
** 参考文章
[[https://www.runoob.com/linux/linux-comm-tr.html][Linux tr命令 - 菜鸟教程]]
* ubuntu-18.04 设置开机启动python脚本
关于xxx.service文件的写法，可参考这篇文章：[[https://blog.csdn.net/superjunenaruto/article/details/105890739][ubuntu 18.04 python脚本 开机自启]]
** 配置开机启动
ubuntu-18.04没有rc.local，不能通过rc.local来设置开机启动脚本，可以自己建一个。

*** 建立rc-local.service文件
#+begin_src bash
sudo vi /etc/systemd/system/rc-local.service
#+END_SRC
然后将下面内容复制进去
#+begin_src bash
[Unit]
Description=/etc/rc.local Compatibility
ConditionPathExists=/etc/rc.local
 
[Service]
Type=forking
ExecStart=/etc/rc.local start
TimeoutSec=0
StandardOutput=tty
RemainAfterExit=yes
SysVStartPriority=99
 
[Install]
WantedBy=multi-user.target
#+END_SRC
 
*** 创建文件rc.local
sudo vi /etc/rc.local

然后将下面内容复制进去
#+begin_src bash
#!/bin/sh -e
#
# rc.local
#
# This script is executed at the end of each multiuser runlevel.
# Make sure that the script will "exit 0" on success or any other
# value on error.
#
# In order to enable or disable this script just change the execution
# bits.
#
# By default this script does nothing.
#后台启动python工程，结果重定向到log.txt
/usr/bin/nohup /usr/bin/python start_person.py > log.txt 2>&1 &
exit 0
#+END_SRC

*** 给rc.local加上权限

sudo chmod +x /etc/rc.local

重启看看日志就可以.
** 解决python启动无法导入第三方模块问题
看日志发现导入模块失败，但是本地直接执行脚本没有任何问题

如 ImportError: No module named torch

分析

1. 在本地进入python交互环境，查看python搜索路径
#+begin_src bash
nvidia@nvidia-desktop:~/data/projects/dt_product$ python
Python 2.7.15+ (default, Nov 27 2018, 23:36:35)
[GCC 7.3.0] on linux2
Type "help", "copyright", "credits" or "license" for more information.
>>> import sys
>>> sys.path
['', '/home/nvidia/.local/lib/python2.7/site-packages', '/home/nvidia/data/projects/dt_product', '/usr/lib/python2.7', '/usr/lib/python2.7/plat-aarch64-linux-gnu', '/usr/lib/python2.7/lib-tk', '/usr/lib/python2.7/lib-old', '/usr/lib/python2.7/lib-dynload', '/usr/local/lib/python2.7/dist-packages', '/usr/lib/python2.7/dist-packages', '/usr/lib/python2.7/dist-packages/gtk-2.0']
>>>
#+END_SRC
2. 新建一个python脚本设置为开机启动，在此脚本中获取python搜索路径
#+begin_src python
!test.py

import sys
print sys.path
#+END_SRC
重新启动环境查看启动重定向得日志 log.txt ：
#+BEGIN_EXAMPLE
['/home/nvidia/data/projects/dt_product', '/usr/lib/python2.7', '/usr/lib/python2.7/plat-aarch64-linux-gnu', '/usr/lib/python2.7/lib-tk', '/usr/lib/python2.7/lib-old', '/usr/lib/python2.7/lib-dynload', '/usr/local/lib/python2.7/dist-packages', '/usr/lib/python2.7/dist-packages', '/usr/lib/python2.7/dist-packages/gtk-2.0']
#+END_EXAMPLE

解决方法：

一种是安装时注意下路径，一种是把这个路径加到环境变量中。

加入环境变量网上搜有几种，但是试了都不行，因为启动python项目时改环境变量未生效，所以最简单得就是在启动python项目前加入该变量。

打开刚才创建得启动python项目得文件，启动前加入环境变量

~sudo vi /etc/rc.local~

#+begin_src bash
#!/bin/sh -e
#
# rc.local
#
# This script is executed at the end of each multiuser runlevel.
# Make sure that the script will "exit 0" on success or any other
# value on error.
#
# In order to enable or disable this script just change the execution
# bits.
#
# By default this script does nothing.

#加入环境变量
export PYTHONPATH=/home/nvidia/.local/lib/python2.7/site-packages:$PYTHONPATH

#后台启动python工程，结果重定向到log.txt
/usr/bin/nohup /usr/bin/python start_person.py > log.txt 2>&1 &
exit 0
#+END_SRC

* ubuntu 设置root默认密码（初始密码）
ubuntu安装好后，root初始密码（默认密码）不知道，需要设置。

1、先用安装时候的用户登录进入系统

2、输入：sudo passwd  按回车

3、输入新密码，重复输入密码，最后提示passwd：password updated sucessfully

此时已完成root密码的设置

4、输入：su root

切换用户到root
* update-alternatives
update-alternatives可以方便实现管理不同版本的程序。

命令格式：update-alternatives [<选项> ...] <命令>

主要参数：
#+begin_example
Commands:
  --install <link> <name> <path> <priority>
    [--slave <link> <name> <path>] ...
                           在系统中加入一组替换项.
  --remove <name> <path>   从 <名称> 替换组中去除 <路径> 项.
  --remove-all <name>      从替换系统中删除 <名称> 替换组.
  --auto <name>            将 <名称> 的主链接切换到自动模式.
  --display <name>         显示关于 <名称> 替换组的信息.
  --query <name>           machine parseable version of --display <name>.
  --list <name>            列出 <名称> 替换组中所有的可用替换项.
  --get-selections         list master alternative names and their status.
  --set-selections         read alternative status from standard input.
  --config <name>          列出 <名称> 替换组中的可选项，并就使用其中
                                 哪一个，征询用户的意见.
  --set <name> <path>      将 <路径> 设置为 <名称> 的替换项.
  --all                    对所有可选项一一调用 --config 命令.

<link> 是指向 /etc/alternatives/<名称> 的符号链接>.
  (e.g. /usr/bin/pager)
<name> 是该链接替换组的主控名.
  (e.g. pager)
<path> 是替换项目标文件的位置.
  (e.g. /usr/bin/less)
<priority> 是一个整数，在自动模式下，这个数字越高的选项，其优先级也就越高.

Options:
  --altdir <directory>     指定不同的可选项目录.
  --admindir <directory>   指定不同的管理目录.
  --log <file>             设置log文件.
  --force                  就算没有通过自检，也强制执行操作。
  --skip-auto              在自动模式中跳过设置正确候选项的提示
                           (只与 --config 有关)
  --verbose                启用详细输出。
  --quiet                  安静模式，输出尽可能少的信息.
  --help                   显示本帮助信息.
  --version                显示版本信息.
#+end_example
** display选项
display选项用来显示一个命令链接的所有可选命令，即查看一个命令链接组的所有信息，包括链接的模式(自动还是手动)、链接priority值、所有可 用的链接命令等等。
** install选项
install选项的功能就是增加一组新的系统命令链接符。
使用语法为：update-alternatives --install <link> <name> <path> <priority> [--slave link name path]...。
其中link为系统中功能相同软件的公共链接目录，比如/usr/bin/java(需绝对目录);
name为命令链接符名称,如java；path为你所要使用新命令、新软件的所在目录；
priority为优先级，当命令链接已存在时，需高于当前值，因为当alternative为自动模式时,系统默认启用priority高的链接；
–slave为从alternative。
** config选项
config选项用来显示和修改实际指向的候选命令，为在现有的命令链接选择一个作为系统默认。
** remove选项
remove选项的功能是删除一个命令的link值，其附带的slave也将一起删除。
使用语法为:update-alternatives --remove name path。
其中name与path与install中的一致，如果所删除的链接组中还有其他链接的话，系统将会自动从其他中选择一个priority高的链接作为默认为链接。
比如：update-alternatives –remove java /usr/lib/jvm/jre1.6.0_20/bin/java
** 用法
安装:
#+begin_src bash
sudo update-alternatives --install link name path priority [ --slave slink sname spath]
#+END_SRC
选项注释:
- link是在/usr/bin/,/usr/local/bin/等默认PATH搜索目录
- name是在/etc/alternatives目录中的链接名
- path是真正的可执行程序的位置,可以在任何位置
- priority是优先级

打印名字的相关链接:
#+begin_src bash
sudo update-alternatives --display name
#+END_SRC
配置名字的相关链接:
#+begin_src bash
sudo update-alternatives --config name
#+END_SRC
移除名字的相关链接:
#+begin_src bash
sudo update-alternatives --remove name path
#+END_SRC
因为优先级的存在,可以为同一个name设置多个path,当删除一个path后,默认连接到slave上.

移除所有名字相关的链接:
#+begin_src bash
sudo update-alternatives --remove-all name
#+END_SRC
** 参考文章
[[https://blog.csdn.net/JasonDing1354/article/details/50470109][【Linux】使用update-alternatives命令进行版本的切换]]
[[https://zhuanlan.zhihu.com/p/20797436][Linux命令之update-alternativse]]
* UNIX-文件IO库
** 文件描述符
对于内核而言，所有打开的文件都通过文件描述符引用。文件描述符是一个非负整数。
当打开一个现有文件或创建一个新文件时，内核向进程返回一个文件描述符。
当读、写一个文件时，使用open或creat返回的文件描述符标识该文件，将其作为参数传送给read或write。
按照惯例，UNIX系统shell把文件描述符0与进程的标准输入关联，文件描述符1与标准输出关联，文件描述符2与标准错误关联。

在符合POSIX.1的应用程序中，幻数0、1、2虽然已被标准化，但应当把它们替换成符号常量STDIN_FILENO、STDOUT_FILENO和STDERR_FILENO以提高可读性。
这些常量都在头文件<unistd.h>中定义。

文件描述符的变化范围是0～OPEN_MAX-1。早期的UNIX系统实现采用的上限值是19（允许每个进程最多打开20个文件），但现在很多系统将其上限值增加至63。
** open和openat
调用open或openat函数可以打开或创建一个文件。

我们将最后一个参数写为...，ISO C用这种方法表明余下的参数的数量及其类型是可变的。
#+begin_src c++
#include <fcntl.h>
int open(const char *path, int oflag,... /* mode_t mode */);
int openat(int fd, const char *path, int oflag, ... /* mode_t mode */ );
#+END_SRC

*** 参数
path参数是要打开或创建文件的名字。

oflag参数可用来说明此函数的多个选项。用下列一个或多个常量进行“或”运算构成oflag参数（这些常量在头文件<fcntl.h>中定义）。
- O_RDONLY 只读打开。
- O_WRONLY 只写打开。
- O_RDWR 读、写打开。大多数实现将O_RDONLY定义为0，O_WRONLY定义为1，O_RDWR定义为2，以与早期的程序兼容。
- O_EXEC 只执行打开。
- O_SEARCH 只搜索打开（应用于目录）。O_SEARCH常量的目的在于在目录打开时验证它的搜索权限。对目录的文件描述符的后续操作就不需要再次检查对该目录的搜索权限。

在这5个常量中必须指定一个且只能指定一个。
下列常量则是可选的。
- O_APPEND 每次写时都追加到文件的尾端。
- O_CLOEXEC 把FD_CLOEXEC常量设置为文件描述符标志。
- O_CREAT 若此文件不存在则创建它。使用此选项时，open函数需同时说明第3个参数mode（openat函数需说明第4个参数mode），用mode指定该新文件的访问权限位。
- O_DIRECTORY 如果path引用的不是目录，则出错。
- O_EXCL 如果同时指定了 O_CREAT，而文件已经存在，则出错。用此可以测试一个文件是否存在，如果不存在，则创建此文件，这使测试和创建两者成为一个原子操作。
- O_NOCTTY 如果path引用的是终端设备，则不将该设备分配作为此进程的控制终端。
- O_NOFOLLOW 如果path引用的是一个符号链接，则出错。
- O_NONBLOCK 如果path引用的是一个FIFO、一个块特殊文件或一个字符特殊文件，则此选项为文件的本次打开操作和后续的I/O操作设置非阻塞方式。较早的System V引入了O_NDELAY（不延迟）标志，它与O_NONBLOCK（不阻塞）选项类似，但它的读操作返回值具有二义性。如果不能从管道、FIFO或设备读得数据，则不延迟选项使read返回0，这与表示已读到文件尾端的返回值0冲突。基于SVR4的系统仍支持这种语义的不延迟选项，但是新的应用程序应当使用不阻塞选项代替之。
- O_SYNC 使每次write等待物理I/O操作完成，包括由该write操作引起的文件属性更新所需的I/O。3.14节将使用此选项。
- O_TRUNC 如果此文件存在，而且为只写或读-写成功打开，则将其长度截断为0。
- O_TTY_INIT 如果打开一个还未打开的终端设备，设置非标准 termios 参数值，使其符合Single UNIX Specification。第18章将讨论终端I/O的termios结构。
- O_DSYNC 使每次write要等待物理I/O操作完成，但是如果该写操作并不影响读取刚写入的数据，则不需等待文件属性被更新。O_DSYNC 和 O_SYNC 标志有微妙的区别。仅当文件属性需要更新以反映文件数据变化（例如，更新文件大小以反映文件中包含了更多的数据）时，O_DSYNC标志才影响文件属性。而设置O_SYNC标志后，数据和属性总是同步更新。当文件用O_DSYN标志打开，在重写其现有的部分内容时，文件时间属性不会同步更新。与此相反，如果文件是用O_SYNC标志打开，那么对该文件的每一次write都将在write返回前更新文件时间，这与是否改写现有字节或追加写文件无关。
- O_RSYNC使每一个以文件描述符作为参数进行的read操作等待，直至所有对文件同一部分挂起的写操作都完成。

**** O_DSYNC
O_DSYNC告诉内核，当向文件写入数据的时候，只有当数据写到了磁盘时，写入操作才算完成（write才返回成功）。
和O_DSYNC同类的文件标志，还有O_SYNC,O_RSYNC，O_DIRECT。
O_SYNC比O_DSYNC更严格，不仅要求数据已经写到了磁盘，而且对应的数据文件的属性（例如文件长度等）也需要更新完成才算write操作成功。可见O_SYNC较之O_DSYNC要多做一些操作。
O_RSYNC表示文件读取时，该文件的OS cache必须已经全部flush到磁盘了【附录3】 ；
如果使用O_DIRECT打开文件，则读/写操作都会跳过OS cache，直接在device（disk）上读/写。因为没有了OS cache，所以会O_DIRECT降低文件的顺序读写的效率。
*** 返回值
两函数的返回值：若成功，返回文件描述符；若出错，返回−1

由open和openat函数返回的文件描述符一定是最小的未用描述符数值。
这一点被某些应用程序用来在标准输入、标准输出或标准错误上打开新的文件。
例如，一个应用程序可以先关闭标准输出（通常是文件描述符1），然后打开另一个文件，此时返回文件描述符1.
可以使用dup2函数来避免这种错误操作.
*** open和openat的区别
fd参数把open和openat函数区分开，共有3种可能性。
（1）path参数指定的是绝对路径名，在这种情况下，fd参数被忽略，openat函数就相当于open函数。
（2）path参数指定的是相对路径名，fd参数指出了相对路径名在文件系统中的开始地址。fd参数是通过打开相对路径名所在的目录来获取。
（3）path参数指定了相对路径名，fd参数具有特殊值AT_FDCWD。在这种情况下，路径名在当前工作目录中获取，openat函数在操作上与open函数类似。

openat函数是POSIX.1最新版本中新增的一类函数之一，希望解决两个问题。
第一，让线程可以使用相对路径名打开目录中的文件，而不再只能打开当前工作目录。同一进程中的所有线程共享相同的当前工作目录，因此很难让同一进程的多个不同线程在同一时间工作在不同的目录中。
第二，可以避免time-of-check-to-time-of-use（TOCTTOU）错误。

TOCTTOU错误的基本思想是：如果有两个基于文件的函数调用，其中第二个调用依赖于第一个调用的结果，那么程序是脆弱的。
因为两个调用并不是原子操作，在两个函数调用之间文件可能改变了，这样也就造成了第一个调用的结果就不再有效，使得程序最终的结果是错误的。
文件系统命名空间中的TOCTTOU错误通常处理的就是那些颠覆文件系统权限的小把戏，这些小把戏通过骗取特权程序降低特权文件的权限控制或者让特权文件打开一个安全漏洞等方式进行。
*** 文件名和路径名截断
如果NAME_MAX是14，而我们却试图在当前目录中创建一个文件名包含15个字符的新文件，此时会发生什么呢？
按照传统，早期的System V版本（如SVR2）允许这种使用方法，但总是将文件名截断为 14 个字符，而且不给出任何信息，而 BSD 类的系统则返回出错状态，并将 errno 设置为ENAMETOOLONG。
无声无息地截断文件名会引起问题，而且它不仅仅影响到创建新文件。
如果NAME_MAX是14，而存在一个文件名恰好就是14个字符的文件，那么以路径名作为其参数的任一函数（open、stat等）都无法确定该文件的原始名是什么。其原因是这些函数无法判断该文件名是否被截断过。

在POSIX.1中，常量_POSIX_NO_TRUNC决定是要截断过长的文件名或路径名，还是返回一个出错。
根据文件系统的类型，此值可以变化。我们可以用fpathconf或pathconf来查询目录具体支持何种行为，到底是截断过长的文件名还是返回出错。

是否返回一个出错值在很大程度上是历史形成的。
例如。基于SVR4的系统对传统的System V文件系统（S5）并不出错，但是它对BSD风格的文件系统（UFS）则出错。
作为另一个例子，Solaris对UFS返回出错，对与DOS兼容的文件系统PCFS则不返回出错，其原因是DOS会无声无息地截断不匹配8.3格式的文件名。
BSD类系统和Linux总是会返回出错。

若_POSIX_NO_TRUNC有效，则在整个路径名超过PATH_MAX，或路径名中的任一文件名超过NAME_MAX时，出错返回，并将errno设置为ENAMETOOLONG。
大多数的现代文件系统支持文件名的最大长度可以为255。因为文件名通常比这个限制要短，因此对大多数应用程序来说这个限制还未出现什么问题。

** creat
creat函数创建一个新文件。
#+begin_src c++
#include <fcntl.h>
int creat(const char *path, mode_t mode);
#+END_SRC
注意，此函数等效于：
open(path, O_WRONLY｜O_CREAT｜O_TRUNC, mode);


在早期的UNIX系统版本中，open的第二个参数只能是0、1或2。无法打开一个尚未存在的文件，因此需要另一个系统调用creat以创建新文件。
现在，open函数提供了选项O_CREAT和O_TRUNC，于是也就不再需要单独的creat函数。

creat的一个不足之处是它以只写方式打开所创建的文件。
在提供open的新版本之前，如果要创建一个临时文件，并要先写该文件，然后又读该文件，则必须先调用creat、close，然后再调用open。
现在则可用下列方式调用open实现：
open(path, O_RDWR｜O_CREAT｜O_TRUNC, mode);
*** 返回值
返回值：若成功，返回为只写打开的文件描述符；若出错，返回−1
** close
可调用close函数关闭一个打开文件。
#+begin_src c++
#include <unistd.h>
int close (int fd)；
#+END_SRC
返回值：若成功，返回0；若出错，返回−1

关闭一个文件时还会释放该进程加在该文件上的所有记录锁。
当一个进程终止时，内核自动关闭它所有的打开文件。很多程序都利用了这一功能而不显式地用close关闭打开文件。
** lseek
#+begin_src c++
#include <unistd.h>
off_t lseek(int fd, off_t offset, int whence);
#+END_SRC
可以调用lseek显式地为一个打开文件设置偏移量。
*** 当前文件偏移量
每个打开文件都有一个与其相关联的“当前文件偏移量”（current file offset）。
它通常是一个非负整数，用以度量从文件开始处计算的字节数。
通常，读、写操作都从当前文件偏移量处开始，并使偏移量增加所读写的字节数。
按系统默认的情况，当打开一个文件时，除非指定O_APPEND选项，否则该偏移量被设置为0。

通常，文件的当前偏移量应当是一个非负整数，但是，某些设备也可能允许负的偏移量。但对于普通文件，其偏移量必须是非负值。
因为偏移量可能是负值，所以在比较 lseek 的返回值时应当谨慎，不要测试它是否小于0，而要测试它是否等于−1。

在Intel x86处理器上运行的FreeBSD的设备/dev/kmem支持负的偏移量。

因为偏移量（off_t）是带符号数据类型，所以文件的最大长度会减少一半。例如，若off_t是32位整型，则文件最大长度是2^31－1个字节。

lseek仅将当前的文件偏移量记录在内核中，它并不引起任何I/O操作。然后，该偏移量用于下一个读或写操作。

文件偏移量可以大于文件的当前长度，在这种情况下，对该文件的下一次写将加长该文件，并在文件中构成一个空洞，这一点是允许的。
位于文件中但没有写过的字节都被读为0。

文件中的空洞并不要求在磁盘上占用存储区。
具体处理方式与文件系统的实现有关，当定位到超出文件尾端之后写时，对于新写的数据需要分配磁盘块，但是对于原文件尾端和新开始写位置之间的部分则不需要分配磁盘块。

因为lseek使用的偏移量是用off_t类型表示的，所以允许具体实现根据各自特定的平台自行选择大小合适的数据类型。
现今大多数平台提供两组接口以处理文件偏移量。一组使用 32位文件偏移量，另一组则使用64位文件偏移量。

应用程序可以将符号常量_FILE_OFFSET_BITS设置为64，以支持64位偏移量。
这样就将off_t定义更改为64位带符号整型。将_FILE_OFFSET_BITS符号常量设置为32以支持32位偏移量。
下图总结了不同平台上，当应用程序没有定义_FILE_OFFSET_BITS时，off_t数据类型的字节数以及_FILE_OFFSET_BITS被定义成32或64时，off_t数据类型的字节数。

#+DOWNLOADED: screenshot @ 2023-06-29 21:55:17
[[file:images/linux笔记/文件IO库/2023-06-29_21-55-17_screenshot.png]]


*** 返回值
返回值：若成功，返回新的文件偏移量；若出错，返回为−1
*** 参数
对参数offset的解释与参数whence的值有关。
- 若whence是SEEK_SET，则将该文件的偏移量设置为距文件开始处offset个字节。
- 若whence是SEEK_CUR，则将该文件的偏移量设置为其当前值加offset，offset可为正或负。
- 若whence是SEEK_END，则将该文件的偏移量设置为文件长度加offset，offset可正可负。

若lseek成功执行，则返回新的文件偏移量，为此可以用下列方式确定打开文件的当前偏移量：
#+begin_src c++
off_t currpos;
currpos = lseek(fd, 0, SEEK_CUR);
#+END_SRC
这种方法也可用来确定所涉及的文件是否可以设置偏移量。
如果文件描述符指向的是一个管道、FIFO或网络套接字，则lseek返回−1，并将errno设置为ESPIPE。

3个符号常量SEEK_SET、SEEK_CUR和SEEK_END是在System V中引入的。
在System V之前，whence被指定为 0（绝对偏移量）、1（相对于当前位置的偏移量）或 2（相对文件尾端的偏移量）。很多软件仍然把这些数字直接写在代码里。

在lseek中的字符l表示长整型。在引入off_t数据类型之前，offset参数和返回值是长整型的。
lseek是在UNIX V7中引入的，当时C语言中增加了长整型（在UNIX V6中，用函数seek和tell提供类似功能）。
*** 实例
**** 测试对其标准输入能否设置偏移量。

#+begin_src c++
#include "apue.h"
int main(void){
  if(lseek(STDIN_FILENO,0,SEEK_CUR)==-1)
    printf("cannot seek\n");
  else
    printf("seek OK\n");
  exit(0);
}
#+END_SRC
如果用交互方式调用此程序，则可得
#+begin_src bash
$ ./a.out < /etc/passwd
seek OK
$ cat < /etc/passwd| ./a.out
cannot seek
$ ./a.out < /var/spool/cron/FIFO
cannot seek
#+END_SRC
**** 创建一个具有空洞的文件。
#+begin_src c++
#include "apue.h"
#include <fcntl.h>
char buf1[] = "abcdefghij";
char buf2[] = "ABCDEFGHIJ";
int main (void){
  int fd;
  if( (fd = creat ("file.hole",FILE_MODE) ) < 0)
    err_sys ( "creat error" ) ;
  if( write ( fd, buf1, 10)!= 10)
    err_sys ( "buf1 write error" ) ;
  /* offset now = 10 */
  if (lseek (fd，16384,SEEK_SET)== -1)
    err_sys ( "lseek error" ) ;
  /* offset now = 16384*/
  if (write (fd,buf2,10)!= 10)
    err_sys ( "buf2 write error" );
  /*offset now = 16394*/
  exit (O) ;
}
#+END_SRC
运行该程序得到：
#+begin_src bash
$ ./a.out
$ ls -l file.hol 检查其大小
-rw-r--r-- 1 sar 16394 Nov 25 01:01 file.hole
$ od -c file.hole 观察实际内容
0000000 a b c d e f g h i j \0 \0 \0 \0 \0 \0

0000020 \0 \0 \0 \0 \0 \0 \0 \0 \0 \0 \0 \0 \0 \0 \0 \0

0040000 A B C D E F G H I J

0040012
#+END_SRC
使用od命令观察该文件的实际内容。
命令行中的-c标志表示以字符方式打印文件内容。
从中可以看到，文件中间的30个未写入字节都被读成0。每一行开始的一个7位数是以八进制形式表示的字节偏移量。

为了证明在该文件中确实有一个空洞，将刚创建的文件与同样长度但无空洞的文件进行比较：
#+begin_src bash
$ ls -ls file.hole file.nohole 比较长度
8 -rw-r--r-- 1 sar 16394 Nov 25 01:01 file.hole
20 -rw-r--r-- 1 sar 16394 Nov 25 01:03 file.nohole
#+END_SRC
虽然两个文件的长度相同，但无空洞的文件占用了20个磁盘块，而具有空洞的文件只占用8个磁盘块。

** read
调用read函数从打开文件中读数据。
#+begin_src c++
#include <unistd.h>

ssize_t read(int fd, void *buf, size_t nbytes);
#+END_SRC

有多种情况可使实际读到的字节数少于要求读的字节数：
- 读普通文件时，在读到要求字节数之前已到达了文件尾端。例如，若在到达文件尾端之前有30个字节，而要求读100个字节，则read返回30。下一次再调用read时，它将返回0（文件尾端）。
- 当从终端设备读时，通常一次最多读一行。
- 当从网络读时，网络中的缓冲机制可能造成返回值小于所要求读的字节数。
- 当从管道或FIFO读时，如若管道包含的字节少于所需的数量，那么read将只返回实际可用的字节数。
- 当从某些面向记录的设备（如磁带）读时，一次最多返回一个记录。
- 当一信号造成中断，而已经读了部分数据量时。读操作从文件的当前偏移量处开始，在成功返回之前，该偏移量将增加实际读到的字节数。

POSIX.1从几个方面对read函数的原型做了更改。经典的原型定义是：
#+begin_src c++
int read(int fd, char *buf, unsigned nbytes);
#+END_SRC
首先，为了与ISO C一致，第2个参数由char *改为void *。在ISO C中，类型void *用于表示通用指针。
其次，返回值必须是一个带符号整型（ssize_t），以保证能够返回正整数字节数、0（表示文件尾端）或−1（出错）。
最后，第3个参数在历史上是一个无符号整型，这允许一个16位的实现一次读或写的数据可以多达 65 534 个字节。在 1990 POSIX.1 标准中，引入了新的基本系统数据类型ssize_t以提供带符号的返回值，不带符号的size_t则用于第3个参数。
*** 返回值
返回值：读到的字节数，若已到文件尾，返回0；若出错，返回−1

如read成功，则返回读到的字节数。如已到达文件的尾端，则返回0。
** write
调用write函数向打开文件写数据。
#+begin_src c++
#include <unistd.h>

ssize_t write(int fd, const void *buf, size_t nbytes);
#+END_SRC

对于普通文件，写操作从文件的当前偏移量处开始。如果在打开该文件时，指定了O_APPEND选项，则在每次写操作之前，将文件偏移量设置在文件的当前结尾处。
在一次成功写之后，该文件偏移量增加实际写的字节数。
*** 返回值
返回值：若成功，返回已写的字节数；若出错，返回−1

其返回值通常与参数nbytes的值相同，否则表示出错。write出错的一个常见原因是磁盘已写满，或者超过了一个给定进程的文件长度限制.

** 缓冲区大小对I/O效率的影响
缓冲区长度大于等于磁盘块长度时,I/O效率最高.

下面该程序将标准输入复制到标准输出
#+begin_src c++
#include "apue.h"

#define BUFFSIZE4096

int main (void){
  int n;
  char buf [BUFFSIZE];
  while ((n = read (STDIN_FILENO,buf，BUFFSIZE))>o )
    if( write (STDOUT_FILENO,buf, n) != n)
      err_sys ( "write error" );
  if (n < 0)
    err_sys ( "read error" ) ;
  exit (0);
}
#+END_SRC
程序读文件，其标准输出被重新定向到/dev/null 上。
此测试所用的文件系统是Linux ext4文件系统，其磁盘块长度为4096字节（磁盘块长度由st_blksize表示）。
这也证明了下图中系统 CPU 时间的几个最小值差不多出现在BUFFSIZE为4096及以后的位置，继续增加缓冲区长度对此时间几乎没有影响。

#+DOWNLOADED: screenshot @ 2023-06-29 22:09:09
[[file:images/linux笔记/文件IO库/2023-06-29_22-09-09_screenshot.png]]

大多数文件系统为改善性能都采用某种预读（read ahead）技术。当检测到正进行顺序读取时，系统就试图读入比应用所要求的更多数据，并假想应用很快就会读这些数据。
预读的效果可以从图3-6中看出，缓冲区长度从32字节处开始的时钟时间与拥有较大缓冲区长度时的时钟时间(系统调用时间,该时间小说明没有磁盘I/O)几乎一样。

** 文件共享
UNIX系统内核使用3种数据结构表示打开文件，它们之间的关系决定了在文件共享方面一个进程对另一个进程可能产生的影响。

(1)每个进程在进程表中都有一个记录项，记录项中包含一张打开文件描述符表，可将其视为一个矢量，每个描述符占用一项。与每个文件描述符相关联的是：
a．文件描述符标志（close_on_exec)
b．指向一个文件表项的指针。

(2)内核为所有打开文件维持一张文件表。每个文件表项包含：
a．文件状态标志（读、写、添写、同步和非阻塞等）；
b．当前文件偏移量；
c．指向该文件v节点表项的指针。

(3)每个打开文件（或设备）都有一个 v 节点（v-node）结构。
v 节点包含了文件类型和对此文件进行各种操作函数的指针。
对于大多数文件，v节点还包含了该文件的i节点（i-node，索引节点）。
这些信息是在打开文件时从磁盘上读入内存的，所以，文件的所有相关信息都是随时可用的。
例如，i 节点包含了文件的所有者、文件长度、指向文件实际数据块在磁盘上所在位置的指针等。

Linux没有使用v节点，而是使用了通用i节点结构。虽然两种实现有所不同，但在概念上， v节点与i节点是一样的。两者都指向文件系统特有的i节点结构。

我们忽略了那些不影响讨论的实现细节。
例如，打开文件描述符表可存放在用户空间（作为一个独立的对应于每个进程的结构，可以换出），而非进程表中。
这些表也可以用多种方式实现，不必一定是数组，例如，可将它们实现为结构的链表。如果不考虑实现细节的话，通用概念是相同的。

下图显示了一个进程对应的3张表之间的关系。
该进程有两个不同的打开文件：一个文件从标准输入打开（文件描述符0），另一个从标准输出打开（文件描述符为1）。

#+DOWNLOADED: screenshot @ 2023-06-29 23:06:31
[[file:images/linux笔记/文件IO库/2023-06-29_23-06-31_screenshot.png]]

如果两个独立进程各自打开了同一文件，则有图3-8中所示的关系。
#+DOWNLOADED: screenshot @ 2023-06-29 23:09:45
[[file:images/linux笔记/文件IO库/2023-06-29_23-09-45_screenshot.png]]
我们假定第一个进程在文件描述符3上打开该文件，而另一个进程在文件描述符4上打开该文件。
打开该文件的每个进程都获得各自的一个文件表项，但对一个给定的文件只有一个v节点表项。
之所以每个进程都获得自己的文件表项，是因为这可以使每个进程都有它自己的对该文件的当前偏移量。

给出了这些数据结构后，现在对IO操作进一步说明。

- 在完成每个write后，在文件表项中的当前文件偏移量即增加所写入的字节数。如果这导致当前文件偏移量超出了当前文件长度，则将i节点表项中的当前文件长度设置为当前文件偏移量（也就是该文件加长了）。
- 如果用O_APPEND标志打开一个文件，则相应标志也被设置到文件表项的文件状态标志中。每次对这种具有追加写标志的文件执行写操作时，文件表项中的当前文件偏移量首先会被设置为i节点表项中的文件长度。这就使得每次写入的数据都追加到文件的当前尾端处。
- lseek函数只修改文件表项中的当前文件偏移量，不进行任何I/O操作。若一个文件用lseek定位到文件当前的尾端，则文件表项中的当前文件偏移量被设置为i节点表项中的当前文件长度（注意，这与用O_APPEND标志打开文件是不同的，详见3.11节）。

可能有多个文件描述符项指向同一文件表项(dup命令)。在fork后也发生同样的情况，此时父进程、子进程各自的每一个打开文件描述符共享同一个文件表项.

注意，文件描述符标志和文件状态标志在作用范围方面的区别，前者只用于一个进程的一个描述符，而后者则应用于指向该给定文件表项的任何进程中的所有描述符。

前面所述的一切对于多个进程读取同一文件都能正确工作。每个进程都有它自己的文件表项，其中也有它自己的当前文件偏移量。
但是，当多个进程写同一文件时，则可能产生预想不到的结果。为了说明如何避免这种情况，需要理解原子操作的概念。

** 原子操作
*** 追加到一个文件
假定有两个独立的进程A和B都对同一文件进行追加写操作。
每个进程都已打开了该文件，但未使用O_APPEND标志。每个进程都有它自己的文件表项，但是共享一个v节点表项。
假定进程A调用了lseek，它将进程A的该文件当前偏移量设置为1500字节（当前文件尾端处）。
然后内核切换进程，进程B运行。进程B执行lseek，也将其对该文件的当前偏移量设置为1500字节（当前文件尾端处）。
然后B调用write，它将B的该文件当前文件偏移量增加至1 600。因为该文件的长度已经增加了，所以内核将v节点中的当前文件长度更新为1600。
然后，内核又进行进程切换，使进程A恢复运行。当A调用write时，就从其当前文件偏移量（1 500）处开始将数据写入到文件。
这样也就覆盖了进程B刚才写入到该文件中的数据。

问题出在逻辑操作“先定位到文件尾端，然后写”，它使用了两个分开的函数调用。
解决问题的方法是使这两个操作对于其他进程而言成为一个原子操作。
任何要求多于一个函数调用的操作都不是原子操作，因为在两个函数调用之间，内核有可能会临时挂起进程（正如我们前面所假定的）。

UNIX系统为这样的操作提供了一种原子操作方法，即在打开文件时设置O_APPEND标志。
这样做使得内核在每次写操作之前，都将进程的当前偏移量设置到该文件的尾端处，于是在每次写之前就不再需要调用lseek。
*** 函数pread和pwrite
pread/pwrite文档可知，这两个函数不会改变文件句柄的偏移量且线程安全，所以多线程环境下推荐使用，

Single UNIX Specification包括了XSI扩展，该扩展允许原子性地定位并执行I/O。
pread和pwrite就是这种扩展。
#+begin_src c++
#include <unistd.h>

ssize_t pread(int fd, void *buf, size_t nbytes, off_t offset);

#+END_SRC

返回值：读到的字节数，若已到文件尾，返回0；若出错，返回−1
#+begin_src c++
ssize_t pwrite(int fd, const void *buf, size_t nbytes, off_t offset);
#+END_SRC

返回值：若成功，返回已写的字节数；若出错，返回−1

调用pread相当于调用lseek后调用read，但是pread又与这种顺序调用有下列重要区别。
- 调用pread时，无法中断其定位和读操作。
- 不更新当前文件偏移量。

调用pwrite相当于调用lseek后调用write，但也与它们有类似的区别。
*** 创建一个文件
当open函数同时指定O_CREAT和O_EXCL两个选项，而该文件又已经存在时，open 将失败。
在这个过程中,检查文件是否存在和创建文件这两个操作是作为一个原子操作执行的。
如果没有这样一个原子操作，那么可能会编写下列程序段：
#+begin_src c++
if ((fd = open(pathname, O_WRONLY)) <0){
    if (errno == ENOENT) {
        if ((fd = creat(path, mode)) < 0)
            err_sys("creat error");
        } else{
            err_sys("open error");
        }
   }
#+END_SRC
如果在open和creat之间，另一个进程创建了该文件，就会出现问题。若在这两个函数调用之间，另一个进程创建了该文件，并且写入了一些数据，然后，原先进程执行这段程序中的creat，这时，刚由另一进程写入的数据就会被擦去。如若将这两者合并在一个原子操作中，这种问题也就不会出现。

一般而言，原子操作（atomic operation）指的是由多步组成的一个操作。
如果该操作原子地执行，则要么执行完所有步骤，要么一步也不执行，不可能只执行所有步骤的一个子集。
** dup和dup2
下面两个函数都可用来复制一个现有的文件描述符。
#+begin_src c++
#include <unistd.h>

int dup(int fd);

int dup2(int fd, int fd2);
#+END_SRC

两函数的返回值：若成功，返回新的文件描述符；若出错，返回−1

由dup返回的新文件描述符一定是当前可用文件描述符中的最小数值。

对于dup2，可以用fd2参数指定新描述符的值。
如果fd等于fd2,则直接返回fd2.
如果fd2已经打开,则先将fd2关闭.
如果fd2未使用,则fd2的FD_CLOEXEC文件描述符标志就被清除，这样fd2在进程调用exec时是打开状态。.

这些函数返回的新文件描述符与参数fd共享同一个文件表项，如图3-9所示。
#+DOWNLOADED: screenshot @ 2023-06-30 19:51:05
[[file:images/linux笔记/文件IO库/2023-06-30_19-51-05_screenshot.png]]
在此图中，我们假定进程启动时执行了：
newfd = dup(1);

当此函数开始执行时，假定下一个可用的描述符是3（这是非常可能的，因为0，1和2都由shell打开）。
因为两个描述符指向同一文件表项，所以它们共享同一文件状态标志（读、写、追加等）以及同一当前文件偏移量。

每个文件描述符都有它自己的一套文件描述符标志。新描述符的执行时关闭（close-on-exec）标志总是由dup函数清除。

复制一个描述符的另一种方法是使用 fcntl 函数，实际上，调用
#+begin_src c++
dup(fd);
#+END_SRC
等效于
#+begin_src c++
fcntl (fd, F_DUPFD, 0);
#+END_SRC

而调用
#+begin_src c++
dup2(fd, fd2)；
#+END_SRC
等效于
#+begin_src c++
close(fd2);
fcntl(fd, F_DUPFD, fd2);
#+END_SRC

在后一种情况下，dup2并不完全等同于close加上fcntl。它们之间的区别具体如下。
（1）dup2 是一个原子操作，而 close 和 fcntl 包括两个函数调用。有可能在 close 和fcntl之间调用了信号捕获函数，它可能修改文件描述符。如果不同的线程改变了文件描述符的话也会出现相同的问题。

（2）dup2和fcntl有一些不同的errno。
dup2系统调用起源于V7，然后传播至所有BSD版本。
而复制文件描述符的fcntl方法则首先由系统III使用，然后由System V继续采用。
SVR3.2选用了dup2函数，4.2BSD则选用了fcntl函数及F_DUPFD功能。
POSIX.1要求兼有dup2及fcntl的F_DUPFD两种功能。
** sync、fsync和fdatasync
传统的UNIX系统实现在内核中设有缓冲区高速缓存或页高速缓存，大多数磁盘I/O都通过缓冲区进行。
当我们向文件写入数据时，内核通常先将数据复制到缓冲区中，然后排入队列，晚些时候再写入磁盘。
这种方式被称为延迟写（delayed write）。

通常，当内核需要重用缓冲区来存放其他磁盘块数据时，它会把所有延迟写数据块写入磁盘。
为了保证磁盘上实际文件系统与缓冲区中内容的一致性，UNIX 系统提供了 sync、fsync 和fdatasync三个函数。
#+begin_src c++
#include<unistd.h>

int fsync(int fd);
int fdatasync(int fd);
void sync(void);
#+END_SRC

返回值：若成功，返回0；若出错，返回−1

sync只是将所有修改过的块缓冲区排入写队列，然后就返回，它并不等待实际写磁盘操作结束。

通常，称为update的系统守护进程周期性地调用（一般每隔30秒）sync函数。这就保证了定期冲洗（flush）内核的块缓冲区。命令sync(1)也调用sync函数。

fsync函数只对由文件描述符fd指定的一个文件起作用，并且等待写磁盘操作结束才返回。fsync可用于数据库这样的应用程序，这种应用程序需要确保修改过的块立即写到磁盘上。

fdatasync函数类似于fsync，但它只影响文件的数据部分。而除数据外，fsync还会同步更新文件的属性。

FreeBSD 8.0不支持fdatasync。
** fcntl
fcntl函数可以改变已经打开文件的属性。
#+begin_src c++
#include<fcntl.h>

int fcntl(int fd, int cmd, ... /* int arg */);
#+END_SRC

*** 命令
fcntl函数有以下5种功能。
1. 复制一个已有的描述符（cmd=F_DUPFD或F_DUPFD_CLOEXEC）。
2. 获取/设置文件描述符标志（cmd=F_GETFD或F_SETFD）。
3. 获取/设置文件状态标志（cmd=F_GETFL或F_SETFL）。
4. 获取/设置异步I/O所有权（cmd=F_GETOWN或F_SETOWN）。
5. 获取/设置记录锁（cmd=F_GETLK、F_SETLK或F_SETLKW）。

**** F_DUPFD
F_DUPFD 复制文件描述符fd。新文件描述符作为函数值返回。它是尚未打开的各描述符中大于或等于第3个参数值（取为整型值）中各值的最小值。新描述符与 fd共享同一文件表项（与dup2类似）。但是，新描述符有它自己的一套文件描述符标志，其 FD_CLOEXEC 文件描述符标志被清除（这表示该描述符在exec时仍保持有效）。

**** F_DUPFD_CLOEXEC
F_DUPFD_CLOEXEC 复制文件描述符，设置与新描述符关联的FD_CLOEXEC文件描述符标志的值，返回新文件描述符。

**** F_GETFD
F_GETFD 对应于fd的文件描述符标志作为函数值返回。当前只定义了一个文件描述符标志FD_CLOEXEC。

**** F_SETFD
F_SETFD 对于fd设置文件描述符标志。新标志值按第3个参数（取为整型值）设置。

要知道，很多现有的与文件描述符标志有关的程序并不使用常量FD_CLOEXEC，而是将此标志设置为0（系统默认，在exec时不关闭）或1（在exec时关闭）。

**** F_GETFL
F_GETFL 对应于fd的文件状态标志作为函数值返回。我们在说明open函数时，已描述了文件状态标志。它们列在图3-10中。
  #+DOWNLOADED: screenshot @ 2023-07-02 23:13:17
  [[file:images/linux笔记/文件IO库/2023-07-02_23-13-17_screenshot.png]]

5个访问方式标志（O_RDONLY、O_WRONLY、O_RDWR、O_EXEC以及O_SEARCH）并不各占1位（由于历史原因，前3个标志的值分别是0、1和2。
这5个值互斥，一个文件的访问方式只能取这5个值之一）。因此首先必须用屏蔽字O_ACCMODE取得访问方式位，然后将结果与这5个值中的每一个相比较。

**** F_SETFL
LF_SETFL 将文件状态标志设置为第3个参数的值（取为整型值）。可以更改的几个标志是：O_APPEND、O_NONBLOCK、O_SYNC、O_DSYNC、O_RSYNC、O_FSYNC和O_ASYNC。
**** F_GETOWN
F_GETOWN 获取当前接收SIGIO和SIGURG信号的进程ID或进程组ID。14.5.2节将论述这两种异步I/O信号。
**** F_SETOWN
F_SETOWN 设置接收SIGIO和SIGURG信号的进程ID或进程组ID。正的arg指定一个进程ID，负的arg表示等于arg绝对值的一个进程组ID。
*** 返回值
返回值：若成功，则依赖于cmd（见下）；若出错，返回−1

fcntl的返回值与命令有关。如果出错，所有命令都返回－1，如果成功则返回某个其他值。
下列4个命令有特定返回值：F_DUPFD、F_GETFD、F_GETFL以及F_GETOWN。第1个命令返回新的文件描述符，第2个和第3个命令返回相应的标志，最后一个命令返回一个正的进程ID或负的进程组ID。
*** 实例
**** 对于指定的描述符打印文件标志
程序的第1个参数指定文件描述符，并对该描述符打印其所选择的文件标志说明。
#+begin_src c++
#include "apue.h"
#include <fcntl.h>
int main(int argc, char *argv[])
{
  int val;
  if (argc != 2)
    err_quit("usage: a.out <descriptor#>");
  if ((val = fcntl(atoi(argv[1]), F_GETFL, 0)) < 0)
    err_sys("fcntl error for fd %d", atoi(argv[1]));
  switch (val & o_ACCMODE)
  {
  case o_RDONLY:
    printf("read only");
    break;
  case o_WRONLY:
    printf("write only");
    break;
  case o_RDWR:
    printf("read write");
    break;
  default:
    err_dump("unknown access mode");
  }
  if (val & O_APPEND)
    printf(",append");
  if (val & o_NONBLOCK)
    printf(", nonblocking");
  if (val & o_sYNC)
    printf(", synchronous writes");
#if !defined(_PoSIx_c_SoURCE) && defined(0_FSYNC) && (o_FSYNC != o_SYNC)
  if (val & o_FSYNC)
    printf(",synchronous writes");
#endif
  putchar(' ln ');
  exit(0);
}
#+END_SRC
注意，我们使用了功能测试宏_POSIX_C_SOURCE，并且条件编译了POSIX.1中没有定义的文件访问标志。

下面显示了从bash（Bourne-again shell）调用该程序时的几种情况。当使用不同shell时，结果会有些不同。
#+begin_src bash
$./a.out 0 < /dev/tty
read only
$./a.out 1 > temp.foo
$ cat temp.foo
write only
$./a.out 2 2>>temp.foo
write only, append
$./a.out 5 5<>temp.foo
read write

子句5<>temp.foo表示在文件描述符5上打开文件temp.foo以供读、写。

#+END_SRC
**** 对于一个文件描述符设置多个文件状态标志
在修改文件描述符标志或文件状态标志时必须谨慎，先要获得现在的标志值，然后按照期望修改它，最后设置新标志值。不能只是执行F_SETFD或F_SETFL命令，这样会关闭以前设置的标志位。
#+begin_src c++
#include "apue.h"
#include < fcntl.h>
void set_fl(int fd，int flags) /* flags are file status flags to turn on */
{
  int val;
  if ((val = fcntl(fd, F_GETFL, 0)) < 0)
    err_sys("fcntl F_GETFL error");
  val |= flags;
  / *turn on flags * /
  if (fcntl(fd, F_SETFL, val) < 0)
    err_sys("fcntl F_SETFL error");
}
#+END_SRC
如果将中间的一条语句改为：
#+begin_src c++
val &= ～flags; /* turn flags off */
#+END_SRC

就构成另一个函数，我们称为 clr_fl。此语句使当前文件状态标志值val与flags的反码进行逻辑“与”运算。

如果在上面的程序的开始处加上下面一行以调用set_fl，则开启了同步写标志。
#+begin_src c++
set_fl(STDOUT_FILENO, O_SYNC);
#+END_SRC

这就使每次write都要等待，直至数据已写到磁盘上再返回。在UNIX系统中，通常write只是将数据排入队列，而实际的写磁盘操作则可能在以后的某个时刻进行。而数据库系统则需要使用 O_SYNC，这样一来，当它从 write 返回时就知道数据已确实写到了磁盘上，以免在系统异常时产生数据丢失。

程序运行时，设置O_SYNC标志会增加系统时间和时钟时间。为了测试这一点，先运行前面提到过的程序将标准输入复制到标准输出
，它从一个磁盘文件中将492.6 MB的数据复制到另一个文件。
然后，对比设置了O_SYNC标志的程序，使其完成同样的工作。在使用ext4文件系统的Linux上执行上述操作，得到的结果如图3-13所示。
#+begin_src c++
#include "apue.h"

#define BUFFSIZE4096

int main (void){
  int n;
  char buf [BUFFSIZE];
  while ((n = read (STDIN_FILENO,buf，BUFFSIZE))>o )
    if( write (STDOUT_FILENO,buf, n) != n)
      err_sys ( "write error" );
  if (n < 0)
    err_sys ( "read error" ) ;
  exit (0);
}
#+END_SRC

#+DOWNLOADED: screenshot @ 2023-07-03 21:53:59
[[file:images/linux笔记/文件IO库/2023-07-03_21-53-59_screenshot.png]]
图3-13中的6行都是在BUFFSIZE为4 096字节时测量的。图3-6中的结果所测量的情况是读一个磁盘文件，然后写到/dev/null，所以没有磁盘输出。图3-13中的第2行对应于读一个磁盘文件，然后写到另一个磁盘文件中。这就是为什么图3-13中第1行与第2行有差别的原因。在写磁盘文件时，系统时间增加了，其原因是内核需要从进程中复制数据，并将数据排入队列以便由磁盘驱动器将其写到磁盘上。当写至磁盘文件时，我们期望时钟时间也会增加。

当支持同步写时，系统时间和时钟时间应当会显著增加。但从第3行可见，同步写所用的系统时间并不比延迟写所用的时间增加很多。这意味着要么Linux操作系统对延迟写和同步写操作的工作量相同（这其实是不太可能的），要么 O_SYNC 标志并没有起到期望的作用。在这种情况下，Linux操作系统并不允许我们用fcntl设置O_SYNC标志，而是显示失败但没有返回出错（但如果在文件打开时能指定该标志，我们还是应该遵重这个标志的）。

最后 3 行中的时钟时间反映了所有写操作写入磁盘时需要的附加等待时间。同步写入文件之后，我们希望对 fsync 的调用并不会产生效果。这种情况理应在图 3-13 中的最后一行中呈现，但既然 O_SYNC 标志并没有起到预期的作用，所以最后一行和第 5 行的表现几乎相同。

图3-14显示了在采用HFS文件系统的Mac OS X 10.6.8上运行同样的测试得到的计时结果。该计时结果与我们的期望相符：同步写比延迟写所消耗的时间增加了很多，而且在同步写后再调用函数fsync并不产生测量结果上的显著差别。还要注意的是，在延迟写后增加一个fsync函数调用，测量结果的差别也不大。其可能原因是，在向某个文件写入新数据时，操作系统已经将以前写入的数据都冲洗到了磁盘上，所以在调用函数fsync时只需要做很少的工作。

#+DOWNLOADED: screenshot @ 2023-07-03 22:11:58
[[file:images/linux笔记/文件IO库/2023-07-03_22-11-58_screenshot.png]]
比较fsync和fdatasync，两者都更新文件内容，用了O_SYNC标志，每次写入文件时都更新文件内容。每一种调用的性能依赖很多因素，包括底层的操作系统实现、磁盘驱动器的速度以及文件系统的类型。

在本例中，我们看到了fcntl的必要性。我们的程序在一个描述符（标准输出）上进行操作，但是根本不知道由shell打开的相应文件的文件名。因为这是shell打开的，因此不能在打开时按我们的要求设置O_SYNC标志。使用fcntl，我们只需要知道打开文件的描述符，就可以修改描述符的属性。在讲解非阻塞管道时还会用到fcntl，因为对于管道，我们所知的只有其描述符。
*** ioctl
ioctl函数一直是I/O操作的杂物箱。不能用本章中其他函数表示的I/O操作通常都能用ioctl表示。终端I/O是使用ioctl最多的地方.
#+begin_src c++
#include <unistd.h>　　/* System V */

#include <sys/ioctl.h> /* BSD and Linux */

int ioctl(int fd, int request, ...);
#+END_SRC

返回值：若出错，返回−1；若成功，返回其他值

ioctl函数是Single UNIX Specification标准的一个扩展部分，以便处理STREAMS设备[Rago 1993]，但是，在SUSv4中已被移至弃用状态。UNIX系统实现用它进行很多杂项设备操作。有些实现甚至将它扩展到用于普通文件。

我们所示的函数原型对应于POSIX.1，FreeBSD 8.0和Mac OS X 10.6.8将第2个参数声明为unsigned long。因为第2个参数总是头文件中一个#defined的名字，所以这种细节并没有什么影响。

对于ISO C原型，它用省略号表示其余参数。但是，通常只有另外一个参数，它常常是指向一个变量或结构的指针。

在此原型中，我们表示的只是ioctl函数本身所要求的头文件。通常，还要求另外的设备专用头文件。例如，除POSIX.1所说明的基本操作之外，终端I/O的ioctl命令都需要头文件<termios.h>。

每个设备驱动程序可以定义它自己专用的一组 ioctl 命令，系统则为不同种类的设备提供通用的ioctl命令。图3-15中总结了FreeBSD支持的通用ioctl命令的一些类别。
#+DOWNLOADED: screenshot @ 2023-07-03 22:21:42
[[file:images/linux笔记/文件IO库/2023-07-03_22-21-42_screenshot.png]]
磁带操作使我们可以在磁带上写一个文件结束标志、倒带、越过指定个数的文件或记录等，用本章中的其他函数（read、write、lseek 等）都难于表示这些操作，所以，对这些设备进行操作最容易的方法就是使用ioctl。
*** /dev/fd
较新的系统都提供名为/dev/fd 的目录，其目录项是名为 0、1、2 等的文件。打开文件/dev/fd/n等效于复制描述符n（假定描述符n是打开的）。

/dev/fd这一功能是由Tom Duff开发的，它首先出现在Research UNIX系统的第8版中，本书说明的所有4种系统（FreeBSD 8.0、Linux 3.2.0、Mac OS X 10.6.8和Solaris 10）都支持这一功能。它不是POSIX.1的组成部分。

在下列函数调用中：

fd = open("/dev/fd/0", mode);

大多数系统忽略它所指定的 mode，而另外一些系统则要求 mode 必须是所引用的文件（在这里是标准输入）初始打开时所使用的打开模式的一个子集。

因为上面的打开等效于

fd = dup(0);

所以描述符0和fd共享同一文件表项。例如，若描述符0先前被打开为只读，那么我们也只能对fd进行读操作。即使系统忽略打开模式，而且下列调用是成功的：

fd = open("/dev/fd/0", O_RDWR);

我们仍然不能对fd进行写操作。

Linux实现中的/dev/fd是个例外。它把文件描述符映射成指向底层物理文件的符号链接。例如，当打开/dev/fd/0时，事实上正在打开与标准输入关联的文件，因此返回的新文件描述符的模式与/dev/fd文件描述符的模式其实并不相关。

我们也可以用/dev/fd作为路径名参数调用creat，这与调用open时用O_CREAT作为第2个参数作用相同。例如，若一个程序调用creat，并且路径名参数是/dev/fd/1，那么该程序仍能工作。

注意，在Linux上这么做必须非常小心。因为Linux实现使用指向实际文件的符号链接，在/dev/fd文件上使用creat会导致底层文件被截断。

某些系统提供路径名/dev/stdin、/dev/stdout 和/dev/stderr，这些等效于/dev/fd/0、/dev/fd/1和/dev/fd/2。

/dev/fd文件主要由shell使用，它允许使用路径名作为调用参数的程序，能用处理其他路径名的相同方式处理标准输入和输出。例如，cat(1)命令对其命令行参数采取了一种特殊处理，它将单独的一个字符“-”解释为标准输入。例如：

filter file2 | cat file1 - file3 | lpr

首先cat读file1，接着读其标准输入（也就是filter file2命令的输出），然后读file3，如果支持/dev/fd，则可以删除cat对“-”的特殊处理，于是我们就可键入下列命令行：

filter file2 | cat file1 /dev/fd/0 file3 | lpr

作为命令行参数的“-”特指标准输入或标准输出，这已由很多程序采用。但是这会带来一些问题，例如，如果用“-”指定第一个文件，那么看来就像指定了命令行的一个选项。/dev/fd则提高了文件名参数的一致性，也更加清晰。
* UNIX-文件和目录
** stat、fstat、fstatat和lstat
#+begin_src c++
#include <sys/stat.h>

int stat(const char *restrict pathname, struct stat *restrict buf);

int fstat(int fd, struct stat *buf);

int lstat(const char *restrict pathname, struct stat *restrict buf);

int fstatat(int fd, const char *restrict pathname, struct stat *restrict buf, int flag);

#+END_SRC

所有4个函数的返回值：若成功；返回0；若出错，返回-1

一旦给出pathname，stat函数将返回与此命名文件有关的信息结构。
fstat函数获得已在描述符fd上打开文件的有关信息。
lstat函数类似于stat，但是当命名的文件是一个符号链接时，lstat返回该符号链接的有关信息，而不是由该符号链接引用的文件的信息。
fstatat函数为一个相对于当前打开目录（由fd参数指向）的路径名返回文件统计信息。flag参数控制着是否跟随着一个符号链接。当AT_SYMLINK_NOFOLLOW标志被设置时，fstatat不会跟随符号链接，而是返回符号链接本身的信息。否则，在默认情况下，返回的是符号链接所指向的实际文件的信息。如果fd参数的值是AT_FDCWD，并且pathname参数是一个相对路径名， fstatat会计算相对于当前目录的pathname参数。如果pathname是一个绝对路径，fd参数就会被忽略。这两种情况下，根据flag的取值，fstatat的作用就跟stat或lstat一样

第2个参数buf是一个指针，它指向一个我们必须提供的结构。函数来填充由buf指向的结构。结构的实际定义可能随具体实现有所不同，但其基本形式是：
#+begin_src c++
struct stat {
  mode_t st_mode;/* file type & mode (permissions) */
  ino_t st_ino;/* i-node number (serial number) */
  dev_t st_dev;/* device number (file system) */
  dev_t st_rdev; /* device number for special files */
  nlink_t st_nlink;/* number of links */
  uid_t st_uid; /* user ID of owner */
  gid_t st_gid; /* group ID of owner */
  off_t st_size; /* size in bytes, for regular files */
  struct timespec st_atime;/* time of last access */
  struct timespec st_mtime;/* time of last modification */
  struct timespec st_ctime;/* time of last file status change */
  blksize_t st_blksize;/* best I/O block size */
  blkcnt_t st_blocks; /* number of disk blocks allocated */
};
#+END_SRC

POSIX.1未要求st_rdev、st_blksize和st_blocks字段。Single UNIX Specification XSI扩展定义了这些字段。

timespec结构类型按照秒和纳秒定义了时间，至少包括下面两个字段：
#+begin_src c++
time_t tv_sec;
long tv_nsec;
#+END_SRC

在2008年版以前的标准中，时间字段定义成st_atime、st_mtime以及st_ctime，它们都是time_t类型的（以秒来表示）。timespec结构提供了更高精度的时间戳。为了保持兼容性，旧的名字可以定义成tv_sec成员。例如，st_atime可以定义成st_atim.tv_sec。

注意，stat结构中的大多数成员都是基本系统数据类型（见2.8节）。我们将说明此结构的每个成员以了解文件属性。

使用 stat 函数最多的地方可能就是 ls -l 命令，用其可以获得有关一个文件的所有信息。
** 文件类型
至此我们已经介绍了两种不同的文件类型：普通文件和目录。UNIX 系统的大多数文件是普通文件或目录，但是也有另外一些文件类型。文件类型包括如下几种。

（1）普通文件（regular file）。这是最常用的文件类型，这种文件包含了某种形式的数据。至于这种数据是文本还是二进制数据，对于UNIX内核而言并无区别。对普通文件内容的解释由处理该文件的应用程序进行。
一个值得注意的例外是二进制可执行文件。为了执行程序，内核必须理解其格式。所有二进制可执行文件都遵循一种标准化的格式，这种格式使内核能够确定程序文本和数据的加载位置。

（2）目录文件（directory file）。这种文件包含了其他文件的名字以及指向与这些文件有关信息的指针。对一个目录文件具有读权限的任一进程都可以读该目录的内容，但只有内核可以直接写目录文件。进程必须使用本章介绍的函数才能更改目录。

（3）块特殊文件（block special file）。这种类型的文件提供对设备（如磁盘）带缓冲的访问，每次访问以固定长度为单位进行。
注意，FreeBSD不再支持块特殊文件。对设备的所有访问需要通过字符特殊文件进行。

（4）字符特殊文件（character special file）。这种类型的文件提供对设备不带缓冲的访问，每次访问长度可变。系统中的所有设备要么是字符特殊文件，要么是块特殊文件。

（5）FIFO。这种类型的文件用于进程间通信，有时也称为命名管道（named pipe）。

（6）套接字（socket）。这种类型的文件用于进程间的网络通信。套接字也可用于在一台宿主机上进程之间的非网络通信。第16章将用套接字进行进程间的通信。

（7）符号链接（symbolic link）。这种类型的文件指向另一个文件。

文件类型信息包含在stat结构的st_mode成员中。可以用图4-1中的宏确定文件类型。这些宏的参数都是stat结构中的st_mode成员。
#+DOWNLOADED: screenshot @ 2023-07-03 23:09:18
[[file:images/linux笔记/UNIX-文件和目录/2023-07-03_23-09-18_screenshot.png]]
POSIX.1允许实现将进程间通信（IPC）对象（如消息队列和信号量等）说明为文件。
图4-2 中的宏可用来从 stat 结构中确定 IPC 对象的类型。这些宏与图 4-1 中的不同，它们的参数并非st_mode，而是指向stat结构的指针。

#+DOWNLOADED: screenshot @ 2023-07-03 23:10:35
[[file:images/linux笔记/UNIX-文件和目录/2023-07-03_23-10-35_screenshot.png]]
*** 实例
图4-3程序取其命令行参数，然后针对每一个命令行参数打印其文件类型。
#+begin_src c++
#include "apue.h"
int main(int argc, char *argv[])
{
  int i;
  struct stat buf;
  char *ptr;
  for (i = 1; i < argc; i++)
  {
    printf("%s: ", argv[i]);
    if (lstat(argv[i], &buf) < 0)
    {
      err_ret("lstat error");
      continue;
    }
    if (S_ISREG(buf.st_mode))
      ptr = "regular";
    else if (S_ISDIR(buf.st_mode))
      ptr = "directory";
    else if (S_ISCHR(buf.st_mode))
      ptr = "character special";
    else if (S_ISBLK(buf.st_mode))
      ptr = "block special";
    else if (S_ISFIFO(buf.st_mode))
      ptr = "fifo";
    else if (S_ISLNK(buf.st_mode))
      ptr = "symbolic link";
    else if (S_IssOcK(buf.st_mode))
      ptr = "socket";
    else
      ptr = "** unknown mode * * ";
    printf("%s\n", ptr);
  }
  exit(0);
}
#+END_SRC
图4-3程序的示例输出是：
#+begin_src bash
$ ./a.out /etc/passwd /etc /dev/log /dev/tty /var/lib/oprofile/opd_pipe /dev/sr0 /dev/cdrom
/etc/passwd: regular
/etc: directory
/dev/log: socket
/dev/tty: character special
/var/lib/oprofile/opd_pipe: fifo
/dev/sr0: block special
/dev/cdrom: symbolic link
#+END_SRC

我们特地使用了lstat函数而不是stat函数以便检测符号链接。如若使用stat函数，则不会观察到符号链接。

早期的UNIX版本并不提供S_ISxxx宏，于是就需要将st_mode与屏蔽字S_IFMT进行逻辑“与”运算，然后与名为S_IFxxx的常量相比较。大多数系统在文件<sys/stat.h>中定义了此屏蔽字和相关的常量。如若查看此文件，则可找到S_ISDIR宏定义为：
#+begin_src c++
#define S_ISDIR (mode) (((mode) & S_IFMT) == S_IFDIR)
#+END_SRC

我们说过，普通文件是最主要的文件类型.

图4-4显示了在一个单用户工作站Linux系统中的统计值和百分比。这些数据是由4.22节中的程序得到的。

#+DOWNLOADED: screenshot @ 2023-07-03 23:15:02
[[file:images/linux笔记/UNIX-文件和目录/2023-07-03_23-15-02_screenshot.png]]
** 设置用户ID和设置组ID
与一个进程相关联的ID有6个或更多，如图4-5所示。
#+DOWNLOADED: screenshot @ 2023-07-03 23:15:22
[[file:images/linux笔记/UNIX-文件和目录/2023-07-03_23-15-22_screenshot.png]]
实际用户ID和实际组ID 标识我们究竟是谁。这两个字段在登录时取自口令文件中的登录项,也就是登录用户的uid和gid。通常，在一个登录会话期间这些值并不改变，但是超级用户进程有方法改变它们.

有效用户ID、有效组ID以及附属组ID决定了我们的文件访问权限。

保存的设置用户ID和保存的设置组ID在执行一个程序时包含了有效用户ID和有效组ID的副本。

在POSIX.1 2001年版中，要求这些保存的ID。在早期POSIX版本中，它们是可选的。一个应用程序在编译时可测试常量_POSIX_SAVED_IDS，或在运行时以参数_SC_SAVED_IDS调用函数sysconf，以判断此实现是否支持这一功能。

通常，有效用户ID等于实际用户ID，有效组ID等于实际组ID。

每个文件有一个所有者和组所有者，所有者由stat结构中的st_uid指定，组所有者则由st_gid指定。

当执行一个程序文件时，进程的有效用户ID通常就是实际用户ID，有效组ID通常是实际组ID。但是可以在文件模式字（st_mode）中设置一个特殊标志，其含义是“当执行此文件时，将进程的有效用户ID设置为文件所有者的用户ID（st_uid）”。与此相类似，在文件模式字中可以设置另一位，它将执行此文件的进程的有效组ID设置为文件的组所有者ID（st_gid）。在文件模式字中的这两位被称为设置用户ID（set-user-ID）位和设置组ID（set-group-ID）位。
当设置-用户-ID（SUID）位设置，则有效用户ID等于程序文件的所有者的uid，而不是实际用户ID；同样，如果设置了设置-用户组-ID（SGID）位，则有效用户组ID等于程序文件所有者的gid，而不是实际用户组ID。

例如，若文件所有者是超级用户，而且设置了该文件的设置用户 ID 位，那么当该程序文件由一个进程执行时，该进程具有超级用户权限。不管执行此文件的进程的实际用户 ID 是什么，都会是这样。例如，UNIX 系统程序passwd(1)允许任一用户改变其口令，该程序是一个设置用户 ID 程序。因为该程序应能将用户的新口令写入口令文件中（一般是/etc/passwd 或/etc/shadow），而只有超级用户才具有对该文件的写权限，所以需要使用设置用户 ID 功能。因为运行设置用户ID 程序的进程通常会得到额外的权限，所以编写这种程序时要特别谨慎。

再回到stat函数，设置用户ID位及设置组ID位都包含在文件的st_mode值中。这两位可分别用常量S_ISUID和S_ISGID测试。
** 文件访问权限
st_mode值也包含了对文件的访问权限位。当提及文件时，指的是前面所提到的任何类型的文件。所有文件类型（目录、字符特别文件等）都有访问权限（access permission）。很多人认为只有普通文件有访问权限，这是一种误解。

每个文件有9个访问权限位，可将它们分成3类，见图4-6。

#+DOWNLOADED: screenshot @ 2023-07-04 22:23:38
[[file:images/linux笔记/UNIX-文件和目录/2023-07-04_22-23-38_screenshot.png]]
在图4-6前3行中，术语用户指的是文件所有者（owner）。
chmod(1)命令用于修改这9个权限位。该命令允许我们用u表示用户（所有者），用g表示组，用o表示其他。

图4-6中的3类访问权限（即读、写及执行）以各种方式由不同的函数使用。
我们将这些不同的使用方式汇总在下面。当说明相关函数时，再进一步讨论。

(1)第一个规则是，我们用名字打开任一类型的文件时，对该名字中包含的每一个目录，包括它可能隐含的当前工作目录都应具有执行权限。这就是为什么对于目录其执行权限位常被称为搜索位的原因。

例如，为了打开文件/usr/include/stdio.h，需要对目录/、/usr和/usr/include具有执行权限。然后，需要具有对文件本身的适当权限，这取决于以何种模式打开它（只读、读-写等）。

如果当前目录是/usr/include，那么为了打开文件stdio.h，需要对当前目录有执行权限。这是隐含当前目录的一个示例。打开stdio.h文件与打开./stdio.h作用相同。注意，对于目录的读权限和执行权限的意义是不相同的。读权限允许我们读目录，获得在该目录中所有文件名的列表。当一个目录是我们要访问文件的路径名的一个组成部分时，对该目录的执行权限使我们可通过该目录（也就是搜索该目录，寻找一个特定的文件名）。引用隐含目录的另一个例子是，如果PATH环境变量（8.10节将对其进行说明）指定了一个我们不具有执行权限的目录，那么shell绝不会在该目录下找到可执行文件。

(2)对于一个文件的读权限决定了我们是否能够打开现有文件进行读操作。这与open函数的O_RDONLY和O_RDWR标志相关。

(3)对于一个文件的写权限决定了我们是否能够打开现有文件进行写操作。这与open函数的O_WRONLY和O_RDWR标志相关。

(4)为了在open函数中对一个文件指定O_TRUNC标志，必须对该文件具有写权限。

(5)为了在一个目录中创建一个新文件，必须对该目录具有写权限和执行权限。

(6)为了删除一个现有文件，必须对包含该文件的目录具有写权限和执行权限。对该文件本身则不需要有读、写权限。

(7)如果用7个exec函数中的任何一个执行某个文件，都必须对该文件具有执行权限。该文件还必须是一个普通文件。

进程每次打开、创建或删除一个文件时，内核就进行文件访问权限测试，而这种测试可能涉及文件的所有者（st_uid和st_gid）、进程的有效ID（有效用户ID和有效组ID）以及进程的附属组ID（若支持的话）。两个所有者ID是文件的性质，而两个有效ID和附属组ID则是进程的性质。
内核进行的测试具体如下。
- 若进程的有效用户ID是0（超级用户），则允许访问。这给予了超级用户对整个文件系统进行处理的最充分的自由。
- 若进程的有效用户ID等于文件的所有者ID（也就是进程拥有此文件），那么如果所有者适当的访问权限位被设置，则允许访问；否则拒绝访问。适当的访问权限位指的是，若进程为读而打开该文件，则用户读位应为1；若进程为写而打开该文件，则用户写位应为1；若进程将执行该文件，则用户执行位应为1。
- 若进程的有效组ID或进程的附属组ID之一等于文件的组ID，那么如果组适当的访问权限位被设置，则允许访问；否则拒绝访问。
- 若其他用户适当的访问权限位被设置，则允许访问；否则拒绝访问。

按顺序执行这 4 步。注意，如果进程拥有此文件（第 2 步），则按用户访问权限批准或拒绝该进程对文件的访问----不查看组访问权限。类似地，若进程并不拥有该文件。但进程属于某个适当的组，则按组访问权限批准或拒绝该进程对文件的访问----不查看其他用户的访问权限。
** 新文件和目录的所有权
新文件的用户ID设置为进程的有效用户ID。关于组ID，POSIX.1允许实现选择下列之一作为新文件的组ID。

（1）新文件的组ID可以是进程的有效组ID。

（2）新文件的组ID可以是它所在目录的组ID。

FreeBSD 8.0和Mac OS X 10.6.8总是使用目录的组ID作为新文件的组ID。
有些Linux文件系统使用 mount(1)命令选项允许在 POSIX.1 提出的两种选项中进行选择。
对于 Linux 3.2.0 和Solaris 10，默认情况下，新文件的组ID取决于它所在的目录的设置组ID位是否被设置。如果该目录的这一位已经被设置，则新文件的组ID设置为目录的组ID；否则新文件的组ID设置为进程的有效组ID。

使用POSIX.1所允许的第二个选项（继承目录的组ID）使得在某个目录下创建的文件和目录都具有该目录的组ID。于是文件和目录的组所有权从该点向下传递。例如，在Linux的/var/mail目录中就使用了这种方法。

正如前面提到的，这种设置组所有权的方法是FreeBSD 8.0和Mac OS X 10.6.8系统默认的，但对于Linux和Solaris则是可选的。在Linux 3.2.0和Solaris 10之下，必须使设置组ID位起作用。更进一步，为使这种方法能够正常工作，mkdir函数要自动地传递一个目录的设置组ID位。
** 函数access和faccessat
正如前面所说，当用 open 函数打开一个文件时，内核以进程的有效用户 ID 和有效组 ID为基础执行其访问权限测试。有时，进程也希望按其实际用户ID和实际组ID来测试其访问能力。
例如，当一个进程使用设置用户ID或设置组ID功能作为另一个用户（或组）运行时，就可能会有这种需要。即使一个进程可能已经通过设置用户ID以超级用户权限运行，它仍可能想验证其实际用户能否访问一个给定的文件。

access和faccessat函数是按实际用户ID和实际组ID进行访问权限测试的。（该测试也分成4步，这与前两节所述的一样，但将有效改为实际。）
#+begin_src c++
#include <unistd.h>

int access(const char *pathname, int mode);

int faccessat(int fd, const char *pathname, int mode, int flag);
#+END_SRC

两个函数的返回值：若成功，返回0；若出错，返回-1

其中，如果测试文件是否已经存在，mode就为F_OK；否则mode是图4-7中所列常量的按位或。
#+DOWNLOADED: screenshot @ 2023-07-04 22:43:24
[[file:images/linux笔记/UNIX-文件和目录/2023-07-04_22-43-24_screenshot.png]]
faccessat函数与access函数在下面两种情况下是相同的：一种是pathname参数为绝对路径，另一种是fd参数取值为AT_FDCWD而pathname参数为相对路径。否则，faccessat计算相对于打开目录（由fd参数指向）的pathname。

flag参数可以用于改变faccessat的行为，如果flag设置为AT_EACCESS，访问检查用的是调用进程的有效用户ID和有效组ID，而不是实际用户ID和实际组ID。
*** 实例
图4-8显示了access函数的使用方法。
#+begin_src c++
#include "apue.h"
#include <fcntl.h>
int main(int argc, char *argv[])
{
  if (argc != 2)
    err_quit("usage: a.out <pathname>");
  if (access(argv[1]，R_OK) < 0)
    err_ret("access error for %s", argv[1]);
  else
    printf("read access OK\n");
  if (open(argv[1], O_RDONLY) < 0)
    err_ret("open error for %s", argv[1]);
  else
    printf("open for reading OK\n");
  exit(0);
}
#+END_SRC
下面是该程序的示例会话：
#+begin_src bash
$ ls -l a.out
-rwxrwxr-x 1 sar 15945 Nov 30 12:10 a.out

$ ./a.out a.out
read access OK
open for reading OK

$ ls -l /etc/shadow
-r-------- 1 root 1315 Jul 17 2002 /etc/shadow

$ ./a.out /etc/shadow
access error for /etc/shadow: Permission denied
open error for /etc/shadow: Permission denied

$ su 成为超级用户
Password: 输入超级用户口令
# chown root a.out  将文件用户ID改为 root
# chmod u+s a.out 并打开设置用户ID位
# ls -l a.out 检查所有者和SUID位
-rwsrwxr-x 1 root 15945 Nov 30 12:10 a.out
# exit 恢复为正常用户

$ ./a.out /etc/shadow
access error for /etc/shadow: Permission denied
open for reading OK
#+END_SRC
在本例中，尽管open函数能打开文件，但通过设置用户ID程序可以确定实际用户不能正常读指定的文件。
** 函数umask
umask 函数为进程设置文件模式创建屏蔽字，并返回之前的值。（这是少数几个没有出错返回函数中的一个。）
#+begin_src c++
#include <sys/stat.h>

mode_t umask(mode_t cmask);
#+END_SRC

返回值：之前的文件模式创建屏蔽字

其中，参数cmask是由图4-6中列出的9个常量（S_IRUSR、S_IWUSR等）中的若干个按位“或”构成的。

在进程创建一个新文件或新目录时，就一定会使用文件模式创建屏蔽字（回忆 3.3 节和 3.4节，在那里我们说明了open和creat函数。这两个函数都有一个参数mode，它指定了新文件的访问权限位）。我们将在4.21节说明如何创建一个新目录。在文件模式创建屏蔽字中为1的位，在文件mode中的相应位一定被关闭。


*** 实例
图4-9程序创建了两个文件，创建第一个时，umask值为0，创建第二个时，umask值禁止所有组和其他用户的访问权限。
#+begin_src c++
#include "apue.h"
#include <fcntl.h>
#define RWRWRW (S_IRUSRIS_IWUSR | S_IRGRP | S_IWGRP | S_IROTH | S_IWOTH)
int main(void)
{
  umask(0);
  if (creat("foo"，RWRWRW) < 0)
    err_sys("creat error for foo");
  umask(S_IRGRP | S_IWGRP | S_IROTH | S_IwOTH);
  if (creat("bar"，, RWRWRW) < 0)
    err_sys("creat error for bar");
  exit(0);
}
#+END_SRC
若运行此程序可得如下结果，从中可见访问权限位是如何设置的。
#+begin_src bash
$ umask 先打印当前文件模式创建屏蔽字
-rw------- 1 sar 0 Dec 7 21:20 bar
-rw-rw-rw- 1 sar 0 Dec 7 21:20 foo
002

$ ./a.out
$ ls -l foo bar
$ umask 观察文件模式创建屏蔽字是否更改
002

#+END_SRC

UNIX系统的大多数用户从不处理他们的umask值。通常在登录时，由shell的启动文件设置一次，然后，再不改变。尽管如此，当编写创建新文件的程序时，如果我们想确保指定的访问权限位已经激活，那么必须在进程运行时修改 umask 值。例如，如果我们想确保任何用户都能读文件，则应将umask设置为0。否则，当我们的进程运行时，有效的umask值可能关闭该权限位。

在前面的示例中，我们用shell的umask命令在运行程序的前、后打印文件模式创建屏蔽字。从中可见，更改进程的文件模式创建屏蔽字并不影响其父进程（常常是shell）的屏蔽字。所有shell都有内置umask命令，我们可以用该命令设置或打印当前文件模式创建屏蔽字。

用户可以设置umask值以控制他们所创建文件的默认权限。该值表示成八进制数，一位代表一种要屏蔽的权限，这示于图4-10中。设置了相应位后，它所对应的权限就会被拒绝。常用的几种 umask 值是 002、022 和 027。002 阻止其他用户写入你的文件，022 阻止同组成员和其他用户写入你的文件，027阻止同组成员写你的文件以及其他用户读、写或执行你的文件。


#+DOWNLOADED: screenshot @ 2023-07-05 22:44:00
[[file:images/linux笔记/UNIX-文件和目录/2023-07-05_22-44-00_screenshot.png]]
Single UNIX Specification要求shell应该支持符号形式的umask命令。与八进制格式不同，符号格式指定许可的权限（即在文件创建屏蔽字中为0的位）而非拒绝的权限（即在文件创建屏蔽字中为1的位）。下面显示了两种格式的命令。
#+begin_src bash
$ umask 先打印当前文件模式创建屏蔽字
$ umask -S 打印符号格式
$ umask 027 更改文件模式创建屏蔽字
$ umask -S 打印符号格式
002
u=rwx,g=rwx,o=rx
u=rwx,g=rx,o=
#+END_SRC

** 函数chmod、fchmod和fchmodat
chmod、fchmod和fchmodat这3个函数使我们可以更改现有文件的访问权限。
#+begin_src c++
#include <sys/stat.h>

int chmod(const char *pathname, mode_t mode);

int fchmod(int fd, mode_t mode);

int fchmodat(int fd, const char *pathname, mode_t mode, int flag);

#+END_SRC

3个函数返回值：若成功，返回0；若出错，返回−1

chmod 函数在指定的文件上进行操作，而 fchmod 函数则对已打开的文件进行操作。
fchmodat函数与chmod函数在下面两种情况下是相同的：一种是pathname参数为绝对路径，另一种是fd参数取值为AT_FDCWD而pathname参数为相对路径。否则，fchmodat计算相对于打开目录（由fd参数指向）的pathname。flag参数可以用于改变fchmodat的行为，当设置了AT_SYMLINK_NOFOLLOW标志时，fchmodat并不会跟随符号链接。

为了改变一个文件的权限位，进程的有效用户ID必须等于文件的所有者ID，或者该进程必须具有超级用户权限。

参数mode是图4-11中所示常量的按位或。

#+DOWNLOADED: screenshot @ 2023-07-05 22:47:57
[[file:images/linux笔记/UNIX-文件和目录/2023-07-05_22-47-57_screenshot.png]]
注意，在图4-11中，有9项是取自图4-6中的9个文件访问权限位。我们另外加了6个，它们是两个设置ID常量（S_ISUID和S_ISGID）、保存正文常量（S_ISVTX）以及3个组合常量（S_IRWXU、S_IRWXG和S_IRWXO）。

保存正文位（S_ISVTX）不是POSIX.1的一部分。在Single UNIX Specification中，它被定义在XSI扩展中。
*** 实例
为了演示umask函数，我们在前面运行了图4-9程序，先让我们回忆文件foo和bar当时的最后状态：
#+begin_src bash
$ ls -l foo bar
-rw------- 1 sar 0 Dec 7 21:20 bar
-rw-rw-rw- 1 sar 0 Dec 7 21:20 foo
#+END_SRC

图4-12的程序修改了这两个文件的模式。
#+begin_src c++
#include "apue.h"
int main(void)
{
  struct stat statbuf;
  /* turn on set-group-ID and turn off group-execute */
  if (stat("foo", &statbuf) < 0)
    err_sys("stat error for foo");
  if (chmod("foo"，(statbuf.st_mode & ~S_IXGRP) | S_ISGID) < 0)
    err_sys("chmod error for foo");
  /* set absolute mode to "rw-r--r--" */
  if (chmod("bar", S_IRUSR / S_IWUSR / S_IRGRP | S_IROTH) < 0)
    err_sys("chmod error for bar");
  exit(O);
}
#+END_SRC
在运行图4-12程序后，这两个文件的最后状态是：
#+begin_src bash
$ ls -l foo bar
-rw-r--r-- 1 sar 0 Dec 7 21:20 bar-rw-rwSrw- 1 sar 0 Dec 7 21:20 foo
#+END_SRC

在本例中，不管文件bar的当前权限位如何，我们都将其权限设置为一个绝对值。对文件foo，我们相对于其当前状态设置权限。为此，先调用stat获得其当前权限，然后修改它。我们显式地打开了设置组ID位、关闭了组执行位。注意，ls命令将组执行权限表示为S，它表示设置组ID位已经设置，同时，组执行位未设置。

在Solaris中，ls命令显示l而非S，这表明对该文件可以加强制性文件或记录锁。这只能用于普通文件，14.3节将更详细地讨论这一点。

最后还要注意，在运行图4-12程序后，ls命令列出的时间和日期并没有改变。在4.19节中，我们会了解到 chmod 函数更新的只是 i 节点最近一次被更改的时间。按系统默认方式，ls -l列出的是最后修改文件内容的时间。

chmod函数在下列条件下自动清除两个权限位。

•Solaris 等系统对用于普通文件的粘着位赋予了特殊含义，在这些系统上如果我们试图设置普通文件的粘着位（S_ISVTX），而且又没有超级用户权限，那么mode中的粘着位自动被关闭（我们将在下一节说明粘着位）。这意味着只有超级用户才能设置普通文件的粘着位。这样做的理由是防止恶意用户设置粘着位，由此影响系统性能。

在FreeBSD 8.0和Solaris 10中，只有超级用户才能对普通文件设置粘着位。Linux 3.2.0和Mac OS X 10.6.8对设置粘着位并无此种限制，其原因是，粘着位对Linux普通文件并无意义。虽然粘着位对FreeBSD的普通文件也无意义，但还是阻止除超级用户以外的任何用户对普通文件设置该位。

•新创建文件的组 ID 可能不是调用进程所属的组。回忆一下 4.6 节，新文件的组 ID可能是父目录的组ID。特别地，如果新文件的组ID不等于进程的有效组ID或者进程附属组 ID 中的一个，而且进程没有超级用户权限，那么设置组 ID 位会被自动被关闭。这就防止了用户创建一个设置组ID文件，而该文件是由并非该用户所属的组拥有的。

这种情况下，FreeBSD 8.0对试图设置组ID的操作肯定会返回失败，而其他的系统则无声息地关闭该位，但不会对试图改变文件访问权限的操作直接做失败处理。

FreeBSD 8.0、Linux 3.2.0、Mac OS X 10.6.8和Solaris 10增加了另一个安全性功能以试图阻止误用某些保护位。如果没有超级用户权限的进程写一个文件，则设置用户 ID 位和设置组ID位会被自动清除。如果恶意用户找到一个他们可以写的设置组ID和设置用户ID文件，即使可以修改此文件，他们也没有对该文件的特殊权限。
** 粘着位
S_ISVTX位有一段有趣的历史。在UNIX尚未使用请求分页式技术的早期版本中，S_ISVTX位被称为粘着位（sticky bit）。如果一个可执行程序文件的这一位被设置了，那么当该程序第一次被执行，在其终止时，程序正文部分的一个副本仍被保存在交换区（程序的正文部分是机器指令）。这使得下次执行该程序时能较快地将其装载入内存。其原因是：通常的UNIX文件系统中，文件的各数据块很可能是随机存放的，相比较而言，交换区是被作为一个连续文件来处理的。对于通用的应用程序，如文本编辑程序和C语言编译器，我们常常设置它们所在文件的粘着位。自然地，对于在交换区中可以同时存放的设置了粘着位的文件数是有限制的，以免过多占用交换区空间，但无论如何这是一个有用的技术。因为在系统再次自举前，文件的正文部分总是在交换区中，这正是名字中“粘着”的由来。后来的UNIX版本称它为保存正文位（saved-text bit），因此也就有了常量S_ISVTX。现今较新的UNIX系统大多数都配置了虚拟存储系统以及快速文件系统，所以不再需要使用这种技术。

现今的系统扩展了粘着位的使用范围，Single UNIX Specification允许针对目录设置粘着位。如果对一个目录设置了粘着位，只有对该目录具有写权限的用户并且满足下列条件之一，才能删除或重命名该目录下的文件：

•拥有此文件；

•拥有此目录；

•是超级用户。

目录/tmp 和/var/tmp 是设置粘着位的典型候选者—任何用户都可在这两个目录中创建文件。任一用户（用户、组和其他）对这两个目录的权限通常都是读、写和执行。但是用户不应能删除或重命名属于其他人的文件，为此在这两个目录的文件模式中都设置了粘着位。

POSIX.1没有定义保存正文位，Single UNIX Specification将它定义在XSI扩展部分。FreeBSD 8.0、Linux 3.2.0、Mac OS X 10.6.8和Solaris 10则支持这种功能。

在Solaris 10中，如果对普通文件设置了粘着位，那么它就具有特殊含义。在这种情况下，如果任何执行位都没有设置，那么操作系统就不会缓存文件内容。
** 函数chown、fchown、fchownat和lchown
下面几个chown函数可用于更改文件的用户ID和组ID。如果两个参数owner或group中的任意一个是-1，则对应的ID不变。

#include <unistd.h>

int chown(const char *pathname, uid_t owner, gid_t group);

int fchown(int fd, uid_t owner, gid_t group);

int fchownat(int fd, const char *pathname, uid_t owner, gid_t group, int flag);

int lchown(const char *pathname, uid_t owner, gid_t group);

4个函数的返回值：若成功，返回0；若出错，返回-1

除了所引用的文件是符号链接以外，这 4 个函数的操作类似。在符号链接情况下，lchown和fchownat（设置了AT_SYMLINK_NOFOLLOW标志）更改符号链接本身的所有者，而不是该符号链接所指向的文件的所有者。

fchown函数改变fd参数指向的打开文件的所有者，既然它在一个已打开的文件上操作，就不能用于改变符号链接的所有者。

fchownat函数与chown或者lchown函数在下面两种情况下是相同的：一种是pathname参数为绝对路径，另一种是fd参数取值为AT_FDCWD而pathname参数为相对路径。在这两种情况下，如果flag参数中设置了AT_SYMLINK_NOFOLLOW标志，fchownat与lchown行为相同，如果flag参数中清除了AT_SYMLINK_NOFOLLOW标志，则fchownat与chown行为相同。如果fd参数设置为打开目录的文件描述符，并且pathname参数是一个相对路径名，fchownat函数计算相对于打开目录的pathname。

基于BSD的系统一直规定只有超级用户才能更改一个文件的所有者。这样做的原因是防止用户改变其文件的所有者从而摆脱磁盘空间限额对他们的限制。System V则允许任一用户更改他们所拥有的文件的所有者。

按照_POSIX_CHOWN_RESTRICTED的值，POSIX.1允许在这两种形式的操作中选用一种。

对于Solaris 10，此功能是个配置选项，其默认值是施加限制。而FreeBSD 8.0、Linux 3.2.0和Mac OS X 10.6.8则总对chown施加限制。

回忆2.6节，_POSIX_CHOWN_RESTRICTED常量可选地定义在头文件<unistd.h>中，而且总是可以用pathconf或fpathconf函数进行查询。此选项还与所引用的文件有关—可在每个文件系统基础上，使该选项起作用或不起作用。在下文中，如提及“若_POSIX_CHOWN_RESTRICTED生效”，则表示“这适用于我们正在谈及的文件”，而不管该实际常量是否在头文件中定义。

若_POSIX_CHOWN_RESTRICTED对指定的文件生效，则

（1）只有超级用户进程能更改该文件的用户ID；

（2）如果进程拥有此文件（其有效用户ID等于该文件的用户ID），参数owner等于-1或文件的用户ID，并且参数group等于进程的有效组ID或进程的附属组ID之一，那么一个非超级用户进程可以更改该文件的组ID。

这意味着，当_POSIX_CHOWN_RESTRICTED有效时，不能更改其他用户文件的用户ID。你可以更改你所拥用的文件的组ID，但只能改到你所属的组。

如果这些函数由非超级用户进程调用，则在成功返回时，该文件的设置用户 ID 位和设置组ID位都被清除。
** 文件长度
stat结构成员st_size表示以字节为单位的文件的长度。此字段只对普通文件、目录文件和符号链接有意义。

FreeBSD 8.0、Mac OS X 10.6.8和Solaris 10对管道也定义了文件长度，它表示可从该管道中读到的字节数。

对于普通文件，其文件长度可以是0，在开始读这种文件时，将得到文件结束（end-of-file）指示。
对于目录，文件长度通常是一个数（如16或512）的整倍数.
对于符号链接，文件长度是在文件名中的实际字节数。例如，在下面的例子中，文件长度7就是路径名usr/lib的长度：
#+begin_src bash
lrwxrwxrwx 1 root 7 Sep 25 07:14 lib -> usr/lib
#+END_SRC
（注意，因为符号链接文件长度总是由st_size指示，所以它并不包含通常C语言用作名字结尾的null字节。）

现今，大多数现代的UNIX系统提供字段st_blksize和st_blocks。其中，第一个是对文件I/O较合适的块长度，第二个是所分配的实际512字节块块数。回忆前面章节，其中提到了当我们将st_blksize用于读操作时，读一个文件所需的时间量最少。为了提高效率，标准I/O库（我们将在第5章中说明）也试图一次读、写st_blksize个字节。

应当了解的是，不同的UNIX版本其st_blocks所用的单位可能不是512字节的块。使用此值并不是可移植的。

*** 文件中的空洞
我们曾经提及普通文件可以包含空洞。在图3-2 程序中例示了这一点。空洞是由所设置的偏移量超过文件尾端，并写入了某些数据后造成的。
作为一个例子，考虑下列情况：
#+begin_src bash
$ ls -l core
-rw-r--r-- 1 sar 8483248 Nov 18 12:18 core

$ du -s core
272 core
#+END_SRC
文件core的长度稍稍超过8 MB，可是du命令报告该文件所使用的磁盘空间总量是272个512字节块（即139 264字节）。
很明显，此文件中有很多空洞。

在很多BSD类系统上，du命令报告的是1 024字节块的块数，Solaris报告的是512字节块的块数。
在Linux上，报告的块数单位取决于是否设置了环境变量POSIXLY_CORRECT。当设置了该环境变量，du 命令报告的是1024 字节块的块数；没有设置该环境变量时，du 命令报告的是512字节块的块数。

正如我们在3.6节中提及的，对于没有写过的字节位置，read函数读到的字节是0。如果执行下面的命令，可以看出正常的I/O操作读整个文件长度：
#+begin_src bash
$ wc -c core
8483248 core
#+END_SRC

带-c选项的wc(1)命令计算文件中的字符数（字节）。

如果使用实用程序（如cat(1)）复制这个文件，那么所有这些空洞都会被填满，其中所有实际数据字节皆填写为0。
#+begin_src bash
$ cat core > core.copy

$ ls -l core*
-rw-r--r-- 1 sar 8483248 Nov 18 12:18 core
-rw-rw-r-- 1 sar 8483248 Nov 18 12:27 core.copy

$ du -s core*
272 core
16592 core.copy
#+END_SRC

从中可见，新文件所用的实际字节数是8 495 104（512×16 592）。此长度与ls命令报告的长度不同，其原因是，文件系统使用了若干块以存放指向实际数据块的各个指针。

有兴趣的读者可以参阅Bach[1986]的4.2节、McKusick 等[1996]的7.2节和7.3节（或McKusick和Neville-Neil[2005]的8.2节和8.3节）、McDougall和Mauro[2007]的15.2节以及Singh[2006]的第12章，以更详细地了解文件的物理结构。

** 文件截断
有时我们需要在文件尾端处截去一些数据以缩短文件。将一个文件的长度截断为0是一个特例，在打开文件时使用O_TRUNC 标志可以做到这一点。为了截断文件可以调用函数 truncate和ftruncate。
#+begin_src c++
#include <unistd.h>

int truncate(const char *pathname, off_t length);
int ftruncate(int fd, off_t length);
#+END_SRC

两个函数的返回值：若成功，返回0；若出错，返回-1

这两个函数将一个现有文件长度截断为 length。如果该文件以前的长度大于 length，则超过length 以外的数据就不再能访问。如果以前的长度小于 length，文件长度将增加，在以前的文件尾端和新的文件尾端之间的数据将读作0（也就是可能在文件中创建了一个空洞）。

早于4.4BSD的BSD系统只能用truncate函数截短一个文件，不能用它扩展一个文件。

Solaris对fcntl函数进行了扩展，增加了F_FREESP，它允许释放一个文件中的任何一部分，而不只是文件尾端处的一部分。

** 文件系统
我们可以把一个磁盘分成一个或多个分区。每个分区可以包含一个文件系统（见图 4-13）。i节点是固定长度的记录项，它包含有关文件的大部分信息。
#+DOWNLOADED: screenshot @ 2023-07-07 22:19:14
[[file:images/linux笔记/UNIX-文件和目录/2023-07-07_22-19-14_screenshot.png]]
如果更仔细地观察一个柱面组的i节点和数据块部分，则可以看到图4-14中所示的情况。

#+DOWNLOADED: screenshot @ 2023-07-07 22:24:27
[[file:images/linux笔记/UNIX-文件和目录/2023-07-07_22-24-27_screenshot.png]]

注意图4-14中的下列各点。
(1)在图中有两个目录项指向同一个i节点。每个i节点中都有一个链接计数，其值是指向该i节点的目录项数。只有当链接计数减少至0时，才可删除该文件（也就是可以释放该文件占用的数据块）。
这就是为什么“解除对一个文件的链接”操作并不总是意味着“释放该文件占用的磁盘块”的原因。
这也是为什么删除一个目录项的函数被称之为 unlink而不是delete的原因。在stat结构中，链接计数包含在st_nlink成员中，其基本系统数据类型是nlink_t。这种链接类型称为硬链接。常量LINK_MAX指定了一个文件链接数的最大值。

(2)另外一种链接类型称为符号链接（symbolic link）。符号链接文件的实际内容（在数据块中）包含了该符号链接所指向的文件的名字。在下面的例子中，目录项中的文件名是 3个字符的字符串lib，而在该文件中包含了7个字节的数据usr/lib：
#+begin_src bash
lrwxrwxrwx 1 root 7 Sep 25 07:14 lib -> urs/lib
#+END_SRC
该i节点中的文件类型是S_IFLNK，于是系统知道这是一个符号链接。

(3)i节点包含了文件有关的所有信息：文件类型、文件访问权限位、文件长度和指向文件数据块的指针等。stat结构中的大多数信息都取自i节点。只有两项重要数据存放在目录项中：文件名和i节点编号。其他的数据项（如文件名长度和目录记录长度）并不是本书关心的。i节点编号的数据类型是ino_t。

(4)因为目录项中的i节点编号指向同一文件系统中的相应i节点，一个目录项不能指向另一个文件系统的i节点。这就是为什么ln(1)命令（构造一个指向一个现有文件的新目录项）不能跨越文件系统的原因。我们将在下一节说明link函数。

(5)当在不更换文件系统的情况下为一个文件重命名时，该文件的实际内容并未移动，只需构造一个指向现有i节点的新目录项，并删除老的目录项。链接计数不会改变。例如，为将文件/usr/lib/foo重命名为/usr/foo，如果目录/usr/lib和/usr在同一文件系统中，则文件foo的内容无需移动。这就是mv(1)命令的通常操作方式。

我们说明了普通文件的链接计数概念，但是对于目录文件的链接计数字段又如何呢？假定我们在工作目录中构造了一个新目录：
#+begin_src bash
$ mkdir testdir
#+END_SRC

图4-15显示了其结果。注意，该图显式地显示了.和..目录项。

#+DOWNLOADED: screenshot @ 2023-07-07 22:39:07
[[file:images/linux笔记/UNIX-文件和目录/2023-07-07_22-39-07_screenshot.png]]
编号为2549的i节点，其类型字段表示它是一个目录，链接计数为2。任何一个叶目录（不包含任何其他目录的目录）的链接计数总是2，数值2来自于命名该目录（testdir）的目录项以及在该目录中的.项。编号为1267的i节点，其类型字段表示它是一个目录，链接计数大于或等于3。它大于或等于3的原因是，至少有3个目录项指向它：一个是命名它的目录项（在图4-15中没有表示出来），第二个是在该目录中的.项，第三个是在其子目录testdir中的..项。注意，在父目录中的每一个子目录都使该父目录的链接计数增加1。

** 函数link、linkat、unlink、unlinkat和remove
如上节所述，任何一个文件可以有多个目录项指向其i节点。创建一个指向现有文件的链接的方法是使用link函数或linkat函数。
#+begin_src c++
#include <unistd.h>

int link(const char *existingpath, const char *newpath);
int linkat(int efd, const char *existingpath, int nfd, const char *newpath, int flag);
#+END_SRC

两个函数的返回值：若成功，返回0；若出错，返回-1

这两个函数创建一个新目录项newpath，它引用现有文件existingpath。如果newpath已经存在，则返回出错。只创建newpath中的最后一个分量，路径中的其他部分应当已经存在。

对于linkat函数，现有文件是通过efd和existingpath参数指定的，新的路径名是通过nfd和newpath参数指定的。默认情况下，如果两个路径名中的任一个是相对路径，那么它需要通过相对于对应的文件描述符进行计算。如果两个文件描述符中的任一个设置为AT_FDCWD，那么相应的路径名（如果它是相对路径）就通过相对于当前目录进行计算。如果任一路径名是绝对路径，相应的文件描述符参数就会被忽略。

当现有文件是符号链接时，由flag参数来控制linkat函数是创建指向现有符号链接的链接还是创建指向现有符号链接所指向的文件的链接。如果在flag参数中设置了AT_SYMLINK_FOLLOW标志，就创建指向符号链接目标的链接。如果这个标志被清除了，则创建一个指向符号链接本身的链接。

创建新目录项和增加链接计数应当是一个原子操作

虽然POSIX.1允许实现支持跨越文件系统的链接，但是大多数实现要求现有的和新建的两个路径名在同一个文件系统中。如果实现支持创建指向一个目录的硬链接，那么也仅限于超级用户才可以这样做。其理由是这样做可能在文件系统中形成循环，大多数处理文件系统的实用程序都不能处理这种情况（4.17 节将说明一个由符号链接引入循环的例子）。因此，很多文件系统实现不允许对于目录的硬链接。

为了删除一个现有的目录项，可以调用unlink函数。
#+begin_src c++
#include <unistd.h>

int unlink(const char *pathname);

int unlinkat(int fd, const char *pathname, int flag);
#+END_SRC

两个函数的返回值：若成功，返回0；若出错，返回-1

这两个函数删除目录项，并将由pathname所引用文件的链接计数减1。如果对该文件还有其他链接，则仍可通过其他链接访问该文件的数据。如果出错，则不对该文件做任何更改。

我们在前面已经提及，为了解除对文件的链接，必须对包含该目录项的目录具有写和执行权限。
如果对该目录设置了粘着位，则对该目录必须具有写权限，并且具备下面三个条件之一：
- 拥有该文件；
- 拥有该目录；
- 具有超级用户权限。

只有当链接计数达到0时，该文件的内容才可被删除。另一个条件也会阻止删除文件的内容—只要有进程打开了该文件，其内容也不能删除。关闭一个文件时，内核首先检查打开该文件的进程个数；如果这个计数达到0，内核再去检查其链接计数；如果计数也是0，那么就删除该文件的内容。

如果pathname参数是相对路径名，那么unlinkat函数计算相对于由fd文件描述符参数代表的目录的路径名。如果fd参数设置为AT_FDCWD，那么通过相对于调用进程的当前工作目录来计算路径名。如果pathname参数是绝对路径名，那么fd参数被忽略。

flag参数给出了一种方法，使调用进程可以改变unlinkat函数的默认行为。当AT_REMOVEDIR标志被设置时，unlinkat 函数可以类似于 rmdir 一样删除目录。如果这个标志被清除， unlinkat与unlink执行同样的操作。

*** remove
#+begin_src c++
#include <stdio.h>

int remove(const char *pathname);
#+END_SRC

返回值：若成功，返回0；若出错，返回-1

ISO C指定remove函数删除一个文件，这更改了UNIX历来使用的名字unlink，其原因是实现C标准的大多数非UNIX系统并不支持文件链接。
*** 实例
图4-16的程序打开一个文件，然后解除它的链接。执行该程序的进程然后睡眠15秒，接着就终止。
#+begin_src c++
#include "apue.h" 
#include < fcntl.h>
int main(void)
{
  if (open("tempfile", O_RDWR) < 0)
    err_sys("open error");
  if (unlink("tempfile") < 0)
    err_sys("unlink error");
  printf("file unlinked\n");
}
#+END_SRC
运行该程序，其结果是：
#+begin_src bash
$ ls -l tempfile 查看文件大小
-rw-r----- 1 sar 413265408 Jan 21 07:14 tempfile

$ df /home 检查可用磁盘空间
Filesystem 1K-blocks Used Available Use% Mounted on/dev/hda4 11021440 1956332 9065108 18% /home

$ ./a.out & 在后台运行图4-16程序
1364 shell打印其进程ID

$ file unlinked 解除文件链接
ls -l tempfile 观察文件是否仍然存在
ls: tempfile: No such file or directory 目录项已删除

$ df /home 检查可用磁盘空间有无变化
Filesystem 1K-blocks Used Available Use% Mounted on/dev/hda4 11021440 1956332 9065108 18% /home

$ done 程序执行结束，关闭所有打开文件
df /home 现在，应当有更多可用磁盘空间
Filesystem 1K-blocks Used Available Use% Mounted on
/dev/hda4 11021440 1552352 9469088 15% /home
#+END_SRC
现在，394.1 MB磁盘空间可用

unlink的这种特性经常被程序用来确保即使是在程序崩溃时，它所创建的临时文件也不会遗留下来。进程用open或creat创建一个文件，然后立即调用unlink，因为该文件仍旧是打开的，所以不会将其内容删除。只有当进程关闭该文件或终止时（在这种情况下，内核关闭该进程所打开的全部文件），该文件的内容才被删除。

如果pathname是符号链接，那么unlink删除该符号链接，而不是删除由该链接所引用的文件。给出符号链接名的情况下，没有一个函数能删除由该链接所引用的文件。

如果文件系统支持的话，超级用户可以调用unlink，其参数pathname指定一个目录，但是通常应当使用rmdir函数，而不使用unlink这种方式。

我们也可以用 remove 函数解除对一个文件或目录的链接。对于文件，remove 的功能与unlink相同。对于目录，remove的功能与rmdir相同。

** 符号链接
符号链接是对一个文件的间接指针，它与上一节所述的硬链接有所不同，硬链接直接指向文件的i节点。

引入符号链接的原因是为了避开硬链接的一些限制:
- 硬链接通常要求链接和文件位于同一文件系统中。
- 只有超级用户才能创建指向目录的硬链接（在底层文件系统支持的情况下）。

对符号链接以及它指向何种对象并无任何文件系统限制，任何用户都可以创建指向目录的符号链接。
符号链接一般用于将一个文件或整个目录结构移到系统中另一个位置。

当使用以名字引用文件的函数时，应当了解该函数是否处理符号链接。也就是该函数是否跟随符号链接到达它所链接的文件。
如若该函数具有处理符号链接的功能，则其路径名参数引用由符号链接指向的文件。否则，一个路径名参数引用链接本身，而不是由该链接指向的文件。

图4-17列出了本章中所说明的各个函数是否处理符号链接。
在图 4-17 中没有列出 mkdir、mkinfo、mknod和rmdir这些函数，其原因是，当路径名是符号链接时，它们都出错返回。
以文件描述符作为参数的一些函数（如fstat、fchmod等）也未在该图中列出，其原因是，对符号链接的处理是由返回文件描述符的函数（通常是open）进行的。
chown是否跟随符号链接取决于实现。在所有现代的系统中，chown函数都跟随符号链接。

符号链接由4.2BSD引入，chown最初并不跟随符号链接，但在4.4BSD中情况发生了变化。SVR4中的System V包含了对符号链接的支持，但与原始BSD中的行为已大不相同，也实现了chown函数跟随符号链接。早期Linux版本中（Linux 2.1.81以前的版本），chown并不跟随符号链接。从2.1.81版开始，chown跟随符号链接。FreeBSD 8.0、Mac OS X 10.6.8和Solaris 10中， chown跟随符号链接。所有这些平台都实现了lchown，它改变符号链接自身的所有权。


#+DOWNLOADED: screenshot @ 2023-07-07 23:05:54
[[file:images/linux笔记/UNIX-文件和目录/2023-07-07_23-05-54_screenshot.png]]

图4-17的一个例外是，同时用O_CREAT和O_EXCL两者调用open函数。在此情况下，若路径名引用符号链接，open将出错返回，errno设置为EEXIST。这种处理方式的意图是堵塞一个安全性漏洞，以防止具有特权的进程被诱骗写错误的文件。

*** 实例
使用符号链接可能在文件系统中引入循环。大多数查找路径名的函数在这种情况发生时都将出错返回，errno值为ELOOP。考虑下列命令序列：
#+begin_src bash
$ mkdir foo 创建一个新目录

$ touch foo/a 创建一个0长度的文件

$ ln -s ../foo foo/testdir 创建一个符号链接
-rw-r----- 1 sar 0 Jan 22 00:16 a
lrwxrwxrwx 1 sar 6 Jan 22 00:16 testdir -> ../foo

$ ls -l foo
total 0
#+END_SRC

这创建了一个目录foo，它包含了一个名为a的文件以及一个指向foo的符号链接。在图4-18中显示了这种结果，图中以圆表示目录，以正方形表示一个文件。

#+DOWNLOADED: screenshot @ 2023-07-07 23:07:04
[[file:images/linux笔记/UNIX-文件和目录/2023-07-07_23-07-04_screenshot.png]]
如果我们写一段简单的程序，使用Solaris的标准函数ftw(3)以降序遍历文件结构，打印每个遇到的路径名，则其输出是：
#+begin_src bash
foo

foo/a

foo/testdir

foo/testdir/a

foo/testdir/testdir

foo/testdir/testdir/a

foo/testdir/testdir/testdir

foo/testdir/testdir/testdir/a

（更多行，直至ftw出错返回，此时，errno值为ELOOP）

#+END_SRC

4.22节提供了我们自己的ftw函数版本，它用lstat代替stat以阻止它跟随符号链接。

注意，Linux的ftw和nftw函数记录了所有看到的目录并避免多次重复处理一个目录，因此这两个函数不显示这种程序运行行为。

这样一个循环是很容易消除的。因为 unlink 并不跟随符号链接，所以可以 unlink 文件foo/testdir。但是如果创建了一个构成这种循环的硬链接，那么就很难消除它。这就是为什么link函数不允许构造指向目录的硬链接的原因（除非进程具有超级用户权限）。

实际上，Rich Stevens在写本节的最初版本时，在自己的系统上做了一个这样的实验。结果文件系统变得错误百出。正常的 fsck(1)实用程序不能修复问题。为了修复文件系统，不得不使用了并不推荐使用的工具clri(8)和dcheck(8)。

对目录的硬链接的需求由来已久，但是使用符号链接和mkdir函数，用户就不再需要创建指向目录的硬链接了。

用open打开文件时，如果传递给open函数的路径名指定了一个符号链接，那么open跟随此链接到达所指定的文件。若此符号链接所指向的文件并不存在，则open返回出错，表示它不能打开该文件。这可能会使不熟悉符号链接的用户感到迷惑，例如：

$ ln -s /no/such/file myfile　　　　　　创建一个符号链接

myfile　　　　　　　　　　　　　　　　　 ls查到该文件

$ cat myfile　　　　　　　　　　　　　　 试图查看该文件

$ ls myfile

cat: myfile: No such file or directory

$ ls -1 myfile　　　　　　　　　　　　　尝试-l选项

lrwxrwxrwx　1　sar　　　 13 Jan 22 00:26　myfile -> /no/such/file

文件myfile存在，但cat却称没有这一文件。其原因是myfile是个符号链接，由该符号链接所指向的文件并不存在。ls命令的-l选项给我们两个提示：第一个字符是l，它表示这是一个符号链接，而->也表明这是一个符号链接。ls 命令还有另一个选项-F，它会在符号链接的文件名后加一个@符号，在未使用-l选项时，这可以帮助我们识别出符号链接。

** 创建和读取符号链接
可以用symlink或symlinkat函数创建一个符号链接。
#+begin_src c++
#include <unistd.h>

int symlink(const char *actualpath, const char *sympath);

int symlinkat(const char *actualpath, int fd, const char *sympath);

#+END_SRC

两个函数的返回值：若成功，返回0；若出错，返回-1

函数创建了一个指向actualpath的新目录项sympath。在创建此符号链接时，并不要求actualpath已经存在（在上一节结束部分的例子中我们已经看到了这一点）。并且，actualpath和sympath并不需要位于同一文件系统中。

symlinkat函数与symlink函数类似，但sympath参数根据相对于打开文件描述符引用的目录（由 fd 参数指定）进行计算。如果 sympath 参数指定的是绝对路径或者 fd 参数设置了AT_FDCWD值，那么symlinkat就等同于symlink函数。

因为open函数跟随符号链接，所以需要有一种方法打开该链接本身，并读该链接中的名字。readlink和readlinkat函数提供了这种功能。
#+begin_src c++
#include <unistd.h>

ssize_t readlink(const char *restrict pathname, char *restrict buf,

size_t bufsize);

ssize_t readlinkat(int fd, const char* restrict pathname,

char *restrict buf, size_t bufsize);

#+END_SRC

两个函数的返回值：若成功，返回读取的字节数；若出错，返回-1

两个函数组合了 open、read 和 close 的所有操作。如果函数成功执行，则返回读入buf的字节数。在buf中返回的符号链接的内容不以null字节终止。

当pathname参数指定的是绝对路径名或者fd参数的值为AT_FDCWD，readlinkat函数的行为与readlink相同。但是，如果fd参数是一个打开目录的有效文件描述符并且pathname参数是相对路径名，则readlinkat计算相对于由fd代表的打开目录的路径名。
** 文件的时间
在4.2节中，我们讨论了Single UNIX Specification 2008年版如何提高stat结构中时间字段的精度，从原来的秒提高到秒加上纳秒。每个文件属性所保存的实际精度依赖于文件系统的实现。对于把时间戳记录在秒级的文件系统来说，纳秒这个字段就会被填充为 0。对于时间戳的记录精度高于秒级的文件系统来说，不足秒的值被转换成纳秒并记录在纳秒这个字段中。

对每个文件维护3个时间字段，它们的意义示于图4-19中。
#+DOWNLOADED: screenshot @ 2023-07-11 22:30:33
[[file:images/linux笔记/UNIX-文件和目录/2023-07-11_22-30-33_screenshot.png]]
注意，修改时间（st_mtim）和状态更改时间（st_ctim）之间的区别。修改时间是文件内容最后一次被修改的时间。状态更改时间是该文件的i节点最后一次被修改的时间。在本章中我们已说明了很多影响到i节点的操作，如更改文件的访问权限、更改用户ID、更改链接数等，但它们并没有更改文件的实际内容。因为i节点中的所有信息都是与文件的实际内容分开存放的，所以，除了要记录文件数据修改时间以外，还需要记录状态更改时间，也就是更改i节点中信息的时间。

注意，系统并不维护对一个i节点的最后一次访问时间，所以access和stat函数并不更改这3个时间中的任一个。

系统管理员常常使用访问时间来删除在一定时间范围内没有被访问过的文件。典型的例子是删除在过去一周内没有被访问过的名为a.out或core的文件。find(1)命令常被用来进行这种类型的操作。

修改时间和状态更改时间可被用来归档那些内容已经被修改或i节点已经被更改的文件。

ls命令按这3个时间值中的一个排序进行显示。系统默认（用-l或-t选项调用时）是按文件的修改时间的先后排序显示。-u选项使ls命令按访问时间排序，-c选项则使其按状态更改时间排序。

图4-20列出了我们已说明过的各种函数对这3个时间的作用。回忆4.14节中所述，目录是包含目录项（文件名和相关的i节点编号）的文件，增加、删除或修改目录项会影响到它所在目录相关的3个时间。这就是在图4-20中包含两列的原因，其中一列是与该文件（或目录）相关的3个时间，另一列是与所引用的文件（或目录）的父目录相关的3个时间。例如，创建一个新文件影响到包含此新文件的目录，也影响该新文件的i节点。但是，读或写一个文件只影响该文件的i节点，而对目录则无影响。

#+DOWNLOADED: screenshot @ 2023-07-11 22:34:58
[[file:images/linux笔记/UNIX-文件和目录/2023-07-11_22-34-58_screenshot.png]]

** 函数futimens、utimensat和utimes
一个文件的访问和修改时间可以用以下几个函数更改。futimens和utimensat函数可以指定纳秒级精度的时间戳。用到的数据结构是与stat函数族相同的timespec结构（见4.2节）。

#include <sys/stat.h>

int futimens(int fd, const struct timespec times[2]);

int utimensat(int fd, const char *path, const struct timespec times[2], int flag);

两个函数返回值：若成功，返回0；若出错，返回-1

这两个函数的times数组参数的第一个元素包含访问时间，第二元素包含修改时间。这两个时间值是日历时间，如1.10节所述，这是自特定时间（1970年1月1日00:00:00）以来所经过的秒数。不足秒的部分用纳秒表示。

时间戳可以按下列4种方式之一进行指定。

（1）如果times参数是一个空指针，则访问时间和修改时间两者都设置为当前时间。

（2）如果times参数指向两个timespec结构的数组，任一数组元素的tv_nsec字段的值为UTIME_NOW，相应的时间戳就设置为当前时间，忽略相应的tv_sec字段。

（3）如果times参数指向两个timespec结构的数组，任一数组元素的tv_nsec字段的值为UTIME_OMIT，相应的时间戳保持不变，忽略相应的tv_sec字段。

（4）如果 times 参数指向两个 timespec 结构的数组，且 tv_nsec 字段的值为既不是UTIME_NOW 也不是 UTIME_OMIT，在这种情况下，相应的时间戳设置为相应的 tv_sec 和tv_nsec字段的值。

执行这些函数所要求的优先权取决于times参数的值。

• 如果times是一个空指针，或者任一tv_nsec字段设为UTIME_NOW，则进程的有效用户ID必须等于该文件的所有者ID；进程对该文件必须具有写权限，或者进程是一个超级用户进程。

• 如果 times 是非空指针，并且任一 tv_nsec 字段的值既不是 UTIME_NOW 也不是UTIME_OMIT，则进程的有效用户ID必须等于该文件的所有者ID，或者进程必须是一个超级用户进程。对文件只具有写权限是不够的。

• 如果times是非空指针，并且两个tv_nsec字段的值都为UTIME_OMIT，就不执行任何的权限检查。

futimens 函数需要打开文件来更改它的时间，utimensat 函数提供了一种使用文件名更改文件时间的方法。pathname参数是相对于fd参数进行计算的，fd要么是打开目录的文件描述符，要么设置为特殊值 AT_FDCWD（强制通过相对于调用进程的当前目录计算pathname）。如果pathname指定了绝对路径，那么fd参数被忽略。

utimensat的flag参数可用于进一步修改默认行为。如果设置了AT_SYMLINK_NOFOLLOW标志，则符号链接本身的时间就会被修改（如果路径名指向符号链接）。默认的行为是跟随符号链接，并把文件的时间改成符号链接的时间。

futimens 和utimensat 函数都包含在POSIX.1 中，第3 个函数utimes 包含在Single UNIX Specification的XSI扩展选项中。

#include <sys/time.h>

int utimes(const char *pathname, const struct timeval times[2]);

函数返回值：若成功，返回0；若出错，返回-1

utimes函数对路径名进行操作。times参数是指向包含两个时间戳（访问时间和修改时间）元素的数组的指针，两个时间戳是用秒和微妙表示的。

struct timeval {

time_t tv_sec; /* seconds */

long tv_usec; /* microseconds */

};

注意，我们不能对状态更改时间st_ctim（i节点最近被修改的时间）指定一个值，因为调用utimes函数时，此字段会被自动更新。

在某些UNIX版本中，touch(1)命令使用这些函数中的某一个。另外，标准归档程序tar(1)和cpio(1)可选地调用这些函数，以便将一个文件的时间值设置为将它归档时保存的时间。
*** 实例
图4-21的程序使用带O_TRUNC选项的open函数将文件长度截断为0，但并不更改其访问时间及修改时间。为了做到这一点，首先用stat函数得到这些时间，然后截断文件，最后再用futimens函数重置这两个时间。可以用以下Linux命令演示图4-21中的程序：
#+begin_src c++
#include "apue.h"
#include <fcntl.h>
int main(int argc, char *argv[]) int i, fd;
struct stat statbuf;
struct timespec times[2];
for (i = 1; i < argc; i++)
{
  if (stat(argv[i], &statbuf) < 0)
  { /* fetch current times */
    err_ret("%s : stat error", argv[i]);
    continue;
  }
  if ((fd = open(argv[i]，O_RDWR | O_TRUNC)) < 0)
  {
    /* truncate */
    err_ret("%s: open error", argv[i]);
    continue;
    times[0] = -statbuf.st_atim;
    times[l] = statbuf.st_mtim;
    if (futimens(fd, times) < 0) /* reset times */
      err_ret("%s: futimens error", argv[i]);
    close(fd);
  }
exit 0 ) ;
}
#+END_SRC

#+begin_src bash
$ ls -l changemod times　　　　 查看长度和最后修改时间

-rwxr-xr-x 1 sar 13792 Jan 22 01:26 changemod

-rwxr-xr-x 1 sar 13824 Jan 22 01:26 times

$ ls -lu changemod times　　　　 查看最后访问时间

-rwxr-xr-x 1 sar 13792 Jan 22 22:22 changemod

-rwxr-xr-x 1 sar 13824 Jan 22 22:22 times

$ date　　　　　　　　　　　　　 打印当天日期Fri Jan 27 20:53:46 EST 2012

$ ./a.out changemod times　　　 运行图4-21的程序

$ ls -l changemod times　　　　 检查结果

-rwxr-xr-x 1 sar　　　　　0 Jan 22 01:26 changemod

-rwxr-xr-x 1 sar　　　　　0 Jan 22 01:26 times

$ ls -lu changemod times　　　　 检查最后访问时间

-rwxr-xr-x 1 sar　　　　　0 Jan 22 22:22 changemod

-rwxr-xr-x 1 sar　　　　　0 Jan 22 22:22 times

$ ls -lc changemod times　　　　 检查状态更改时间

-rwxr-xr-x 1 sar　　　　　0 Jan 27 20:53 changemod

-rwxr-xr-x 1 sar　　　　　0 Jan 27 20:53 times

#+END_SRC

正如我们所预见的一样，最后修改时间和最后访问时间未变。但是，状态更改时间则更改为程序运行时的时间。
** 函数mkdir、mkdirat和rmdir
用mkdir和mkdirat函数创建目录，用rmdir函数删除目录。
#+begin_src c++
#include <sys/stat.h>

int mkdir(const char *pathname, mode_t mode);

int mkdirat(int fd, const char *pathname, mode_t mode);

#+END_SRC

两个函数返回值：若成功，返回0；若出错，返回-1

这两个函数创建一个新的空目录。其中，.和..目录项是自动创建的。所指定的文件访问权限mode由进程的文件模式创建屏蔽字修改。

常见的错误是指定与文件相同的mode（只指定读、写权限）。但是，对于目录通常至少要设置一个执行权限位，以允许访问该目录中的文件名（见习题4.16）。

按照4.6节中讨论的规则来设置新目录的用户ID和组ID。

Solaris 10和Linux 3.2.0也使新目录继承父目录的设置组ID位。这就使得在新目录中创建的文件将继承该目录的组ID。对于 Linux，文件系统的实现决定是否支持此特征。例如，ext2、ext3和ext4文件系统用mount(1)命令的一个选项来控制是否支持此特征。但是，Linux的UFS文件系统实现则是不可选择的，新目录继承父目录的设置组ID位，这仿效了历史上BSD的实现。在BSD系统中，新目录的组ID是从父目录继承的。

基于BSD的系统并不要求在目录间传递设置组ID位，因为不论设置组ID位如何，新创建的文件和目录总是继承父目录的组ID。因为FreeBSD 8.0和Mac OS X 10.6.8是基于4.4BSD的，它们不要求继承设置组 ID 位。在这些平台上，新创建的文件和目录总是继承父目录的组 ID，这与是否设置了设置组ID位无关。

早期的UNIX版本并没有mkdir函数，它是由4.2BSD和SVR3引入的。在早期版本中，进程要调用mknod函数创建一个新目录，但是只有超级用户进程才能使用mknod函数。为了避免这一点，创建目录的命令mkdir(1)必须由根用户拥有，而且对它设置了设置用户ID位。要通过一个进程创建一个目录，必须用system(3)函数调用mkdir(1)命令。

mkdirat函数与mkdir函数类似。当fd参数具有特殊值AT_FDCWD或者pathname参数指定了绝对路径名时，mkdirat与mkdir完全一样。否则，fd参数是一个打开目录，相对路径名根据此打开目录进行计算。

用rmdir函数可以删除一个空目录。空目录是只包含.和..这两项的目录。
#+begin_src c++
#include <unistd.h>

int rmdir(const char *pathname);

#+END_SRC

返回值：若成功，返回0；若出错，返回-1

如果调用此函数使目录的链接计数成为 0，并且也没有其他进程打开此目录，则释放由此目录占用的空间。如果在链接计数达到0时，有一个或多个进程打开此目录，则在此函数返回前删除最后一个链接及.和..项。另外，在此目录中不能再创建新文件。但是在最后一个进程关闭它之前并不释放此目录。（即使另一些进程打开该目录，它们在此目录下也不能执行其他操作。这样处理的原因是，为了使rmdir函数成功执行，该目录必须是空的。）
** 读目录
对某个目录具有访问权限的任一用户都可以读该目录，但是，为了防止文件系统产生混乱，只有内核才能写目录。回忆 4.5 节，一个目录的写权限位和执行权限位决定了在该目录中能否创建新文件以及删除文件，它们并不表示能否写目录本身。

目录的实际格式依赖于 UNIX 系统实现和文件系统的设计。早期的系统（如 V7）有一个比较简单的结构：每个目录项是16个字节，其中14个字节是文件名，2个字节是i节点编号。而对于4.2BSD，由于它允许更长的文件名，所以每个目录项的长度是可变的。这就意味着读目录的程序与系统相关。为了简化读目录的过程，UNIX 现在包含了一套与目录有关的例程，它们是POSIX.1的一部分。很多实现阻止应用程序使用read函数读取目录的内容，由此进一步将应用程序与目录格式中与实现相关的细节隔离。
#+begin_src c++
#include <dirent.h>

DIR *opendir(const char *pathname);

DIR *fdopendir(int fd);

#+END_SRC

两个函数返回值：若成功，返回指针；若出错，返回NULL
#+begin_src c++
struct dirent *readdir(DIR *dp);
#+END_SRC

返回值：若成功，返回指针；若在目录尾或出错，返回NULL
#+begin_src c++
void rewinddir(DIR *dp);

int closedir(DIR *dp);

#+END_SRC

返回值：若成功，返回0；若出错，返回-1
#+begin_src c++
long telldir(DIR *dp);

#+END_SRC

返回值：与dp关联的目录中的当前位置
#+begin_src c++
void seekdir(DIR *dp, long loc);
#+END_SRC

fdopendir函数最早出现在SUSv4（Single UNIX Specification第4版）中，它提供了一种方法，可以把打开文件描述符转换成目录处理函数需要的DIR结构。

telldir 和 seekdir 函数不是基本 POSIX.1 标准的组成部分。它们是 Single UNIX Specification中的XSI扩展，所以可以期望所有符合UNIX系统的实现都会提供这两个函数。

回忆一下，在图1-3程序中（ls命令的基本实现部分）使用了其中几个函数。

定义在头文件<dirent.h>中的dirent结构与实现有关。实现对此结构所做的定义至少包含下列两个成员：
#+begin_example
ino_t d_ino;　　　　　　　 /* i-node number */

char　d_name[];　　　　　　/* null-terminated filename */

#+end_example

POSIX.1并没有定义d_ino项，因为这是一个实现特征，但在POSIX.1的XSI扩展中定义了d_ino。POSIX.1在此结构中只定义了d_name项。

注意，d_name项的大小并没有指定，但必须保证它能包含至少NAME_MAX个字节（不包含终止null字节，回忆图2-15）。因为文件名是以null字节结束的，所以在头文件中如何定义数组d_name并无多大关系，数组大小并不表示文件名的长度。

DIR 结构是一个内部结构，上述 7 个函数用这个内部结构保存当前正在被读的目录的有关信息。其作用类似于FILE结构。FILE结构由标准I/O库维护，我们将在第5章中对它进行说明。

由opendir和fdopendir返回的指向DIR结构的指针由另外5个函数使用。opendir执行初始化操作，使第一个readdir返回目录中的第一个目录项。DIR结构由fdopendir创建时，readdir返回的第一项取决于传给fdopendir函数的文件描述符相关联的文件偏移量。注意，目录中各目录项的顺序与实现有关。它们通常并不按字母顺序排列。


** 函数chdir、fchdir和getcwd
每个进程都有一个当前工作目录，此目录是搜索所有相对路径名的起点（不以斜线开始的路径名为相对路径名）。当用户登录到 UNIX 系统时，其当前工作目录通常是口令文件（/etc/passwd）中该用户登录项的第6个字段—用户的起始目录（home directory）。当前工作目录是进程的一个属性，起始目录则是登录名的一个属性。

进程调用chdir或fchdir函数可以更改当前工作目录。
#+begin_src c++
#include <unistd.h>

int chdir(const char *pathname);

int fchdir(int fd);

#+END_SRC

两个函数的返回值：若成功，返回0；若出错，返回-1

在这两个函数中，分别用pathname或打开文件描述符来指定新的当前工作目录。

因为内核必须维护当前工作目录的信息，所以我们应能获取其当前值。遗憾的是，内核为每个进程只保存指向该目录 v 节点的指针等目录本身的信息，并不保存该目录的完整路径名。

Linux内核可以确定完整路径名。完整路径名的各个组成部分分布在mount表和dcache表中，然后进行重新组装，比如在读取/proc/self/cwd符号链接时。

我们需要一个函数，它从当前工作目录（.）开始，用..找到其上一级目录，然后读其目录项，直到该目录项中的i节点编号与工作目录i节点编号相同，这样地就找到了其对应的文件名。按照这种方法，逐层上移，直到遇到根，这样就得到了当前工作目录完整的绝对路径名。很幸运，函数getcwd就提供了这种功能。

#include <unistd.h>

char *getcwd(char *buf, s i z e_t size);

返回值：若成功，返回buf；若出错，返回NULL

必须向此函数传递两个参数，一个是缓冲区地址buf，另一个是缓冲区的长度size（以字节为单位）。该缓冲区必须有足够的长度以容纳绝对路径名再加上一个终止 null 字节，否则返回出错（请回忆2.5.5节中有关为最大长度路径名分配空间的讨论）。

某些getcwd的早期实现允许第一个参数buf为NULL。在这种情况下，此函数调用malloc动态地分配size字节数的空间。这不是POSIX.1或Single UNIX Specification的所属部分，应当避免使用。
*** 实例
**** 实例1
因为当前工作目录是进程的一个属性，所以它只影响调用 chdir 的进程本身，而不影响其他进程（我们将在第8章更详细地说明进程之间的关系）。这就意味着图4-23的程序并不会产生我们可能希望得到的结果。
#+begin_src c++
#include "apue.h"
int main(void)
{
  if (chdir("/ tmp") < 0)
    err_sys("chdir failed");
  printf("chdir to /tmp succeeded \n");
  exit(0);
}

#+END_SRC
如果编译图4-23程序，并且调用其可执行目标代码文件mycd，则可以得到下列结果：

$ pwd

/usr/lib

$ mycd

chdir to /tmp succeeded

$ pwd

/usr/lib

从中可以看出，执行mycd命令的shell的当前工作目录并没有改变，这是shell执行程序工作方式的一个副作用。每个程序运行在独立的进程中，shell 的当前工作目录并不会随着程序调用chdir而改变。由此可见，为了改变shell进程自己的工作目录，shell应当直接调用chdir函数，为此，cd命令内建在shell中。
**** 实例2
图 4-24的程序将工作目录更改至一个指定的目录，然后调用 getcwd，最后打印该工作目录。
#+begin_src c++
#include "apue.h"
int main(void)
{
  char *ptr;
  size_t size;
  if (chdir("/usr/spool/uucppublic") < 0)
    err_sys("chdir failed");
  ptr = path_alloc(&size); /* our own function */
  if (getcwd(ptr, size) == NULL)
    err_sys("getcwd failed");
  printf("cwd = %s \n", ptr);
  exit(0);
}
#+END_SRC
如果运行该程序，则可得
#+begin_src bash
$ ./a.out

cwd = /var/spool/uucppublic

$ ls -l /usr/spool

lrwxrwxrwx 1 root 12 Jan 31 07:57 /usr/spool -> ../var/spool

#+END_SRC
注意，chdir跟随符号链接（正如我们希望的，如图4-17中所示），但是当getcwd沿目录树上溯遇到/var/spool 目录时，它并不了解该目录由符号链接/usr/spool 所指向。这是符号链接的一种特性。

当一个应用程序需要在文件系统中返回到它工作的出发点时，getcwd 函数是有用的。在更换工作目录之前，我们可以调用getcwd函数先将其保存起来。在完成了处理后，就可将所保存的原工作目录路径名作为调用参数传送给chdir，这样就返回到了文件系统中的出发点。

fchdir函数向我们提供了一种完成此任务的便捷方法。在更换到文件系统中的不同位置前，无需调用getcwd函数，而是使用open打开当前工作目录，然后保存其返回的文件描述符。当希望回到原工作目录时，只要简单地将该文件描述符传送给fchdir。
** 设备特殊文件
st_dev和st_rdev这两个字段经常引起混淆，在18.9节，我们编写ttyname函数时，需要使用这两个字段。有关规则很简单：

•每个文件系统所在的存储设备都由其主、次设备号表示。设备号所用的数据类型是基本系统数据类型dev_t。主设备号标识设备驱动程序，有时编码为与其通信的外设板；次设备号标识特定的子设备。回忆图4-13，一个磁盘驱动器经常包含若干个文件系统。在同一磁盘驱动器上的各文件系统通常具有相同的主设备号，但是次设备号却不同。

•我们通常可以使用两个宏：major和minor来访问主、次设备号，大多数实现都定义这两个宏。这就意味着我们无需关心这两个数是如何存放在dev_t对象中的。

早期的系统用16位整型存放设备号：8位用于主设备号，8位用于次设备号。FreeBSD 8.0和Mac OS X 10.6.8使用32位整型，其中8位表示主设备号，24位表示次设备号。在32位系统中，Solaris 10用32位整型表示dev_t，其中14位用于主设备号，18位用于次设备号。在64位系统中，Solaris 10用64位整型表示dev_t，主设备号和次设备号各用其中的32位表示。在Linux 3.2.0上，虽然dev_t是64位整型，但其中只有12位用于主设备号，20位用于次设备号。

POSIX.1说明dev_t类型是存在的，但没有定义它包含什么，或如何取得其内容。大多数实现定义了宏major和minor，但在哪一个头文件中定义它们则与实现有关。基于BSD的UNIX系统将它们定义在<sys/types>中。Solaris 在<sys/mkdev.h>中定义了它们的函数原型，因为在<sys/sysmacros.h>中的宏定义都弃用了。Linux 将它们定义在<sys/sysmacros.h>中，而该头文件又包含在<sys/type.h>中。

•系统中与每个文件名关联的 st_dev 值是文件系统的设备号，该文件系统包含了这一文件名以及与其对应的i节点。

•只有字符特殊文件和块特殊文件才有st_rdev值。此值包含实际设备的设备号。
*** 实例
图4-25的程序为每个命令行参数打印设备号，另外，若此参数引用的是字符特殊文件或块特殊文件，则还打印该特殊文件的st_rdev值。
#+begin_src c++
#include "apue.h"
#ifdef SOLARIS
#include <sys/mkdev.h>
#endif
int main(int argc, char *argv[])
{
  int i;
  struct stat buf;
  for (i = 1; i < argc; i++)
  {
    printf("%s: ", argv[i]);
    if (stat(argv[i], &buf) < 0)
    {
      err_ret("stat error");
      continue;
    }
    printf("dev = %d/%d", major(buf.st_dev), minor(buf.st_dev));
    if (S_ISCHR(buf.st_mode) l / S_ISBLK(buf.st_mode))
    {
      printf("(%s) rdev = %d/ %d",
             (S_ISCHR(buf.st_mode)) ? "character" : "block", major(buf.st_rdev), minor(buf.st_rdev));
    }
    printf("\n");
  }
  exit(O);
}
#+END_SRC
在Linux上运行此程序得到下面的输出：

$ ./a.out / /home/sar /dev/tty[01]

/: dev = 8/3

/home/sar: dev = 8/4

/dev/tty0: dev = 0/5 (character) rdev = 4/0

/dev/tty1: dev = 0/5 (character) rdev = 4/1

$ mount　　　　　　　　　　　　　　　哪些目录安装在哪些设备上?

/dev/sda3 on / type ext3 (rw,errors=remount-ro,commit=0)

/dev/sda4 on /home type ext2 (rw,commit=0)

$ ls -l /dev/tty[01] /dev/sda[34]

brw-rw---- 1 root　　8, 3 2011-07-01 11:08 /dev/sda3

brw-rw---- 1 root　　8, 4 2011-07-01 11:08 /dev/sda4

crw--w---- 1 root　　4, 0 2011-07-01 11:08 /dev/tty0

crw------- 1 root　　4, 1 2011-07-01 11:08 /dev/tty1

传给该程序的前两个参数是目录（/和/home/sar），后两个参数是设备名/dev/tty[01]。（我们用 shell 正则表达式语言以缩短所需的输入量。shell 将字符串/dev/tty[01]扩展为/dev/tty0 /dev/tty1。）

我们期望设备是字符特殊文件。从程序的输出可见，根目录和/home/sar 目录的设备号不同，这表示它们位于不同的文件系统中。运行mount(1)命令可以证明了这一点。

然后用ls命令查看由mount命令报告的两个磁盘设备和两个终端设备。这两个磁盘设备是块特殊文件，而两个终端设备是字符特殊文件。（通常，只有那些包含随机访问文件系统的设备类型是块特殊文件设备，如硬盘驱动器、软盘驱动器和CD-ROM等。UNIX的早期版本支持磁带存放文件系统，但这从未广泛使用过。）

注意，两个终端设备（st_dev）的文件名和i节点在设备0/5上（devtmpfs伪文件系统，它实现了/dev文件系统），但是它们的实际设备号是4/0和4/1。
** 文件访问权限位小结
我们已经说明了所有文件访问权限位，其中某些位有多种用途。图4-26列出了所有这些权限位，以及它们对普通文件和目录文件的作用。

最后9个常量还可以分成如下3组：
- S_IRWXU = S_IRUSR｜S_IWUSR｜S_IXUSR
- S_IRWXG = S_IRGRP｜S_IWGRP｜S_IXGRP
- S_IRWXO = S_IROTH｜S_IWOTH｜S_IXOTH


#+DOWNLOADED: screenshot @ 2023-07-11 23:21:23
[[file:images/linux笔记/UNIX-文件和目录/2023-07-11_23-21-23_screenshot.png]]

* UNIX-标准I/O库
标准I/O库处理很多细节，如缓冲区分配、以优化的块长度执行I/O等。这些处理使用户不必担心如何选择使用正确的块长度.
** 流和FILE对象
在文件IO库里,所有I/O函数都是围绕文件描述符的。当打开一个文件时，即返回一个文件描述符，然后该文件描述符就用于后续的I/O操作。
而对于标准I/O库，它们的操作是围绕流（stream）进行的.当用标准I/O库打开或创建一个文件时，我们已使一个流与一个文件相关联。

对于ASCII字符集，一个字符用一个字节表示。对于国际字符集，一个字符可用多个字节表示。
标准I/O文件流可用于单字节或多字节（“宽”）字符集。
流的定向（stream's orientation）决定了所读、写的字符是单字节还是多字节的。
当一个流最初被创建时，它并没有定向。如若在未定向的流上使用一个多字节 I/O 函数（见<wchar.h>），则将该流的定向设置为宽定向的。
若在未定向的流上使用一个单字节I/O函数，则将该流的定向设为字节定向的。
只有两个函数可改变流的定向。freopen函数（稍后讨论）清除一个流的定向；fwide函数可用于设置流的定向。
#+begin_src c++
#include <stdio.h>

#include <wchar.h>

int fwide(FILE *fp, int mode);
#+END_SRC

返回值：若流是宽定向的，返回正值；若流是字节定向的，返回负值；若流是未定向的，返回0

根据mode参数的不同值，fwide函数执行不同的工作。
- 如若mode参数值为负，fwide将试图使指定的流是字节定向的。
- 如若mode参数值为正，fwide将试图使指定的流是宽定向的。
- 如若mode参数值为0，fwide将不试图设置流的定向，但返回标识该流定向的值。

注意，fwide 并不改变已定向流的定向。还应注意的是，fwide 无出错返回。
试想，如若流是无效的，那么将发生什么呢？我们唯一可依靠的是，在调用 fwide 前先清除 errno，从fwide返回时检查errno的值。在本书的其余部分，我们只涉及字节定向流。

当打开一个流时，标准I/O函数fopen返回一个指向FILE对象的指针。该对象通常是一个结构，它包含了标准I/O库为管理该流需要的所有信息，包括用于实际I/O的文件描述符、指向用于该流缓冲区的指针、缓冲区的长度、当前在缓冲区中的字符数以及出错标志等。

应用程序没有必要检验FILE对象。为了引用一个流，需将FILE指针作为参数传递给每个标准I/O函数。在本书中，我们称指向FILE对象的指针（类型为FILE*）为文件指针。
** 标准输入、标准输出和标准错误
对一个进程预定义了 3 个流，并且这 3 个流可以自动地被进程使用，它们是：标准输入、标准输出和标准错误。
这些流引用的文件与在 3.2 节中提到文件描述符 STDIN_FILENO、STDOUT_FILENO 和STDERR_FILENO所引用的相同。

这3个标准I/O流通过预定义文件指针stdin、stdout和stderr加以引用。这3个文件指针定义在头文件<stdio.h>中。
** 缓冲
标准I/O库提供缓冲的目的是尽可能减少使用read和write调用的次数（见图3-6，其中显示了在不同缓冲区长度情况下，执行I/O所需的CPU时间量）。
它也对每个I/O流自动地进行缓冲管理，从而避免了应用程序需要考虑这一点所带来的麻烦。遗憾的是，标准I/O库最令人迷惑的也是它的缓冲。
*** 三种类型的缓冲
标准I/O提供了以下3种类型的缓冲。

（1）全缓冲。在这种情况下，在填满标准I/O缓冲区后才进行实际I/O操作。对于驻留在磁盘上的文件通常是由标准I/O库实施全缓冲的。在一个流上执行第一次I/O操作时，相关标准I/O函数通常调用malloc获得需使用的缓冲区。

术语冲洗（flush）说明标准I/O缓冲区的写操作。
缓冲区可由标准I/O例程自动地冲洗（例如，当填满一个缓冲区时），或者可以调用函数 fflush 冲洗一个流。
值得注意的是，在 UNIX环境中，flush有两种意思。在标准I/O库方面，flush（冲洗）意味着将缓冲区中的内容写到磁盘上（该缓冲区可能只是部分填满的）。在终端驱动程序方面，flush（刷清）表示丢弃已存储在缓冲区中的数据。

（2）行缓冲。在这种情况下，当在输入和输出中遇到换行符时，标准I/O库执行I/O操作。这允许我们一次输出一个字符（用标准I/O函数fputc），但只有在写了一行之后才进行实际I/O操作。当流涉及一个终端时（如标准输入和标准输出），通常使用行缓冲。

对于行缓冲有两个限制。
第一，因为标准I/O库用来收集每一行的缓冲区的长度是固定的，所以只要填满了缓冲区，那么即使还没有写一个换行符，也进行I/O操作。
第二，任何时候只要通过标准I/O 库要求从（a）一个不带缓冲的流，或者（b）一个行缓冲的流（它从内核请求需要数据）得到输入数据，那么就会冲洗所有行缓冲输出流。在（b）中带了一个在括号中的说明，其理由是，所需的数据可能已在该缓冲区中，它并不要求一定从内核读数据。很明显，从一个不带缓冲的流中输入（即（a）项）需要从内核获得数据。

（3）不带缓冲。标准I/O库不对字符进行缓冲存储。例如，若用标准I/O函数fputs写15个字符到不带缓冲的流中，我们就期望这15个字符能立即输出，很可能使用文件IO里的write函数将这些字符写到相关联的打开文件中。

标准错误流stderr通常是不带缓冲的，这就使得出错信息可以尽快显示出来，而不管它们是否含有一个换行符。

ISO C要求下列缓冲特征。
- 当且仅当标准输入和标准输出并不指向交互式设备时，它们才是全缓冲的。
- 标准错误决不会是全缓冲的。

但是，这并没有告诉我们如果标准输入和标准输出指向交互式设备时，它们是不带缓冲的还是行缓冲的；以及标准错误是不带缓冲的还是行缓冲的。很多系统默认使用下列类型的缓冲：
- 标准错误是不带缓冲的。
- 若是指向终端设备的流，则是行缓冲的；否则是全缓冲的。

本书讨论的4种平台都遵从标准I/O缓冲的这些惯例，标准错误是不带缓冲的，打开至终端设备的流是行缓冲的，其他流是全缓冲的。
*** 更改缓冲类型
对任何一个给定的流，如果我们并不喜欢这些系统默认，则可调用下列两个函数中的一个更改缓冲类型。
#+begin_src c++
#include <stdio.h>

void setbuf(FILE *restrict fp, char *restrict buf);

int setvbuf(FILE *restrict fp, char *restrict buf, int mode, size_t size);
#+END_SRC

返回值：若成功，返回0；若出错，返回非0

这些函数一定要在流已被打开后调用（这是十分明显的，因为每个函数都要求一个有效的文件指针作为它们的第一个参数），而且也应在对该流执行任何一个其他操作之前调用。

可以使用setbuf 函数打开或关闭缓冲机制。为了带缓冲进行 I/O，参数buf必须指向一个长度为BUFSIZ的缓冲区（该常量定义在<stdio.h>中）。通常在此之后该流就是全缓冲的，但是如果该流与一个终端设备相关，那么某些系统也可将其设置为行缓冲的。为了关闭缓冲，将buf设置为NULL。

使用setvbuf，我们可以精确地说明所需的缓冲类型。这是用mode参数实现的：
- _IOFBF 全缓冲
- _IOLBF 行缓冲
- _IONBF 不带缓冲

如果指定一个不带缓冲的流，则忽略buf和size参数。
如果指定全缓冲或行缓冲，则buf和size可选择地指定一个缓冲区及其长度。
如果该流是带缓冲的，而buf是NULL，则标准I/O库将自动地为该流分配适当长度的缓冲区。适当长度指的是由常量BUFSIZ所指定的值。

某些C函数库实现使用stat结构中的成员st_blksize所指定的值决定最佳I/O缓冲区长度。

图5-1列出了这两个函数的动作，以及它们的各个选项。

#+DOWNLOADED: screenshot @ 2023-07-08 10:18:51
[[file:images/linux笔记/UNIX-标准I/O库/2023-07-08_10-18-51_screenshot.png]]
要了解，如果在一个函数内分配一个自动变量类的标准I/O缓冲区，则从该函数返回之前，必须关闭该流（7.8节将对此做更多讨论）。另外，其些实现将缓冲区的一部分用于存放它自己的管理操作信息，所以可以存放在缓冲区中的实际数据字节数少于 size。一般而言，应由系统选择缓冲区的长度，并自动分配缓冲区。在这种情况下关闭此流时，标准I/O库将自动释放缓冲区。
*** 冲洗一个流
任何时候，我们都可强制冲洗一个流。
#+begin_src c++
#include<stdio.h>

int fflush(FILE *fp);

#+END_SRC

返回值：若成功，返回0；若出错，返回EOF

此函数使该流所有未写的数据都被传送至内核。作为一种特殊情形，如若fp是NULL，则此函数将导致所有输出流被冲洗。
** 打开流
下列3个函数打开一个标准I/O流。
#+begin_src c++
#include <stdio.h>

FILE *fopen(const char *restrict pathname, const char *restrict type);

FILE *freopen(const char *restrict pathname, const char *restrict type, FILE *restrict fp);

FILE *fdopen(int fd, const char *type);

#+END_SRC

3个函数的返回值：若成功，返回文件指针；若出错，返回NULL

这3个函数的区别如下。
（1）fopen函数打开路径名为pathname的一个指定的文件。
（2）freopen 函数在一个指定的流上打开一个指定的文件，如若该流已经打开，则先关闭该流。若该流已经定向，则使用 freopen 清除该定向。此函数一般用于将一个指定的文件打开为一个预定义的流：标准输入、标准输出或标准错误。
（3）fdopen函数取一个已有的文件描述符（我们可能从open、dup、dup2、fcntl、pipe、socket、socketpair或accept函数得到此文件描述符），并使一个标准的I/O流与该描述符相结合。此函数常用于由创建管道和网络通信通道函数返回的描述符。因为这些特殊类型的文件不能用标准I/O函数fopen打开，所以我们必须先调用设备专用函数以获得一个文件描述符，然后用fdopen使一个标准I/O流与该描述符相结合。

fopen和freopen是ISO C的所属部分。而ISO C并不涉及文件描述符，所以仅有POSIX.1具有fdopen。

type参数指定对该I/O流的读、写方式，ISO C规定type参数可以有15种不同的值，如图5-2所示。
#+DOWNLOADED: screenshot @ 2023-07-09 14:43:28
[[file:images/linux笔记/UNIX-标准I/O库/2023-07-09_14-43-28_screenshot.png]]
使用字符b作为type的一部分，这使得标准I/O系统可以区分文本文件和二进制文件。因为UNIX内核并不对这两种文件进行区分，所以在UNIX系统环境下指定字符b作为type的一部分实际上并无作用。

对于fdopen，type参数的意义稍有区别。因为该描述符已被打开，所以fdopen为写而打开并不截断该文件。（例如，若该描述符原来是由open函数创建的，而且该文件已经存在，则其O_TRUNC标志将决定是否截断该文件。fdopen函数不能截断它为写而打开的任一文件。）另外，标准I/O追加写方式也不能用于创建该文件（因为如果一个描述符引用一个文件，则该文件一定已经存在）。

当用追加写类型打开一个文件后，每次写都将数据写到文件的当前尾端处。如果有多个进程用标准I/O追加写方式打开同一文件，那么来自每个进程的数据都将正确地写到文件中。

4.4BSD 以前的伯克利版本以及 Kernighan 和 Ritchie[1988]第 177 页上所示的简单版本的 fopen 函数并不能正确地处理追加写方式。这些版本在打开流时，调用lseek定位到文件尾端。在涉及多个进程时，为了正确地支持追加写方式，该文件必须用O_APPEND标志打开，我们已在3.3节中对此进行了讨论。在每次写前，做一次lseek操作同样也不能正确工作。

当以读和写类型打开一个文件时（type中+号），具有下列限制。
- 如果中间没有fflush、fseek、fsetpos或rewind，则在输出的后面不能直接跟随输入。
- 如果中间没有fseek、fsetpos或rewind，或者一个输入操作没有到达文件尾端，则在输入操作之后不能直接跟随输出。

对应于图5-2，图5-3中列出了打开一个流的6种不同的方式。

#+DOWNLOADED: screenshot @ 2023-07-09 14:49:52
[[file:images/linux笔记/UNIX-标准I/O库/2023-07-09_14-49-52_screenshot.png]]
注意，在指定w或a类型创建一个新文件时，我们无法说明该文件的访问权限位（第3章中所述的open函数和creat函数则能做到这一点）。POSIX.1要求实现使用如下的权限位集来创建文件：

S_IRUSR | S_IWUSR | S_IRGRP | S_IWGRP | S_IROTH | S_IWOTH

回忆4.8节，我们可以通过调整umask值来限制这些权限。

除非流引用终端设备，否则按系统默认，流被打开时是全缓冲的。若流引用终端设备，则该流是行缓冲的。一旦打开了流，那么在对该流执行任何操作之前，如果希望，则可使用前节所述的setbuf和setvbuf改变缓冲的类型。

调用fclose关闭一个打开的流。
#+begin_src c++
#include <stdio.h>

int fclose(FILE *fp);

#+END_SRC

返回值：若成功，返回0；若出错，返回EOF

在该文件被关闭之前，冲洗缓冲中的输出数据。缓冲区中的任何输入数据被丢弃。如果标准I/O库已经为该流自动分配了一个缓冲区，则释放此缓冲区。

当一个进程正常终止时（直接调用exit函数，或从main函数返回），则所有带未写缓冲数据的标准I/O流都被冲洗，所有打开的标准I/O流都被关闭。
** 读和写流
一旦打开了流，则可在3种不同类型的非格式化I/O中进行选择，对其进行读、写操作。

（1）每次一个字符的I/O。一次读或写一个字符，如果流是带缓冲的，则标准I/O函数处理所有缓冲。

（2）每次一行的I/O。如果想要一次读或写一行，则使用fgets和fputs。每行都以一个换行符终止。当调用fgets时，应说明能处理的最大行长。

（3）直接 I/O。fread和fwrite函数支持这种类型的I/O。每次 I/O操作读或写某种数量的对象，而每个对象具有指定的长度。这两个函数常用于从二进制文件中每次读或写一个结构。

直接I/O（direct I/O）这个术语来自ISO C标准，有时也被称为：二进制I/O、一次一个对象I/O、面向记录的I/O或面向结构的I/O。不要把这个特性和FreeBSD和Linux支持的open函数的O_DIRECT标志混淆，它们之间是没有关系的。

*** 输入函数

以下3个函数可用于一次读一个字符。
#+begin_src c++
#include <stdio.h>

int getc(FILE *fp);

int fgetc(FILE *fp);

int getchar(void);

#+END_SRC

3个函数的返回值：若成功，返回下一个字符；若已到达文件尾端或出错，返回EOF

函数getchar等同于getc(stdin)。前两个函数的区别是，getc可被实现为宏，而fgetc不能实现为宏。这意味着以下几点。

（1）getc的参数不应当是具有副作用的表达式，因为它可能会被计算多次。

（2）因为fgetc一定是个函数，所以可以得到其地址。这就允许将fgetc的地址作为一个参数传送给另一个函数。

（3）调用fgetc所需时间很可能比调用getc要长，因为调用函数所需的时间通常长于调用宏。

这3个函数在返回下一个字符时，将其unsigned char类型转换为int类型。说明为无符号的理由是，如果最高位为1也不会使返回值为负。要求整型返回值的理由是，这样就可以返回所有可能的字符值再加上一个已出错或已到达文件尾端的指示值。在<stdio.h>中的常量EOF被要求是一个负值，其值经常是−1。这就意味着不能将这3个函数的返回值存放在一个字符变量中，以后还要将这些函数的返回值与常量EOF比较。

注意，不管是出错还是到达文件尾端，这3个函数都返回同样的值。为了区分这两种不同的情况，必须调用ferror或feof。
#+begin_src c++
#include <stdio.h>

int ferror(FILE *fp);

int feof(FILE *fp);

#+END_SRC

两个函数返回值：若条件为真，返回非0（真）；否则，返回0（假）

#+begin_src c++
void clearerr(FILE *fp);
#+END_SRC

在大多数实现中，为每个流在FILE对象中维护了两个标志：
- 出错标志；
- 文件结束标志。

调用clearerr可以清除这两个标志。

从流中读取数据以后，可以调用ungetc将字符再压送回流中。
#+begin_src c++
#include <stdio.h>

int ungetc(int c, FILE *fp);

#+END_SRC

返回值：若成功，返回c；若出错，返回EOF

压送回到流中的字符以后又可从流中读出，但读出字符的顺序与压送回的顺序相反。应当了解，虽然ISO C允许实现支持任何次数的回送，但是它要求实现提供一次只回送一个字符。我们不能期望一次能回送多个字符。

回送的字符，不一定必须是上一次读到的字符。不能回送EOF。但是当已经到达文件尾端时，仍可以回送一个字符。下次读将返回该字符，再读则返回EOF。之所以能这样做的原因是，一次成功的ungetc调用会清除该流的文件结束标志。

当正在读一个输入流，并进行某种形式的切词或记号切分操作时，会经常用到回送字符操作。有时需要先看一看下一个字符，以决定如何处理当前字符。然后就需要方便地将刚查看的字符回送，以便下一次调用getc时返回该字符。如果标准I/O库不提供回送能力，就需将该字符存放到一个我们自己的变量中，并设置一个标志以便判别在下一次需要一个字符时是调用 getc，还是从我们自己的变量中取用这个字符。

用ungetc压送回字符时，并没有将它们写到底层文件中或设备上，只是将它们写回标准I/O库的流缓冲区中。

*** 输出函数

对应于上面所述的每个输入函数都有一个输出函数。
#+begin_src c++
#include <stdio.h>

int putc(int c, FILE *fp);

int fputc(int c, FILE *fp);

int putchar(int c);

#+END_SRC

3个函数返回值：若成功，返回c；若出错，返回EOF

与输入函数一样，putchar(c)等同于putc(c, stdout)，putc可被实现为宏，而fputc不能实现为宏。
** 每次一行I/O
下面两个函数提供每次输入一行的功能。
#+begin_src c++
#include <stdio.h>

char *fgets(char *restrict buf, int n，FILE *restrict fp);

char *gets(char *buf);
#+END_SRC

两个函数返回值：若成功，返回buf；若已到达文件尾端或出错，返回NULL

这两个函数都指定了缓冲区的地址，读入的行将送入其中。gets从标准输入读，而fgets则从指定的流读。

对于fgets，必须指定缓冲的长度n。此函数一直读到下一个换行符为止，但是不超过n−1个字符，读入的字符被送入缓冲区。该缓冲区以null字节结尾。如若该行包括最后一个换行符的字符数超过n−1，则fgets只返回一个不完整的行，但是，缓冲区总是以null字节结尾。对fgets的下一次调用会继续读该行。

gets 是一个不推荐使用的函数。其问题是调用者在使用 gets 时不能指定缓冲区的长度。这样就可能造成缓冲区溢出（如若该行长于缓冲区长度），写到缓冲区之后的存储空间中，从而产生不可预料的后果。这种缺陷曾被利用，造成1988年的因特网蠕虫事件。有关说明请见1989年6月的Communications of the ACM（vol.32,no.6）。gets与fgets的另一个区别是，gets并不将换行符存入缓冲区中。

这两个函数对换行符处理方式的差别与UNIX的进展有关。在V7的手册（1979）中就说明：“为了向后兼容，gets删除换行符，而fgets则保留换行符。”

虽然ISO C要求提供gets，但请使用fgets，而不要使用gets。事实上，在SUSv4中， gets被标记为弃用的接口，而且在ISO C标准的最新版本（ISO/IEC 9899:2011）中已被忽略。

fputs和puts提供每次输出一行的功能。

#include <stdio.h>

int fputs(const char *restrict str, FILE *restrict fp);

int puts(const char *str);

两个函数返回值：若成功，返回非负值；若出错，返回EOF

函数fputs将一个以null字节终止的字符串写到指定的流，尾端的终止符null不写出。注意，这并不一定是每次输出一行，因为字符串不需要换行符作为最后一个非null字节。通常，在null字节之前是一个换行符，但并不要求总是如此。

puts将一个以null字节终止的字符串写到标准输出，终止符不写出。但是，puts随后又将一个换行符写到标准输出。

puts 并不像它所对应的 gets 那样不安全。但是我们还是应避免使用它，以免需要记住它在最后是否添加了一个换行符。如果总是使用 fgets 和 fputs, 那么就会熟知在每行终止处我们必须自己处理换行符。
** 标准I/O的效率
** 二进制I/O
** 定位流
** 格式化I/O
** 实现细节
** 临时文件
** 内存流
** 标准I/O的替代软件
* UNIX-进程环境
** main函数
C程序总是从main函数开始执行。main函数的原型是：

int main(int argc, char *argv[]);

其中，argc是命令行参数的数目，argv是指向参数的各个指针所构成的数组。7.4 节将对命令行参数进行说明。

当内核执行C程序时（使用一个exec函数，8.10节将说明exec函数），在调用main前先调用一个特殊的启动例程。可执行程序文件将此启动例程指定为程序的起始地址——这是由连接编辑器设置的，而连接编辑器则由C编译器调用。启动例程从内核取得命令行参数和环境变量值，然后为按上述方式调用main函数做好安排。
** 进程终止
有8种方式使进程终止（termination），其中5种为正常终止，它们是：
1. 从main返回;
2. 调用exit;
3. 调用_exit或_Exit;
4. 最后一个线程从其启动例程返回;
5. 从最后一个线程调用pthread_exit.

异常终止有3种方式，它们是：
1. 调用abort;
2. 接到一个信号;
3. 最后一个线程对取消请求做出响应

上节提及的启动例程是这样编写的，使得从main返回后立即调用exit函数。如果将启动例程以C代码形式表示（实际上该例程常常用汇编语言编写），则它调用main函数的形式可能是：
#+begin_src c++
exit(main(argc, argv));
#+END_SRC
*** 退出函数
3个函数用于正常终止一个程序：_exit和_Exit立即进入内核，exit则先执行一些清理处理，然后返回内核。
#+begin_src c++
#include <stdlib.h>

void exit(int status);

void _Exit(int status);

#include <unistd.h>

void _exit(int status);

#+END_SRC
使用不同头文件的原因是exit和_Exit是由ISO C说明的，而_exit是由POSIX.1说明的。

由于历史原因，exit 函数总是执行一个标准 I/O 库的清理关闭操作：对于所有打开流调用fclose函数。回忆5.5节，这造成输出缓冲中的所有数据都被冲洗（写到文件上）。

3个退出函数都带一个整型参数，称为终止状态（或退出状态，exit status）。大多 数UNIX系统shell都提供检查进程终止状态的方法。如果（a）调用这些函数时不带终止状态，或（b）main执行了一个无返回值的return语句，或（c）main没有声明返回类型为整型，则该进程的终止状态是未定义的。但是，若main的返回类型是整型，并且main执行到最后一条语句时返回（隐式返回），那么该进程的终止状态是0。

这种处理是ISO C标准1999版引入的。历史上，若main函数终止时没有显式使用return语句或调用exit函数，那么进程终止状态是未定义的。

main函数返回一个整型值与用该值调用exit是等价的。于是在main函数中

exit(0);

等价于

return(0);

**** 实例

图7-1中的程序是经典的“hello, world”实例。

#+DOWNLOADED: screenshot @ 2023-07-24 22:31:58
[[file:images/linux笔记/UNIX-进程环境/2023-07-24_22-31-58_screenshot.png]]
对该程序进行编译，然后运行，则可见到其终止码是随机的。如果在不同的系统上编译该程序，我们很可能得到不同的终止码，这取决于main函数返回时栈和寄存器的内容：
#+begin_src bash
$ gcc hello.c

$ ./a.out
hello, world

$ echo $?  打印终止状态
13
#+END_SRC

现在，我们启用1999 ISO C编译器扩展，则可见到终止码改变了：
#+begin_src bash
$ gcc -std=c99 hello.c 启用 gcc的1999 ISO C扩展

$ echo $?   打印终止状态
hello.c:4: warning: return type defaults to 'int'

$ ./a.out
hello, world
0
#+END_SRC

注意，当我们启用1999 ISO C扩展时，编译器发出警告消息。打印该警告消息的原因是：main函数的类型没有显式地声明为整型。
如果我们增加了这一声明，那么此警告消息就不会出现。但是，如果我们使编译器所推荐的警告消息都起作用（使用-Wall标志），则可能见到类似于“control reaches end of nonvoid function.”（控制到达非void函数的尾端）这样的警告消息。

将main声明为返回整型，但在main函数体内用exit代替return，对某些C编译器和UNIX lint(1)程序而言会产生不必要的警告信息，因为这些编译器并不了解main中的exit与return语句的作用相同。避开这种警告信息的一种方法是在main中使用return语句而不是exit。但是这样做的结果是不能用UNIX的grep实用程序来找出程序中所有的exit调用。另一个解决方法是将main说明为返回void而不是int，然后仍然调用exit。这样做可以避免编译器的警告，但从程序设计角度看却并不正确，而且会产生其他的编译警告，因为 main 的返回类型应当是带符号整型。本章将main表示为返回整型，因为这是ISO C和POSIX.1所定义的。

不同的编译器产生警告消息的详细程度是不一样的。除非使用警告选项，否则GNU C编译器不会发出不必要的警告消息。

*** 函数atexit

按照ISO C的规定，一个进程可以登记多至32个函数，这些函数将由exit自动调用。我们称这些函数为终止处理程序（exit handler），并调用atexit函数来登记这些函数。
#+begin_src c++
#include <stdlib.h>

int atexit(void (*func)(void));
#+END_SRC

返回值：若成功，返回0；若出错，返回非0

其中，atexit 的参数是一个函数地址，当调用此函数时无需向它传递任何参数，也不期望它返回一个值。exit调用这些函数的顺序与它们登记时候的顺序相反。同一函数如若登记多次，也会被调用多次。

终止处理程序这一机制是由ANSI C标准于1989年引入的。早于ANSI C的系统，如SVR3和4.3BSD，都不提供这种终止处理程序。

ISO C要求，系统至少应支持32个终止处理程序，但实现经常会提供更多的支持（参见图2-15）。为了确定一个给定的平台支持的最大终止处理程序数，可以使用sysconf函数（如图2-14所示）。

根据ISO C和POSIX.1，exit首先调用各终止处理程序，然后关闭（通过fclose）所有打开流。POSIX.1扩展了ISO C标准，它说明，如若程序调用exec函数族中的任一函数，则将清除所有已安装的终止处理程序。图7-2显示了一个C程序是如何启动的，以及它终止的各种方式。

#+DOWNLOADED: screenshot @ 2023-07-24 22:35:48
[[file:images/linux笔记/UNIX-进程环境/2023-07-24_22-35-48_screenshot.png]]
注意，内核使程序执行的唯一方法是调用一个exec函数。进程自愿终止的唯一方法是显式或隐式地（通过调用 exit）调用_exit 或_Exit。进程也可非自愿地由一个信号使其终止（图 7-2中没有显示）。

**** 实例

图7-3的程序说明如何使用atexit函数。
#+begin_src c++
#include "apue.h"
static void my_exit1(void);
static void my_exit2(void);

int main (void)(
if (atexit(my_exit2) != o )
    err_sys ( "can't register my_exit2" );
if (atexit(my_exit1) != o )
    err_sys ( "can't register my_exit1");
if (atexit (my_exit1) != o )
    err_sys ( "can't register my_exitl" ) ;
    
    printf ( "main is done\n" ) ;return (0 ) ;
}

static void my_exit1 (void)(
    printf ( "first exit handler\n" );
}
static void my_exit2 (void)(
    printf ("second exit handlerln" );
}
#+END_SRC
图7-3 终止处理程序实例

执行该程序产生：
#+begin_src bash
$ ./a.out
main is done
first exit handler
first exit handler
second exit handler
#+END_SRC

终止处理程序每登记一次，就会被调用一次。在图7-3的程序中，第一个终止处理程序被登记两次，所以也会被调用两次。注意，在main中没有调用exit，而是用了return语句。
** 命令行参数
当执行一个程序时，调用exec的进程可将命令行参数传递给该新程序。这是UNIX shell的一部分常规操作。在前几章的很多实例中，我们已经看到了这一点。

*** 实例

图7-4 所示的程序将其所有命令行参数都回显到标准输出上。注意，通常的 echo(1)程序不回显第0个参数。
#+begin_src c++
#include "apue.h"
int main(int argc, char *argv[])
{
    inti;
    for (i = 0; i < argc; i++) /* echo all command-line args */
        printf("argv [ %d] : %s ln", i, argv[i]);
    exit(O);
}
#+END_SRC
图7-4 将所有命令行参数回显到标准输出

编译此程序，并将可执行代码文件命名为echoarg，则得到：
#+begin_src bash
$ ./echoarg arg1 TEST foo
argv[0]: ./echoarg
argv[1]: arg1
argv[2]: TEST
argv[3]: foo
#+END_SRC

ISO C和POSIX.1都要求argv[argc]是一个空指针。这就使我们可以将参数处理循环改写为：

for (i = 0; argv[i] != NULL; i++)

** 环境表
每个程序都接收到一张环境表。与参数表一样，环境表也是一个字符指针数组，其中每个指针包含一个以null结束的C字符串的地址。全局变量environ则包含了该指针数组的地址：

extern char **environ;

例如，如果该环境包含5个字符串，那么它看起来如图7-5中所示。其中，每个字符串的结尾处都显式地有一个null字节。我们称environ为环境指针（environment pointer），指针数组为环境表，其中各指针指向的字符串为环境字符串。

#+DOWNLOADED: screenshot @ 2023-07-24 23:05:52
[[file:images/linux笔记/UNIX-进程环境/2023-07-24_23-05-52_screenshot.png]]
按照惯例，环境由
name = value
这样的字符串组成，

如图7-5中所示。大多数预定义名完全由大写字母组成，但这只是一个惯例。

在历史上，大多数UNIX系统支持main函数带3个参数，其中第3个参数就是环境表地址：

int main(int argc, char *argv[], char *envp[]);

因为ISO C规定main函数只有两个参数，而且第3个参数与全局变量environ相比也没有带来更多益处，所以 POSIX.1 也规定应使用 environ 而不使用第 3 个参数。通常用 getenv 和putenv函数（见7.9节）来访问特定的环境变量，而不是用environ变量。但是，如果要查看整个环境，则必须使用environ指针。
** C程序的存储空间布局
历史沿袭至今，C程序一直由下列几部分组成：
(1)正文段。这是由CPU执行的机器指令部分。通常，正文段是可共享的，所以即使是频繁执行的程序（如文本编辑器、C编译器和shell等）在存储器中也只需有一个副本，另外，正文段常常是只读的，以防止程序由于意外而修改其指令。

(2)初始化数据段。通常将此段称为数据段，它包含了程序中需明确地赋初值的变量。例如， C程序中任何函数之外的声明：
int maxcount = 99;
使此变量以其初值存放在初始化数据段中。

(3)未初始化数据段。通常将此段称为bss段，这一名称来源于早期汇编程序一个操作符，意思是“由符号开始的块”（block started by symbol），在程序开始执行之前，内核将此段中的数据初始化为0或空指针。函数外的声明：
long sum[1000];
使此变量存放在非初始化数据段中。

(4)栈。自动变量以及每次函数调用时所需保存的信息都存放在此段中。每次函数调用时，其返回地址以及调用者的环境信息（如某些机器寄存器的值）都存放在栈中。然后，最近被调用的函数在栈上为其自动和临时变量分配存储空间。通过以这种方式使用栈，C递归函数可以工作。递归函数每次调用自身时，就用一个新的栈帧，因此一次函数调用实例中的变量集不会影响另一次函数调用实例中的变量。

(5)堆。通常在堆中进行动态存储分配。由于历史上形成的惯例，堆位于未初始化数据段和栈之间。

图 7-6 显示了这些段的一种典型安排方式。这是程序的逻辑布局，虽然并不要求一个具体实现一定以这种方式安排其存储空间，但这是一种我们便于说明的典型安排。
对于 32 位 Intel x86 处理器上的 Linux，正文段从 0x08048000 单元开始，栈底则在0xC0000000 之下开始（在这种特定结构中，栈从高地址向低地址方向增长）。堆顶和栈顶之间未用的虚地址空间很大。

#+DOWNLOADED: screenshot @ 2023-07-24 23:09:46
[[file:images/linux笔记/UNIX-进程环境/2023-07-24_23-09-46_screenshot.png]]
还有若干其他类型的段，如包含符号表的段、包含调试信息的段以及包含动态共享库链接表的段等。这些部分并不装载到进程执行的程序映像中。

从图7-6还可注意到，未初始化数据段的内容并不存放在磁盘程序文件中。其原因是，内核在程序开始运行前将它们都设置为 0。需要存放在磁盘程序文件中的段只有正文段和初始化数据段。

size(1)命令报告正文段、数据段和bss段的长度（以字节为单位）。例如：
#+begin_src bash
$ size /usr/bin/cc /bin/sh
text　　data　　 bss　　　dec　　hex　 filename
346919　　3576　　6680　 357175　 57337　 /usr/bin/cc
102134　　1776　 11272　 115182　 1c1ee　 /bin/sh
#+END_SRC

#+END_SRC

第4列和第5列是分别以十进制和十六进制表示的3段总长度。

** 共享库
现在，大多数UNIX系统支持共享库。共享库使得可执行文件中不再需要包含公用的库函数，而只需在所有进程都可引用的存储区中保存这种库例程的一个副本。

程序第一次执行或者第一次调用某个库函数时，用动态链接方法将程序与共享库函数相链接。这减少了每个可执行文件的长度，但增加了一些运行时间开销。这种时间开销发生在该程序第一次被执行时，或者每个共享库函数第一次被调用时。
共享库的另一个优点是可以用库函数的新版本代替老版本而无需对使用该库的程序重新连接编辑（假定参数的数目和类型都没有发生改变）。

在不同的系统中，程序可能使用不同的方法说明是否要使用共享库。比较典型的有 cc(1)和ld(1)命令的选项。作为长度方面发生变化的例子，先用无共享库方式创建下列可执行文件（典型的hello.c程序）：
#+begin_src bash
$ gcc -static hello1.c　　　　　阻止gcc 使用共享库

$ ls -l a.out
-rwxrwxr-x 1 sar　　　　879443 Sep 2 10:39 a.out

$ size a.out
text　　data　　 bss　　 dec　　hex　 filename
787775　　6128　 11272　805175　c4937　 a.out
#+END_SRC

如果再使用共享库编译此程序，则可执行文件的正文和数据段的长度都显著减小：
#+begin_src bash
$ gcc hello1.c　　　　　　　　 gcc 默认使用共享库

$ ls -l a.out
-rwxrwxr-x 1 sar　　　　8378 Sep 2 10:39 a.out

$ size a.out
text　　data　　bss　 dec　　　hex　 filename
1176　　　504　　 16　 1696　　　6a0　 a.out
#+END_SRC
** 存储空间分配
ISO C说明了3个用于存储空间动态分配的函数。
（1）malloc，分配指定字节数的存储区。此存储区中的初始值不确定。
（2）calloc，为指定数量指定长度的对象分配存储空间。该空间中的每一位（bit）都初始化为0。
（3）realloc，增加或减少以前分配区的长度。当增加长度时，可能需将以前分配区的内容移到另一个足够大的区域，以便在尾端提供增加的存储区，而新增区域内的初始值则不确定。

#+begin_src c++
#include <stdlib.h>

void *malloc(size_t size);

void *calloc(size_t nobj, size_t size);

void *realloc(void *ptr, size_t newsize);

#+END_SRC

3个函数返回值：若成功，返回非空指针；若出错，返回NULL
#+begin_src c++
void free(void *ptr);
#+END_SRC

这3个分配函数所返回的指针一定是适当对齐的，使其可用于任何数据对象。例如，在一个特定的系统上，如果最苛刻的对齐要求是，double必须在8的倍数地址单元处开始，那么这3个函数返回的指针都应这样对齐。

因为这 3 个 alloc 函数都返回通用指针 void *，所以如果在程序中包括了#include<stdlib.h>（以获得函数原型），那么当我们将这些函数返回的指针赋予一个不同类型的指针时，就不需要显式地执行强制类型转换。未声明函数的默认返回值为int，所以使用没有正确函数声明的强制类型转换可能会隐藏系统错误，因为int类型的长度与函数返回类型值的长度不同（本例中是指针）。

函数free 释放ptr指向的存储空间。被释放的空间通常被送入可用存储区池，以后，可在调用上述3个分配函数时再分配。

realloc函数使我们可以增、减以前分配的存储区的长度（最常见的用法是增加该区）。例如，如果先为一个数组分配存储空间，该数组长度为 512，然后在运行时填充它，但运行一段时间后发现该数组原先的长度不够用，此时就可调用 realloc 扩充相应存储空间。如果在该存储区后有足够的空间可供扩充，则可在原存储区位置上向高地址方向扩充，无需移动任何原先的内容，并返回与传给它相同的指针值。如果在原存储区后没有足够的空间，则 realloc 分配另一个足够大的存储区，将现存的512个元素数组的内容复制到新分配的存储区。然后，释放原存储区，返回新分配区的指针。因为这种存储区可能会移动位置，所以不应当使任何指针指在该区中。

注意，realloc的最后一个参数是存储区的新长度，不是新、旧存储区长度之差。作为一个特例，若ptr是一个空指针，则realloc的功能与malloc相同，用于分配一个指定长度为newsize的存储区。

这些函数的早期版本允许调用realloc分配自上次malloc、realloc或calloc调用以来所释放的块。这种技巧可回溯到 V7，它利用 malloc 的搜索策略，实现存储器紧缩。Solaris仍支持这一功能，而很多其他平台则不支持。这种功能不被赞同，不应再使用。

这些分配例程通常用sbrk(2)系统调用实现。该系统调用扩充（或缩小）进程的堆（见图7-6）。

虽然sbrk可以扩充或缩小进程的存储空间，但是大多数malloc和free的实现都不减小进程的存储空间。释放的空间可供以后再分配，但将它们保持在malloc池中而不返回给内核。

大多数实现所分配的存储空间比所要求的要稍大一些，额外的空间用来记录管理信息——分配块的长度、指向下一个分配块的指针等。这就意味着，如果超过一个已分配区的尾端或者在已分配区起始位置之前进行写操作，则会改写另一块的管理记录信息。这种类型的错误是灾难性的，但是因为这种错误不会很快就暴露出来，所以也就很难发现。

在动态分配的缓冲区前或后进行写操作，破坏的可能不仅仅是该区的管理记录信息。在动态分配的缓冲区前后的存储空间很可能用于其他动态分配的对象。这些对象与破坏它们的代码可能无关，这造成寻求信息破坏的源头更加困难。

其他可能产生的致命性的错误是：释放一个已经释放了的块；调用free时所用的指针不是3个alloc函数的返回值等。如若一个进程调用malloc函数，但却忘记调用free函数，那么该进程占用的存储空间就会连续增加，这被称为泄漏（leakage）。如果不调用free函数释放不再使用的空间，那么进程地址空间长度就会慢慢增加，直至不再有空闲空间。此时，由于过度的换页开销，会造成性能下降。

因为存储空间分配出错很难跟踪，所以某些系统提供了这些函数的另一种实现版本。每次调用这3个分配函数中的任意一个或free时，它们都进行附加的检错。在调用连接编辑器时指定一个专用库，在程序中就可使用这种版本的函数。此外还有公共可用的资源，在对其进行编译时使用一个特殊标志就会使附加的运行时检查生效。

FreeBSD、Mac OS X以及Linux通过设置环境变量支持附加的调试功能。另外，通过符号链接/etc/malloc.conf可将选项传递给FreeBSD函数库。
*** 替代的存储空间分配程序

有很多可替代malloc和free的函数。某些系统已经提供替代存储空间分配函数的库。另一些系统只提供标准的存储空间分配程序。如果需要，软件开发者可以下载替代函数。下面讨论某些替代函数和库。

1．libmalloc

基于SVR4的UNIX系统，如Solaries，包含了libmalloc库，它提供了一套与ISO C存储空间分配函数相匹配的接口。libmalloc库包括mallopt函数，它使进程可以设置一些变量，并用它们来控制存储空间分配程序的操作。还可使用另一个名为mallinfo的函数，以对存储空间分配程序的操作进行统计。

2．vmalloc

Vo[1996]说明一种存储空间分配程序，它允许进程对于不同的存储区使用不同的技术。除了一些vmalloc特有的函数外，该库也提供了ISO C存储空间分配函数的仿真器。

3．quick-fit

历史上所使用的标准 malloc 算法是最佳适配或首次适配存储分配策略。quick-fit（快速适配）算法比上述两种算法快，但可能使用较多存储空间。Weinstock和Wulf[1988]对该算法进行了描述，该算法基于将存储空间分裂成各种长度的缓冲区，并将未使用的缓冲区按其长度组成不同的空闲区列表。现在许多分配程序都基于快速适配。

4．jemalloc

jemalloc函数实现是FreeBSD 8.0中的默认存储空间分配程序，它是库函数malloc族在FreeBSD中的实现。它的设计具有良好的可扩展性，可用于多处理器系统中使用多线程的应用程序。Evans[2006]说明了具体实现及其性能评估。

5．TCMalloc

TCMalloc函数用于替代malloc函数族以提供高性能、高扩展性和高存储效率。从高速缓存中分配缓冲区以及释放缓冲区到高速缓存中时，它使用线程-本地高速缓存来避免锁开销。它还有内置的堆检查程序和堆分析程序帮助调试和分析动态存储的使用。TCMalloc库是开源可用的，是Google-perftools工具中的一个。Ghemawat和Menage[2005]对此做了简单介绍。

6．函数alloca

还有一个函数也值得一提，这就是alloca。它的调用序列与malloc相同，但是它是在当前函数的栈帧上分配存储空间，而不是在堆中。其优点是：当函数返回时，自动释放它所使用的栈帧，所以不必再为释放空间而费心。其缺点是：alloca 函数增加了栈帧的长度，而某些系统在函数已被调用后不能增加栈帧长度，于是也就不能支持alloca函数。尽管如此，很多软件包还是使用alloca函数，也有很多系统实现了该函数。
** 环境变量
如同前述，环境字符串的形式是：

name=value

UNIX内核并不查看这些字符串，它们的解释完全取决于各个应用程序。例如，shell使用了大量的环境变量。其中某一些在登录时自动设置（如HOME、USER等），有些则由用户设置。我们通常在一个shell启动文件中设置环境变量以控制shell的动作。例如，若设置了环境变量MAILPATH，则它告诉Bourne shell、GNU Bourne-again shell和Korn shell到哪里去查看邮件。

ISO C定义了一个函数getenv，可以用其取环境变量值，但是该标准又称环境的内容是由实现定义的。
#+begin_src c++
#include <stdlib.h>

char *getenv(const char *name);

#+END_SRC

返回值：指向与name关联的value的指针；若未找到，返回NULL

注意，此函数返回一个指针，它指向name=value字符串中的value。我们应当使用getenv从环境中取一个指定环境变量的值，而不是直接访问environ。

Single UNIX Specification中的POSIX.1定义了某些环境变量。如果支持XSI扩展，那么其中也包含了另外一些环境变量定义。图7-7列出了由Single UNIX Specification定义的环境变量，并指明本书讨论的4种实现对它们的支持情况。由POSIX.1定义的各环境变量标记为•，否则为XSI扩展。本书讨论的4种UNIX实现使用了很多依赖于实现的环境变量。注意，ISO C没有定义任何环境变量。

#+DOWNLOADED: screenshot @ 2023-07-26 23:21:41
[[file:images/linux笔记/UNIX-进程环境/2023-07-26_23-21-41_screenshot.png]]
除了获取环境变量值，有时也需要设置环境变量。我们可能希望改变现有变量的值，或者是增加新的环境变量。（在下一章将会了解到，我们能影响的只是当前进程及其后生成和调用的任何子进程的环境，但不能影响父进程的环境，这通常是一个shell进程。尽管如此，修改环境表的能力仍然是很有用的。）遗憾的是，并不是所有系统都支持这种能力。图7-8列出了由不同的标准及实现支持的各种函数。


#+DOWNLOADED: screenshot @ 2023-07-26 23:22:02
[[file:images/linux笔记/UNIX-进程环境/2023-07-26_23-22-02_screenshot.png]]
clearenv不是Single UNIX Specification的组成部分。它被用来删除环境表中的所有项。在图7-8中，中间3个函数的原型是：
#+begin_src c++
#include <stdlib.h>

int putenv(char *str);

#+END_SRC

函数返回值：若成功，返回0；若出错，返回非0
#+begin_src c++
int setenv(const char *name, const char *value, int rewrite);

int unsetenv(const char *name);

#+END_SRC

两个函数返回值：若成功，返回0；若出错，返回−1

这3个函数的操作如下。

•putenv取形式为name=value的字符串，将其放到环境表中。如果name已经存在，则先删除其原来的定义。

•setenv将name设置为value。如果在环境中name已经存在，那么（a）若rewrite非0，则首先删除其现有的定义；（b）若rewrite为0，则不删除其现有定义（name不设置为新的value，而且也不出错）。

•unsetenv删除name的定义。即使不存在这种定义也不算出错。

注意，putenv和setenv之间的差别。setenv必须分配存储空间，以便依据其参数创建name=value字符串。putenv可以自由地将传递给它的参数字符串直接放到环境中。确实，许多实现就是这么做的，因此，将存放在栈中的字符串作为参数传递给putenv就会发生错误，其原因是，从当前函数返回时，其栈帧占用的存储区可能将被重用。

这些函数在修改环境表时是如何进行操作的呢？对这一问题进行研究、考察是非常有益的。回忆图7-6，其中，环境表（指向实际name=value字符串的指针数组）和环境字符串通常存放在进程存储空间的顶部（栈之上）。删除一个字符串很简单——只要先在环境表中找到该指针，然后将所有后续指针都向环境表首部顺次移动一个位置。但是增加一个字符串或修改一个现有的字符串就困难得多。环境表和环境字符串通常占用的是进程地址空间的顶部，所以它不能再向高地址方向（向上）扩展：同时也不能移动在它之下的各栈帧，所以它也不能向低地址方向（向下）扩展。两者组合使得该空间的长度不能再增加。

（1）如果修改一个现有的name：

a．如果新value的长度少于或等于现有value的长度，则只要将新字符串复制到原字符串所用的空间中；

b．如果新value的长度大于原长度，则必须调用malloc为新字符串分配空间，然后将新字符串复制到该空间中，接着使环境表中针对name的指针指向新分配区。

（2）如果要增加一个新的name，则操作就更加复杂。首先，必须调用malloc为name=value字符串分配空间，然后将该字符串复制到此空间中。

a．如果这是第一次增加一个新name，则必须调用malloc为新的指针表分配空间。接着，将原来的环境表复制到新分配区，并将指向新name=value字符串的指针存放在该指针表的表尾，然后又将一个空指针存放在其后。最后使environ指向新指针表。再看一下图7-6，如果原来的环境表位于栈顶之上（这是一种常见情况），那么必须将此表移至堆中。

但是，此表中的大多数指针仍指向栈顶之上的各name=value字符串。

b．如果这不是第一次增加一个新name，则可知以前已调用malloc在堆中为环境表分配了空间，所以只要调用 realloc，以分配比原空间多存放一个指针的空间。然后将指向新name=value字符串的指针存放在该表表尾，后面跟着一个空指针。
** 函数setjmp和longjmp
** 函数getrlimit和setrlimit
* UNIX-进程控制
** 进程标识
每个进程都有一个非负整型表示的唯一进程ID。因为进程ID标识符总是唯一的，常将其用作其他标识符的一部分以保证其唯一性。例如，应用程序有时就把进程 ID 作为名字的一部分来创建一个唯一的文件名。

虽然是唯一的，但是进程ID是可复用的。当一个进程终止后，其进程ID就成为复用的候选者。大多数UNIX 系统实现延迟复用算法，使得赋予新建进程的 ID 不同于最近终止进程所使用的ID。这防止了将新进程误认为是使用同一ID的某个已终止的先前进程。

系统中有一些专用进程，但具体细节随实现而不同。
ID为 0的进程通常是调度进程，常常被称为交换进程（swapper）。该进程是内核的一部分，它并不执行任何磁盘上的程序，因此也被称为系统进程。
进程ID 1通常是init进程，在自举过程结束时由内核调用。该进程的程序文件在UNIX的早期版本中是/etc/init，在较新版本中是/sbin/init。此进程负责在自举内核后启动一个UNIX系统。init通常读取与系统有关的初始化文件（/etc/rc*文件或/etc/inittab文件，以及在/etc/init.d中的文件），并将系统引导到一个状态（如多用户）。init 进程决不会终止。它是一个普通的用户进程（与交换进程不同，它不是内核中的系统进程），但是它以超级用户特权运行.

在Mac OS X 10.4中，init进程被launchd进程替代，执行的任务集与init相同，但扩展了功能。可参阅Singh[2006]在5.10节中的讨论来了解launchd是如何操作的。

每个UNIX系统实现都有它自己的一套提供操作系统服务的内核进程，例如，在某些UNIX的虚拟存储器实现中，进程ID 2是页守护进程（page daemon），此进程负责支持虚拟存储器系统的分页操作。

除了进程ID，每个进程还有一些其他标识符。下列函数返回这些标识符。
#+begin_src c++
#include <unistd.h>

pid_t getpid(void);

//返回值：调用进程的进程ID

pid_t getppid(void);

//返回值：调用进程的父进程ID

uid_t getuid(void);

//返回值：调用进程的实际用户ID

uid_t geteuid(void);

//返回值：调用进程的有效用户ID

gid_t getgid(void);

//返回值：调用进程的实际组ID

gid_t getegid(void);

//返回值：调用进程的有效组ID

#+END_SRC
注意，这些函数都没有出错返回，在下一节讨论fork函数时，将进一步讨论父进程ID。
** 函数fork
一个现有的进程可以调用fork函数创建一个新进程。
#+begin_src c++
#include <unistd.h>

pid_t fork(void);

#+END_SRC

返回值：子进程返回0，父进程返回子进程ID；若出错，返回−1

由fork创建的新进程被称为子进程（child process）。fork函数被调用一次，但返回两次。两次返回的区别是子进程的返回值是 0，而父进程的返回值则是新建子进程的进程 ID。将子进程ID返回给父进程的理由是：因为一个进程的子进程可以有多个，并且没有一个函数使一个进程可以获得其所有子进程的进程 ID。fork 使子进程得到返回值 0 的理由是：一个进程只会有一个父进程，所以子进程总是可以调用 getppid 以获得其父进程的进程 ID（进程ID 0总是由内核交换进程使用，所以一个子进程的进程ID不可能为0）。

子进程和父进程继续执行fork调用之后的指令。子进程是父进程的副本。例如，子进程获得父进程数据空间、堆和栈的副本。注意，这是子进程所拥有的副本。父进程和子进程并不共享这些存储空间部分。父进程和子进程共享正文段（见7.6节）。

由于在fork之后经常跟随着exec，所以现在的很多实现并不执行一个父进程数据段、栈和堆的完全副本。作为替代，使用了写时复制（Copy-On-Write，COW）技术。这些区域由父进程和子进程共享，而且内核将它们的访问权限改变为只读。如果父进程和子进程中的任一个试图修改这些区域，则内核只为修改区域的那块内存制作一个副本，通常是虚拟存储系统中的一“页”。Bach[1986]的9.2节和 McKusick等[1996]的5.6节和5.7节对这种特征做了更详细的说明。

某些平台提供 fork 函数的几种变体。本书讨论的 4 种平台都支持下节将要讨论的vfork(2)。

Linux 3.2.0 提供了另一种新进程创建函数—clone(2)系统调用。这是一种fork的推广形式，它允许调用者控制哪些部分由父进程和子进程共享。

FreeBSD 8.0提供了rfork(2)系统调用，它类似于Linux的clone系统调用。rfork调用是从Plan 9操作系统（Pike等[1995]）派生出来的。

Solaris 10提供了两个线程库：一个用于POSIX线程（pthreads），另一个用于Solaris线程。在这两个线程库中，fork 的行为有所不同。对于 POSIX 线程，fork 创建一个进程，它仅包含调用该fork的线程，但对于Solaris线程，fork创建的进程包含了调用线程所在进程的所有线程的副本。在Solaris 10中，这种行为改变了。不管使用哪种线程库，fork创建的子进程只保留调用线程的副本。Solaris也提供了fork1函数，它创建的进程只复制调用线程。还有forkall函数，它创建的进程复制了进程中所有的线程。
*** 实例
图8-1程序演示了fork函数，从中可以看到子进程对变量所做的改变并不影响父进程中该变量的值。
#+begin_src c++
#include "apue.h"
int globvar = 6; /* external variable in initialized data */
char buf[] = "a write to stdout \n";
int main(void)
{
  intvar; /* automatic variable on the stack */
  pid_tpid;
  var = 88;
  if (write(STDOUT_FILENO，buf, sizeof(buf) - 1) != sizeof(buf) - 1)
    err_sys("write error");
  printf("before fork\n"); /* we don't flush stdout */
  if ((pid = fork()) < 0)
  {
    err_sys("fork error");
  }
  else if (pid == 0) /* child */
  {
    globvar++; /* modify variables */
    var++;
  }
  else
  {
    sleep(2); /*parent */
  }
  printf("pid = %ld,glob = %d,var = %d\n"，(long)getpid(), globvar, var);
  exit(0);
}
#+END_SRC
如果执行此程序则得到：
#+begin_src bash
$ ./a.out
a write to stdout
before fork
pid = 430, glob = 7, var = 89 子进程的变量值改变了
pid = 429, glob = 6, var = 88 父进程的变量值没有改变

$ a.out > temp.out

$ cat temp.out
a write to stdout
before fork
pid = 432, glob = 7, var = 89
before fork
pid = 431, glob = 6, var = 88
#+END_SRC
一般来说，在fork之后是父进程先执行还是子进程先执行是不确定的，这取决于内核所使用的调度算法。如果要求父进程和子进程之间相互同步，则要求某种形式的进程间通信。在图8-1程序中，父进程使自己休眠2 s，以此使子进程先执行。但并不保证2 s已经足够，

当写标准输出时，我们将buf长度减去1作为输出字节数，这是为了避免将终止null字节写出。strlen 计算不包含终止 null 字节的字符串长度，而 sizeof 则计算包括终止 null字节的缓冲区长度。两者之间的另一个差别是，使用 strlen 需进行一次函数调用，而对于sizeof 而言，因为缓冲区已用已知字符串进行初始化，其长度是固定的，所以 sizeof 是在编译时计算缓冲区长度。

注意图8-1所示的程序中fork与I/O函数之间的交互关系。回忆第3章中所述，write函数是不带缓冲的。因为在fork之前调用write，所以其数据写到标准输出一次。但是，标准I/O库是带缓冲的。回忆一下5.12节，如果标准输出连到终端设备，则它是行缓冲的；否则它是全缓冲的。当以交互方式运行该程序时，只得到该printf输出的行一次，其原因是标准输出缓冲区由换行符冲洗。但是当将标准输出重定向到一个文件时，却得到printf输出行两次。其原因是，在fork之前调用了printf一次，但当调用fork时，该行数据仍在缓冲区中，然后在将父进程数据空间复制到子进程中时，该缓冲区数据也被复制到子进程中，此时父进程和子进程各自有了带该行内容的缓冲区。在exit之前的第二个printf将其数据追加到已有的缓冲区中。当每个进程终止时，其缓冲区中的内容都被写到相应文件中。

文件共享

对图8-1程序需注意的另一点是：在重定向父进程的标准输出时，子进程的标准输出也被重定向。实际上，fork的一个特性是父进程的所有打开文件描述符都被复制到子进程中。我们说“复制”是因为对每个文件描述符来说，就好像执行了dup函数。父进程和子进程每个相同的打开描述符共享一个文件表项（见图3-9）。

考虑下述情况，一个进程具有3个不同的打开文件，它们是标准输入、标准输出和标准错误。在从fork返回时，我们有了如图8-2中所示的结构。
#+DOWNLOADED: screenshot @ 2023-07-12 23:18:13
[[file:images/linux笔记/UNIX-进程控制/2023-07-12_23-18-13_screenshot.png]]


重要的一点是，父进程和子进程共享同一个文件偏移量。考虑下述情况：一个进程fork了一个子进程，然后等待子进程终止。假定，作为普通处理的一部分，父进程和子进程都向标准输出进行写操作。如果父进程的标准输出已重定向（很可能是由 shell 实现的），那么子进程写到该标准输出时，它将更新与父进程共享的该文件的偏移量。在这个例子中，当父进程等待子进程时，子进程写到标准输出；而在子进程终止后，父进程也写到标准输出上，并且知道其输出会追加在子进程所写数据之后。如果父进程和子进程不共享同一文件偏移量，要实现这种形式的交互就要困难得多，可能需要父进程显式地动作。

如果父进程和子进程写同一描述符指向的文件，但又没有任何形式的同步（如使父进程等待子进程），那么它们的输出就会相互混合（假定所用的描述符是在fork之前打开的）。虽然这种情况是可能发生的（见图8-2），但这并不是常用的操作模式。

在fork之后处理文件描述符有以下两种常见的情况。

（1）父进程等待子进程完成。在这种情况下，父进程无需对其描述符做任何处理。当子进程终止后，它曾进行过读、写操作的任一共享描述符的文件偏移量已做了相应更新。

（2）父进程和子进程各自执行不同的程序段。在这种情况下，在fork之后，父进程和子进程各自关闭它们不需使用的文件描述符，这样就不会干扰对方使用的文件描述符。这种方法是网络服务进程经常使用的。

除了打开文件之外，父进程的很多其他属性也由子进程继承，包括：
- 实际用户ID、实际组ID、有效用户ID、有效组ID
- 附属组ID
- 进程组ID
- 会话ID
- 控制终端
- 设置用户ID标志和设置组ID标志
- 当前工作目录
- 根目录
- 文件模式创建屏蔽字
- 信号屏蔽和安排
- 对任一打开文件描述符的执行时关闭（close-on-exec）标志
- 环境
- 连接的共享存储段
- 存储映像
- 资源限制

父进程和子进程之间的区别具体如下。
- fork的返回值不同。
- 进程ID不同。
- 这两个进程的父进程ID不同：子进程的父进程ID是创建它的进程的ID，而父进程的父进程ID则不变。
- 子进程的tms_utime、tms_stime、tms_cutime和tms_ustime的值设置为0（这些时间将在8.17节中介绍）。
- 子进程不继承父进程设置的文件锁。
- 子进程的未处理闹钟被清除。
- 子进程的未处理信号集设置为空集。

其中很多特性至今尚未讨论过，我们将在以后几章中对它们进行说明。

使fork失败的两个主要原因是：（a）系统中已经有了太多的进程（通常意味着某个方面出了问题），（b）该实际用户ID的进程总数超过了系统限制。回忆图2-11，其中CHILD_MAX规定了每个实际用户ID在任一时刻可拥有的最大进程数。

fork有以下两种用法。

（1）一个父进程希望复制自己，使父进程和。这在网络服务进程中是常见的—父进程等待客户端的服务请求。当这种请求到达时，父进程调用fork，使子进程处理此请求。父进程则继续等待下一个服务请求。

（2）一个进程要执行一个不同的程序。这对 shell 是常见的情况。在这种情况下，子进程从fork返回后立即调用exec（我们将在8.10节说明exec）。

某些操作系统将第 2 种用法中的两个操作（fork 之后执行 exec）组合成一个操作，称为spawn。UNIX系统将这两个操作分开，因为在很多场合需要单独使用fork，其后并不跟随exec。另外，将这两个操作分开，使得子进程在fork和exec之间可以更改自己的属性，如I/O重定向、用户ID、信号安排等。在第15章中有很多这方面的例子。

Single UNIX Specification在高级实时选项组中确实包括了spawn接口。但是该接口并不想替换fork和exec。它们的目的是支持难于有效实现fork的系统，特别是对存储管理缺少硬件支持的系统。
** 函数vfork
vfork 起源于较早的 2.9BSD。有些人认为，该函数是有瑕疵的。但是本书讨论的 4 种平台都支持它。事实上，BSD 的开发者在 4.4BSD 中删除了该函数，但4.4BSD 派生的所有开放源码BSD版本又将其收回。在SUSv3中，vfork被标记为弃用的接口，在SUSv4中被完全删除。我们只是由于历史的原因还是把它包含进
来。可移植的应用程序不应该使用这个函数。
** 函数exit
如7.3节所述，进程有5种正常终止及3种异常终止方式。5种正常终止方式具体如下。
1. 在main函数内执行return语句。如在7.3节中所述，这等效于调用exit。

2. 调用exit函数。此函数由ISO C定义，其操作包括调用各终止处理程序（终止处理程序在调用atexit函数时登记），然后关闭所有标准I/O流等。因为ISO C并不处理文件描述符、多进程（父进程和子进程）以及作业控制，所以这一定义对UNIX系统而言是不完整的。

3. 调用_exit或_Exit函数。ISOC定义_Exit，其目的是为进程提供一种无需运行终止处理程序或信号处理程序而终止的方法。对标准 I/O 流是否进行冲洗，这取决于实现。在 UNIX系统中，_Exit 和_exit 是同义的，并不冲洗标准 I/O流。_exit 函数由 exit 调用，它处理UNIX系统特定的细节。_exit是由POSIX.1说明的。
在大多数UNIX系统实现中，exit(3)是标准C库中的一个函数，而_exit(2)则是一
个系统调用。

4. 进程的最后一个线程在其启动例程中执行return语句。但是，该线程的返回值不用作进程的返回值。当最后一个线程从其启动例程返回时，该进程以终止状态0返回。

5. 进程的最后一个线程调用 pthread_exit 函数。如同前面一样，在这种情况
中，进程终止状态总是0，这与传送给pthread_exit的参数无关。

3种异常终止具体如下。
1. 调用abort。它产生SIGABRT信号，这是下一种异常终止的一种特例。

2. 当进程接收到某些信号时。信号可由进程自身（如调用abort函数）、其他进程或内核产生。例如，若进程引用地址空间之外的存储单元、或者除以0，内核就会为该进程产生相应的信号。

3. 最后一个线程对“取消”（cancellation）请求作出响应。默认情况下，“取消”以延迟方式发生：一个线程要求取消另一个线程，若干时间之后，目标线程终止。

不管进程如何终止，最后都会执行内核中的同一段代码。这段代码为相应进程关闭所有打开描述符，释放它所使用的存储器等。

对上述任意一种终止情形，我们都希望终止进程能够通知其父进程它是如何终止的。对于 3个终止函数（exit、_exit和_Exit），实现这一点的方法是，将其退出状态（exit status）作为参数传送给函数。在异常终止情况，内核（不是进程本身）产生一个指示其异常终止原因的终止状态（termination status）。在任意一种情况下，该终止进程的父进程都能用wait或waitpid函数得其终止状态。

注意，这里使用了“退出状态”（它是传递给向3个终止函数的参数，或main的返回值）和“终止状态”两个术语，以表示有所区别。在最后调用_exit时，内核将退出状态转换成终止状态（回忆图7-2）。图8-4说明父进程检查子进程终止状态的不同方法。如果子进程正常终止，则父进程可以获得子进程的退出状态。

在说明fork函数时，显而易见，子进程是在父进程调用fork后生成的。上面又说明了子进程将其终止状态返回给父进程。但是如果父进程在子进程之前终止，又将如何呢？其回答是：对于父进程已经终止的所有进程，它们的父进程都改变为init 进程。我们称这些进程由 init进程收养。其操作过程大致是：在一个进程终止时，内核逐个检查所有活动进程，以判断它是否是正要终止进程的子进程，如果是，则该进程的父进程ID就更改为1（init进程的ID）。这种处理方法保证了每个进程有一个父进程。

另一个我们关心的情况是，如果子进程在父进程之前终止，那么父进程又如何能在做相应检查时得到子进程的终止状态呢？如果子进程完全消失了，父进程在最终准备好检查子进程是否终止时是无法获取它的终止状态的。内核为每个终止子进程保存了一定量的信息，所以当终止进程的父进程调用wait或waitpid时，可以
得到这些信息。这些信息至少包括进程ID、该进程的终止状态以及该进程使用的CPU时间总量。内核可以释放终止进程所使用的所有存储区，关闭其所有打开文件。在 UNIX 术语中，一个已经终止、但是其父进程尚未对其进行善后处理（获取终止子进程的有关信息、释放它仍占用的资源）的进程被称为僵死进程（zombie）。ps(1)命令将僵死进程的状态打印为Z。如果编写一个长期运行的程序，它fork了很多子进程，那么除非父进程等待取得子进程的终止状态，不然这些子进程终止后就会变成僵死进程。

最后一个要考虑的问题是：一个由init进程收养的进程终止时会发生什么？它会不会变成一个僵死进程？对此问题的回答是“否”，因为init被编写成无论何时只要有一个子进程终止， init 就会调用一个 wait 函数取得其终止状态。这样也就防止了在系统中塞满僵死进程。当提及“一个init的子进程”时，这指的可能是init直接产生的进程，也可能是其父进程已终止，由init收养的进程。

** 函数wait和waitpid
当一个进程正常或异常终止时，内核就向其父进程发送 SIGCHLD 信号。
因为子进程终止是个异步事件（这可以在父进程运行的任何时候发生），所以这种信号也是内核向父进程发的异步通知。
父进程可以选择忽略该信号，或者提供一个该信号发生时即被调用执行的函数（信号处理程序）。对于这种信号的系统默认动作是忽略它。
- 如果其所有子进程都还在运行，则阻塞。
- 如果一个子进程已终止，正等待父进程获取其终止状态，则取得该子进程的终止状态立即返回。
- 如果它没有任何子进程，则立即出错返回 。

如果进程由于接收到SIGCHLD信号而调用wait，我们期望wait会立即返回。但是如果在随机时间点调用wait，则进程可能会阻塞。
#+begin_src c++
#include <sys/wait.h>

pid_t wait(int *statloc);

pid_t waitpid(pid_t pid, int *statloc, int options);
#+END_SRC

两个函数返回值：若成功，返回进程ID；若出错，返回0（见后面的说明）或−1

这两个函数的区别如下。
- 在一个子进程终止前，wait使其调用者阻塞，而waitpid有一选项，可使调用者不阻塞。
- waitpid并不等待在其调用之后的第一个终止子进程，它有若干个选项，可以控制它所等待的进程。

如果子进程已经终止，并且是一个僵死进程，则wait立即返回并取得该子进程的状态；否则wait使其调用者阻塞，直到一个子进程终止。如调用者阻塞而且它有多个子进程，则在其某一子进程终止时，wait就立即返回。因为wait返回终止子进程的进程ID，所以它总能了解是哪一个子进程终止了。

这两个函数的参数statloc是一个整型指针。如果statloc不是一个空指针，则终止进程的终止状态就存放在它所指向的单元内。如果不关心终止状态，则可将该参数指定为空指针。

依据传统，这两个函数返回的整型状态字是由实现定义的。其中某些位表示退出状态（正常返回），其他位则指示信号编号（异常返回），有一位指示是否产生了core文件等。POSIX.1规定，终止状态用定义在<sys/wait.h>中的各个宏来查看。有4个互斥的宏可用来取得进程终止的原因，它们的名字都以WIF开始。基于这4个宏中哪一个值为真，就可选用其他宏来取得退出状态、信号编号等。这4个互斥的宏示于图8-4中。


#+DOWNLOADED: screenshot @ 2023-07-27 22:11:48
[[file:images/linux笔记/UNIX-进程控制/2023-07-27_22-11-48_screenshot.png]]
图8-4 检查wait和waitpid所返回的终止状态的宏

*** 实例
函数pr_exit使用图8-4中的宏以打印进程终止状态的说明。注意，如果定义了WCOREDUMP宏，则此函数也处理该宏。
#+begin_src c+
+#include "apue.h"
#include <sys/wait.h>
void pr_exit(int status)
{
    if (WIFEXITED(status))
        printf("normal termination,exit status = %d\n",
               WEXITSTATUS(status));
    else if (WIFSIGNALED(status))
        printf("abnormal termination,signal number = %d%s \n", WTERMSIG(status),
#ifdef WCOREDUMP
               WCOREDUMP(status) ? "(core file generated)" : "");
#else
               "");
#endif
    else if (WIFSTOPPED(status))
        printf("child stopped,signal number = %d\n",
               WSTOPSIG(status));
}
#+END_SRC
图8-5 打印exit状态的说明

FreeBSD 8.0、Linux 3.2.0、Mac OS X 10.6.8以及Solaris 10都支持WCOREDUMP宏。但是如果定义了_POSIX_C_SOURCE常量，有些平台就隐藏这个定义（回忆2.7节）。

图8-6中程序调用pr_exit函数，演示终止状态的各种值。
#+begin_src c++
#include "apue.h"
#include <sys/ wait.h>
int main(void)
{
    pid_t pid;
    int status;
    if ((pid = fork()) < 0)
        err_sys("fork error");
    else if (pid == 0) /*child */
        exit(7);

    if (wait(&status) != pid) /* wait for child */
        err_sys("wait error");
    pr_exit(status); /*and print its status */

    if ((pid = fork()) < 0)
        err_sys("fork error");
    else if (pid -= 0) /*child */
        abort();       /* generates SIGABRT */

    if (wait(&status) != pid) /* wait for child */
        err_sys("wait error");
    pr_exit(status); /* and print its status */

    if ((pid = fork()) < 0)
        err_sys("fork error");
    else if (pid == 0) /* child */
        status /= 0;   /* divide by 0 generates SIGFPE */

    if (wait(&status) != pid) /* wait for child */
        err_sys("wait error");
    pr_exit(status); /* and print its status */
    exit(O);
}
#+END_SRC
图8-6 演示不同的exit值

运行该程序可得：
#+begin_src bash
$ ./a.out
normal termination, exit status = 7
abnormal termination, signal number = 6 (core file generated)
abnormal termination, signal number = 8 (core file generated)
#+END_SRC

现在，我们可以从WTERMSIG中打印信号编号。可以查看<signal.h>头文件验证SIGABRT的值为6，SIGFPE的值为8。

正如前面所述，如果一个进程有几个子进程，那么只要有一个子进程终止，wait 就返回。如果要等待一个指定的进程终止（如果知道要等待进程的ID），那么该如何做呢？在早期的UNIX版本中，必须调用wait，然后将其返回的进程ID和所期望的进程ID相比较。如果终止进程不是所期望的，则将该进程ID和终止状态保存起来，然后再次调用wait。反复这样做，直到所期望的进程终止。下一次又想等待一个特定进程时，先查看已终止的进程列表，若其中已有要等待的进程，则获取相关信息；否则调用wait。其实，我们需要的是等待一个特定进程的函数。POSIX.定义了waitpid函数以提供这种功能（以及其他一些功能）。

对于waitpid函数中pid参数的作用解释如下。
- pid ==−1 等待任一子进程。此种情况下，waitpid与wait等效。
- pid > 0 等待进程ID与pid相等的子进程。
- pid == 0 等待组ID等于调用进程组ID的任一子进程。
- pid <−1 等待组ID等于pid绝对值的任一子进程。

waitpid函数返回终止子进程的进程ID，并将该子进程的终止状态存放在由statloc指向的存储单元中。对于 wait，其唯一的出错是调用进程没有子进程（函数调用被一个信号中断时，也可能返回另一种出错。第10章将对此进行讨论）。但是对于waitpid，如果指定的进程或进程组不存在，或者参数pid指定的进程不是调用进程的子进程，都可能出错。

options参数使我们能进一步控制waitpid的操作。此参数或者是0，或者是图8-7中常量按位或运算的结果。

FreeBSD 8.0和Solaris 10支持另一个非标准的可选常量WNOWAIT，它使系统将终止状态已由waitpid返回的进程保持在等待状态，这样它可被再次等待。
#+DOWNLOADED: screenshot @ 2023-07-27 22:41:07
[[file:images/linux笔记/UNIX-进程控制/2023-07-27_22-41-07_screenshot.png]]
图8-7 waitpid的options常量

waitpid函数提供了wait函数没有提供的3个功能。
（1）waitpid可等待一个特定的进程，而wait则返回任一终止子进程的状态。在讨论popen函数时会再说明这一功能。
（2）waitpid提供了一个 wait 的非阻塞版本。有时希望获取一个子进程的状态，但不想阻塞。
（3）waitpid通过WUNTRACED和WCONTINUED选项支持作业控制。

*** 实例
如果一个进程fork一个子进程，但不要它等待子进程终止，也不希望子进程处于僵死状态直到父进程终止，实现这一要求的诀窍是调用fork两次。图8-8程序实现了这一点。

** 函数waitid
** 函数wait3和wait4
** 竞争条件
** 函数exec
** 更改用户ID和更改组ID
** 解释器文件
** 函数system
** 进程会计
** 用户标识
** 进程调度
** 进程时间

* UNIX-线程
每个线程都包含有表示执行环境所必需的信息，其中包括进程中标识线程的线程ID、一组寄存器值、栈、调度优先级和策略、信号屏蔽字、errno变量以及线程私有数据。一个进程的所有信息对该进程的所有线程都是共享的，包括可执行程序的代码、程序的全局内存和堆内存、栈以及文件描述符。
** 线程标识
就像每个进程有一个进程ID一样，每个线程也有一个线程ID。进程 ID在整个系统中是唯一的，但线程ID不同，线程ID只有在它所属的进程上下文中才有意义。

回忆一下进程ID，它是用pid_t数据类型来表示的，是一个非负整数。线程ID是用pthread_t数据类型来表示的，实现的时候可以用一个结构来代表pthread_t数据类型，所以可移植的操作系统实现不能把它作为整数处理。因此必须使用一个函数来对两个线程ID进行比较。
#+begin_src bash
#include <pthread.h>

int pthread_equal(pthread_t tid1, pthread_t tid2);
#+end_src
返回值：若相等，返回非0数值；否则，返回0

Linux 3.2.0使用无符号长整型表示pthread_t数据类型。Solaris 10把pthread_t数据类型表示为无符号整型。FreeBSD 8.0和Mac OS X 10.6.8用一个指向pthread结构的指针来表示pthread_t数据类型。

用结构表示pthread_t数据类型的后果是不能用一种可移植的方式打印该数据类型的值。在程序调试过程中打印线程ID有时是非常有用的，而在其他情况下通常不需要打印线程ID。最坏的情况是，有可能出现不可移植的调试代码，当然这也算不上是很大的局限性。

线程可以通过调用pthread_self函数获得自身的线程ID。
#+begin_src bash
#include <pthread.h>

pthread_t pthread_self(void);
#+end_src
返回值：调用线程的线程ID

当线程需要识别以线程ID作为标识的数据结构时，pthread_self函数可以与pthread_equal函数一起使用。例如，主线程可能把工作任务放在一个队列中，用线程ID来控制每个工作线程处理哪些作业。
如图11-1所示，主线程把新的作业放到一个工作队列中，由3个工作线程组成的线程池从队列中移出作业。主线程不允许每个线程任意处理从队列顶端取出的作业，而是由主线程控制作业的分配，主线程会在每个待处理作业的结构中放置处理该作业的线程ID，每个工作线程只能移出标有自己线程ID的作业。

#+DOWNLOADED: screenshot @ 2023-12-25 23:25:29
[[file:images/linux笔记/UNIX-线程/2023-12-25_23-25-29_screenshot.png]]
图11-1 工作队列实例
** 线程创建
在传统UNIX进程模型中，每个进程只有一个控制线程。从概念上讲，这与基于线程的模型中每个进程只包含一个线程是相同的。在POSIX线程（pthread）的情况下，程序开始运行时，它也是以单进程中的单个控制线程启动的。在创建多个控制线程以前，程序的行为与传统的进程并没有什么区别。新增的线程可以通过调用pthread_create函数创建。
#+begin_src bash
#include <pthread.h>

int pthread_create(pthread_t *restrict tidp,
const pthread_attr_t *restrict attr,
void *(*start_rtn)(void *), void *restrict arg);
#+end_src
返回值：若成功，返回0；否则，返回错误编号

当pthread_create成功返回时，新创建线程的线程ID会被设置成tidp指向的内存单元。attr参数用于定制各种不同的线程属性。我们将在后面中讨论线程属性，但现在我们把它置为NULL，创建一个具有默认属性的线程。

新创建的线程从start_rtn函数的地址开始运行，该函数只有一个无类型指针参数arg。如果需要向start_rtn函数传递的参数有一个以上，那么需要把这些参数放到一个结构中，然后把这个结构的地址作为arg参数传入。

线程创建时并不能保证哪个线程会先运行：是新创建的线程，还是调用线程。新创建的线程可以访问进程的地址空间，并且继承调用线程的浮点环境和信号屏蔽字，但是该线程的挂起信号集会被清除。

注意，pthread 函数在调用失败时通常会返回错误码，它们并不像其他的 POSIX 函数一样设置errno。每个线程都提供errno的副本，这只是为了与使用errno的现有函数兼容。在线程中，从函数中返回错误码更为清晰整洁，不需要依赖那些随着函数执行不断变化的全局状态，这样可以把错误的范围限制在引起出错的函数中。
*** 实例
虽然没有可移植的打印线程 ID 的方法，但是可以写一个小的测试程序来完成这个任务，以便更深入地了解线程是如何工作的。图 11-2 中的程序创建了一个线程，打印了进程 ID、新线程的线程ID以及初始线程的线程ID。

#+begin_src c++
#include "apue.h"
#include <pthread.h>

pthread_t ntid;

void
printids ( const char *s)
{
    pid_t pid;
    pthread_t tid;
    pid = getpid();
    tid = pthread_self();
    printf ("%s pid %lu tid 8lu (0x%lx)\n",s,(unsigned long)pid,(unsigned long)tid,(unsigned long)tid) ;
}

void*
thr_fn (void *arg)
{
    printids ( "new thread: ");
    return ( (void * ) 0) ;
}

int
main (void)
{
    int err;
    err = pthread_create(&ntid,NULL,thr_fn,NULL);
    if (err !=0)
        err_exit (err, "can't create thread" ) ;
    printids ( "main thread : " );
    sleep (1) ;
    exit(0) ;
}
#+end_src
图11-2 打印线程ID

这个实例有两个特别之处，需要处理主线程和新线程之间的竞争。第一个特别之处在于，主线程需要休眠，如果主线程不休眠，它就可能会退出，这样新线程还没有机会运行，整个进程可能就已经终止了。这种行为特征依赖于操作系统中的线程实现和调度算法。

在Solaris上运行图11-2中的程序，得到：
#+begin_src bash
$ ./a.out
main thread: pid 20075 tid 1 (0x1)
new thread: pid 20075 tid 2 (0x2)
#+end_src
正如我们期望的，两个线程的进程ID相同，但线程ID不同。在FreeBSD上运行图11-2中的程序，得到：
#+begin_src bash
$ ./a.out
main thread: pid 37396 tid 673190208 (0x28201140)
new thread: pid 37396 tid 673280320 (0x28217140)
#+end_src
也如我们期望的，两个线程有相同的进程ID。如果把线程ID看成是十进制整数，那么这两个值看起来很奇怪，但是如果把它们转化成十六进制，看起来就更合理了。就像前面提到的，FreeBSD使用指向线程数据结构的指针作为它的线程ID。

我们期望Mac OS X与FreeBSD相似，但事实上，在Mac OS X中，主线程ID与用pthread_create新创建的线程的线程ID不在相同的地址范围内：
#+begin_src bash
$ ./a.out
main thread: pid 31807 tid 140735073889440 (0x7fff70162ca0)
new thread: pid 31807 tid 4295716864 (0x1000b7000)
#+end_src
相同的程序在Linux上运行得到：
#+begin_src bash
$ ./a.out
main thread: pid 17874 tid 140693894424320 (0x7ff5d9996700)
new thread: pid 17874 tid 140693886129920 (0x7ff5d91ad700)
#+end_src
尽管Linux线程ID是用无符号长整型来表示的，但是它们看起来像指针。

Linux 2.4和Linux 2.6在线程实现上是不同的。Linux 2.4中，LinuxThreads是用单独的进程实现每个线程的，这使得它很难与POSIX线程的行为匹配。Linux 2.6中，对Linux内核和线程库进行了很大的修改，采用了一个称为Native POSIX线程库（Native POSIX Thread Library，NPTL）的新线程实现。它支持单个进程中有多个线程的模型，也更容易支持POSIX线程的语义。

** 线程终止
如果进程中的任意线程调用了 exit、_Exit 或者_exit，那么整个进程就会终止。与此相类似，如果默认的动作是终止进程，那么，发送到线程的信号就会终止整个进程。

单个线程可以通过3种方式退出，因此可以在不终止整个进程的情况下，停止它的控制流。
（1）线程可以简单地从启动例程中返回，返回值是线程的退出码。
（2）线程可以被同一进程中的其他线程取消。
（3）线程调用pthread_exit。

#+begin_src bash
#include <pthread.h>

void pthread_exit(void *rval_ptr);
#+end_src
rval_ptr 参数是一个无类型指针，与传给启动例程的单个参数类似。进程中的其他线程也可以通过调用pthread_join函数访问到这个指针。
#+begin_src bash
#include <pthread.h>

int pthread_join(pthread_t thread, void **rval_ptr);
#+end_src
返回值：若成功，返回0；否则，返回错误编号

调用线程将一直阻塞，直到指定的线程调用pthread_exit、从启动例程中返回或者被取消。如果线程简单地从它的启动例程返回，rval_ptr就包含返回码。如果线程被取消，由rval_ptr指定的内存单元就设置为PTHREAD_CANCELED。

可以通过调用pthread_join自动把线程置于分离状态，这样资源就可以恢复。如果线程已经处于分离状态，pthread_join调用就会失败，返回EINVAL，尽管这种行为是与具体实现相关的。

如果对线程的返回值并不感兴趣，那么可以把rval_ptr设置为 NULL。在这种情况下，调用pthread_join函数可以等待指定的线程终止，但并不获取线程的终止状态。

图11-6总结了线程函数和进程函数之间的相似之处
| 进程原语 | 线程原语             | 描述                      |
|---------+---------------------+--------------------------|
| fork    | pthread_create      | 创建新的控制流             |
| exit    | pthread_exit        | 从现有的控制流中退出        |
| waitpid | pthread_join        | 从控制流中得到退出状态      |
| atexit  | pthread_cancel_push | 注册在退出控制流时调用的函数 |
| getpid  | pthread_self        | 获取控制流的ID             |
| abort   | pthread_cancel      | 请求控制流的非正常退出      |
图11-6 进程和线程原语的比较
*** 实例

图11-3展示了如何获取已终止的线程的退出码。
#+begin_src c++
#include "apue.h"
#include <pthread.h>
void *
thr_fn1(void *arg)
{
    printf("thread 1 returning\n");
    return ((void *)1);
}
void *
thr_fn2(void *arg)
{
    printf("thread 2 exiting\n");
    pthread_exit((void *)2);
}
int main(void)
{
    int err;
    pthread_t tidl, tid2;
    void *tret;
    err = pthread_create(&tid1, NULL, thr_fn1, NULL);
    if (err != 0)
        err_exit(err, "can't create thread 1");
    err = pthread_create(&tid2, NULL, thr_fn2, NULL);
    if (err != 0)
        err_exit(err, "can't create thread 2");
    err = pthread_join(tid1, &tret);
    if (err != 0)
        err_exit(err, "can't join with thread 1");
    printf("thread 1 exit code %ld\n", (long)tret);
    err = pthread_join(tid2, &tret);
    if (err != 0)
        err_exit(err, "can't join with thread 2");
    printf("thread 2 exit code %ld\n", (long)tret);
    exit(0);
}
#+end_src
图11-3 获得线程退出状态

运行图11-3中的程序，得到的结果是：
#+begin_src bash
$ ./a.out
thread 1 returning
thread 2 exiting
thread 1 exit code 1
thread 2 exit code 2
#+end_src
可以看到，当一个线程通过调用pthread_exit退出或者简单地从启动例程中返回时，进程中的其他线程可以通过调用pthread_join函数获得该线程的退出状态。

pthread_create和pthread_exit函数的无类型指针参数可以传递的值不止一个，这个指针可以传递包含复杂信息的结构的地址，但是注意，这个结构所使用的内存在调用者完成调用以后必须仍然是有效的。例如，在调用线程的栈上分配了该结构，那么其他的线程在使用这个结构时内存内容可能已经改变了。又如，线程在自己的栈上分配了一个结构，然后把指向这个结构的指针传给pthread_exit，那么调用pthread_join的线程试图使用该结构时，这个栈有可能已经被撤销，这块内存也已另作他用。

*** 实例

图11-4中的程序给出了用自动变量（分配在栈上）作为pthread_exit的参数时出现的问题。
#+begin_src c++
#include "apue.h"
#include <pthread.h>
struct foo
{
    int a, b, c, d;
};
void printfoo(const char *s, const struct foo *fp)
{
    printf("%s", s);
    printf("structure at 0x%lx\n", (unsigned long)fp);
    printf("foo.a = %d\n", fp->a);
    printf("foo.b = %d\n", fp->b);
    printf("foo.c = %d\n", fp->c);
    printf("foo.d = %dln", fp->d);
}
void *
thr_fn1(void *arg)
{
    struct foo foo = {1, 2, 3, 4};
    printfoo("thread 1 :\n", &foo);
    pthread_exit((void *)&foo);
}
void *
thr_fn2(void *arg)
{
    printf("thread 2: ID is %lu\n", (unsigned long)pthread_self());
    pthread_exit((void *)0);
}
int main(void)
{
    int        err;
    pthread_t tid1, tid2;
    struct foo *fp;
    err = pthread_create(&tid1, NULL, thr_fn1, NULL);
    if (err != 0)
        err_exit(err, "can't create thread 1");
    err = pthread_join(tid1, (void *)&fp);
    if (err != 0)
        err_exit(err, "can't join with thread 1");
    sleep(1);
    printf("parent starting second thread\n");
    err = pthread_create(&tid2, NULL, thr_fn2, NULL);
    if (err != 0)
        err_exit(err, "can't create thread 2");
    sleep(1);
    printfoo("parent:\n", fp);
    exit(0);
}
#+end_src
图11-4 pthread_exit参数的不正确使用

在Linux上运行此程序，得到：
#+begin_src bash
$ ./a.out
thread 1:
structure at 0x7f2c83682ed0
foo.a = 1
foo.b = 2
foo.c = 3
foo.d = 4
parent starting second thread
thread 2: ID is 139829159933696
parent:
structure at 0x7f2c83682ed0
foo.a = -2090321472
foo.b = 32556
foo.c = 1
foo.d = 0
#+end_src
当然，运行结果根据内存体系结构、编译器以及线程库的实现会有所不同。在Solaris上的结果类似：
#+begin_src bash
$ ./a.out
thread 1:
structure at 0xffffffff7f0fbf30
foo.a = 1
foo.b = 2
foo.c = 3
foo.d = 4
parent starting second thread
thread 2: ID is 3
parent:
structure at 0xffffffff7f0fbf30
foo.a = -1
foo.b = 2136969048
foo.c = -1
foo.d = 2138049024
#+end_src
可以看到，当主线程访问这个结构时，结构的内容（在线程tid1的栈上分配的）已经改变了。注意第二个线程（tid2）的栈是如何覆盖第一个线程的栈的。为了解决这个问题，可以使用全局结构，或者用malloc函数分配结构。

在Mac OS X上运行的结果有所不同：
#+begin_src bash
$ ./a.out
thread 1:
structure at 0x1000b6f00
foo.a = 1
foo.b = 2
foo.c = 3
foo.d = 4
parent starting second thread
thread 2: ID is 4295716864
parent:
structure at 0x1000b6f00
Segmentation fault (core dumped)
#+end_src
在这种情况下，父进程试图访问已退出的第一个线程传给它的结构时，内存不再有效，这时得到的是SIGSEGV信号。

FreeBSD上，父进程访问内存时，内存并没有被覆写，得到的结果是：
#+begin_src bash
thread 1:
structure at 0xbf9fef88
foo.a = 1
foo.b = 2
foo.c = 3
foo.d = 4
parent starting second thread
thread 2: ID is 673279680
parent:
structure at 0xbf9fef88
foo.a = 1
foo.b = 2
foo.c = 3
foo.d = 4
#+end_src
虽然线程退出后，内存依然是完整的，但我们不能期望情况总是这样的。从其他平台上的结果中可以看出，情况并不都是这样的。

线程可以通过调用pthread_cancel函数来请求取消同一进程中的其他线程。

*** pthread_cancel
#+begin_src c++
#include <pthread.h>

int pthread_cancel(pthread_t tid);
#+end_src

返回值：若成功，返回0；否则，返回错误编号

在默认情况下，pthread_cancel 函数会使得由tid标识的线程的行为表现为如同调用了参数为PTHREAD_ CANCELED 的pthread_exit 函数，但是，线程可以选择忽略取消或者控制如何被取消。注意pthread_cancel并不等待线程终止，它仅仅提出请求。

*** 线程清理处理程序
线程可以安排它退出时需要调用的函数，这与进程在退出时可以用atexit函数（见7.3节）安排退出是类似的。这样的函数称为线程清理处理程序（thread cleanup handler）。一个线程可以建立多个清理处理程序。处理程序记录在栈中，也就是说，它们的执行顺序与它们注册时相反。
#+begin_src c++
#include <pthread.h>

void pthread_cleanup_push(void (*rtn)(void *), void *arg);

void pthread_cleanup_pop(int execute);
#+end_src
当线程执行以下动作时，清理函数rtn是由pthread_cleanup_push函数调度的，调用时只有一个参数arg：
- 调用pthread_exit时；
- 响应取消请求时；
- 用非零execute参数调用pthread_cleanup_pop时。

如果 execute 参数设置为 0，清理函数将不被调用。不管发生上述哪种情况，pthread_cleanup_pop都将删除上次pthread_cleanup_push调用建立的清理处理程序。

这些函数有一个限制，由于它们可以实现为宏，所以必须在与线程相同的作用域中以匹配对的形式使用。pthread_cleanup_push 的宏定义可以包含字符{，这种情况下，在 pthread_cleanup_pop的定义中要有对应的匹配字符}。

*** 实例
图11-5给出了一个如何使用线程清理处理程序的例子。虽然例子是人为编造的，但它描述了其中涉及的清理机制。注意，虽然我们从来没想过要传一个参数0给线程启动例程，但还是需要把pthread_cleanup_pop调用和pthread_cleanup_push调用匹配起来，否则，程序编译就可能通不过。

#+begin_src c++
#include "apue.h"
#include <pthread.h>
void cleanup(void *arg)
{
    printf("cleanup: %s\n", (char *)arg);
}
void *
thr_fnl(void *arg)
{
    printf("thread 1 start\n");
    pthread_clcanup_push(cleanup, "thread 1 first handler");
    pthread_cleanup_push(cleanup, "thread 1 second handler");
    printf("thread i push completein");
    if (arg)
        return ((void *)1);
    pthread_cleanup_pop(0);
    pthread_cleanup_pop(0);
    return (void * )1);
}
void *
thr_fn2(void *arg)
{
    printf("thread 2 start\n ");
    pthread_cleanup_push(cleanup, "thread 2 first handler");
    pthread_cleanup_push(cleanup, "thread 2 second handler");
    printf("thread 2 push completein");
    if (arg)
        pthread_exit(void *) 2);
    pthread_cleanup_pop(0);
    pthread_cleanup_pop(0);
    pthread_exit((void *)2);
}
int main(void)
{
    int err;
    thread_t tidl, tid2;
    void *tret;
    err = pthread_create(&tid1, NULL, thr_fnl, (void *)1);
    if (err != 0)
        err_exit(err, "can't create thread 1");
    err = pthread_create(&tid2, NULL, thr_fn2, (void *)1);
    if (err != 0)
        err_exit(err, "can't create thread 2");
    err = pthread_join(tid1, &tret);
    if (err != 0)
        err_exit(err, "can't join with thread 1");
    printf("thread l exit code %ld\n", (long)tret);
    err = pthread_join(tid2, &tret);
    if (err != 0)
        err_exit(err, "can't join with thread 2");
    printf("thread 2. exit code %ld\n", (long)tret);
    exit(0);
}
#+end_src
在Linux或者Solaris上运行图11-5中的程序会得到：
#+begin_src bash
$ ./a.out
thread 1 start
thread 1 push complete
thread 2 start
thread 2 push complete
cleanup: thread 2 second handler
cleanup: thread 2 first handler
thread 1 exit code 1
thread 2 exit code 2
#+end_src
从输出结果可以看出，两个线程都正确地启动和退出了，但是只有第二个线程的清理处理程序被调用了。因此，如果线程是通过从它的启动例程中返回而终止的话，它的清理处理程序就不会被调用。还要注意，清理处理程序是按照与它们安装时相反的顺序被调用的。

如果在FreeBSD或者Mac OS X上运行相同的程序，可以看到程序会出现段异常并产生core文件。这是因为在这两个平台上，pthread_cleanup_push是用宏实现的，而宏把某些上下文存放在栈上。当线程1在调用pthread_cleanup_push和调用pthread_cleanup_pop之间返回时，栈已被改写，而这两个平台在调用清理处理程序时就用了这个被改写的上下文。在Single UNIX Specification中，函数如果在调用pthread_cleanup_push和pthread_cleanup_pop之间返回，会产生未定义行为。唯一的可移植方法是调用pthread_exit。

*** pthread_detach
在默认情况下，线程的终止状态会保存直到对该线程调用pthread_join。如果线程已经被分离，线程的底层存储资源可以在线程终止时立即被收回。在线程被分离后，我们不能用pthread_join函数等待它的终止状态，因为对分离状态的线程调用pthread_join会产生未定义行为。
可以调用pthread_detach分离线程。
#+begin_src c++
#include <pthread.h>

int pthread_detach(pthread_t tid);
#+end_src
返回值：若成功，返回0；否则，返回错误编号

当我们的线程运行结束后，最后显示的调用被回收。这样就出现两种回收方式。
1. pthread_join是一个阻塞函数，调用方会阻塞到pthread_join所指定的tid的线程结束后才被回收，但是在此之前，调用方是霸占系统资源的。
2. pthread_detach，不会阻塞，调用它后，线程运行结束后会自动释放资源。

一个可结合线程在运行结束后，若没有调用pthread_join，会进入一个类似zombie process的状态，也就是系统中还有一些资源没有回收。需要pthread_join来回收这些资源。（这就类似进程操作中的waitpid函数）线程在创建时默认的状态是joinable, 如果一个线程结束运行但没有被join,则它的状态类似于进程中的Zombie Process（僵尸进程）,即还有一部分资源没有被回收（退出状态码），所以创建线程者应该 pthread_join来等待线程运行结束，并可得到线程的退出代码，回收其资源（类似于wait,waitpid)，这样不会导致系统越用越慢的现象。
但是 pthread_join(pthread_id)函数是阻塞函数，在调用pthread_join(pthread_id)后，如果该线程没有运行结束，调用者会被阻塞，在有些情况下我们并不希望如此，比如在Web服务器中当 主线程 为每个新来的链接创建一个子线程进行处理的时候，主线程并不希望因为调用pthread_join而阻塞（因为还要继续处理之后到来的链接），这时可以在子线程中加入代码pthread_detach( pthread_self())或者父线程调用pthread_detach(thread_id)（非阻塞，可立即返回）
这将该子线程的状态设置为detached,则该线程运行结束后会自动释放所有资源.

*** 参考文章
[[https://blog.csdn.net/qq_33573235/article/details/79288487][pthread_detach()函数的作用]]
** 线程同步
*** 并发场景简介
当多个控制线程共享相同的内存时，需要确保每个线程看到一致的数据视图。如果每个线程使用的变量都是其他线程不会读取和修改的，那么就不存在一致性问题。同样，如果变量是只读的，多个线程同时读取该变量也不会有一致性问题。但是，当一个线程可以修改的变量，其他线程也可以读取或者修改的时候，我们就需要对这些线程进行同步，确保它们在访问变量的存储内容时不会访问到无效的值。

当一个线程修改变量时，其他线程在读取这个变量时可能会看到一个不一致的值。在变量修改时间多于一个存储器访问周期的处理器结构中，当存储器读与存储器写这两个周期交叉时，这种不一致就会出现。当然，这种行为是与处理器体系结构相关的，但是可移植的程序并不能对使用何种处理器体系结构做出任何假设。

图 11-7 描述了两个线程读写相同变量的假设例子。在这个例子中，线程 A读取变量然后给这个变量赋予一个新的数值，但写操作需要两个存储器周期。当线程B在这两个存储器写周期中间读取这个变量时，它就会得到不一致的值。

#+DOWNLOADED: screenshot @ 2024-01-11 22:06:36
[[file:images/linux笔记/UNIX-线程/2024-01-11_22-06-36_screenshot.png]]
图11-7 两个线程的交叉存储器周期

为了解决这个问题，线程不得不使用锁，同一时间只允许一个线程访问该变量。图11-8描述了这种同步。如果线程B希望读取变量，它首先要获取锁。同样，当线程A更新变量时，也需要获取同样的这把锁。这样，线程B在线程A释放锁以前就不能读取变量。

#+DOWNLOADED: screenshot @ 2024-01-11 22:07:06
[[file:images/linux笔记/UNIX-线程/2024-01-11_22-07-06_screenshot.png]]
图11-8 两个线程同步内存访问

两个或多个线程试图在同一时间修改同一变量时，也需要进行同步。考虑变量增量操作的情况（图11-9），增量操作通常分解为以下3步。
（1）从内存单元读入寄存器。
（2）在寄存器中对变量做增量操作。
（3）把新的值写回内存单元。

如果两个线程试图几乎在同一时间对同一个变量做增量操作而不进行同步的话，结果就可能出现不一致，变量可能比原来增加了1，也有可能比原来增加了2，具体增加了1还是2要取决于第二个线程开始操作时获取的数值。如果第二个线程执行第1步要比第一个线程执行第3步要早，第二个线程读到的值与第一个线程一样，为变量加1，然后写回去，事实上没有实际的效果，总的来说变量只增加了1。

如果修改操作是原子操作，那么就不存在竞争。在前面的例子中，如果增加1只需要一个存储器周期，那么就没有竞争存在。如果数据总是以顺序一致出现的，就不需要额外的同步。当多个线程观察不到数据的不一致时，那么操作就是顺序一致的。在现代计算机系统中，存储访问需要多个总线周期，多处理器的总线周期通常在多个处理器上是交叉的，所以我们并不能保证数据是顺序一致的。

#+DOWNLOADED: screenshot @ 2024-01-11 22:09:16
[[file:images/linux笔记/UNIX-线程/2024-01-11_22-09-16_screenshot.png]]
图11-9 两个非同步的线程对同一个变量做增量操作

在顺序一致环境中，可以把数据修改操作解释为运行线程的顺序操作步骤。可以把这样的操作描述为“线程A对变量增加了1，然后线程B对变量增加了1，所以变量的值就比原来的大2”，或者描述为“线程B对变量增加了1，然后线程A对变量增加了1，所以变量的值就比原来的大2”。这两个线程的任何操作顺序都不可能让变量出现除了上述值以外的其他值。

除了计算机体系结构以外，程序使用变量的方式也会引起竞争，也会导致不一致的情况发生。例如，我们可能对某个变量加 1，然后基于这个值做出某种决定。因为这个增量操作步骤和这个决定步骤的组合并非原子操作，所以就给不一致情况的出现提供了可能。
*** 互斥量
可以使用 pthread 的互斥接口来保护数据，确保同一时间只有一个线程访问数据。互斥量（mutex）从本质上说是一把锁，在访问共享资源前对互斥量进行设置（加锁），在访问完成后释放（解锁）互斥量。对互斥量进行加锁以后，任何其他试图再次对互斥量加锁的线程都会被阻塞直到当前线程释放该互斥锁。如果释放互斥量时有一个以上的线程阻塞，那么所有该锁上的阻塞线程都会变成可运行状态，第一个变为运行的线程就可以对互斥量加锁，其他线程就会看到互斥量依然是锁着的，只能回去再次等待它重新变为可用。在这种方式下，每次只有一个线程可以向前执行。

只有将所有线程都设计成遵守相同数据访问规则的，互斥机制才能正常工作。操作系统并不会为我们做数据访问的串行化。如果允许其中的某个线程在没有得到锁的情况下也可以访问共享资源，那么即使其他的线程在使用共享资源前都申请锁，也还是会出现数据不一致的问题。

互斥变量是用pthread_mutex_t数据类型表示的。

在使用互斥变量以前，必须首先对它进行初始化，可以把它设置为常量PTHREAD_MUTEX_INITIALIZER（只适用于静态分配的互斥量），也可以通过调用pthread_mutex_init函数进行初始化。
如果动态分配互斥量（例如，通过调用malloc函数），在释放内存前需要调用pthread_mutex_destroy。

#+begin_src c++
#include <pthread.h>

int pthread_mutex_init(pthread_mutex_t *restrict mutex, const pthread_mutexattr_t *restrict attr);

int pthread_mutex_destroy(pthread_mutex_t *mutex);
#+end_src
两个函数的返回值：若成功，返回0；否则，返回错误编号

要用默认的属性初始化互斥量，只需把attr设为NULL。

对互斥量进行加锁，需要调用 pthread_mutex_lock。如果互斥量已经上锁，调用线程将阻塞直到互斥量被解锁。
对互斥量解锁，需要调用pthread_mutex_unlock。

#+begin_src c++
#include <pthread.h>

int pthread_mutex_lock(pthread_mutex_t *mutex);

int pthread_mutex_trylock(pthread_mutex_t *mutex);

int pthread_mutex_unlock(pthread_mutex_t *mutex);
#+end_src
所有函数的返回值：若成功，返回0；否则，返回错误编号

如果线程不希望被阻塞，它可以使用pthread_mutex_trylock尝试对互斥量进行加锁。如果调用 pthread_mutex_trylock 时互斥量处于未锁住状态，那么 pthread_mutex_trylock将锁住互斥量，不会出现阻塞直接返回0，否则pthread_mutex_trylock 就会失败，不能锁住互斥量，返回EBUSY。
*** 实例

图11-10描述了用于保护某个数据结构的互斥量。当一个以上的线程需要访问动态分配的对象时，我们可以在对象中嵌入引用计数，确保在所有使用该对象的线程完成数据访问之前，该对象内存空间不会被释放。

在对引用计数加 1、减 1、检查引用计数是否到达 0 这些操作之前需要锁住互斥量。在foo_alloc 函数中将引用计数初始化为 1 时没必要加锁，因为在这个操作之前分配线程是唯一引用该对象的线程。但是在这之后如果要将该对象放到一个列表中，那么它就有可能被别的线程发现，这时候需要首先对它加锁。

在使用该对象前，线程需要调用foo_hold对这个对象的引用计数加1。当对象使用完毕时，必须调用foo_rele释放引用。最后一个引用被释放时，对象所占的内存空间就被释放。

在这个例子中，我们忽略了线程在调用foo_hold之前是如何找到对象的。如果有另一个线程在调用foo_hold时阻塞等待互斥锁，这时即使该对象引用计数为0，foo_rele释放该对象的内存仍然是不对的。可以通过确保对象在释放内存前不会被找到这种方式来避免上述问题。可以通过下面的例子来看看如何做到这一点。

#+begin_src c++
#include <stdlib.h>
#include <pthread.h>

struct foo
{
    int f_count;
    pthread_mutex_t f_lock;
    int f_id;
    /* ... more stuff here ... */
};
struct foo *
foo_alloc(int id) /* allocate the object*/
{
    struct foo *fp;
    if ((fp = malloc(sizeof(struct foo))) != NULL)
    {
        fp->f_count = 1;
        fp->f_id = id;
        if (pthread_mutex_init(&fp->f_lock, NULL) != 0)
        {
            free(fp);
            return (NULL);
        }
        /* ... continue initialization ... */
        return (fp);
    }
}
void foo_hold(struct foo *fp) /* add a reference to the object */
{
    pthread_mutex_lock(&fp->f_lock);
    fp->f_count++;
    pthread_mutex_unlock(&fp->f_lock);
}
void foo_rele(struct foo *fp) /* release a reference to the object */
{
    pthread_mutex_lock(&fp->f_lock);
    if (--fp->f_count -= 0)
    { /* last reference */
        pthread_mutex_unlock(&fp->f_lock);
        pthread_mutex_destroy(&fp->f_lock);
        free(fp);
    }
    else
    {
        pthread_mutex_unlock(&fp->f_lock);
    }
}
#+end_src
图11-10 使用互斥量保护数据结构
*** 避免死锁
如果线程试图对同一个互斥量加锁两次，那么它自身就会陷入死锁状态，但是使用互斥量时，还有其他不太明显的方式也能产生死锁。例如，程序中使用一个以上的互斥量时，如果允许一个线程一直占有第一个互斥量，并且在试图锁住第二个互斥量时处于阻塞状态，但是拥有第二个互斥量的线程也在试图锁住第一个互斥量。因为两个线程都在相互请求另一个线程拥有的资源，所以这两个线程都无法向前运行，于是就产生死锁。

可以通过仔细控制互斥量加锁的顺序来避免死锁的发生。例如，假设需要对两个互斥量A和B同时加锁。如果所有线程总是在对互斥量B加锁之前锁住互斥量A，那么使用这两个互斥量就不会产生死锁（当然在其他的资源上仍可能出现死锁）。类似地，如果所有的线程总是在锁住互斥量A之前锁住互斥量B，那么也不会发生死锁。
可能出现的死锁只会发生在一个线程试图锁住另一个线程以相反的顺序锁住的互斥量。

有时候，应用程序的结构使得对互斥量进行排序是很困难的。如果涉及了太多的锁和数据结构，可用的函数并不能把它转换成简单的层次，那么就需要采用另外的方法。在这种情况下，可以先释放占有的锁，然后过一段时间再试。这种情况可以使用pthread_mutex_trylock接口避免死锁。如果已经占有某些锁而且pthread_mutex_trylock接口返回成功，那么就可以前进。但是，如果不能获取锁，可以先释放已经占有的锁，做好清理工作，然后过一段时间再重新试。
*** 实例
在这个例子中，我们更新了图11-10的程序，展示了两个互斥量的使用方法。在同时需要两个互斥量时，总是让它们以相同的顺序加锁，这样可以避免死锁。第二个互斥量维护着一个用于跟踪foo数据结构的散列列表。这样hashlock互斥量既可以保护foo数据结构中的散列表fh，又可以保护散列链字段f_next。foo结构中的f_lock互斥量保护对foo结构中的其他字段的访问。
#+begin_src c++
#include <stdlib.h>
#include <pthread.h>
#define NHASH 29
#define HASH(id) (((unsigned long)id) % NHASH)
struct foo *fh[NHASH];
pthread_mutex_t hashlock = PTHREAD_MUTEX_INITIALIZER;
struct foo
{
    int f_count;
    pthread_mutex_t f_lock;
    int f_id;
    struct foo *f_next; /* protected by hashlock */
    /* ... more stuff here ... */
};
struct foo *
foo_alloc(int id) /* allocate the object */
{
    struct foo *fp;
    int idx;
    if ((fp = malloc(sizeof(struct foo))) != NULL)
    {
        fp->f_count = 1;
        fp->f_id = id;
        if (pthread_mutex_init(&fp->f_lock, NULL) != 0)
        {
            free(fp);
            return (NULL);
        }
        idx = HASH(id);
        pthread_mutex_lock(&hashlock);
        fp->f_next = fh[idx];
        fh[idx] = fp;
        pthread_mutex_lock(&fp->f_lock);
        pthread_mutex_unlock(&hashlock);
        /* ... continue initialization ... */
        pthread_mutex_unlock(&fp->f_lock);
    }
    return (fp);
}
void foo_hold(struct foo *fp) /* add a reference to the object */
{
    pthread_mutex_lock(&fp->f_lock);
    fp->f_count++;
    pthread_mutex_unlock(&fp->f_lock);
}
struct foo *
foo_find(int id) /* find an existing object */
{
    struct foo *fp;
    pthread_mutex_lock(&hashlock);
    for (fp = fh[HASH(id)]; fp != NULL; fp = fp->f_next)
    {
        if (fp->f_id == id)
        {
            foo_hold(fp);
            break;
        }
    }
    pthread_mutex_unlock(&hashlock);
    return (fp);
}
void foo_rele(struct foo *fp) /* release a reference to the object */
{
    struct foo *tfp;
    int idx;
    pthread_mutex_lock(&fp->f_lock);
    if (fp->f_count == 1)
    { /* last reference */
        pthread_mutex_unlock(&fp->f_lock);
        pthread_mutex_lock(&hashlock);
        pthread_mutex_lock(&fp->f_lock);
        /* need to recheck the condition */
        if (fp->f_count != 1)
        {
            fp->f_count--;
            pthread_mutex_unlock(&fp->f_lock);
            pthread_mutex_unlock(&hashlock);
            return;
        }
        /* remove from list */
        idx = HASH(fp->f_id);
        tfp = fh[idx];
        if (tfp == fp)
        {
            fh[idx] = fp->f_next;
        }
        else
        {
            while (tfp->f_next != fp)
                tfp = tfp->f_next;
            tfp->f_next = fp->f_next;
        }
        pthread_mutex_unlock(&hashlock);
        pthread_mutex_unlock(&fp->f_lock);
        pthread_mutex_destroy(&fp->f_lock);
        free(fp);
    }
    else
    {
        fp->f_count--;
        pthread_mutex_unlock(&fp->f_lock);
    }
}
#+end_src
图11-11 使用两个互斥量

比较图 11-11 和图 11-10，可以看出，分配函数现在锁住了散列列表锁，把新的结构添加到了散列桶中，而且在对散列列表的锁解锁之前，先锁定了新结构中的互斥量。因为新的结构是放在全局列表中的，其他线程可以找到它，所以在初始化完成之前，需要阻塞其他线程试图访问新结构。

foo_find函数锁住散列列表锁，然后搜索被请求的结构。如果找到了，就增加其引用计数并返回指向该结构的指针。注意，加锁的顺序是，先在foo_find函数中锁定散列列表锁，然后再在foo_hold函数中锁定foo结构中的f_lock互斥量。

现在有了两个锁以后，foo_rele函数就变得更加复杂了。如果这是最后一个引用，就需要对这个结构互斥量进行解锁，因为我们需要从散列列表中删除这个结构，这样才可以获取散列列表锁，然后重新获取结构互斥量。从上一次获得结构互斥量以来我们可能被阻塞着，所以需要重新检查条件，判断是否还需要释放这个结构。如果另一个线程在我们为满足锁顺序而阻塞时发现了这个结构并对其引用计数加1，那么只需要简单地对整个引用计数减1，对所有的东西解锁，然后返回。

这种锁方法很复杂，所以我们需要重新审视原来的设计。我们也可以使用散列列表锁来保护结构引用计数，使事情大大简化。结构互斥量可以用于保护foo结构中的其他任何东西。图11-12反映了这种变化。

#+begin_src c++
#include <stdlib.h>
#include <pthread.h>
#define NHASH 29
#define HASH(id) (((unsigned long)id) % NHASH)
struct foo *fh[NHASH];
pthread_mutex_t hashlock = PTHREAD_MUTEX_INITIALIZER;
struct foo
{
    int f_count; /* protected by hashlock */
    pthread_mutex_t f_lock;
    int f_id;
    struct foo *f_next; /* protected by hashlock */
    /* ... more stuff here ... */
};
struct foo *
foo_alloc(int id) /* allocate the object */
{
    struct foo *fp;
    int idx;
    if ((fp = malloc(sizeof(struct foo))) != NULL)
    {
        fp->f_count = 1;
        fp->f_id = id;
        if (pthread_mutex_init(&fp->f_lock, NULL) != 0)
        {
            free(fp);
            return (NULL);
        }
        idx = HASH(id);
        pthread_mutex_lock(&hashlock);
        fp->f_next = fh[idx];
        fh[idx] = fp;
        pthread_mutex_lock(&fp->f_lock);
        pthread_mutex_unlock(&hashlock);
        /* ... continue initialization ... */
        pthread_mutex_unlock(&fp->f_lock);
    }
    return (fp);
}
void foo_hold(struct foo *fp) /* add a reference to the object */
{
    pthread_mutex_lock(&hashlock);
    fp->f_count++;
    pthread_mutex_unlock(&hashlock);
}
struct foo *
foo_find(int id) /* find an existing object */
{
    struct foo *fp;
    pthread_mutex_lock(&hashlock);
    for (fp = fh[HASH(id)]; fp != NULL; fp = fp->f_next)
    {
        if (fp->f_id == id)
        {
            fp->f_count++;
            break;
        }
    }
    pthread_mutex_unlock(&hashlock);
    return (fp);
}
void foo_rele(struct foo *fp) /* release a reference to the object */
{
    struct foo *tfp;
    int idx;
    pthread_mutex_lock(&hashlock);
    if (--fp->f_count == 0)
    { /* last reference, remove from list */
        idx = HASH(fp->f_id);
        tfp = fh[idx];
        if (tfp == fp)
        {
            fh[idx] = fp->f_next;
        }
        else
        {
            while (tfp->f_next != fp)
                tfp = tfp->f_next;
            tfp->f_next = fp->f_next;
        }
        pthread_mutex_unlock(&hashlock);
        pthread_mutex_destroy(&fp->f_lock);
        free(fp);
    }
    else
    {
        pthread_mutex_unlock(&hashlock);
    }
}
#+end_src
图11-12 简化的锁

注意，与图11-11中的程序相比，图11-12中的程序就简单多了。图11和图12的最主要区别在于:图12的hashlock锁的范围更大了,每次访问列表中的数据时,都需要持有hashlocak.图12的程序,并发性比较差.两种用途使用相同的锁时，围绕散列列表和引用计数的锁的排序问题就不存在了。
多线程的软件设计涉及这两者之间的折中。如果锁的粒度太粗，就会出现很多线程阻塞等待相同的锁，这可能并不能改善并发性。如果锁的粒度太细，那么过多的锁开销会使系统性能受到影响，而且代码变得复杂。作为一个程序员，需要在满足锁需求的情况下，在代码复杂性和性能之间找到正确的平衡。
*** 函数pthread_mutex_timedlock
当线程试图获取一个已加锁的互斥量时，pthread_mutex_timedlock 互斥量原语允许绑定线程阻塞时间。pthread_mutex_timedlock函数与pthread_mutex_lock是基本等价的，但是在达到超时时间值时，pthread_mutex_timedlock 不会对互斥量进行加锁，而是返回错误码ETIMEDOUT。
#+begin_src c++
#include <pthread.h>
#include <time.h>

int pthread_mutex_timedlock(pthread_mutex_t *restrict mutex,const struct timespec *restrict tsptr);
#+end_src
返回值：若成功，返回0；否则，返回错误编号

超时指定愿意等待的绝对时间（与相对时间对比而言，指定在时间X之前可以阻塞等待，而不是说愿意阻塞Y秒）。这个超时时间是用timespec结构来表示的，它用秒和纳秒来描述时间。
*** 实例

图11-13给出了如何用pthread_mutex_timedlock避免永久阻塞。
#+begin_src c++
#include "apue.h"
#include <pthread.h>
int main(void)
{
    int err;
    struct timespec tout;
    struct tm *tmp;
    char buf[64];
    pthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER;
    pthread_mutex_lock(&lock);
    printf("mutex is locked\n");
    clock_gettime(CLOCK_REALTIME, &tout);
    tmp = localtime(&tout.tv_sec);
    strftime(buf, sizeof(buf), "%r", tmp);
    printf("current time is %s\n", buf);
    tout.tv_sec += 10;
    /* 10 seconds from now */
    /* caution: this could lead to deadlock */
    err = pthread_mutex_timedlock(&lock, &tout);
    clock_gettime(CLOCK_REALTIME, &tout);
    tmp = localtime(&tout.tv_sec);
    strftime(buf, sizeof(buf), "%r", tmp);
    printf("the time is now %s\n", buf);
    if (err == 0)
        printf("mutex locked again!\n");
    else
        printf("can’t lock mutex again: %s\n", strerror(err));
    exit(0);
}
#+end_src

图11-13 使用pthread_mutex_timedlock

图11-13中的程序运行结果输出如下：
#+begin_src bash
$ ./a.out
mutex is locked
current time is 11:41:58 AM
the time is now 11:42:08 AM
can’t lock mutex again: Connection timed out
#+end_src
这个程序故意对它已有的互斥量进行加锁，目的是演示pthread_mutex_timedlock是如何工作的。不推荐在实际中使用这种策略，因为它会导致死锁。

注意，阻塞的时间可能会有所不同，造成不同的原因有多种：开始时间可能在某秒的中间位置，系统时钟的精度可能不足以精确到支持我们指定的超时时间值，或者在程序继续运行前，调度延迟可能会增加时间值。

Mac OS X 10.6.8还没有支持pthread_mutex_timedlock，但是FreeBSD 8.0、Linux 3.2.0以及Solaris 10支持该函数，虽然Solaris仍然把它放在实时库librt中。Solaris 10还提供了另一个使用相对超时时间的函数。
*** 读写锁
读写锁（reader-writer lock）与互斥量类似，不过读写锁允许更高的并行性。互斥量要么是锁住状态，要么就是不加锁状态，而且一次只有一个线程可以对其加锁。读写锁可以有3种状态：读模式下加锁状态，写模式下加锁状态，不加锁状态。一次只有一个线程可以占有写模式的读写锁，但是多个线程可以同时占有读模式的读写锁。

当读写锁是写加锁状态时，在这个锁被解锁之前，所有试图对这个锁加锁的线程都会被阻塞。当读写锁在读加锁状态时，所有试图以读模式对它进行加锁的线程都可以得到访问权，但是任何希望以写模式对此锁进行加锁的线程都会阻塞，直到所有的线程释放它们的读锁为止。虽然各操作系统对读写锁的实现各不相同，但当读写锁处于读模式锁住的状态，而这时有一个线程试图以写模式获取锁时，读写锁通常会阻塞随后的读模式锁请求。这样可以避免读模式锁长期占用，而等待的写模式锁请求一直得不到满足。

读写锁非常适合于对数据结构读的次数远大于写的情况。当读写锁在写模式下时，它所保护的数据结构就可以被安全地修改，因为一次只有一个线程可以在写模式下拥有这个锁。当读写锁在读模式下时，只要线程先获取了读模式下的读写锁，该锁所保护的数据结构就可以被多个获得读模式锁的线程读取。

读写锁也叫做共享互斥锁（shared-exclusive lock）。当读写锁是读模式锁住时，就可以说成是以共享模式锁住的。当它是写模式锁住的时候，就可以说成是以互斥模式锁住的。

与互斥量相比，读写锁在使用之前必须初始化，在释放它们底层的内存之前必须销毁。
#+begin_src c++
#include <pthread.h>

int pthread_rwlock_init(pthread_rwlock_t *restrict rwlock,
const pthread_rwlockattr_t *restrict attr);

int pthread_rwlock_destroy(pthread_rwlock_t *rwlock);
#+end_src
两个函数的返回值：若成功，返回0；否则，返回错误编号

读写锁通过调用 pthread_rwlock_init 进行初始化。如果希望读写锁有默认的属性，可以传一个null指针给attr

Single UNIX Specification在XSI扩展中定义了PTHREAD_RWLOCK_INITIALIZER常量。如果默认属性就足够的话，可以用它对静态分配的读写锁进行初始化。

在释放读写锁占用的内存之前，需要调用 pthread_rwlock_destroy 做清理工作。如果pthread_rwlock_init为读写锁分配了资源，pthread_rwlock_destroy将释放这些资源。如果在调用 pthread_rwlock_destroy 之前就释放了读写锁占用的内存空间，那么分配给这个锁的资源就会丢失。

要在读模式下锁定读写锁，需要调用pthread_rwlock_rdlock。要在写模式下锁定读写锁，需要调用pthread_rwlock_wrlock。不管以何种方式锁住读写锁，都可以调用pthread_rwlock_unlock进行解锁。
#+begin_src c++
#include <pthread.h>

int pthread_rwlock_rdlock(pthread_rwlock_t *rwlock);

int pthread_rwlock_wrlock(pthread_rwlock_t *rwlock);

int pthread_rwlock_unlock(pthread_rwlock_t *rwlock);
#+end_src
所有函数的返回值：若成功，返回0；否则，返回错误编号

各种实现可能会对共享模式下可获取的读写锁的次数进行限制，所以需要检查 pthread_rwlock_rdlock的返回值。即使pthread_rwlock_wrlock和pthread_rwlock_unlock有错误返回，而且从技术上来讲，在调用函数时应该总是检查错误返回，但是如果锁设计合理的话，就不需要检查它们。错误返回值的定义只是针对不正确使用读写锁的情况（如未经初始化的锁），或者试图获取已拥有的锁从而可能产生死锁的情况。但是需要注意，有些特定的实现可能会定义另外的错误返回。

Single UNIX Specification还定义了读写锁原语的条件版本。
#+begin_src c++
#include <pthread.h>

int pthread_rwlock_tryrdlock(pthread_rwlock_t *rwlock);

int pthread_rwlock_trywrlock(pthread_rwlock_t *rwlock);
#+end_src
两个函数的返回值：若成功，返回0；否则，返回错误编号

可以获取锁时，这两个函数返回0。否则，它们返回错误EBUSY。这两个函数可以用于我们前面讨论的遵守某种锁层次但还不能完全避免死锁的情况。
*** 实例

图11-14中的程序解释了读写锁的使用。作业请求队列由单个读写锁保护。这个例子给出了图11-1所示的一种可能的实现，多个工作线程获取单个主线程分配给它们的作业。

#+begin_src c++
#include <stdlib.h>
#include <pthread.h>
struct job
{
    struct job *j_next;
    struct job *j_prev;
    pthread_t j_id;
    /* tells which thread handles this job */
    /* ... more stuff here ... */
};
struct queue
{
    struct job *q_head;
    struct job *q_tail;
    pthread_rwlock_t q_lock;
};
/*
 * Initialize a queue.
 */
int queue_init(struct queue *qp)
{
    int err;
    qp->q_head = NULL;
    qp->q_tail = NULL;
    err = pthread_rwlock_init(&qp->q_lock, NULL);
    if (err != 0)
        return (err);
    /* ... continue initialization ... */
    return (0);
}
/*
 * Insert a job at the head of the queue.
 */
void job_insert(struct queue *qp, struct job *jp)
{
    pthread_rwlock_wrlock(&qp->q_lock);
    jp->j_next = qp->q_head;
    jp->j_prev = NULL;
    if (qp->q_head != NULL)
        qp->q_head->j_prev = jp;
    else
        qp->q_tail = jp;
    /* list was empty */
    qp->q_head = jp;
    pthread_rwlock_unlock(&qp->q_lock);
}
/*
 * Append a job on the tail of the queue.
 */
void job_append(struct queue *qp, struct job *jp)
{
    pthread_rwlock_wrlock(&qp->q_lock);
    jp->j_next = NULL;
    jp->j_prev = qp->q_tail;
    if (qp->q_tail != NULL)
        qp->q_tail->j_next = jp;
    else
        qp->q_head = jp;
    /* list was empty */
    qp->q_tail = jp;
    pthread_rwlock_unlock(&qp->q_lock);
}
/*
 * Remove the given job from a queue.
 */
void job_remove(struct queue *qp, struct job *jp)
{
    pthread_rwlock_wrlock(&qp->q_lock);
    if (jp == qp->q_head)
    {
        qp->q_head = jp->j_next;
        if (qp->q_tail == jp)
            qp->q_tail = NULL;
        else
            jp->j_next->j_prev = jp->j_prev;
    }
    else if (jp == qp->q_tail)
    {
        qp->q_tail = jp->j_prev;
        jp->j_prev->j_next = jp->j_next;
    }
    else
    {
        jp->j_prev->j_next = jp->j_next;
        jp->j_next->j_prev = jp->j_prev;
    }
    pthread_rwlock_unlock(&qp->q_lock);
}
/*
 * Find a job for the given thread ID.
 */
struct job *
job_find(struct queue *qp, pthread_t id)
{
    struct job *jp;
    if (pthread_rwlock_rdlock(&qp->q_lock) != 0)
        return (NULL);
    for (jp = qp->q_head; jp != NULL; jp = jp->j_next)
        if (pthread_equal(jp->j_id, id))
            break;
    pthread_rwlock_unlock(&qp->q_lock);
    return (jp);
}
#+end_src
图11-14 使用读写锁

在这个例子中，凡是需要向队列中增加作业或者从队列中删除作业的时候，都采用了写模式来锁住队列的读写锁。不管何时搜索队列，都需要获取读模式下的锁，允许所有的工作线程并发地搜索队列。在这种情况下，只有在线程搜索作业的频率远远高于增加或删除作业时，使用读写锁才可能改善性能。

工作线程只能从队列中读取与它们的线程 ID 匹配的作业。由于作业结构同一时间只能由一个线程使用，所以不需要额外的加锁。
*** 带有超时的读写锁
与互斥量一样，Single UNIX Specification提供了带有超时的读写锁加锁函数，使应用程序在获取读写锁时避免陷入永久阻塞状态。这两个函数是 pthread_rwlock_timedrdlock 和 pthread_rwlock_timedwrlock。
#+begin_src c++
#include <pthread.h>
#include <time.h>

int pthread_rwlock_timedrdlock(pthread_rwlock_t *restrict rwlock,
const struct timespec *restrict tsptr);

int pthread_rwlock_timedwrlock(pthread_rwlock_t *restrict rwlock,
const struct timespec *restrict tsptr);
#+end_src
两个函数的返回值：若成功，返回0；否则，返回错误编号

这两个函数的行为与它们“不计时的”版本类似。tsptr参数指向timespec结构，指定线程应该停止阻塞的时间。如果它们不能获取锁，那么超时到期时，这两个函数将返回 ETIMEDOUT错误。与pthread_mutex_timedlock函数类似，超时指定的是绝对时间，而不是相对时间。
*** 条件变量
条件变量是线程可用的另一种同步机制。条件变量给多个线程提供了一个会合的场所。条件变量与互斥量一起使用时，允许线程以无竞争的方式等待特定的条件发生。

条件本身是由互斥量保护的。线程在改变条件状态之前必须首先锁住互斥量。其他线程在获得互斥量之前不会察觉到这种改变，因为互斥量必须在锁定以后才能计算条件。

在使用条件变量之前，必须先对它进行初始化。由pthread_cond_t数据类型表示的条件变量可以用两种方式进行初始化，可以把常量PTHREAD_COND_INITIALIZER赋给静态分配的条件变量，但是如果条件变量是动态分配的，则需要使用pthread_cond_init函数对它进行初始化。

在释放条件变量底层的内存空间之前，可以使用pthread_cond_destroy函数对条件变量进行反初始化（deinitialize）。

#+begin_src c++
#include <pthread.h>

int pthread_cond_init(pthread_cond_t *restrict cond,
const pthread_condattr_t *restrict attr);

int pthread_cond_destroy(pthread_cond_t *cond);
#+end_src
两个函数的返回值：若成功，返回0；否则，返回错误编号

除非需要创建一个具有非默认属性的条件变量，否则pthread_cond_init函数的attr参数可以设置为NULL。

我们使用pthread_cond_wait等待条件变量变为真。如果在给定的时间内条件不能满足，那么会生成一个返回错误码的变量。
#+begin_src c++
#include <pthread.h>

int pthread_cond_wait(pthread_cond_t *restrict cond,
pthread_mutex_t *restrict mutex);

int pthread_cond_timedwait(pthread_cond_t *restrict cond,
pthread_mutex_t *restrict mutex,
const struct timespec *restrict tsptr);
#+end_src
两个函数的返回值：若成功，返回0；否则，返回错误编号

传递给pthread_cond_wait的互斥量对条件进行保护。调用者把锁住的互斥量传给函数，函数然后自动把调用线程放到等待条件的线程列表上，对互斥量解锁。这就关闭了条件检查和线程进入休眠状态等待条件改变这两个操作之间的时间通道，这样线程就不会错过条件的任何变化。pthread_cond_wait返回时，互斥量再次被锁住。

pthread_cond_timedwait函数的功能与pthread_cond_wait函数相似，只是多了一个超时（tsptr）。超时值指定了我们愿意等待多长时间，它是通过timespec结构指定的。

如图11-13所示，需要指定愿意等待多长时间，这个时间值是一个绝对数而不是相对数。例如，假设愿意等待3分钟。那么，并不是把3分钟转换成timespec结构，而是需要把当前时间加上3分钟再转换成timespec结构。

可以使用clock_gettime函数（见6.10节）获取timespec结构表示的当前时间。但是目前并不是所有的平台都支持这个函数，因此，也可以用另一个函数 gettimeofday 获取timeval结构表示的当前时间，然后把这个时间转换成timespec结构。要得到超时值的绝对时间，可以使用下面的函数（假设阻塞的最大时间使用分来表示的）：
#+begin_src c++
#include <sys/time.h>
#include <stdlib.h>

void
maketimeout(struct timespec *tsp, long minutes)
{
struct timeval now;

/* get the current time */
gettimeofday(&now, NULL);
tsp->tv_sec = now.tv_sec;
tsp->tv_nsec = now.tv_usec * 1000; /* usec to nsec */

/* add the offset to get timeout value */
tsp->tv_sec += minutes * 60;
}
#+end_src
如果超时到期时条件还是没有出现，pthread_cond_timewait 将重新获取互斥量，然后返回错误ETIMEDOUT。从pthread_cond_wait或者pthread_cond_timedwait调用成功返回时，线程需要重新计算条件，因为另一个线程可能已经在运行并改变了条件。

有两个函数可以用于通知线程条件已经满足。pthread_cond_signal函数至少能唤醒一个等待该条件的线程，而pthread_cond_broadcast函数则能唤醒等待该条件的所有线程。

POSIX 规范为了简化 pthread_cond_signal 的实现，允许它在实现的时候唤醒一个以上的线程。
#+begin_src c++
#include <pthread.h>

int pthread_cond_signal(pthread_cond_t *cond);

int pthread_cond_broadcast(pthread_cond_t *cond);
#+end_src
两个函数的返回值：若成功，返回0；否则，返回错误编号

在调用pthread_cond_signal或者pthread_cond_broadcast时，我们说这是在给线程或者条件发信号。必须注意，一定要在改变条件状态以后再给线程发信号。
**** 为什么pthread_cond_wait需要互斥锁mutex作为参数
***** 生产者和消费者问题的介绍
存在一个共享缓冲区，生产者向共享缓冲区写入数据，消费者从共享缓冲区中读取数据。

生产者和消费者存在同步关系：当共享缓冲区为满时，生产者需要等待，等待消费者从共享缓冲区取走数据；当共享缓冲区为空时，消费者需要等待，等待生产者向共享缓冲区中写入数据。

使用环形队列实现共享缓冲区，数据结构如下：
#+begin_src c++
#define CAPACITY 8     // 缓冲区的最大容量
int buffer[CAPACITY];  // 缓冲区数组
int in;                // 缓冲区的写指针
int out;               // 缓冲区的读指针
int size;              // 缓冲区中的数据个数
缓冲区的相关代码如下

void buffer_init()
{
    in = 0;
    out = 0;
    size = 0;
}

// 判断缓冲区是否为空
int buffer_is_empty()
{
    return size == 0; 
}

// 判断缓冲区是否为满
int buffer_is_full()
{
    return size == CAPACITY; 
}

// 向缓冲区中追加一个数据
void buffer_put(int item)
{
    buffer[in] = item;
    in = (in + 1) % CAPACITY;
    size++;
}

// 从缓冲区中取走一个数据
int buffer_get()
{
    int item;

    item = buffer[out];
    out = (out + 1) % CAPACITY;
    size--;

    return item;
}
#+end_src
如果存在多个生产者和多个消费者，变量in、out和size会被它们共享访问，因此生产者和消费者还存在互斥关系：
- 当某个生产者执行buffer_is_full、buffer_put时，访问了变量in、out和size，只能允许该生产者独占访问这三个变量，禁止其他生产者和消费者访问这些共享变量。
- 当某个消费者执行buffer_is_empty、buffer_get时，访问了变量in、out和size，只能允许该消费者独占访问这三个变量，禁止其他生产者和消费者访问这些共享变量。
***** 用于同步和互斥的全局变量
总结以上
- 生产者和消费者中存在有同步关系，需要使用pthread_cond_wait和pthread_cond_signal解决
- 生产者和消费者中存在有互斥关系，需要使用pthread_mutex_lock和pthread_mutex_unlock解决

程序中需要引入两个全局变量cond和mutex用于同步和互斥
- pthread_cond_t cond;
- pthread_mutex_t mutex;
***** 使用pthread_cond_wait(cond)解决生产者和消费者问题(第一版)
下面我们尝试使用没有mutex参数的pthread_cond_wait来模拟生产者消费者，假想中没有mutex参数的pthread_cond_wait原型如下：
int pthread_cond_wait(pthread_cond_t *cond);

pthread_cond_wait(cond)的功能非常简单，仅仅阻塞当前线程。在生产者消费者这个应用场景中，很快就能发现pthread_cond_wait(cond)的问题。

使用pthread_cond_wait(cond)解决生产者和消费者问题的代码如下：
#+begin_src c++

// 生产者线程执行的流程
void producer_loop()
{
    int i;

    // 生产CAPACITY*2个数据
    for (i = 0; i < CAPACITY*2; i++) {  
        pthread_mutex_lock(&mutex);

        // 当缓冲区为满时，生产者需要等待
        while (buffer_is_full()) {   
            // 当前线程已经持有了mutex，调用pthread_cond_wait阻塞，必然导致死锁
            pthread_cond_wait(&cond);
        }

        // 此时，缓冲区肯定不是满的，向缓冲区写数据
        buffer_put(i);

        pthread_mutex_unlock(&mutex);        

        // 缓冲区的状态发生了变化，唤醒其它的生产者或消费者
        pthread_cond_signal(&cond);
    }
}

// 消费者线程执行的流程
void consumer_loop()
{
    int i;

    // 消费CAPACITY*2个数据
    for (i = 0; i < CAPACITY*2; i++) {  
        pthread_mutex_lock(&mutex);

        // 当缓冲区为空时，消费者需要等待
        while (buffer_is_empty()) {   
            // 当前线程已经持有了mutex，调用pthread_cond_wait阻塞，必然导致死锁
            pthread_cond_wait(&cond);
        }

        // 此时，缓冲区肯定不是空的，从缓冲区取数据
        int item = buffer_get();

        pthread_mutex_unlock(&mutex);        

        // 缓冲区的状态发生了变化，唤醒其它的生产者或消费者
        pthread_cond_signal(&cond);
    }
}
#+end_src
以上程序存在一个会导致死锁的严重错误，以生产者为例：
1. 当前缓冲区已经满了，生产者运行，首先获取mutex
2. 然后检测buffer_is_full为真，生产者无法放入数据
3. 调用pthread_cond_wait，该生产者进入阻塞状态，等待被消费者唤醒
4. 消费者试图获取mutex，由于mutex已经被占用了，消费者将进入阻塞状态
5. 生产者和消费者均进入阻塞状态，系统死锁
***** 使用pthread_cond_wait(cond)解决生产者和消费者问题(第二版)
为了解决死锁的问题，需要对上一节的程序进行如下改进
- 调用线程调用pthread_cond_wait(cond)前，已经持有了mutex
- 执行pthread_cond_wait(cond)前，调用pthread_unlock(mutex)释放mutex
- 执行pthread_cond_wait(cond)后，调用pthread_lock(mutex)再次获得mutex

#+begin_src c++

// 生产者线程执行的流程
void producer_loop()
{
    int i;

    // 生产CAPACITY*2个数据
    for (i = 0; i < CAPACITY*2; i++) {  
        pthread_mutex_lock(&mutex);

        // 当缓冲区为满时，生产者需要等待
        while (buffer_is_full()) {   
            pthread_mutex_unlock(&mutex);
            pthread_cond_wait(&cond);
            pthread_mutex_lock(&mutex);
        }

        // 此时，缓冲区肯定不是满的，向缓冲区写数据
        buffer_put(i);

        pthread_mutex_unlock(&mutex);        

        // 缓冲区的状态发生了变化，唤醒其它的生产者或消费者
        pthread_cond_signal(&cond);
    }
}

// 消费者线程执行的流程
void consumer_loop()
{
    int i;

    // 消费CAPACITY*2个数据
    for (i = 0; i < CAPACITY*2; i++) {  
        pthread_mutex_lock(&mutex);

        // 当缓冲区为空时，消费者需要等待
        while (buffer_is_empty()) {   
            pthread_mutex_unlock(&mutex);
            pthread_cond_wait(&cond);
            pthread_mutex_lock(&mutex);            
        }

        // 此时，缓冲区肯定不是空的，从缓冲区取数据
        int item = buffer_get();

        pthread_mutex_unlock(&mutex);        

        // 缓冲区的状态发生了变化，唤醒其它的生产者或消费者
        pthread_cond_signal(&cond);
    }
}
#+end_src
这里解释一下为什么线程调用pthread_cond_wait返回后，需要再次调用pthread_mutex_lock获取锁。以生产者为例，以下为生产者向buffer中追加数据的代码段：
#+begin_src c++
// 生产者向buffer中追加数据
pthread_mutex_lock(&mutex);
while (buffer_is_full()) {   
    pthread_mutex_unlock(&mutex);
    pthread_cond_wait(&cond);
    pthread_mutex_lock(&mutex);
}
buffer_put(i);
pthread_mutex_unlock(&mutex);
#+end_src
在上面这段代码中，生产者线程会调用buffer_is_full和buffer_put，访问共享变量in、out和size。必须保证线程以独占的方式访问这些共享变量，即线程在调用buffer_is_full和buffer_put前必须持有锁。线程从pthread_cond_wait返回后，调用pthread_mutex_lock再次获得锁，然后执行语句while (buffer_is_full())时，因为已经拥有了锁，所以通过buffer_is_full访问共享变量是安全的。

该版本代码存在的问题是:由于 pthread_mutex_unlock 和 pthread_cond_wait 两个函数调用不是原子的，可能导致这种情况发生：生产者在调用 pthread_mutext_unlock 之后，但是在调用 pthread_cond_wait 之前，消费者调用了 pthread_mutex_lock 和 pthread_cond_signal，生产者再调用 pthread_cond_wait 时，会丢失消费者的 pthread_cond_signal 唤醒操作，导致这个生产者阻塞。
***** 使用pthread_cond_wait(cond, mutex)解决生产者和消费者问题
在上一个版本的程序中，生产者和消费者中存在如下代码段
#+begin_src c++
// 先释放mutex、再阻塞、最后再次获取mutex
pthread_mutex_unlock(&mutex);
pthread_cond_wait(&cond);
pthread_mutex_lock(&mutex);
#+end_src
为了解决原子操作问题,将这三行代码改成一个命令pthread_cond_wait(cond, mtex)即可.

使用pthread_cond_wait(cond, mutex)解决生产者和消费者问题的代码如下：
#+begin_src c++

// 生产者线程执行的流程
void producer_loop()
{
    int i;

    // 生产CAPACITY*2个数据
    for (i = 0; i < CAPACITY*2; i++) {  
        pthread_mutex_lock(&mutex);

        // 当缓冲区为满时，生产者需要等待
        while (buffer_is_full()) {   
            // 当前线程已经持有了mutex，首先释放mutex，然后阻塞，醒来后再次获取mutex            
            pthread_cond_wait(&cond, &mutex);
        }

        // 此时，缓冲区肯定不是满的，向缓冲区写数据
        buffer_put(i);

        pthread_mutex_unlock(&mutex);        

        // 缓冲区的状态发生了变化，唤醒其它的生产者或消费者
        pthread_cond_signal(&cond);
    }
}

// 消费者线程执行的流程
void consumer_loop()
{
    int i;

    // 消费CAPACITY*2个数据
    for (i = 0; i < CAPACITY*2; i++) {  
        pthread_mutex_lock(&mutex);

        // 当缓冲区为空时，消费者需要等待
        while (buffer_is_empty()) {  
            // 当前线程已经持有了mutex，首先释放mutex，然后阻塞，醒来后再次获取mutex 
            pthread_cond_wait(&cond, &mutex);
        }

        // 此时，缓冲区肯定不是空的，从缓冲区取数据
        int item = buffer_get();

        pthread_mutex_unlock(&mutex);        

        // 缓冲区的状态发生了变化，唤醒其它的生产者或消费者
        pthread_cond_signal(&cond);
    }
}
#+end_src
***** 参考文章
[[https://zhuanlan.zhihu.com/p/58838318][为什么pthread_cond_wait需要互斥锁mutex作为参数]]
*** 实例

图11-15给出了如何结合使用条件变量和互斥量对线程进行同步。

#+begin_src c++
#include <pthread.h>
struct msg
{
    struct msg *m_next;
    /* ... more stuff here ... */
};
struct msg *workq;
pthread_cond_t qready = PTHREAD_COND_INITIALIZER;
pthread_mutex_t qlock = PTHREAD_MUTEX_INITIALIZER;
void process_msg(void)
{
    struct msg *mp;
    for (;;)
    {
        pthread_mutex_lock(&qlock);
        while (workq == NULL)
            pthread_cond_wait(&qready, &qlock);
        mp = workq;
        workq = mp->m_next;
        pthread_mutex_unlock(&qlock);
        /* now process the message mp */
    }
}
void enqueue_msg(struct msg *mp)
{
    pthread_mutex_lock(&qlock);
    mp->m_next = workq;
    workq = mp;
    pthread_mutex_unlock(&qlock);
    pthread_cond_signal(&qready);
}
#+end_src
图11-15 使用条件变量

条件是工作队列的状态。我们用互斥量保护条件，在 while 循环中判断条件。把消息放到工作队列时，需要占有互斥量，但在给等待线程发信号时，不需要占有互斥量。只要线程可以在调用pthread_cond_signal之前把消息从队列中拉出，我们就可以在释放互斥量以后完成这部分工作。因为我们是在 while 循环中检查条件，所以不存在这样的问题：线程醒来，发现队列仍为空，然后返回继续等待。如果代码不能容忍这种竞争，就需要在给线程发信号的时候占有互斥量。
**** 参考文献
[[https://stackoverflow.com/questions/4544234/calling-pthread-cond-signal-without-locking-mutex][Calling pthread_cond_signal without locking mutex]]
*** 自旋锁
自旋锁与互斥量类似，但它不是通过休眠使进程阻塞，而是在获取锁之前一直处于忙等（自旋）阻塞状态。自旋锁可用于以下情况：锁被持有的时间短，而且线程并不希望在重新调度上花费太多的成本。

自旋锁通常作为底层原语用于实现其他类型的锁。根据它们所基于的系统体系结构，可以通过使用测试并设置指令有效地实现。当然这里说的有效也还是会导致CPU资源的浪费：当线程自旋等待锁变为可用时，CPU不能做其他的事情。这也是自旋锁只能够被持有一小段时间的原因。

当自旋锁用在非抢占式内核中时是非常有用的：除了提供互斥机制以外，它们会阻塞中断，这样中断处理程序就不会让系统陷入死锁状态，因为它需要获取已被加锁的自旋锁（把中断想成是另一种抢占）。在这种类型的内核中，中断处理程序不能休眠，因此它们能用的同步原语只能是自旋锁。

但是，在用户层，自旋锁并不是非常有用，除非运行在不允许抢占的实时调度类中。运行在分时调度类中的用户层线程在两种情况下可以被取消调度：当它们的时间片到期时，或者具有更高调度优先级的线程就绪变成可运行时。在这些情况下，如果线程拥有自旋锁，它就会进入休眠状态，阻塞在锁上的其他线程自旋的时间可能会比预期的时间更长。

很多互斥量的实现非常高效，以至于应用程序采用互斥锁的性能与曾经采用过自旋锁的性能基本是相同的。事实上，有些互斥量的实现在试图获取互斥量的时候会自旋一小段时间，只有在自旋计数到达某一阈值的时候才会休眠。这些因素，加上现代处理器的进步，使得上下文切换越来越快，也使得自旋锁只在某些特定的情况下有用。

自旋锁的接口与互斥量的接口类似，这使得它可以比较容易地从一个替换为另一个。可以用pthread_spin_init 函数对自旋锁进行初始化。用 pthread_spin_destroy 函数进行自旋锁的反初始化。
#+begin_src c++
#include <pthread.h>

int pthread_spin_init(pthread_spinlock_t *lock, int pshared);

int pthread_spin_destroy(pthread_spinlock_t *lock);
#+end_src
两个函数的返回值：若成功，返回0；否则，返回错误编号

只有一个属性是自旋锁特有的，这个属性只在支持线程进程共享同步（Thread Process-Shared Synchronization）选项（这个选项目前在Single UNIX Specification中是强制的，见图2-5）的平台上才用得到。pshared 参数表示进程共享属性，表明自旋锁是如何获取的。如果它设为 PTHREAD_PROCESS_SHARED，则自旋锁能被可以访问锁底层内存的线程所获取，即便那些线程属于不同的进程，情况也是如此。否则pshared参数设为 PTHREAD_PROCESS_PRIVATE，自旋锁就只能被初始化该锁的进程内部的线程所访问。

可以用pthread_spin_lock或pthread_spin_trylock对自旋锁进行加锁，前者在获取锁之前一直自旋，后者如果不能获取锁，就立即返回EBUSY 错误。注意，pthread_spin_trylock不能自旋。不管以何种方式加锁，自旋锁都可以调用pthread_spin_unlock函数解锁。
#+begin_src c++

#include <pthread.h>

int pthread_spin_lock(pthread_spinlock_t *lock);

int pthread_spin_trylock(pthread_spinlock_t *lock);

int pthread_spin_unlock(pthread_spinlock_t *lock);
#+end_src
所有函数的返回值：若成功，返回0；否则，返回错误编号

注意，如果自旋锁当前在解锁状态的话，pthread_spin_lock函数不要自旋就可以对它加锁。如果线程已经对它加锁了，结果就是未定义的。调用pthread_spin_lock会返回EDEADLK错误（或其他错误），或者调用可能会永久自旋。具体行为依赖于实际的实现。试图对没有加锁的自旋锁进行解锁，结果也是未定义的。

不管是pthread_spin_lock还是pthread_spin_trylock，返回值为0的话就表示自旋锁被加锁。需要注意，不要调用在持有自旋锁情况下可能会进入休眠状态的函数。如果调用了这些函数，会浪费CPU资源，因为其他线程需要获取自旋锁需要等待的时间就延长了。
*** 屏障
屏障（barrier）是用户协调多个线程并行工作的同步机制。屏障允许每个线程等待，直到所有的合作线程都到达某一点，然后从该点继续执行。我们已经看到一种屏障，pthread_join函数就是一种屏障，允许一个线程等待，直到另一个线程退出。

但是屏障对象的概念更广，它们允许任意数量的线程等待，直到所有的线程完成处理工作，而线程不需要退出。所有线程达到屏障后可以接着工作。

可以使用 pthread_barrier_init 函数对屏障进行初始化，用 thread_barrier_destroy函数反初始化。
#+begin_src c++

#include <pthread.h>

int pthread_barrier_init(pthread_barrier_t *restrict barrier,
const pthread_barrierattr_t *restrict attr,
unsigned int count);

int pthread_barrier_destroy(pthread_barrier_t *barrier);
#+end_src
两个函数的返回值：若成功，返回0；否则，返回错误编号

初始化屏障时，可以使用count参数指定，在允许所有线程继续运行之前，必须到达屏障的线程数目。使用attr参数指定屏障对象的属性，我们会在下一章详细讨论。现在设置attr为NULL，用默认属性初始化屏障。如果使用pthread_barrier_init函数为屏障分配资源，那么在反初始化屏障时可以调用pthread_barrier_destroy函数释放相应的资源。

可以使用pthread_barrier_wait函数来表明，线程已完成工作，准备等所有其他线程赶上来。
#+begin_src c++

#include <pthread.h>

int pthread_barrier_wait(pthread_barrier_t *barrier);
#+end_src
返回值：若成功，返回0或者PTHREAD_BARRIER_SERIAL_THREAD；否则，返回错误编号

调用pthread_barrier_wait的线程在屏障计数（调用pthread_barrier_init时设定）未满足条件时，会进入休眠状态。如果该线程是最后一个调用pthread_barrier_wait的线程，就满足了屏障计数，所有的线程都被唤醒。

对于一个任意线程，pthread_barrier_wait函数返回了PTHREAD_BARRIER_SERIAL_THREAD。剩下的线程看到的返回值是0。这使得一个线程可以作为主线程，它可以工作在其他所有线程已完成的工作结果上。

一旦达到屏障计数值，而且线程处于非阻塞状态，屏障就可以被重用。但是除非在调用了pthread_barrier_destroy函数之后，又调用了pthread_barrier_init函数对计数用另外的数进行初始化，否则屏障计数不会改变。
*** 实例

图11-16给出了在一个任务上合作的多个线程之间如何用屏障进行同步。
#+begin_src c++
#include "apue.h"
#include <pthread.h>
#include <limits.h>
#include <sys/time.h>
#define NTHR 8               /* number of threads */
#define NUMNUM 8000000L      /* number of numbers to sort */
#define TNUM (NUMNUM / NTHR) /* number to sort per thread */

long nums[NUMNUM];
long snums[NUMNUM];
pthread_barrier_t b;
#ifdef SOLARIS
#define heapsort qsort
#else
extern int heapsort(void *, size_t, size_t,
                    int (*)(const void *, const void *));
#endif
/*
 * Compare two long integers (helper function for heapsort)
 */
int complong(const void *arg1, const void *arg2)
{
    long l1 = *(long *)arg1;
    long l2 = *(long *)arg2;
    if (l1 == l2)
        return 0;
    else if (l1 < l2)
        return -1;
    else
        return 1;
}
/*
 * Worker thread to sort a portion of the set of numbers.
 */
void *
thr_fn(void *arg)
{
    long idx = (long)arg;
    heapsort(&nums[idx], TNUM, sizeof(long), complong);
    pthread_barrier_wait(&b);
    /*
     * Go off and perform more work ...
     */
    return ((void *)0);
}
/*
 * Merge the results of the individual sorted ranges.
 */
void merge()
{
    long idx[NTHR];
    long i, minidx, sidx, num;
    for (i = 0; i < NTHR; i++)
        idx[i] = i * TNUM;
    for (sidx = 0; sidx < NUMNUM; sidx++)
    {
        num = LONG_MAX;
        for (i = 0; i < NTHR; i++)
        {
            if ((idx[i] < (i + 1) * TNUM) && (nums[idx[i]] < num))
            {
                num = nums[idx[i]];
                minidx = i;
            }
        }
        snums[sidx] = nums[idx[minidx]];
        idx[minidx]++;
    }
}
int main()
{
    unsigned long i;
    struct timeval start, end;
    long long startusec, endusec;
    double elapsed;
    int err;
    pthread_t tid;
    /*
     * Create the initial set of numbers to sort.
     */
    srandom(1);
    for (i = 0; i < NUMNUM; i++)
        nums[i] = random();
    /*
     * Create 8 threads to sort the numbers.
     */
    gettimeofday(&start, NULL);
    pthread_barrier_init(&b, NULL, NTHR + 1);
    for (i = 0; i < NTHR; i++)
    {
        err = pthread_create(&tid, NULL, thr_fn, (void *)(i * TNUM));
        if (err != 0)
            err_exit(err, "can’t create thread");
    }
    pthread_barrier_wait(&b);
    merge();
    gettimeofday(&end, NULL);
    /*
     * Print the sorted list.
     */
    startusec = start.tv_sec * 1000000 + start.tv_usec;
    endusec = end.tv_sec * 1000000 + end.tv_usec;
    elapsed = (double)(endusec - startusec) / 1000000.0;
    printf("sort took %.4f seconds\n", elapsed);
    for (i = 0; i < NUMNUM; i++)
        printf("%ld\n", snums[i]);
    exit(0);
}
#+end_src
图11-16 使用屏障

这个例子给出了多个线程只执行一个任务时，使用屏障的简单情况。在更加实际的情况下，工作线程在调用pthread_barrier_wait函数返回后会接着执行其他的活动。

在这个实例中，使用8个线程分解了800万个数的排序工作。每个线程用堆排序算法对100万个数进行排序（详细算法请参阅Knuth[1998]）。然后主线程调用一个函数对这些结果进行合并。

并不需要使用 pthread_barrier_wait 函数中的返回值 PTHREAD_BARRIER_SERIAL_THREAD 来决定哪个线程执行结果合并操作，因为我们使用了主线程来完成这个任务。这也是把屏障计数值设为工作线程数加1的原因，主线程也作为其中的一个候选线程。

如果只用一个线程去完成800万个数的堆排序，那么与图11-16中的程序相比，我们将能看到图11-16中的程序在性能上有显著提升。在8核处理器系统上，单线程程序对800万个数进行排序需要12.14秒。同样的系统，使用8个并行线程和1个合并结果的线程，相同的800万个数的排序仅需要1.91秒，速度提升了6倍。

* UNIX-线程控制
** 线程限制
在2.5.4节中讨论了sysconf函数。Single UNIX Specification定义了与线程操作有关的一些限制，图2-11并没有列出这些限制。与其他的系统限制一样，这些限制也可以通过sysconf函数进行查询。图12-1总结了这些限制。

#+DOWNLOADED: screenshot @ 2024-01-14 10:26:03
[[file:images/linux笔记/线程控制/2024-01-14_10-26-03_screenshot.png]]
图12-1 线程限制和sysconf的name参数

与 sysconf 报告的其他限制一样，这些限制的使用是为了增强应用程序在不同的操作系统实现之间的可移植性。例如，如果应用程序需要为它管理的每个文件创建4个线程，但是系统却并不允许创建所有这些线程，这时可能就必须限制当前可并发管理的文件数。

图12-2给出了本书描述的4种操作系统实现中线程限制的值。如果操作系统实现的限制是不确定的，列出的值就是“没有确定的限制”（no limit）。但这并不意味着值是无限制的。

#+DOWNLOADED: screenshot @ 2024-01-14 10:26:47
[[file:images/linux笔记/线程控制/2024-01-14_10-26-47_screenshot.png]]
图12-2 线程配置限制的实例

注意，虽然某个操作系统实现可能没有提供访问这些限制的方法，但这并不意味着这些限制不存在，这只是意味着操作系统实现没有为使用sysconf访问这些值提供可用的方法。

** 线程属性
pthread 接口允许我们通过设置每个对象关联的不同属性来细调线程和同步对象的行为。通常，管理这些属性的函数都遵循相同的模式。

1. 每个对象与它自己类型的属性对象进行关联（线程与线程属性关联，互斥量与互斥量属性关联，等等）。一个属性对象可以代表多个属性。属性对象对应用程序来说是不透明的。这意味着应用程序并不需要了解有关属性对象内部结构的详细细节，这样可以增强应用程序的可移植性。取而代之的是，需要提供相应的函数来管理这些属性对象。
2. 有一个初始化函数，把属性设置为默认值。
3. 还有一个销毁属性对象的函数。如果初始化函数分配了与属性对象关联的资源，销毁函数负责释放这些资源。
4. 每个属性都有一个从属性对象中获取属性值的函数。由于函数成功时会返回0，失败时会返回错误编号，所以可以通过把属性值存储在函数的某一个参数指定的内存单元中，把属性值返回给调用者。
5. 每个属性都有一个设置属性值的函数。在这种情况下，属性值作为参数按值传递。

在第11章所有调用pthread_create函数的实例中，传入的参数都是空指针，而不是指向pthread_attr_t结构的指针。可以使用pthread_attr_t结构修改线程默认属性，并把这些属性与创建的线程联系起来。可以使用pthread_attr_init函数初始化pthread_attr_t结构。在调用pthread_attr_init以后，pthread_attr_t结构所包含的就是操作系统实现支持的所有线程属性的默认值。
#+begin_src c++
#include <pthread.h>

int pthread_attr_init(pthread_attr_t *attr);

int pthread_attr_destroy(pthread_attr_t *attr);
#+end_src
两个函数的返回值：若成功，返回0；否则，返回错误编号

如果要反初始化pthread_attr_t结构，可以调用pthread_attr_destroy函数。如果pthread_attr_init的实现对属性对象的内存空间是动态分配的，pthread_attr_destroy就会释放该内存空间。除此之外，pthread_attr_destroy还会用无效的值初始化属性对象，因此，如果该属性对象被误用，将会导致pthread_create函数返回错误码。

图 12-3 总结了 POSIX.1 定义的线程属性。POSIX.1 还为线程执行调度（Thread Execution Scheduling）选项定义了额外的属性，用以支持实时应用，但我们并不打算在这里讨论这些属性。图12-3同时给出了各个操作系统平台对每个线程属性的支持情况。
#+DOWNLOADED: screenshot @ 2024-01-14 10:30:25
[[file:images/linux笔记/线程控制/2024-01-14_10-30-25_screenshot.png]]
图12-3 POSIX.1线程属性

11.5节介绍了分离线程的概念。如果对现有的某个线程的终止状态不感兴趣的话，可以使用pthread_detach函数让操作系统在线程退出时收回它所占用的资源。

如果在创建线程时就知道不需要了解线程的终止状态，就可以修改 pthread_attr_t 结构中的detachstate线程属性，让线程一开始就处于分离状态。可以使用 pthread_attr_setdetachstate函数把线程属性detachstate设置成以下两个合法值之一：PTHREAD_CREATE_DETACHED，以分离状态启动线程；或者PTHREAD_CREATE_JOINABLE，正常启动线程，应用程序可以获取线程的终止状态。

#+begin_src c++
#include <pthread.h>

int pthread_attr_getdetachstate(const pthread_attr_t *restrict attr,int *detachstate);

int pthread_attr_setdetachstate(pthread_attr_t *attr, int *detachstate);
#+end_src
两个函数的返回值：若成功，返回0；否则，返回错误编号

可以调用pthread_attr_getdetachstate函数获取当前的detachstate线程属性。第二个参数是出参,要么设置成 PTHREAD_CREATE_DETACHED，要么设置成 PTHREAD_CREATE_JOINABLE，具体要取决于给定pthread_attr_t结构中的属性值。

*** 实例

图12-4给出了一个以分离状态创建线程的函数。

#+begin_src c++
#include "apue.h"
#include <pthread.h>
int makethread(void *(*fn)(void *), void *arg)
{
    int err;
    pthread_t tid;
    pthread_attr_t attr;
    err = pthread_attr_init(&attr);
    if (err != 0)
        return (err);
    err = pthread_attr_setdetachstate(&attr, PTHREAD_CREATE_DETACHED);
    if (err == 0)
        err = pthread_create(&tid, &attr, fn, arg);
    pthread_attr_destroy(&attr);
    return (err);
}
#+end_src
图12-4 以分离状态创建线程

注意，此例忽略了pthread_attr_destroy函数调用的返回值。在这个实例中，我们对线程属性进行了合理的初始化，因此 pthread_attr_destroy 应该不会失败。但是，如果pthread_attr_destroy确实出现了失败的情况，将难以清理：必须销毁刚刚创建的线程，也许这个线程可能已经运行，并且与 pthread_attr_destroy 函数可能是异步执行的。忽略pthread_attr_destroy 的错误返回可能出现的最坏情况是，如果 pthread_attr_init 已经分配了内存空间，就会有少量的内存泄漏。另一方面，如果 pthread_attr_init 成功地对线程属性进行了初始化，但之后pthread_attr_destroy的清理工作失败，那么将没有任何补救策略，因为线程属性结构对应用程序来说是不透明的，可以对线程属性结构进行清理的唯一接口是pthread_attr_destroy，但它失败了。

对于遵循POSIX标准的操作系统来说，并不一定要支持线程栈属性，但是对于遵循Single UNIX Specification 中 XSI 选项的系统来说，支持线程栈属性就是必需的。可以在编译阶段使用_POSIX_THREAD_ATTR_STACKADDR和_POSIX_THREAD_ATTR_STACKSIZE符号来检查系统是否支持每一个线程栈属性。如果系统定义了这些符号中的一个，就说明它支持相应的线程栈属性。或者，也可以在运行阶段把_SC_THREAD_ATTR_ STACKADDR 和_SC_THREAD_ATTR_STACKSIZE 参数传给sysconf函数，检查运行时系统对线程栈属性的支持情况。

*** 线程栈
可以使用函数pthread_attr_getstack和pthread_attr_setstack对线程栈属性进行管理。

#+begin_src c++

#include <pthread.h>

int pthread_attr_getstack(const pthread_attr_t *restrict attr,
void **restrict stackaddr,size_t *restrict stacksize);

int pthread_attr_setstack(pthread_attr_t *attr,
void *stackaddr, size_t stacksize);
#+end_src
两个函数的返回值：若成功，返回0；否则，返回错误编号

对于进程来说，虚地址空间的大小是固定的。因为进程中只有一个栈，所以它的大小通常不是问题。但对于线程来说，同样大小的虚地址空间必须被所有的线程栈共享。如果应用程序使用了许多线程，以致这些线程栈的累计大小超过了可用的虚地址空间，就需要减少默认的线程栈大小。另一方面，如果线程调用的函数分配了大量的自动变量，或者调用的函数涉及许多很深的栈帧（stack frame），那么需要的栈大小可能要比默认的大。

如果线程栈的虚地址空间都用完了，那可以使用malloc或者mmap（见14.8节）来为可替代的栈分配空间，并用pthread_attr_setstack函数来改变新建线程的栈位置。由stackaddr参数指定的地址可以用作线程栈的内存范围中的最低可寻址地址，该地址与处理器结构相应的边界应对齐。当然，这要假设malloc和mmap所用的虚地址范围与线程栈当前使用的虚地址范围不同。

stackaddr线程属性被定义为栈的最低内存地址，但这并不一定是栈的开始位置。对于一个给定的处理器结构来说，如果栈是从高地址向低地址方向增长的，那么stackaddr线程属性将是栈的结尾位置，而不是开始位置。

应用程序也可以通过pthread_attr_getstacksize和pthread_attr_setstacksize函数读取或设置线程属性stacksize。
#+begin_src c++

#include <pthread.h>

int pthread_attr_getstacksize(const pthread_attr_t *restrict attr,
size_t *restrict stacksize);

int pthread_attr_setstacksize (pthread_attr_t *attr, size_t stacksize);
#+end_src
两个函数的返回值：若成功，返回0；否则，返回错误编号

如果希望改变默认的栈大小，但又不想自己处理线程栈的分配问题，这时使用pthread_attr_setstacksize函数就非常有用。设置stacksize属性时，选择的stacksize不能小于PTHREAD_STACK_MIN。

线程属性guardsize控制着线程栈末尾之后用以避免栈溢出的扩展内存的大小。这个属性默认值是由具体实现来定义的，但常用值是系统页大小。可以把guardsize线程属性设置为0，不允许属性的这种特征行为发生：在这种情况下，不会提供警戒缓冲区。同样，如果修改了线程属性stackaddr，系统就认为我们将自己管理栈，进而使栈警戒缓冲区机制无效，这等同于把guardsize线程属性设置为0。

#+begin_src c++

#include <pthread.h>

iint pthread_attr_getguardsize(const pthread_attr_t *restrict attr,
size_t *restrict guardsize);

int pthread_attr_setguardsize(pthread_attr_t *attr, size_t guardsize);
#+end_src
两个函数的返回值：若成功，返回0；否则，返回错误编号

如果guardsize线程属性被修改了，操作系统可能会把它取为页大小的整数倍。如果线程的栈指针溢出到警戒区域，应用程序就可能通过信号接收到出错信息。

Single UNIX Specification还定义了一些其他的可选线程属性供实时应用程序使用，但在这里不讨论这些属性。

线程还有一些其他的pthread_attr_t结构中没有表示的属性：可撤销状态和可撤销类型。
** 同步属性
就像线程具有属性一样，线程的同步对象也有属性。
*** 互斥量属性
互斥量属性是用pthread_mutexattr_t结构表示的。第11章中每次对互斥量进行初始化时，都是通过使用PTHREAD_MUTEX_INITIALIZER常量或者用指向互斥量属性结构的空指针作为参数调用pthread_mutex_init函数，得到互斥量的默认属性。

对于非默认属性，可以用pthread_mutexattr_init初始化pthread_mutexattr_t结构，用pthread_mutexattr_destroy来反初始化。

#+begin_src c++

#include <pthread.h>

int pthread_mutexattr_init(pthread_mutexattr_t *attr);

int pthread_mutexattr_destroy(pthread_mutexattr_t *attr);
#+end_src
两个函数的返回值：若成功，返回0；否则，返回错误编号

pthread_mutexattr_init 函数将用默认的互斥量属性初始化 pthread_mutexattr_t结构。值得注意的3个属性是：进程共享属性、健壮属性以及类型属性。POSIX.1中，进程共享属性是可选的。可以通过检查系统中是否定义了_POSIX_THREAD_PROCESS_SHARED 符号来判断这个平台是否支持进程共享这个属性，也可以在运行时把_SC_THREAD_PROCESS_SHARED 参数传给sysconf函数进行检查。虽然这个选项并不是遵循POSIX标准的操作系统必须提供的，但是Single UNIX Specification要求遵循XSI标准的操作系统支持这个选项。

在进程中，多个线程可以访问同一个同步对象。正如在第11章中看到的，这是默认的行为。在这种情况下，进程共享互斥量属性需设置为PTHREAD_PROCESS_PRIVATE。

我们将在第14章和第15章中看到，存在这样的机制：允许相互独立的多个进程把同一个内存数据块映射到它们各自独立的地址空间中。就像多个线程访问共享数据一样，多个进程访问共享数据通常也需要同步。如果进程共享互斥量属性设置为PTHREAD_PROCESS_SHARED，从多个进程彼此之间共享的内存数据块中分配的互斥量就可以用于这些进程的同步。

可以使用pthread_mutexattr_getpshared函数查询pthread_mutexattr_t结构，得到它的进程共享属性，使用pthread_mutexattr_setpshared函数修改进程共享属性。

#+begin_src c++

#include <pthread.h>

int pthread_mutexattr_getpshared(const pthread_mutexattr_t
*restrict attr,int *restrict pshared);

int pthread_mutexattr_setpshared(pthread_mutexattr_t *attr,
int pshared);
#+end_src
两个函数的返回值：若成功，返回0；否则，返回错误编号

进程共享互斥量属性设置为PTHREAD_PROCESS_PRIVATE时，允许pthread线程库提供更有效的互斥量实现，这在多线程应用程序中是默认的情况。在多个进程共享多个互斥量的情况下， pthread线程库可以限制开销较大的互斥量实现。

互斥量健壮属性与在多个进程间共享的互斥量有关。这意味着，当持有互斥量的进程终止时，需要解决互斥量状态恢复的问题。这种情况发生时，互斥量处于锁定状态，恢复起来很困难。其他阻塞在这个锁的进程将会一直阻塞下去。

可以使用 pthread_mutexattr_getrobust 函数获取健壮的互斥量属性的值。可以调用 pthread_mutexattr_setrobust函数设置健壮的互斥量属性的值。
#+begin_src c++

#include <pthread.h>

int pthread_mutexattr_getrobust(const pthread_mutexattr_t
*restrict attr,int *restrict robust);

int pthread_mutexattr_setrobust(pthread_mutexattr_t *attr,
int robust);
#+end_src
两个函数的返回值：若成功，返回0；否则，返回错误编号

健壮属性取值有两种可能的情况。默认值是 PTHREAD_MUTEX_STALLED，这意味着持有互斥量的进程终止时不需要采取特别的动作。这种情况下，使用互斥量后的行为是未定义的，等待该互斥量解锁的应用程序会被有效地“拖住”。另一个取值是PTHREAD_MUTEX_ROBUST。这个值将导致线程调用pthread_mutex_lock获取锁，而该锁被另一个进程持有，但它终止时并没有对该锁进行解锁，此时线程会阻塞，从pthread_mutex_lock返回的值为EOWNERDEAD而不是0。应用程序可以通过这个特殊的返回值获知，若有可能（要保护状态的细节以及如何进行恢复会因不同的应用程序而异），不管它们保护的互斥量状态如何，都需要进行恢复。

使用健壮的互斥量改变了我们使用pthread_mutex_lock的方式，因为现在必须检查3个返回值而不是之前的两个：不需要恢复的成功、需要恢复的成功以及失败。但是，即使不用健壮的互斥量，也可以只检查成功或者失败。

在本书的4个平台中，只有Linux 3.2.0目前支持健壮的线程互斥量。Solaris 10只在它的Solaris线程库中支持健壮的线程互斥量（参阅Solaris手册的mutex_init(3C)获取相关的信息）。但是Solaris 11支持健壮的线程互斥量。

如果应用状态无法恢复，在线程对互斥量解锁以后，该互斥量将处于永久不可用状态。为了避免这样的问题，线程可以调用 pthread_mutex_consistent 函数，指明与该互斥量相关的状态在互斥量解锁之前是一致的。

#+begin_src c++

#include <pthread.h>

int pthread_mutex_consistent(pthread_mutex_t *mutex);

#+end_src
返回值：若成功，返回0；否则，返回错误编号

如果线程没有先调用 pthread_mutex_consistent 就对互斥量进行了解锁，那么其他试图获取该互斥量的阻塞线程就会得到错误码ENOTRECOVERABLE。如果发生这种情况，互斥量将不再可用。线程通过提前调用pthread_mutex_consistent，能让互斥量正常工作，这样它就可以持续被使用。

类型互斥量属性控制着互斥量的锁定特性。POSIX.1定义了4种类型。
- PTHREAD_MUTEX_NORMAL 一种标准互斥量类型，不做任何特殊的错误检查或死锁检测。
- PTHREAD_MUTEX_ERRORCHECK 此互斥量类型提供错误检查。
- PTHREAD_MUTEX_RECURSIVE 此互斥量类型允许同一线程在互斥量解锁之前对该互斥量进行多次加锁。递归互斥量维护锁的计数，在解锁次数和加锁次数不相同的情况下，不会释放锁。所以，如果对一个递归互斥量加锁两次，然后解锁一次，那么这个互斥量将依然处于加锁状态，对它再次解锁以前不能释放该锁。(递归互斥锁)
- PTHREAD_MUTEX_DEFAULT 此互斥量类型可以提供默认特性和行为。操作系统在实现它的时候可以把这种类型自由地映射到其他互斥量类型中的一种。例如，Linux 3.2.0把这种类型映射为普通的互斥量类型，而FreeBSD 8.0则把它映射为错误检查互斥量类型。

这4种类型的行为如图12-5所示。“不占用时解锁”这一栏指的是，一个线程对被另一个线程加锁的互斥量进行解锁的情况。“在已解锁时解锁”这一栏指的是，当一个线程对已经解锁的互斥量进行解锁时将会发生什么，这通常是编码错误引起的。

#+DOWNLOADED: screenshot @ 2024-01-27 22:00:11
[[file:images/linux笔记/UNIX-线程控制/2024-01-27_22-00-11_screenshot.png]]
图12-5 互斥量类型行为

可以用pthread_mutexattr_gettype函数得到互斥量类型属性，用pthread_mutexattr_settype函数修改互斥量类型属性。

#+begin_src c++

#include <pthread.h>

int pthread_mutexattr_gettype(const pthread_mutexattr_t*restrict attr,int*restrict type);

int pthread_mutexattr_settype(pthread_mutexattr_t *attr, int type);
#+end_src
两个函数的返回值: 若成功，返回0；否则，返回错误编号

回忆 11.6.6 节中学过的，互斥量用于保护与条件变量关联的条件。在阻塞线程之前，pthread_cond_wait和pthread_cond_timedwait函数释放与条件相关的互斥量。这就允许其他线程获取互斥量、改变条件、释放互斥量以及给条件变量发信号。既然改变条件时必须占有互斥量，使用递归互斥量就不是一个好主意。如果递归互斥量被多次加锁，然后用在调用pthread_cond_wait函数中，那么条件永远都不会得到满足，因为pthread_cond_wait所做的解锁操作并不能释放互斥量。

如果需要把现有的单线程接口放到多线程环境中，递归互斥量是非常有用的，但由于现有程序兼容性的限制，不能对函数接口进行修改。然而，使用递归锁可能很难处理，因此应该只在没有其他可行方案的时候才使用它们。
**** 实例

图12-6描述了一种情况，在这种情况中递归互斥量看起来像是在解决并发问题。假设func1和 func2 是函数库中现有的函数，其接口不能改变，因为存在调用这两个接口的应用程序，而且应用程序不能改动。


#+DOWNLOADED: screenshot @ 2024-01-27 22:12:05
[[file:images/linux笔记/UNIX-线程控制/2024-01-27_22-12-05_screenshot.png]]

图12-6 使用递归锁的一种可能情况

为了保持接口跟原来相同，我们把互斥量嵌入到了数据结构中，把这个数据结构的地址（x）作为参数传入。这种方案只有在为此数据结构提供分配函数时才可行，所以应用程序并不知道数据结构的大小（假设我们在其中增加互斥量之后必须扩大该数据结构的大小）。

如果在最早定义数据结构时，预留了足够的可填充字段，允许把某些填充字段替换成互斥量，这种方法也是可行的。不过遗憾的是，大多数程序员并不善于预测未来，所以这并不是普遍可行的实践。

如果func1和func2函数都必须操作这个结构，而且可能会有一个以上的线程同时访问该数据结构，那么 func1 和 func2 必须在操作数据以前对互斥量加锁。如果 func1 必须调用func2，这时如果互斥量不是递归类型的，那么就会出现死锁。如果能在调用 func2 之前释放互斥量，在 func2 返回后重新获取互斥量，那么就可以避免使用递归互斥量，但这也给其他的线程提供了机会，其他的线程可以在 func1 执行期间抓住互斥量的控制，修改这个数据结构。这也许是不可接受的，当然具体的情况要取决于互斥量试图提供什么样的保护。

图12-7显示了这种情况下使用递归互斥量的一种替代方法。通过提供func2函数的私有版本，称之为func2_locked函数，可以保持func1和func2函数接口不变，而且避免使用递归互斥量。要调用 func2_locked 函数，必须占有嵌入在数据结构中的互斥量，这个数据结构的地址是作为参数传入的。func2_locked的函数体包含func2的副本，func2现在只是获取互斥量，调用func2_locked，然后释放互斥量。


#+DOWNLOADED: screenshot @ 2024-01-27 22:22:23
[[file:images/linux笔记/UNIX-线程控制/2024-01-27_22-22-23_screenshot.png]]

图12-7 避免使用递归锁的一种可能情况

如果并不一定要保持库函数接口不变，就可以在每个函数中增加第二个参数表明这个结构是否被调用者锁定。但是，如果可以的话，保持接口不变通常是更好的选择，可以避免实现过程中人为加入的东西对原有系统产生不良影响。

提供加锁和不加锁版本的函数，这样的策略在简单的情况下通常是可行的。在更加复杂的情况下，比如，库需要调用库以外的函数，而且可能会再次回调库中的函数时，就需要依赖递归锁。
**** 实例

图12-8中的程序解释了有必要使用递归互斥量的另一种情况。这里，有一个“超时”（timeout）函数，它允许安排另一个函数在未来的某个时间运行。假设线程并不是很昂贵的资源，就可以为每个挂起的超时函数创建一个线程。线程在时间未到时将一直等待，时间到了以后再调用请求的函数。


#+begin_src c++
#include "apue.h"
#include <pthread.h>
#include <time.h>
#include <sys/time.h>
extern int makethread(void *(*)(void *), void *);
struct to_info
{
    void (*to_fn)(void *);   /* function */
    void *to_arg;            /* argument */
    struct timespec to_wait; /* time to wait */
};
#define SECTONSEC 1000000000 /* seconds to nanoseconds */
#if !defined(CLOCK_REALTIME) || defined(BSD)
#define clock_nanosleep(ID, FL, REQ, REM) nanosleep((REQ), (REM))
#endif
#ifndef CLOCK_REALTIME
#define CLOCK_REALTIME 0
#define USECTONSEC 1000 /* microseconds to nanoseconds */
void clock_gettime(int id, struct timespec *tsp)
{
    struct timeval tv;
    gettimeofday(&tv, NULL);
    tsp->tv_sec = tv.tv_sec;
    tsp->tv_nsec = tv.tv_usec * USECTONSEC;
}
#endif
void *timeout_helper(void *arg)
{
    struct to_info *tip;
    tip = (struct to_info *)arg;
    clock_nanosleep(CLOCK_REALTIME, 0, &tip->to_wait, NULL);
    (*tip->to_fn)(tip->to_arg);
    free(arg);
    return (0);
}
void timeout(const struct timespec *when, void (*func)(void *), void *arg)
{
    struct timespec now;
    struct to_info *tip;
    int err;
    clock_gettime(CLOCK_REALTIME, &now);
    if ((when->tv_sec > now.tv_sec) ||
        (when->tv_sec == now.tv_sec && when->tv_nsec > now.tv_nsec))
    {
        tip = malloc(sizeof(struct to_info));
        if (tip != NULL)
        {
            tip->to_fn = func;
            tip->to_arg = arg;
            tip->to_wait.tv_sec = when->tv_sec - now.tv_sec;
            if (when->tv_nsec >= now.tv_nsec)
            {
                tip->to_wait.tv_nsec = when->tv_nsec - now.tv_nsec;
            }
            else
            {
                tip->to_wait.tv_sec--;
                tip->to_wait.tv_nsec = SECTONSEC - now.tv_nsec +
                                       when->tv_nsec;
            }
            err = makethread(timeout_helper, (void *)tip);
            if (err == 0)
                return;
            else
                free(tip);
        }
    }
    /*
     * We get here if (a) when <= now, or (b) malloc fails, or
     * (c) we can’t make a thread, so we just call the function now.
     */
    (*func)(arg);
}
pthread_mutexattr_t attr;
pthread_mutex_t mutex;
void retry(void *arg)
{
    pthread_mutex_lock(&mutex);
    /* perform retry steps ... */
    pthread_mutex_unlock(&mutex);
}
int main(void)
{
    int err, condition, arg;
    struct timespec when;
    if ((err = pthread_mutexattr_init(&attr)) != 0)
        err_exit(err, "pthread_mutexattr_init failed");
    if ((err = pthread_mutexattr_settype(&attr,
                                         PTHREAD_MUTEX_RECURSIVE)) != 0)
        err_exit(err, "can’t set recursive type");
    if ((err = pthread_mutex_init(&mutex, &attr)) != 0)
        err_exit(err, "can’t create recursive mutex");
    /* continue processing ... */
    pthread_mutex_lock(&mutex);
    /*
     * Check the condition under the protection of a lock to
     * make the check and the call to timeout atomic.
     */
    if (condition)
    {
        /*
         * Calculate the absolute time when we want to retry.
         */
        clock_gettime(CLOCK_REALTIME, &when);
        when.tv_sec += 10; /* 10 seconds from now */
        timeout(&when, retry, (void *)((unsigned long)arg));
    }
    pthread_mutex_unlock(&mutex);
    /* continue processing ... */
    exit(0);
}
#+end_src
图12-8 使用递归互斥量

如果我们不能创建线程，或者安排函数运行的时间已过，这时问题就出现了。在这些情况下，我们只需在当前上下文中调用之前请求运行的函数。因为函数要获取的锁和我们现在占有的锁是同一个，所以除非该锁是递归的，否则就会出现死锁。

在图12-4中我们使用makethread函数以分离状态创建线程。因为传递给timeout函数的func函数参数将在未来运行，所以我们不希望一直空等线程结束。

可以调用sleep等待超时到期，但它提供的时间粒度是秒级的。如果希望等待的时间不是整数秒，就需要用nanosleep或者clock_nanosleep函数，它们两个提供了更高精度的休眠时间。

在未定义CLOCK_REALTIME的系统中，我们根据nanosleep定义clock_nanosleep。然而，FreeBSD 8.0 定义这个符号支持 clock_gettime 和 clock_settime，但并不支持clock_nanosleep。（只有Linux 3.2.0和Solaris 10目前支持clock_nanosleep。）

另外，在未定义CLOCK_REALTIME的系统中，我们提供了我们自己的clock_gettime实现，该实现调用了gettimeofday并把微妙转换成纳秒。

timeout的调用者需要占有互斥量来检查条件，并且把retry函数安排为原子操作。retry函数试图对同一个互斥量进行加锁。除非互斥量是递归的，否则，如果 timeout 函数直接调用retry，会导致死锁。
*** 读写锁属性
读写锁与互斥量类似，也是有属性的。可以用 pthread_rwlockattr_init 初始化pthread_rwlockattr_t结构，用pthread_rwlockattr_destroy反初始化该结构。
#+begin_src c++

#include <pthread.h>

int pthread_rwlockattr_init(pthread_rwlockattr_t *attr);

int pthread_rwlockattr_destroy(pthread_rwlockattr_t *attr);
#+end_src
两个函数的返回值：若成功，返回0；否则，返回错误编号

读写锁支持的唯一属性是进程共享属性。它与互斥量的进程共享属性是相同的。就像互斥量的进程共享属性一样，有一对函数用于读取和设置读写锁的进程共享属性。
#+begin_src c++

  #include <pthread.h>

  int pthread_rwlockattr_getpshared(const pthread_rwlockattr_t *
  restrict yyaldh2 gg 酒精代谢能力 - Google 搜索
  attr,int *restrict pshared);

  int pthread_rwlockattr_setpshared(pthread_rwlockattr_t *attr,
  int pshared);
#+end_src
两个函数的返回值：若成功，返回0；否则，返回错误编号

虽然POSIX只定义了一个读写锁属性，但不同平台的实现可以自由地定义额外的、非标准的属性。
*** 条件变量属性
Single UNIX Specification目前定义了条件变量的两个属性：进程共享属性和时钟属性。与其他的属性对象一样，有一对函数用于初始化和反初始化条件变量属性。
#+begin_src c++

#include <pthread.h>

int pthread_condattr_init(pthread_condattr_t *attr);

int pthread_condattr_destroy(pthread_condattr_t *attr);
#+end_src
两个函数的返回值：若成功，返回0；否则，返回错误编号

与其他的同步属性一样，条件变量支持进程共享属性。它控制着条件变量是可以被单进程的多个线程使用，还是可以被多进程的线程使用。要获取进程共享属性的当前值，可以用 pthread_condattr_getpshared函数。设置该值可以用pthread_condattr_setpshared函数。
#+begin_src c++

#include <pthread.h>

int pthread_condattr_getpshared(const pthread_condattr_t *
restrict attr,int *restrict pshared);

int pthread_condattr_setpshared(pthread_condattr_t *attr,
int pshared);
#+end_src
两个函数的返回值：若成功，返回0；否则，返回错误编号

时钟属性控制计算pthread_cond_timedwait函数的超时参数（tsptr）时采用的是哪个时钟。合法值取自图 6-8 中列出的时钟 ID。可以使用 pthread_condattr_getclock 函数获取可被用于pthread_cond_timedwait 函数的时钟 ID，在使用 pthread_cond_timedwait 函数前需要用pthread_condattr_t对象对条件变量进行初始化。可以用pthread_condattr_setclock函数对时钟ID进行修改。
#+begin_src c++

#include <pthread.h>

int pthread_condattr_getclock(const pthread_condattr_t *
restrict attr,clockid_t *restrict clock_id);

int pthread_condattr_setclock(pthread_condattr_t *attr,
clockid_t clock_id);
#+end_src
两个函数的返回值:若成功，返回0；否则，返回错误编号

奇怪的是，Single UNIX Specification并没有为其他有超时等待函数的属性对象定义时钟属性。
*** 屏障属性
屏障也有属性。可以使用pthread_barrierattr_init函数对屏障属性对象进行初始化，用pthread_barrierattr_destroy函数对屏障属性对象进行反初始化。
#+begin_src c++

#include <pthread.h>

int pthread_barrierattr_init(pthread_barrierattr_t *attr);

int pthread_barrierattr_destroy(pthread_barrierattr_t *attr);
#+end_src
两个函数的返回值：若成功，返回0；否则，返回错误编号

目前定义的屏障属性只有进程共享属性，它控制着屏障是可以被多进程的线程使用，还是只能被初始化屏障的进程内的多线程使用。与其他属性对象一样，有一个获取属性值的函数（pthread_barrierattr_getpshared）和一个设置属性值的函数（pthread_barrierattr_ setpshared）。
#+begin_src c++

#include <pthread.h>

int pthread_barrierattr_getpshared(const pthread_barrierattr_t *
restrict attr,int *restrict pshared);

int pthread_barrierattr_setpshared(pthread_barrierattr_t *attr,
int pshared);
#+end_src
两个函数的返回值：若成功，返回0；否则，返回错误编号

进程共享属性的值可以是 PTHREAD_PROCESS_SHARED（多进程中的多个线程可用），也可以是PTHREAD_PROCESS_PRIVATE（只有初始化屏障的那个进程内的多个线程可用）。
** 重入
线程在遇到重入问题时与信号处理程序是类似的。在这两种情况下，多个控制线程在相同的时间有可能调用相同的函数。

如果一个函数在相同的时间点可以被多个线程安全地调用，就称该函数是线程安全的。在Single UNIX Specification中定义的所有函数中，除了图12-9中列出的函数，其他函数都保证是线程安全的。另外，ctermid和tmpnam函数在参数传入空指针时并不能保证是线程安全的。类似地，如果参数mbstate_t传入的是空指针，也不能保证wcrtomb和wcsrtombs函数是线程安全的。

支持线程安全函数的操作系统实现会在<unistd.h>中定义符号_POSIX_THREAD_SAFE_FUNCTIONS。应用程序也可以在sysconf函数中传入_SC_THREAD_SAFE_FUNCTIONS参数在运行时检查是否支持线程安全函数。在SUSv4之前，要求所有遵循XSI的实现都必须支持线程安全函数，但是在SUSv4中，线程安全函数支持这个需求已经要求具体实现考虑遵循POSIX。

操作系统实现支持线程安全函数这个特性时，对POSIX.1中的一些非线程安全函数，它会提供可替代的线程安全版本。图12-10列出了这些函数的线程安全版本。这些函数的命名方式与它们的非线程安全版本的名字相似，只不过在名字最后加了_r，表明这些版本是可重入的。很多函数并不是线程安全的，因为它们返回的数据存放在静态的内存缓冲区中。通过修改接口，要求调用者自己提供缓冲区可以使函数变为线程安全。


#+DOWNLOADED: screenshot @ 2024-01-30 07:29:39
[[file:images/linux笔记/UNIX-线程控制/2024-01-30_07-29-39_screenshot.png]]
图12-9 POSIX.1中不能保证线程安全的函数

#+DOWNLOADED: screenshot @ 2024-01-30 07:29:53
[[file:images/linux笔记/UNIX-线程控制/2024-01-30_07-29-53_screenshot.png]]
图12-10 替代的线程安全函数

如果一个函数对多个线程来说是可重入的，就说这个函数就是线程安全的。但这并不能说明对信号处理程序来说该函数也是可重入的。如果函数对异步信号处理程序的重入是安全的，那么就可以说函数是异步信号安全的。我们在10.6节中讨论可重入函数时，图10-4中的函数就是异步信号安全函数。

除了图12-10中列出的函数，POSIX.1还提供了以线程安全的方式管理FILE对象的方法。可以使用flockfile和ftrylockfile获取给定FILE对象关联的锁。这个锁是递归的：当你占有这把锁的时候，还是可以再次获取该锁，而且不会导致死锁。虽然这种锁的具体实现并无规定，但要求所有操作 FILE 对象的标准 I/O 例程的动作行为必须看起来就像它们内部调用了flockfile和funlockfile。

#+begin_src c++

#include <stdio.h>

int ftrylockfile(FILE *fp);
#+end_src
返回值：若成功，返回0；若不能获取锁，返回非0数值
#+begin_src c++

void flockfile(FILE *fp);

void funlockfile(FILE *fp);
#+end_src
虽然标准的I/O例程可能从它们各自的内部数据结构的角度出发，是以线程安全的方式实现的，但有时把锁开放给应用程序也是非常有用的。这允许应用程序把多个对标准I/O函数的调用组合成原子序列。当然，在处理多个FILE对象时，需要注意潜在的死锁，需要对所有的锁仔细地排序。

如果标准I/O例程都获取它们各自的锁，那么在做一次一个字符的I/O时就会出现严重的性能下降。在这种情况下，需要对每一个字符的读写操作进行获取锁和释放锁的动作。为了避免这种开销，出现了不加锁版本的基于字符的标准I/O例程。
#+begin_src c++

#include <stdio.h>

int getchar_unlocked(void);

int getc_unlocked(FILE *fp);
#+end_src
两个函数的返回值: 若成功，返回下一个字符；若遇到文件尾或者出错，返回EOF
#+begin_src c++

int putchar_unlocked(int c);

int putc_unlocked(int c, FILE *fp);
#+end_src
两个函数的返回值：若成功，返回c；若出错，返回EOF

除非被flockfile（或ftrylockfile）和funlockfile的调用包围，否则尽量不要调用这4个函数，因为它们会导致不可预期的结果（比如，由于多个控制线程非同步访问数据引起的种种问题）。

一旦对FILE对象进行加锁，就可以在释放锁之前对这些函数进行多次调用。这样就可以在多次的数据读写上分摊总的加解锁的开销。
*** 实例

图12-11显示了getenv（见7.9节）的一个可能实现。这个版本不是可重入的。如果两个线程同时调用这个函数，就会看到不一致的结果，因为所有调用getenv的线程返回的字符串都存储在同一个静态缓冲区中。

#+begin_src c++
#include <limits.h>
#include <string.h>
#define MAXSTRINGSZ 4096
static char envbuf[MAXSTRINGSZ];
extern char **environ;
char *getenv(const char *name)
{
    int i, len;
    len = strlen(name);
    for (i = 0; environ[i] != NULL; i++)
    {
        if ((strncmp(name, environ[i], len) == 0) &&
            (environ[i][len] == ’=’))
        {
            strncpy(envbuf, &environ[i][len + 1], MAXSTRINGSZ - 1);
            return (envbuf);
        }
    }
    return (NULL);
}
#+end_src
图12-11 getenv的非可重入版本

图12-12给出了getenv的可重入的版本。这个版本叫做getenv_r。它使用pthread_once函数来确保不管多少线程同时竞争调用getenv_r，每个进程只调用thread_init函数一次。12.6节会详细描述pthread_once函数。

#+begin_src c++
#include <string.h>
#include <errno.h>
#include <pthread.h>
#include <stdlib.h>
extern char **environ;
pthread_mutex_t env_mutex;
static pthread_once_t init_done = PTHREAD_ONCE_INIT;
static void
thread_init(void)
{
    pthread_mutexattr_t attr;
    pthread_mutexattr_init(&attr);
    pthread_mutexattr_settype(&attr, PTHREAD_MUTEX_RECURSIVE);
    pthread_mutex_init(&env_mutex, &attr);
    pthread_mutexattr_destroy(&attr);
}
int getenv_r(const char *name, char *buf, int buflen)
{
    int i, len, olen;
    pthread_once(&init_done, thread_init);
    len = strlen(name);
    pthread_mutex_lock(&env_mutex);
    for (i = 0; environ[i] != NULL; i++)
    {
        if ((strncmp(name, environ[i], len) == 0) &&
            (environ[i][len] == ’=’))
        {
            olen = strlen(&environ[i][len + 1]);
            if (olen >= buflen)
            {
                pthread_mutex_unlock(&env_mutex);
                return (ENOSPC);
            }
            strcpy(buf, &environ[i][len + 1]);
            pthread_mutex_unlock(&env_mutex);
            return (0);
        }
    }
    pthread_mutex_unlock(&env_mutex);
    return (ENOENT);
}
#+end_src
图12-12 getenv的可重入（线程安全）版本

要使getenv_r可重入，需要改变接口，调用者必须提供它自己的缓冲区，这样每个线程可以使用各自不同的缓冲区避免其他线程的干扰。但是，注意，要想使getenv_r成为线程安全的，这样做还不够，需要在搜索请求的字符时保护环境不被修改。可以使用互斥量，通过getenv_r和putenv函数对环境列表的访问进行串行化。

可以使用读写锁，从而允许对getenv_r进行多次并发访问，但增加的并发性可能并不会在很大程度上改善程序的性能，这里面有两个原因：第一，环境列表通常并不会很长，所以扫描列表时并不需要长时间地占有互斥量；第二，对getenv和putenv的调用也不是频繁发生的，所以改善它们的性能并不会对程序的整体性能产生很大的影响。

即使可以把getenv_r变成线程安全的，这也不意味着它对信号处理程序是可重入的。如果使用的是非递归的互斥量，线程从信号处理程序中调用 getenv_r 就有可能出现死锁。如果信号处理程序在线程执行getenv_r时中断了该线程，这时我们已经占有加锁的env_mutex，这样其他线程试图对这个互斥量的加锁就会被阻塞，最终导致线程进入死锁状态。所以，必须使用递归互斥量阻止其他线程改变我们正需要的数据结构，还要阻止来自信号处理程序的死锁。问题是pthread函数并不保证是异步信号安全的，所以不能把pthread函数用于其他函数，让该函数成为异步信号安全的。
** 线程特定数据
线程特定数据（thread-specific data），也称为线程私有数据（thread-private data），是存储和查询某个特定线程相关数据的一种机制。我们把这种数据称为线程特定数据或线程私有数据的原因是，我们希望每个线程可以访问它自己单独的数据副本，而不需要担心与其他线程的同步访问问题。

线程模型促进了进程中数据和属性的共享，许多人在设计线程模型时会遇到各种麻烦。那么为什么有人想在这样的模型中促进阻止共享的接口呢？这其中有两个原因。

第一，有时候需要维护基于每线程（per-thread）的数据。因为线程ID并不能保证是小而连续的整数，所以就不能简单地分配一个每线程数据数组，用线程ID作为数组的索引。即使线程ID确实是小而连续的整数，我们可能还希望有一些额外的保护，防止某个线程的数据与其他线程的数据相混淆。

采用线程私有数据的第二个原因是，它提供了让基于进程的接口适应多线程环境的机制。一个很明显的实例就是errno。回忆1.7节中对errno 的讨论。以前的接口（线程出现以前）把errno 定义为进程上下文中全局可访问的整数。系统调用和库例程在调用或执行失败时设置errno，把它作为操作失败时的附属结果。为了让线程也能够使用那些原本基于进程的系统调用和库例程，errno被重新定义为线程私有数据。这样，一个线程做了重置errno的操作也不会影响进程中其他线程的errno值。

我们知道一个进程中的所有线程都可以访问这个进程的整个地址空间。除了使用寄存器以外，一个线程没有办法阻止另一个线程访问它的数据。线程特定数据也不例外。虽然底层的实现部分并不能阻止这种访问能力，但管理线程特定数据的函数可以提高线程间的数据独立性，使得线程不太容易访问到其他线程的线程特定数据。

在分配线程特定数据之前，需要创建与该数据关联的键。这个键将用于获取对线程特定数据的访问。使用pthread_key_create创建一个键。
#+begin_src c++

#include <pthread.h>

int pthread_key_create(pthread_key_t *keyp, void (*destructor)(void *));
#+end_src
返回值：若成功，返回0；否则，返回错误编号

创建的键存储在keyp指向的内存单元中，这个键可以被进程中的所有线程使用，但每个线程把这个键与不同的线程特定数据地址进行关联。创建新键时，每个线程的数据地址设为空值。

除了创建键以外，pthread_key_create 可以为该键关联一个可选择的析构函数。当这个线程退出时，如果数据地址已经被置为非空值，那么析构函数就会被调用，它唯一的参数就是该数据地址。如果传入的析构函数为空，就表明没有析构函数与这个键关联。当线程调用pthread_exit或者线程执行返回，正常退出时，析构函数就会被调用。同样，线程取消时，只有在最后的清理处理程序返回之后，析构函数才会被调用。如果线程调用了exit、_exit、_Exit或abort，或者出现其他非正常的退出时，就不会调用析构函数。

线程通常使用malloc为线程特定数据分配内存。析构函数通常释放已分配的内存。如果线程在没有释放内存之前就退出了，那么这块内存就会丢失，即线程所属进程就出现了内存泄漏。

线程可以为线程特定数据分配多个键，每个键都可以有一个析构函数与它关联。每个键的析构函数可以互不相同，当然所有键也可以使用相同的析构函数。每个操作系统实现可以对进程可分配的键的数量进行限制（回忆一下图12-1中的PTHREAD_KEYS_MAX）。

线程退出时，线程特定数据的析构函数将按照操作系统实现中定义的顺序被调用。析构函数可能会调用另一个函数，该函数可能会创建新的线程特定数据，并且把这个数据与当前的键关联起来。当所有的析构函数都调用完成以后，系统会检查是否还有非空的线程特定数据值与键关联，如果有的话，再次调用析构函数。这个过程将会一直重复直到线程所有的键都为空线程特定数据值，或者已经做了PTHREAD_DESTRUCTOR_ITERATIONS（见图12-1）中定义的最大次数的尝试。

对所有的线程，我们都可以通过调用pthread_key_delete来取消键与线程特定数据值之间的关联关系。
#+begin_src c++

#include <pthread.h>

int pthread_key_delete(pthread_key_t key);
#+end_src
返回值：若成功，返回0；否则，返回错误编号

注意，调用pthread_key_delete并不会激活与键关联的析构函数。要释放任何与键关联的线程特定数据值的内存，需要在应用程序中采取额外的步骤。

需要确保分配的键并不会由于在初始化阶段的竞争而发生变动。下面的代码会导致两个线程都调用pthread_key_create。
#+begin_src c++
void destructor(void *);

pthread_key_t key;

int init_done = 0;

int threadfunc(void *arg)
{
    if (!init_done)
    {
        init_done = 1;
        err = pthread_key_create(&key, destructor);
    }
}
#+end_src
有些线程可能看到一个键值，而其他的线程看到的可能是另一个不同的键值，这取决于系统是如何调度线程的，解决这种竞争的办法是使用pthread_once。
#+begin_src c++

#include <pthread.h>

pthread_once_t initflag = PTHREAD_ONCE_INIT;

int pthread_once(pthread_once_t *initflag, void (*initfn)(void));
#+end_src
返回值：若成功，返回0；否则，返回错误编号

initflag 必须是一个非本地变量（如全局变量或静态变量），而且必须初始化为 PTHREAD_ONCE_INIT。

如果每个线程都调用pthread_once，系统就能保证初始化例程initfn只被调用一次，即系统首次调用pthread_once时。创建键时避免出现冲突的一个正确方法如下：
#+begin_src c++
void destructor(void *);

pthread_key_t key;

pthread_once_t init_done = PTHREAD_ONCE_INIT;

void thread_init(void)
{
    err = pthread_key_create(&key, destructor);
}

int threadfunc(void *arg)
{
}

pthread_once(&init_done, thread_init);
#+end_src
键一旦创建以后，就可以通过调用pthread_setspecific函数把键和线程特定数据关联起来。可以通过pthread_getspecific函数获得线程特定数据的地址。
#+begin_src c++

#include <pthread.h>

void *pthread_getspecific(pthread_key_t key);
#+end_src
返回值：线程特定数据值；若没有值与该键关联，返回NULL

#+begin_src c++

int pthread_setspecific(pthread_key_t key, const void *value);
#+end_src
返回值：若成功，返回0；否则，返回错误编号

如果没有线程特定数据值与键关联，pthread_getspecific将返回一个空指针，我们可以用这个返回值来确定是否需要调用pthread_setspecific。
*** pthread_once详解和使用
int pthread_once(pthread_once_t *once_control, void (*init_routine) (void))；

功能：使用初值为PTHREAD_ONCE_INIT的once_control变量保证init_routine()函数在本进程执行序列中仅执行一次。

在多线程编程环境下，尽管pthread_once()调用会出现在多个线程中，init_routine()函数仅执行一次，究竟在哪个线程中执行是不定的，是由内核调度来决定。

Linux Threads使用互斥锁和条件变量保证由pthread_once()指定的函数执行且仅执行一次，而once_control表示是否执行过。

如果once_control的初值不是PTHREAD_ONCE_INIT（Linux Threads定义为0），pthread_once() 的行为就会不正常。

在LinuxThreads中，实际"一次性函数"的执行状态有三种：NEVER(0)、IN_PROGRESS(1)、DONE(2)，如果once初值设为1，则由于所有pthread_once()都必须等待其中一个激发"已执行一次"信号，因此所有pthread_once ()都会陷入永久的等待中；如果设为2，则表示该函数已执行过一次，从而所有pthread_once()都会立即返回0。

具体的一个实例：
#+begin_src c++
#include <iostream>
#include <pthread.h>
using namespace std;

pthread_once_t once = PTHREAD_ONCE_INIT;

void once_run(void)
{
    cout << "once_run in thread " << (unsigned int)pthread_self() << endl;
}

void *child1(void *arg)
{
    pthread_t tid = pthread_self();
    cout << "thread " << (unsigned int)tid << " enter" << endl;
    pthread_once(&once, once_run);
    cout << "thread " << tid << " return" << endl;
}

void *child2(void *arg)
{
    pthread_t tid = pthread_self();
    cout << "thread " << (unsigned int)tid << " enter" << endl;
    pthread_once(&once, once_run);
    cout << "thread " << tid << " return" << endl;
}

int main(void)
{
    pthread_t tid1, tid2;
    cout << "hello" << endl;
    pthread_create(&tid1, NULL, child1, NULL);
    pthread_create(&tid2, NULL, child2, NULL);
    sleep(10);
    cout << "main thread exit" << endl;
    return 0;
}
#+end_src
执行结果：
#+begin_example
hello
thread 3086535584 enter
once_run in thread 3086535584
thread 3086535584 return
thread 3076045728 enter
thread 3076045728 return
main thread exit
#+end_example
**** 参考文章
[[https://www.cnblogs.com/qinwanlin/p/pthread_once.html][pthread_once详解和使用 - qinwanlin - 博客园]]
*** 实例

图12-11给出了getenv的假设实现。接着又给出了一个新的接口，提供的功能相同，不过它是线程安全的（见图12-12）。但是如果不修改应用程序，直接使用新的接口会出现什么问题呢？这种情况下，可以使用线程特定数据来维护每个线程的数据缓冲区副本，用于存放各自的返回字符串，如图12-13所示。

#+begin_src c++
#include <limits.h>
#include <string.h>
#include <pthread.h>
#include <stdlib.h>
#define MAXSTRINGSZ 4096
static pthread_key_t key;
static pthread_once_t init_done = PTHREAD_ONCE_INIT;
pthread_mutex_t env_mutex = PTHREAD_MUTEX_INITIALIZER;
extern char **environ;
static void thread_init(void)
{
    pthread_key_create(&key, free);
}
char *getenv(const char *name)
{
    int i, len;
    char *envbuf;
    pthread_once(&init_done, thread_init);
    pthread_mutex_lock(&env_mutex);
    envbuf = (char *)pthread_getspecific(key);
    if (envbuf == NULL)
    {
        envbuf = malloc(MAXSTRINGSZ);
        if (envbuf == NULL)
        {
            pthread_mutex_unlock(&env_mutex);
            return (NULL);
        }
        pthread_setspecific(key, envbuf);
    }
    len = strlen(name);
    for (i = 0; environ[i] != NULL; i++)
    {
        if ((strncmp(name, environ[i], len) == 0) &&
            (environ[i][len] == ’=’))
        {
            strncpy(envbuf, &environ[i][len + 1], MAXSTRINGSZ - 1);
            pthread_mutex_unlock(&env_mutex);
            return (envbuf);
        }
    }
    pthread_mutex_unlock(&env_mutex);
    return (NULL);
}
#+end_src
图12-13 线程安全的getenv的兼容版本

我们使用 pthread_once 来确保只为我们将使用的线程特定数据创建一个键。如果pthread_getspecific 返回的是空指针，就需要先分配内存缓冲区，然后再把键与该内存缓冲区关联。否则，如果返回的不是空指针，就使用pthread_getspecific返回的内存缓冲区。对析构函数，使用free来释放之前由malloc分配的内存。只有当线程特定数据值为非空时，析构函数才会被调用。

注意，虽然这个版本的getenv是线程安全的，但它并不是异步信号安全的。对信号处理程序而言，即使使用递归的互斥量，这个版本的 getenv 也不可能是可重入的，因为它调用了malloc，而malloc函数本身并不是异步信号安全的。
** 取消选项
** 线程和信号
** 线程和fork
** 线程和I/O
** 小结
* unzip命令
Linux unzip命令用于解压缩zip文件

语法:
#+begin_src bash
unzip [-cflptuvz][-agCjLMnoqsVX][-P <密码>][.zip文件][文件][-d <目录>][-x <文件>] 或 unzip [-Z]
#+END_SRC
参数：
#+BEGIN_EXAMPLE
-c 将解压缩的结果显示到屏幕上，并对字符做适当的转换。
-f 更新现有的文件。
-l 显示压缩文件内所包含的文件。
-p 与-c参数类似，会将解压缩的结果显示到屏幕上，但不会执行任何的转换。
-t 检查压缩文件是否正确。
-u 与-f参数类似，但是除了更新现有的文件外，也会将压缩文件中的其他文件解压缩到目录中。
-v 执行是时显示详细的信息。
-z 仅显示压缩文件的备注文字。
-a 对文本文件进行必要的字符转换。
-b 不要对文本文件进行字符转换。
-C 压缩文件中的文件名称区分大小写。
-j 不处理压缩文件中原有的目录路径。
-L 将压缩文件中的全部文件名改为小写。
-M 将输出结果送到more程序处理。
-n 解压缩时不要覆盖原有的文件。
-o 不必先询问用户，unzip执行后覆盖原有文件。
-P<密码> 使用zip的密码选项。
-q 执行时不显示任何信息。
-s 将文件名中的空白字符转换为底线字符。
-V 保留VMS的文件版本信息。
-X 解压缩时同时回存文件原来的UID/GID。
[.zip文件] 指定.zip压缩文件。
[文件] 指定要处理.zip压缩文件中的哪些文件。
-d<目录> 指定文件解压缩后所要存储的目录。
-x<文件> 指定不要处理.zip压缩文件中的哪些文件。
-Z unzip -Z等于执行zipinfo指令。
#+END_EXAMPLE

* which
Linux which命令用于查找文件。

which指令会在环境变量$PATH设置的目录里查找符合条件的文件。

语法:
which [文件...]

参数：
- -n<文件名长度> 指定文件名长度，指定的长度必须大于或等于所有文件中最长的文件名。
- -p<文件名长度> 与-n参数相同，但此处的<文件名长度>包括了文件的路径。
- -w 指定输出时栏位的宽度。
- -V 显示版本信息。
- -a 在每个参数里寻找命令，并打印出每个命令的路径
* Vmware虚拟机
NAT模式下，多个虚拟机都是连接到同一个网关地址
** ubuntu终端放大缩小
<Ctrl> + <->减小字号
<Ctrl> + <Shift> + <+>增大字号
终端设置
1、打开终端；
2、Edit→Profile Preferences
3、在General里最后一行设置默认大小

Ubuntu快速安装模式中，root用户默认不设置密码，可执行下面的命令为root设置密码
#+BEGIN_SRC bash
sudo passwd
#+END_SRC
** 硬盘扩容
1.扩展虚拟机硬盘大小（关机状态才能扩容）

#+DOWNLOADED: file:F:/org/图片/20171225160128418.png @ 2020-06-02 19:14:00
[[file:虚拟机/2020-06-02_19-14-00_20171225160128418.png]]

2.安装修改文件大小的软件，此软件和Window上的DiskGenius用法相似。
#+BEGIN_SRC bash
sudo apt-get install gparted
#+END_SRC

打开gparted
#+DOWNLOADED: file:F:/org/图片/20171225160133078.png @ 2020-06-02 19:15:12
[[file:虚拟机/2020-06-02_19-15-12_20171225160133078.png]]

3.和DiskGenius相同，只有相邻的空间时没有被分配的才能扩展空间大小，所以我们先删除/dev/sda2，保存修改（点击变成绿色的对号）。

#+DOWNLOADED: file:F:/org/图片/20171225160136902.png @ 2020-06-02 19:17:46
[[file:虚拟机/2020-06-02_19-17-46_20171225160136902.png]]

4./dev/sda1之后的空间都是未分配的空间，我们可以把鼠标放在/dev/sda1，右键
#+DOWNLOADED: file:F:/org/图片/20171225160140891.png @ 2020-06-02 19:18:34
[[file:虚拟机/2020-06-02_19-18-34_20171225160140891.png]]

鼠标拖动改变大小，或者直接在New size对应的文本框输入大小。预留部分空间给我们在第三步删除的交换分区。
#+DOWNLOADED: file:F:/org/图片/20171225160144569.png @ 2020-06-02 19:27:49
[[file:虚拟机/2020-06-02_19-27-49_20171225160144569.png]]

5.鼠标放在剩余的未分配的空间，创建交换分区，保存修改。
#+DOWNLOADED: file:F:/org/图片/20171225160148123.png @ 2020-06-02 19:28:52
[[file:虚拟机/2020-06-02_19-28-52_20171225160148123.png]]

6.sudo fdisk -l，/dev/sda1空间从40G扩展到了58G
#+DOWNLOADED: file:F:/org/图片/20171225160152672.png @ 2020-06-02 19:39:22
[[file:虚拟机/2020-06-02_19-39-22_20171225160152672.png]]
** 解决VM Workstation安装VMware Tools显示灰色的办法
解决办法如下：
1.关闭虚拟机；

2.在虚拟机设置分别设置CD/DVD、CD/DVD2和软盘为自动检测三个步骤；

3.再重启虚拟机，灰色字即点亮。

如果上述步骤不行，就执行方法二：
1.关闭虚拟机；

2.在虚拟机将CD/DVD设置为VMware安装目录中的linux.iso（如ubuntu-16.04.5-desktop-i386.iso）、CD/DVD2设置和CD/DVD一样也是可以的（这里建议设置为自动检测，因为设置为自动检测也是可以的）和和软盘为自动检测三个步骤；

3.再重启虚拟机，灰色字即点亮。
** VMware 虚拟机如何连接网络
*** 一、首先查看自己的虚拟机服务有没有开启，选择电脑里面的服务查看；
1.计算机点击右键选择管理

#+DOWNLOADED: file:F:/org/图片/20170103235137966.jpg @ 2020-10-29 15:25:51
[[file:虚拟机/2020-10-29_15-25-51_20170103235137966.jpg]]

2.进入管理选择VM开头的服务如果没有开启的话就右键开启

#+DOWNLOADED: file:F:/org/图片/20170103235345453.jpg @ 2020-10-29 15:26:15
[[file:虚拟机/2020-10-29_15-26-15_20170103235345453.jpg]]
*** 二、虚拟机服务开启后就查看本地网络虚拟机的网卡启动没有
1.电脑右下角网络标志右键进入网络和共享中心
#+DOWNLOADED: file:F:/org/图片/20170103235608659 (1).jpg @ 2020-10-29 15:27:21
[[file:虚拟机/2020-10-29_15-27-21_20170103235608659 (1).jpg]]

2.点击更改适配器，查看虚拟机的虚拟网卡启动没有，没有启动的话右键点击启动

#+DOWNLOADED: file:F:/org/图片/20170103235743739.jpg @ 2020-10-29 15:27:39
[[file:虚拟机/2020-10-29_15-27-39_20170103235743739.jpg]]

#+DOWNLOADED: file:F:/org/图片/20170103235832318.jpg @ 2020-10-29 15:28:33
[[file:虚拟机/2020-10-29_15-28-33_20170103235832318.jpg]]


3.网卡开启后设置ip地址，此处设置的ip和本机的ip没有关系，设置成你虚拟机里面运行的计算机需要的ip地址网段

#+DOWNLOADED: file:F:/org/图片/20170104000142275.jpg @ 2020-10-29 15:28:43
[[file:虚拟机/2020-10-29_15-28-43_20170104000142275.jpg]]
*** 三、此时你的本机设置完成了，该设置虚拟机了
1.打开虚拟机，选择你使用的操作系统打开详情页选择网络适配器，选择NAT模式并选择启动时连接，如下图；
#+DOWNLOADED: file:F:/org/图片/20170104000401889.jpg @ 2020-10-29 15:29:52
[[file:虚拟机/2020-10-29_15-29-52_20170104000401889.jpg]]
2.选择完后点击虚拟机页面上的编辑进入虚拟网络编辑器

#+DOWNLOADED: file:F:/org/图片/20170104001142827.jpg @ 2020-10-29 15:30:06
[[file:虚拟机/2020-10-29_15-30-06_20170104001142827.jpg]]

3.进来后会出现这个窗口，选择右下角更改设置，使用管理员进行修改
#+DOWNLOADED: file:F:/org/图片/20170104001303104.jpg @ 2020-10-29 15:30:17
[[file:虚拟机/2020-10-29_15-30-17_20170104001303104.jpg]]

4.更改完成后，更改下方的ip地址，此处的ip地址段和你在本机网络虚拟网卡（二-3）里面设置的ip要在一个网段里面,本机设置的是ip地址，而在此处设置的是ip网段
#+DOWNLOADED: file:F:/org/图片/20170104001424828.jpg @ 2020-10-29 15:31:20
[[file:虚拟机/2020-10-29_15-31-20_20170104001424828.jpg]]

5.选择DHCP,进行设置你的虚拟机分配虚拟计算机的ip地址范围

#+DOWNLOADED: file:F:/org/图片/20170104001826299.jpg @ 2020-10-29 15:31:41
[[file:虚拟机/2020-10-29_15-31-41_20170104001826299.jpg]]

6.设置完DHCP后进行网关的设置，选择NAT设置，设置你虚拟计算机的网关地址。
#+DOWNLOADED: file:F:/org/图片/20170104001943940.jpg @ 2020-10-29 15:31:52
[[file:虚拟机/2020-10-29_15-31-52_20170104001943940.jpg]]
*** 四、这时候，必要条件就已经配合结束了，开启虚拟计算机，进入IPv4的设置。
填写ip地址，IP地址要在你在虚拟机DHCP分配的ip地址（三-5）范围内
填写网关，就是在上面设置虚拟机网关的地址（三-6）
DNS服务器可以设置114.114.114.144 8.8.8.8 等。
*** 五、这时候基本就可以进行网络连接了，打开网页试一下，如果还连接不上，查看是否是哪一步没有设置对，在就重新启动虚拟计算机的网络。
** 修改时区和时间
~timedatectl set-timezone Asia/Shanghai~
** VirtualBox 主机ping不通虚拟机的解决办法
虚拟机与主机之间相互ping通有一个问题，就是虚拟机能够ping通主机,本地主机ping不通虚拟机

解决办法：
*** 如果虚拟机有两个网卡

将虚拟机网卡2的连接方式改成桥接即可：

#+DOWNLOADED: screenshot @ 2023-03-05 15:01:07
[[file:images/Vmware虚拟机/2023-03-05_15-01-07_screenshot.png]]
️要将虚拟机重启，否则是成功不了的（重要）

然后就能够通过网卡2进行连接：

#+DOWNLOADED: screenshot @ 2023-03-05 15:01:25
[[file:images/Vmware虚拟机/2023-03-05_15-01-25_screenshot.png]]
*** 虚拟机只有一个网卡

也是将网卡1改成桥接模式

#+DOWNLOADED: screenshot @ 2023-03-05 15:01:47
[[file:images/Vmware虚拟机/2023-03-05_15-01-47_screenshot.png]]
要将虚拟机重启，否则是成功不了的（重要）

然后就成功ping通了
** 网络连接模式
桥接、NAT、Host-only上网方式的区别：
- 桥接 通过使用物理机网卡 具有单独ip
- NAT 把物理机为路由器进行上网
- host-only 只能与物理机相连
*** NAT
网络地址转换（英语：Network Address Translation，缩写：NAT；又称网络掩蔽、IP掩蔽）在计算机网络中是一种在IP数据包通过路由器或防火墙时重写来源IP地址或目的IP地址的技术。这种技术被普遍使用在有多台主机但只通过一个公有IP地址访问互联网的私有网络中。它是一个方便且得到了广泛应用的技术。当然，NAT也让主机之间的通信变得复杂，导致了通信效率的降低。

NAT模式实际是虚拟了一个网卡出来，虚拟机直接使用链接这个虚拟网卡，每次访问和交互通过这个虚拟网卡交换数据。
虚拟机发送数据给实体机：虚拟机系统->虚拟网卡->实体机系统（可以发现是不经过真实网卡的流程简单很多）；虚拟机访问外网：虚拟机系统->虚拟网卡->实体机系统->真实网卡->路由器->外网

NAT 模式下，虚拟机仅仅可以同路由器下网段中的一台真实机通讯，而这台真实机就是安装虚拟机的这台电脑，之所以可以通讯是因为这台电脑本身充当了虚拟机的路由器，相当于路由器的 192.168.1.1 这个地址，而你在 vmware 下的网卡管理中是可以看到这个地址的。


#+DOWNLOADED: screenshot @ 2023-03-05 15:07:33
[[file:images/Vmware虚拟机/2023-03-05_15-07-33_screenshot.png]]

*** 桥接
桥接就是指：就是通过一台设备（可能不止一个）把几个网络串起来形成的连接

虚拟出来的操作系统就像是局域网中的一独立的主机，它可以通过路由器网线访问网内任何一台机器。不过虚拟机需要占用你同一个网段的一个 IP 地址，当且仅当虚拟机和实体机在同一个网段，两者才可以进行通信

** 参考文章
[[https://blog.csdn.net/qq_19734597/article/details/103386987][VirtualBox 主机ping不通虚拟机的解决办法]]
[[https://cloud.tencent.com/developer/article/1463782][桥接、NAT、Host-only上网方式的区别]]
* vim
[[https://vim.rtorr.com/lang/zh_cn][Vim Cheat Sheet]]
** 移动光标
h 或 向左箭头键(←) 光标向左移动一个字符
j 或 向下箭头键(↓) 光标向下移动一个字符
k 或 向上箭头键(↑) 光标向上移动一个字符
l 或 向右箭头键(→) 光标向右移动一个字符
[Ctrl] + [f] 屏幕『向下』移动一页，相当于 [Page Down]按键 (常用)
[Ctrl] + [b] 屏幕『向上』移动一页，相当于 [Page Up] 按键 (常用)
[Ctrl] + [d] 屏幕『向下』移动半页
[Ctrl] + [u] 屏幕『向上』移动半页
+ 光标移动到非空格符的下一列
- 光标移动到非空格符的上一列
n<space> 那个 n 表示『数字』，例如 20 。按下数字后再按空格键，光标会向右移动这一列的 n个字符。例如 20<space> 则光标会向后面移动 20 个字符距离。
0 或功能键[Home] 这是数字『 0 』：移动到这一列的最前面字符处 (常用)
$ 或功能键[End] 移动到这一列的最后面字符处(常用)
H 光标移动到这个屏幕的最上方那一列的第一个字符
M 光标移动到这个屏幕的中央那一列的第一个字符
L 光标移动到这个屏幕的最下方那一列的第一个字符
G 移动到这个文件的最后一列(常用)
nG n 为数字。移动到这个文件的第 n 列。例如 20G 则会移动到这个文件的第 20 列(可配合 :set nu)
gg 移动到这个文件的第一列，相当于 1G 啊！ (常用)
n<Enter> n 为数字。光标向下移动 n 列(常用)
** 搜寻与替换
r, R 进入取代模式(Replace mode)：r 只会取代光标所在的那一个字符一次；R 会一直取代光标所在的文字，直到按下 ESC为止；(常用)
/word 向光标之下寻找一个名称为 word 的字符串。例如要在文件内搜寻 vbird 这个字符串，就输入 /vbird 即可！ (常用)
?word 向光标之上寻找一个字符串名称为 word 的字符串。
n 这个 n 是英文按键。代表『重复前一个搜寻的动作』。举例来说， 如果刚刚我们执行/vbird 去向下搜寻 vbird 这个字符串，则按下 n 后，会向下继续搜寻下一个名称为vbird 的字符串。如果是执行 ?vbird 的话，那么按下 n 则会向上继续搜寻名称为vbird 的字符串！
N 这个 N 是英文按键。与 n 刚好相反，为『反向』进行前一个搜寻动作。 例如 /vbird后，按下 N 则表示『向上』搜寻 vbird 。使用 /word 配合 n 及 N 是非常有帮助的！可以让你重复的找到一些你搜寻的关键词！
:n1,n2s/word1/word2/g n1 与 n2 为数字。在第 n1 与 n2 行之间寻找 word1 这个字符串，并将该字符串取代为 word2 ！举例来说，在 100 到 200 行之间搜寻 vbird 并取代为 VBIRD 则：『:100,200s/vbird/VBIRD/g』。(常用)
:1,$s/word1/word2/g 从第一行到最后一行寻找 word1 字符串，并将该字符串取代为 word2 ！(常用)。这个1和$都可以空着的，例如,$表示从当前行到最后一行
:1,$s/word1/word2/gc 从第一行到最后一行寻找 word1 字符串，并将该字符串取代为 word2 ！且在取代前显示提示字符给用户确认 (confirm) 是否需要取代！(常用)
:%s/word1/word2/g 全文替换
*** 关于替换\n换行符的问题
详细内容可参考文章:https://vim.fandom.com/wiki/Search_and_replace

字符串查找时，”\n” 是换行，”\r” 是回车，也就是经常会看到的 ^M。

字符串替换时，”\r” 是换行，’\n” 是空字符（0x00）。

When searching:
#+BEGIN_EXAMPLE
., *, \, [, ^, and $ are metacharacters.
+, ?, |, &, {, (, and ) must be escaped to use their special function.
\/ is / (use backslash + forward slash to search for forward slash)
\t is tab, \s is whitespace (space or tab)
\n is newline, \r is CR (carriage return = Ctrl-M = ^M)
After an opening [, everything until the next closing ] specifies a /collection. Character ranges can be represented with a -; for example a letter a, b, c, or the number 1 can be matched with [1a-c]. Negate the collection with [^ instead of [; for example [^1a-c] matches any character except a, b, c, or 1.
\{#\} is used for repetition. /foo.\{2\} will match foo and the two following characters. The \ is not required on the closing } so /foo.\{2} will do the same thing.
\(foo\) makes a backreference to foo. Parenthesis without escapes are literally matched. Here the \ is required for the closing \).
#+END_EXAMPLE
When replacing:
#+BEGIN_EXAMPLE
\r is newline, \n is a null byte (0x00).
\& is ampersand (& is the text that matches the search pattern).
\0 inserts the text matched by the entire pattern
\1 inserts the text of the first backreference. \2 inserts the second backreference, and so on.
#+END_EXAMPLE

**** 参考文章
[[http://www.leakon.com/archives/830/comment-page-1][VIM 替换 \n 换行符]]
** 删除、复制与粘贴
x, X 在一列字当中，x 为向后删除一个字符 (相当于 [del] 按键)， X 为向前删除一个字符(相当于 [backspace] 亦即是退格键) (常用)
nx n 为数字，连续向后删除 n 个字符。举例来说，我要连续删除 10 个字符， 『10x』。
dd 删除游标所在的那一整列(常用)
ndd n 为数字。删除光标所在的向下 n 列，例如 20dd 则是删除 20 列 (常用)
d1G 删除光标所在到第一列的所有数据
dG 删除光标所在到最后一列的所有数据
d$ 删除游标所在处，到该列的最后一个字符
d0 那个是数字的 0 ，删除游标所在处，到该列的最前面一个字符
yy 复制游标所在的那一列(常用)
nyy n 为数字。复制光标所在的向下 n 列，例如 20yy 则是复制 20 列(常用)
y1G 复制光标所在列到第一列的所有数据
yG 复制光标所在列到最后一列的所有数据
y0 复制光标所在的那个字符到该列行首的所有数据
y$ 复制光标所在的那个字符到该列行尾的所有数据
p, P p 为将已复制的数据在光标下一列贴上，P 则为贴在游标上一列！ 举例来说，我目前光标在第 20 列，且已经复制了 10 列数据。则按下 p 后， 那 10 列数据会贴在原本的 20列之后，亦即由 21 列开始贴。但如果是按下 P 呢？ 那么原本的第 20 列会被推到变成 30 列。 (常用)
J 将光标所在列与下一列的数据结合成同一列
c 重复删除多个数据，例如向下删除 10 列，[ 10cj ]
** 重复撤销
u 复原前一个动作。(常用)
[Ctrl]+r 重做上一个动作。(常用)
. 不要怀疑！这就是小数点！意思是重复前一个动作的意思。 如果你想要重复删除、重复贴上等等动作，按下小数点『.』就好了！ (常用)
** 插入
i, I 进入插入模式(Insert mode)：i 为『从目前光标所在处插入』， I 为『在目前所在列的第一个非空格符处开始插入』。(常用)
a, A 进入插入模式(Insert mode)：a 为『从目前光标所在的下一个字符处开始插入』， A 为『从光标所在列的最后一个字符处开始插入』。(常用)
o, O 进入插入模式(Insert mode)：这是英文字母 o 的大小写。o 为『在目前光标所在的下一列处插入新的一列』； O 为在目前光标所在处的上一列插入新的一列！(常用)
** 指令列模式的储存、离开等指令
:w 将编辑的数据写入硬盘文件中(常用)
:w! 若文件属性为『只读』时，强制写入该文件。不过，到底能不能写入， 还是跟你对该文件的文件权限有关啊！
:q 离开 vi (常用)
:q! 若曾修改过文件，又不想储存，使用 ! 为强制离开不储存文件。
:wq 储存后离开，若为 :wq! 则为强制储存后离开 (常用)
ZZ 这是大写的 Z 喔！若文件没有更动，则不储存离开，若文件已经被更动过，则储存后离开！
:w [filename] 将编辑的数据储存成另一个文件（类似另存新档）
:r [filename] 在编辑的数据中，读入另一个文件的数据。亦即将 『filename』 这个文件内容加到游标所在列后面
:n1,n2 w [filename] 将 n1 到 n2 的内容储存成 filename 这个文件。
:! command 暂时离开 vi 到指令列模式下执行 command 的显示结果！例如『:! ls /home』即可在 vi 当中察看 /home 底下以 ls 输出的文件信息！
** vim 环境的变更
:set nu 显示行号，设定之后，会在每一列的前缀显示该列的行号
:set nonu 与 set nu 相反，为取消行号！
** 区块选择(Visual Block)
v 字符选择，会将光标经过的地方反白选择！
V 列选择，会将光标经过的列反白选择！
[Ctrl]+v 区块选择，可以用长方形的方式选择资料
y 将反白的地方复制起来
d 将反白的地方删除掉
p 将刚刚复制的区块，在游标所在处贴上！
** 环境设定
vim 的环境设定参数有很多，如果你想要知道目前的设定值，可以在一般指令模式时输入:set all  来查阅

:set nu与:set nonu 就是设定与取消行号啊！
:set hlsearch与:set nohlsearch hlsearch 就是 high light search(高亮度搜寻)。 这个就是设定是否将搜寻的字符串反白的设定值。默认值是 hlsearch
:set autoindent与:set noautoindent 是否自动缩排？autoindent 就是自动缩排。
:set backup 是否自动储存备份档？一般是 nobackup 的， 如果设定 backup 的话，那么当你更动任何一个文件时，则源文件会被另存成一个档名为 filename~ 的文件。 举例来说，我们编辑 hosts ，设定 :set backup ，那么当更动 hosts 时，在同目录下，就会产生 hosts~文件名的文件，记录原始的 hosts 文件内容
:set ruler 还记得我们提到的右下角的一些状态栏说明吗？ 这个 ruler 就是在显示或不显示该设定值的啦！
:set showmode 这个则是，是否要显示 --INSERT-- 之类的字眼在左下角的状态栏。
:set backspace=(012) 一般来说， 如果我们按下 i 进入编辑模式后，可以利用退格键 (backspace) 来删除任意字符的。 但是，某些 distribution 则不许如此。此时，我们就可以透过 backspace来设定啰～ 当 backspace 为 2 时，就是可以删除任意值；0 或 1 时，仅可删除刚刚输入的字符，而无法删除原本就已经存在的文字了！
:set all 显示目前所有的环境参数设定值。
:set 显示与系统默认值不同的设定参数， 一般来说就是你有自行变动过的设定参数啦！
:syntax on与:syntax off 是否依据程序相关语法显示不同颜色？ 举例来说，在编辑一个纯文本档时，如果开头是以 # 开始，那么该列就会变成蓝色。 如果你懂得写程序，那么这个 :syntax on 还会主动的帮你除错呢！但是， 如果你仅是编写纯文本文件，要避免颜色对你的屏幕产生的干扰，则可以取消这个设定 。
:set bg=dark与:set bg=light 可用以显示不同的颜色色调，预设是『 light 』。如果你常常发现批注的字体深蓝色实在很不容易看， 那么这里可以设定为 dark 喔！试看看，会有不同的样式呢！
** 让Vim显示dos下的^M符号
参考文章：[[https://stackoverflow.com/questions/21228946/why-does-vim-sometimes-show-m-and-sometimes-not-even-if-they-are-there][Why does vim sometimes show ^M and sometimes not (even if they are there)?]]

When opening a file, vim tries to detect if it's a MS-DOS/Windows or a unix file. If all lines are terminated by \r\n, it's probably a DOS file, if only some of them are, vim may assume unix as well. If the file format is set to DOS, vim ignores \r when reading the file, and shows [dos] in the status line directly after reading the file.

我的理解是vim将文件当做dos文件，所以将\r\n作为换行符显示。在这里，vim正确地显示了文件的内容，但是其他的软件未必会正确地将\r\n为换行符，所以用其他的软件读取改文件，就会出现错误。为了能让vim将^M显示出来，只要将文件编码格式设置为unix即可。

vim中键入： :e ++ff=unix 即可让vim显示^M

设置文件编码格式:set ff=unix 然后保存:wq ，即可去除^M

The :e ++ff=unix command tells Vim to read the file again, forcing unix file format. 

To learn about ff, execute ":help ff"
* vscode 相关
** vscode的sftp
 ps：SFTP目前不能处理中文文件
*** SFTP原理
 SFTP原理是这样的：首先本地要有一个项目文件夹，同时远程也有一个项目文件夹，然后通过配置文件来同步二者。
 SFTP可以查看远程项目所有文件，但不能直接操作，必须操作本地项目文件，再同步到远程项目。

 现在我们本地和远程均有一个文件夹“sftpFolder”，用VsCode打开本地文件夹“sftpFolder”，然后执行 ctrl+shift+p ，搜索 SFTP:Config ，回车后，会生成一个“.vscode/sftp.json”，这个就是配置文件。
 同时，如下图左侧会多了一个“远程目录”。

 #+DOWNLOADED: file:E%3A/org/%E5%9B%BE%E7%89%87/Snipaste_2021-10-13_10-46-50.png @ 2021-10-13 10:47:31
 [[file:vs_code%E7%9A%84sftp/2021-10-13_10-47-31_Snipaste_2021-10-13_10-46-50.png]]
*** SFTP配置

 #+DOWNLOADED: file:E%3A/org/%E5%9B%BE%E7%89%87/Snipaste_2021-10-13_10-47-59.png @ 2021-10-13 10:48:26
 [[file:vs_code%E7%9A%84sftp/2021-10-13_10-48-26_Snipaste_2021-10-13_10-47-59.png]]
 配置文件不能写注释，所以这里说明一下其中几个属性：
 - uploadOnSave：本地更新文件保存会自动同步到远程文件（不会同步重命名文件和删除文件）
 - downloadOnOpen：从远程服务器下载打开的文件
 - ignore：忽略的文件（匹配的文件不会同步）
 - watcher：监听器（可以重命名文件和删除文件）
     - autoUpload：文件变更会自动同步（修改和重命名）
     - autoDelete：文件删除会自动同步
** 调试配置文件
VSCode 内置了对 Node.js 的调试支持，如果你需要调试其他语言如 C++、PHP、Python 等，可以在 VSCode 的插件市场安装对应的插件。

name：调试界面下拉选择项的名称

type：必填项，调试类型，是vscode用于计算调试代码需要用哪个扩展

request，必填项，有两种类型，分别是 launch 和 attach，前者的意思就是 VSCode 会打开这个程序然后进入调试，后者的意思是你已经打开了程序，然后接通程序的内部调试协议进行调试，

program，程序的启动入口

mode：可以设置为auto，debug，remote，test，exeC中的一个

program：调试程序的路径（绝对路径）

env：调试时使用的环境变量。例如：{"ENVNAME"："ENVVALUE"}

envFile：包含环境变量文件的绝对路径，在env中设置的属性会覆盖envFi1e中的配置

args：启动时的命令行参数

showLog：布尔值，是否将调试信息输出

logOutput：配置调试输出的组件（debugger，gdbwire，lldbout，debuglineerr，rpc），使用,分隔，showLog设置为true时}此项配置生效

buildFlags：构建go程序时传给go编译器的标志

remotePath：远程调试程序的绝对路径，当mode设置为remote时有效

runtimeExecutable，使用什么命令启动
*** Variables Reference
**** Predefined variables
The following predefined variables are supported:
- ${workspaceFolder} - the path of the folder opened in VS Code
- ${workspaceFolderBasename} - the name of the folder opened in VS Code without any slashes (/)
- ${file} - the current opened file
- ${fileWorkspaceFolder} - the current opened file's workspace folder
- ${relativeFile} - the current opened file relative to workspaceFolder
- ${relativeFileDirname} - the current opened file's dirname relative to workspaceFolder
- ${fileBasename} - the current opened file's basename
- ${fileBasenameNoExtension} - the current opened file's basename with no file extension
- ${fileDirname} - the current opened file's dirname
- ${fileExtname} - the current opened file's extension
- ${cwd} - the task runner's current working directory on startup
- ${lineNumber} - the current selected line number in the active file
- ${selectedText} - the current selected text in the active file
- ${execPath} - the path to the running VS Code executable
- ${defaultBuildTask} - the name of the default build task
- ${pathSeparator} - the character used by the operating system to separate components in file paths
***** Predefined variables examples#
Supposing that you have the following requirements:
1. A file located at /home/your-username/your-project/folder/file.ext opened in your editor;
2. The directory /home/your-username/your-project opened as your root workspace.
So you will have the following values for each variable:
- ${workspaceFolder} - /home/your-username/your-project
- ${workspaceFolderBasename} - your-project
- ${file} - /home/your-username/your-project/folder/file.ext
- ${fileWorkspaceFolder} - /home/your-username/your-project
- ${relativeFile} - folder/file.ext
- ${relativeFileDirname} - folder
- ${fileBasename} - file.ext
- ${fileBasenameNoExtension} - file
- ${fileDirname} - /home/your-username/your-project/folder
- ${fileExtname} - .ext
- ${lineNumber} - line number of the cursor
- ${selectedText} - text selected in your code editor
- ${execPath} - location of Code.exe
- ${pathSeparator} - / on macOS or linux, \ on Windows

#+BEGIN_EXAMPLE
Tip: Use IntelliSense inside string values for tasks.json and launch.json to get a full list of predefined variables.
#+END_EXAMPLE

*** 参考文章
[[https://www.barretlee.com/blog/2019/03/18/debugging-in-vscode-tutorial/][VSCode 调试中 launch.json 配置不完全指南]]
** VS Code中C/C++ 无法跳转到定义的解决办法
安装C/C++ 和 C++ intellisense 两个插件

已安装插件的情况下， 会遇到之前正常的的VS code突然无法跳转了，怎么按都没反应，这时候将编译器重启一下，会发现跳转功能又正常了

添加包含路径
1. 在VS code界面按 ctrl+shift+P ，然后输入 >configurations 调出下面的选项，点击红框

#+DOWNLOADED: screenshot @ 2022-09-18 15:04:51
[[file:images/linux笔记/vscode_相关/2022-09-18_15-04-51_screenshot.png]]
2. 选择VS code 文件目录中常用的文件夹，我的是“user”

#+DOWNLOADED: screenshot @ 2022-09-18 15:05:04
[[file:images/linux笔记/vscode_相关/2022-09-18_15-05-04_screenshot.png]]
3. 然后会发现，所选的文件夹下，多了这些东东

#+DOWNLOADED: screenshot @ 2022-09-18 15:05:16
[[file:images/linux笔记/vscode_相关/2022-09-18_15-05-16_screenshot.png]]
4. 点击新生成的json文件，在includePath 中添加想要跳转的文件所在的路径，建议使用相对路径，当然绝对路径也是可以的。设置之后也是重启编辑器才会生效
#+DOWNLOADED: screenshot @ 2022-09-18 15:05:30
[[file:images/linux笔记/vscode_相关/2022-09-18_15-05-30_screenshot.png]]
5. 如果还没有生效，就在C/C++ 插件中，Add Node Addon include paths 取消掉

#+DOWNLOADED: screenshot @ 2022-09-18 15:05:50
[[file:images/linux笔记/vscode_相关/2022-09-18_15-05-50_screenshot.png]]

#+DOWNLOADED: screenshot @ 2022-09-18 15:05:55
[[file:images/linux笔记/vscode_相关/2022-09-18_15-05-55_screenshot.png]]
6. 如果还没有生效，那么看看要跳转的变量或函数，与当前文件是直接包含还是间接包含。 换成直接包含试试？
*** 参考文章
[[https://blog.csdn.net/hb69222/article/details/117034317][VS Code中C/C++ 无法跳转到定义的解决办法]]
** 文件标签栏多行显示
按住 ctrl + shift + p

输入 open workspace settings,选择打开工作区设置

输入workbench.editor.wrapTabs,勾选该设置项即可
* watch命令
watch是一个非常实用的命令，基本所有的Linux发行版都带有这个小工具，如同名字一样，watch可以帮你监测一个命令的运行结果，省得你一遍遍的手动运行。在Linux下，watch是周期性的执行下个程序，并全屏显示执行结果。你可以拿他来监测你想要的一切命令的结果变化，比如 tail 一个 log 文件，ls 监测某个文件的大小变化。

命令格式：
watch[参数][命令]

命令参数：
- -n或--interval  watch缺省每2秒运行一下程序，可以用-n或-interval来指定间隔的时间。
- -d或--differences  用-d或--differences 选项watch 会高亮显示变化的区域。 而-d=cumulative选项会把变动过的地方(不管最近的那次有没有变动)都高亮显示出来。
- -t 或-no-title  会关闭watch命令在顶部的时间间隔,命令，当前时间的输出。
- -h, --help 查看帮助文档

FreeBSD和Linux下watch命令的不同，在Linux下，watch是周期性的执行下个程序，并全屏显示执行结果，如：watch -n 1 -d netstat -ant，而在FreeBSD下的watch命令是查看其它用户的正在运行的操作，watch允许你偷看其它terminal正在做什么，该命令只能让超级用户使用。
** 实例
#+begin_src bash
watch -n 1 -d netstat -ant       # 命令：每隔一秒高亮显示网络链接数的变化情况
watch -n 1 -d 'pstree|grep http' # 每隔一秒高亮显示http链接数的变化情况。 后面接的命令若带有管道符，需要加''将命令区域归整。
watch 'netstat -an | grep:21 | \ grep<模拟攻击客户机的IP>| wc -l' # 实时查看模拟攻击客户机建立起来的连接数
watch -d 'ls -l|grep scf'       # 监测当前目录中 scf' 的文件的变化
watch -n 10 'cat /proc/loadavg' # 10秒一次输出系统的平均负载
watch uptime
watch -t uptime
watch -d -n 1 netstat -ntlp
watch -d 'ls -l | fgrep goface'     # 监测goface的文件
watch -t -differences=cumulative uptime
watch -n 60 from            # 监控mail
watch -n 1 "df -i;df"       # 监测磁盘inode和block数目变化情况
#+END_SRC
* wget
** 介绍
Linux系统中的wget是一个下载文件的工具，它用在命令行下。对于Linux用户是必不可少的工具，我们经常要下载一些软件或从远程服务器恢复备份到本地服务器。wget支持HTTP，HTTPS和FTP协议，可以使用HTTP代理。所谓的自动下载是指，wget可以在用户退出系统的之后在后台执行。这意味这你可以登录系统，启动一个wget下载任务，然后退出系统，wget将在后台执行直到任务完成，相对于其它大部分浏览器在下载大量数据时需要用户一直的参与，这省去了极大的麻烦。

wget 可以跟踪HTML页面上的链接依次下载来创建远程服务器的本地版本，完全重建原始站点的目录结构。这又常被称作”递归下载”。在递归下载的时候，wget 遵循Robot Exclusion标准(/robots.txt). wget可以在下载的同时，将链接转换成指向本地文件，以方便离线浏览。

wget 非常稳定，它在带宽很窄的情况下和不稳定网络中有很强的适应性.如果是由于网络的原因下载失败，wget会不断的尝试，直到整个文件下载完毕。如果是服务器打断下载过程，它会再次联到服务器上从停止的地方继续下载。这对从那些限定了链接时间的服务器上下载大文件非常有用。

用于从网络上下载资源，没有指定目录，下载资源回默认为当前目录。wget虽然功能强大，但是使用起来还是比较简单：

wget优点：
1）支持断点下传功能；这一点，也是网络蚂蚁和FlashGet当年最大的卖点，现在，Wget也可以使用此功能，那些网络不是太好的用户可以放心了；

2）同时支持FTP和HTTP下载方式；尽管现在大部分软件可以使用HTTP方式下载，但是，有些时候，仍然需要使用FTP方式下载软件；

3）支持代理服务器；对安全强度很高的系统而言，一般不会将自己的系统直接暴露在互联网上，所以，支持代理是下载软件必须有的功能；

4）设置方便简单；可能，习惯图形界面的用户已经不是太习惯命令行了，但是，命令行在设置上其实有更多的优点，最少，鼠标可以少点很多次，也不要担心是否错点鼠标；

5）程序小，完全免费；程序小可以考虑不计，因为现在的硬盘实在太大了；完全免费就不得不考虑了，即使网络上有很多所谓的免费软件，但是，这些软件的广告却不是我们喜欢的。
** 参数
*** 启动参数：
-V, –version 显示wget的版本后退出

-h, –help 打印语法帮助

-b, –background 启动后转入后台执行

-e, –execute=COMMAND 执行`.wgetrc’格式的命令，wgetrc格式参见/etc/wgetrc或~/.wgetrc
*** 记录和输入文件参数：

-o, –output-file=FILE 把记录写到FILE文件中

-a, –append-output=FILE 把记录追加到FILE文件中

-d, –debug 打印调试输出

-q, –quiet 安静模式(没有输出)

-v, –verbose 冗长模式(这是缺省设置)

-nv, –non-verbose 关掉冗长模式，但不是安静模式

-i, –input-file=FILE 下载在FILE文件中出现的URLs

-F, –force-html 把输入文件当作HTML格式文件对待

-B, –base=URL 将URL作为在-F -i参数指定的文件中出现的相对链接的前缀

–sslcertfile=FILE 可选客户端证书

–sslcertkey=KEYFILE 可选客户端证书的KEYFILE

–egd-file=FILE 指定EGD socket的文件名
*** 下载参数：

–bind-address=ADDRESS 指定本地使用地址(主机名或IP，当本地有多个IP或名字时使用)

-t, –tries=NUMBER 设定最大尝试链接次数(0 表示无限制).

-O –output-document=FILE 把文档写到FILE文件中

-nc, –no-clobber 不要覆盖存在的文件或使用.#前缀

-c, –continue 接着下载没下载完的文件

–progress=TYPE 设定进程条标记

-N, –timestamping 不要重新下载文件除非比本地文件新

-S, –server-response 打印服务器的回应

–spider 不下载任何东西

-T, –timeout=SECONDS 设定响应超时的秒数

-w, –wait=SECONDS 两次尝试之间间隔SECONDS秒

–waitretry=SECONDS 在重新链接之间等待1…SECONDS秒

–random-wait 在下载之间等待0…2*WAIT秒

-Y, –proxy=on/off 打开或关闭代理

-Q, –quota=NUMBER 设置下载的容量限制

–limit-rate=RATE 限定下载输率
*** 目录参数：

-nd –no-directories 不创建目录

-x, –force-directories 强制创建目录

-nH, –no-host-directories 不创建主机目录

-P, –directory-prefix=PREFIX 将文件保存到目录 PREFIX/…

–cut-dirs=NUMBER 忽略 NUMBER层远程目录

*** HTTP 选项参数：

–http-user=USER 设定HTTP用户名为 USER.

–http-passwd=PASS 设定http密码为 PASS

-C, –cache=on/off 允许/不允许服务器端的数据缓存 (一般情况下允许)

-E, –html-extension 将所有text/html文档以.html扩展名保存

–ignore-length 忽略 `Content-Length’头域

–header=STRING 在headers中插入字符串 STRING

–proxy-user=USER 设定代理的用户名为 USER

–proxy-passwd=PASS 设定代理的密码为 PASS

–referer=URL 在HTTP请求中包含 `Referer: URL’头

-s, –save-headers 保存HTTP头到文件

-U, –user-agent=AGENT 设定代理的名称为 AGENT而不是 Wget/VERSION

–no-http-keep-alive 关闭 HTTP活动链接 (永远链接)

–cookies=off 不使用 cookies

–load-cookies=FILE 在开始会话前从文件 FILE中加载cookie

–save-cookies=FILE 在会话结束后将 cookies保存到 FILE文件中
*** FTP 选项参数：

-nr, –dont-remove-listing 不移走 `.listing’文件

-g, –glob=on/off 打开或关闭文件名的 globbing机制

–passive-ftp 使用被动传输模式 (缺省值).

–active-ftp 使用主动传输模式

–retr-symlinks 在递归的时候，将链接指向文件(而不是目录)
*** 递归下载参数：

-r, –recursive 递归下载－－慎用!

-l, –level=NUMBER 最大递归深度 (inf 或 0 代表无穷)

–delete-after 在现在完毕后局部删除文件

-k, –convert-links 转换非相对链接为相对链接

-K, –backup-converted 在转换文件X之前，将之备份为 X.orig

-m, –mirror 等价于 -r -N -l inf -nr

-p, –page-requisites 下载显示HTML文件的所有图片

递归下载中的包含和不包含(accept/reject)：

-A, –accept=LIST 分号分隔的被接受扩展名的列表

-R, –reject=LIST 分号分隔的不被接受的扩展名的列表

-D, –domains=LIST 分号分隔的被接受域的列表

–exclude-domains=LIST 分号分隔的不被接受的域的列表

–follow-ftp 跟踪HTML文档中的FTP链接

–follow-tags=LIST 分号分隔的被跟踪的HTML标签的列表

-G, –ignore-tags=LIST 分号分隔的被忽略的HTML标签的列表

-H, –span-hosts 当递归时转到外部主机

-L, –relative 仅仅跟踪相对链接

-I, –include-directories=LIST 允许目录的列表

-X, –exclude-directories=LIST 不被包含目录的列表

-np, –no-parent 不要追溯到父目录

wget -S –spider url 不下载只显示过程
* xargs（用来给命令传递参数）
xargs（英文全拼： eXtended ARGuments）是给命令传递参数的一个过滤器，也是组合多个命令的一个工具。

xargs 可以将管道或标准输入（stdin）数据转换成命令行参数，也能够从文件的输出中读取数据。

xargs 也可以将单行或多行文本输入转换为其他格式，例如多行变单行，单行变多行。

xargs 默认的命令是 echo，这意味着通过管道传递给 xargs 的输入将会包含换行和空白，不过通过 xargs 的处理，换行和空白将被空格取代。

xargs 是一个强有力的命令，它能够捕获一个命令的输出，然后传递给另外一个命令。

之所以能用到这个命令，关键是由于很多命令不支持|管道来传递参数，而日常工作中有有这个必要，所以就有了 xargs 命令，例如：
#+begin_src bash
find /sbin -perm +700 |ls -l       #这个命令是错误的
find /sbin -perm +700 |xargs ls -l   #这样才是正确的
#+END_SRC

命令格式：
somecommand |xargs -item  command
** 参数
-a file 从文件中读入作为 stdin
-e flag ，注意有的时候可能会是-E，flag必须是一个以空格分隔的标志，当xargs分析到含有flag这个标志的时候就停止。
-p 当每次执行一个argument的时候询问一次用户。
-n num 后面加次数，表示命令在执行的时候一次用的argument的个数，默认是用所有的。
-t 表示先打印命令，然后再执行。
-i 或者是-I，这得看linux支持了，将xargs的每项名称，一般是一行一行赋值给 {}，可以用 {} 代替。
-r no-run-if-empty 当xargs的输入为空的时候则停止xargs，不用再去执行了。
-s num 命令行的最大字符数，指的是 xargs 后面那个命令的最大命令行字符数。
-L num 从标准输入一次读取 num 行送给 command 命令。
-l 同 -L。
-d delim 分隔符，默认的xargs分隔符是回车，argument的分隔符是空格，这里修改的是xargs的分隔符。
-x exit的意思，主要是配合-s使用。。
-P 修改最大的进程数，默认是1，为0时候为as many as it can ，这个例子我没有想到，应该平时都用不到的吧。
-0 不仅可以将分隔符从默认的空格变成 NULL，还会将单引号、双引号、反斜线等统统默认为是普通字符
** 参数使用例子
*** -E
我们正在处理一份日志文件 country.list 中的内容，将日志文件中的字符以空行作为分隔符依次 echo 出来，一旦遇到 korea 便终止退出：
#+BEGIN_SRC bash
[roc@roclinux ~]$ echo "china usa korea japan" > country.list
 
[roc@roclinux ~]$ cat country.list
china usa korea japan
 
[roc@roclinux ~]$ cat country.list | xargs -E 'korea' echo
china usa
#+END_SRC
*** -p
#+BEGIN_SRC bash
[roc@roclinux ~]$ find . -type f |xargs -p rm -f
rm -f ./china.txt ./usa.txt ./japan.txt ?...n
#+END_SRC
*** -n
#+BEGIN_SRC bash
[roc@roclinux 20160408]$ find . -type f |xargs -p -n 1 rm -f
rm -f ./china.txt ?...n
rm -f ./usa.txt ?...y
rm -f ./japan.txt ?...n
#+END_SRC
** 与管道的区别
管道可以实现：将前面的标准输出作为后面的“标准输入”。

管道无法实现：将前面的标准输出作为后面的“命令参数”。

** 注意事项
xargs 的标准输入中出现的“换行符、空格、制表符”都将被空格取代。下面来看一个带有换行符的例子：
#+BEGIN_SRC bash
#我们准备好了带有换行的标准输入
[roc@roclinux ~]$ echo -e "china.txt\njapan.txt"
china.txt
japan.txt
 
#可见, 换行符和空格的作用一样
[roc@roclinux ~]$ echo -e "china.txt\njapan.txt" | xargs cat
hello beijing
hello tokyo
#+END_SRC
* xmodmap
First, generate the current keycode map:

xmodmap -pke > .Xmodmap

To detect what the keycode is for specific key, use command:
$ xev -event keyboard

Now save the file, and activate the key map:
$ xmodmap .Xmodmap

[[https://dev.to/0xbf/remap-keys-in-the-keyboard-in-ubuntu-5a36][Remap keys in the keyboard in Ubuntu]]
* yum
** 指定安装目录
比如安装桌面环境到/cjk/vnc下：
yum -c /etc/yum.conf --installroot=/cjk/vnc/ --releasever=/ groupinstall -y "GNOME Desktop"

-c /etc/yum.conf 表示指定yum配置文件地址（这个可有可无）
--installroot=/opt 表示指定自定义的安装目录 （这个是关键）
--releasever=/ 表示--installroot=/xxx 为安装该软件的根目录
* zsh
** 安装zsh
如果你用 Redhat Linux，执行：sudo yum install zsh

如果你用 Ubuntu Linux，执行：sudo apt-get install zsh

安装完成后设置当前用户使用 zsh：chsh -s /bin/zsh，根据提示输入当前用户的密码就可以了。
** 安装oh my zsh
安装「oh my zsh」可以自动安装也可以手动安装。

自动安装：
#+begin_src bash
wget https://github.com/robbyrussell/oh-my-zsh/raw/master/tools/install.sh -O - | sh
#+END_SRC
手动安装：
#+begin_src bash
git clone git://github.com/robbyrussell/oh-my-zsh.git ~/.oh-my-zsh
cp ~/.oh-my-zsh/templates/zshrc.zsh-template ~/.zshrc
#+END_SRC

都不复杂，安装完成之后退出当前会话重新打开一个终端窗口，你就可以见到这个彩色的提示了：

#+DOWNLOADED: screenshot @ 2021-12-11 10:24:52
[[file:images/linux笔记/zsh/2021-12-11_10-24-52_screenshot.png]]
** 启动文件顺序 
对于Zsh，其不同方式的执行顺序如下所示。【请注意，如果不存在〜/.zshrc，则zsh似乎也会读取〜/.profile】

#+DOWNLOADED: screenshot @ 2021-12-11 10:04:54
[[file:images/linux笔记/启动文件/2021-12-11_10-04-54_screenshot.png]]
** autojump安装
安装[[https://github.com/wting/autojump][autojump官网]]的安装方式，先安装autojump
#+begin_src bash
# 下载插件autojump到/.oh-my-zsh/custom目录中
git clone https://gitee.com/null_454_5218/autojump.git
# 解压缩后进入目录，执行install.py
./install.py
#+END_SRC
配置zshrc文件
#+begin_src bash
vi ~/.zshrc
#在配置结尾处或者参考上面处添加此行命令
plugins=(
  git
  zsh-autosuggestions
  autojump
)
#+END_SRC

除了还要在~/.zshrc中配置plugins，还要将下面这句写到zshrc文件中：
#+begin_src bash
[[ -s ~/.autojump/etc/profile.d/autojump.sh ]] && . ~/.autojump/etc/profile.d/autojump.sh
#+END_SRC
*** 参考文章
[[https://zhuanlan.zhihu.com/p/19556676][终极 Shell——ZSH]]
[[https://my.oschina.net/u/4264517/blog/4522246][搞机： oh-my-zsh + autojump + screen 让你的终端起飞]]
** 参考文章
[[https://zhuanlan.zhihu.com/p/19556676][终极 Shell——ZSH]]
* 统计文件个数
统计当前文件夹下文件的个数，包括子文件夹里的
#+BEGIN_SRC bash
ls -lR|grep "^-"|wc -l
#+END_SRC
统计文件夹下目录的个数，包括子文件夹里的
#+BEGIN_SRC bash
ls -lR|grep "^d"|wc -l
#+END_SRC
统计当前文件夹下文件的个数
#+BEGIN_SRC bash
ls -l |grep "^-"|wc -l
#+END_SRC
统计当前文件夹下目录的个数
#+BEGIN_SRC bash
ls -l |grep "^d"|wc -l
#+END_SRC
附：
统计输出信息的行数
#+BEGIN_SRC bash
wc -l
#+END_SRC
将长列表输出信息过滤一部分，只保留一般文件，如果只保留目录就是 ^d
#+BEGIN_SRC bash
grep "^-"
#+END_SRC
* 查看GPU使用情况
Nvidia自带了一个nvidia-smi的命令行工具，会显示显存使用情况：
#+BEGIN_SRC bash
>>>nvidia-smi
#+END_SRC
nvidia-smi是nvidia 的系统管理界面 ，其中smi是System management interface的缩写，它可以收集各种级别的信息，查看显存使用情况。此外, 可以启用和禁用 GPU 配置选项 (如 ECC 内存功能)。
** 常用的Nvidia-smi指令
*** nvidia-smi
【功能】 显示出当前GPU的所有基础信息。

#+DOWNLOADED: file:E:/org/图片/Snipaste_2021-11-22_09-36-20.png @ 2021-11-22 09:36:35
[[file:查看GPU使用情况/2021-11-22_09-36-35_Snipaste_2021-11-22_09-36-20.png]]

解释相关参数含义：
- GPU：本机中的GPU编号
- Name：GPU 类型
- Persistence-M：
- Fan：风扇转速
- Temp：温度，单位摄氏度
- Perf：表征性能状态，从P0到P12，P0表示最大性能，P12表示状态最小性能
- Pwr:Usage/Cap：能耗表示
- Bus-Id：涉及GPU总线的相关信息；
- Disp.A：Display Active，表示GPU的显示是否初始化
- Memory-Usage：显存使用率
- Volatile GPU-Util：浮动的GPU利用率
- Uncorr. ECC：关于ECC的东西
- Compute M.：计算模式
- Processes 显示每块GPU上每个进程所使用的显存情况。
*** nvidia-smi -L 命令
【功能】 列出所有可用的 NVIDIA 设备

#+DOWNLOADED: file:E:/org/图片/Snipaste_2021-11-22_09-37-45.png @ 2021-11-22 09:37:49
[[file:查看GPU使用情况/2021-11-22_09-37-49_Snipaste_2021-11-22_09-37-45.png]]
*** nvidia-smi topo --matrix 命令
【功能】查看系统拓扑

【说明】 要正确地利用更先进的 NVIDIA GPU 功能 (如 GPUDirect)，使用系统拓扑正确配置往往是至关重要的。该拓扑指的是 PCI Express 设备 (GPUs, InfiniBand HCAs, storage controllers, 等) 如何互相连接以及如何连接到系统的CPU。如果使用不正确的拓扑, 某些功能可能会减慢甚至停止工作

#+DOWNLOADED: file:E:/org/图片/Snipaste_2021-11-22_09-38-18.png @ 2021-11-22 09:38:23
[[file:查看GPU使用情况/2021-11-22_09-38-23_Snipaste_2021-11-22_09-38-18.png]]
*** nvidia-smi -q -d CLOCK 命令
【功能】查看当前的 GPU 时钟速度、默认时钟速度和最大可能的时钟速度

#+DOWNLOADED: file:E:/org/图片/Snipaste_2021-11-22_09-38-47.png @ 2021-11-22 09:38:52
[[file:查看GPU使用情况/2021-11-22_09-38-52_Snipaste_2021-11-22_09-38-47.png]]
*** nvidia-smi -q -d SUPPORTED_CLOCKS 
【功能】显示每个 GPU 的可用时钟速度列表

#+DOWNLOADED: file:E:/org/图片/Snipaste_2021-11-22_09-39-20.png @ 2021-11-22 09:39:25
[[file:查看GPU使用情况/2021-11-22_09-39-25_Snipaste_2021-11-22_09-39-20.png]]
*** nvidia-smi vgpu
【功能】 查看当前vGPU的状态信息：
#+DOWNLOADED: file:E:/org/图片/Snipaste_2021-11-22_09-39-47.png @ 2021-11-22 09:39:52
[[file:查看GPU使用情况/2021-11-22_09-39-52_Snipaste_2021-11-22_09-39-47.png]]

【补充说明】 虚拟图形处理单元（vGPU）是在虚拟桌面上渲染图形的一个组件。倘若没有此组件，显示如下：

#+DOWNLOADED: file:E:/org/图片/Snipaste_2021-11-22_09-40-08.png @ 2021-11-22 09:40:12
[[file:查看GPU使用情况/2021-11-22_09-40-12_Snipaste_2021-11-22_09-40-08.png]]
*** nvidia-smi vgpu -p 
【功能】循环显示虚拟桌面中应用程序对GPU资源的占用情况

#+DOWNLOADED: file:E:/org/图片/Snipaste_2021-11-22_09-40-41.png @ 2021-11-22 09:40:47
[[file:查看GPU使用情况/2021-11-22_09-40-47_Snipaste_2021-11-22_09-40-41.png]]
*** nvidia-smi -q
【功能】 查看当前所有GPU的信息，也可以通过参数i指定具体的GPU。
#+DOWNLOADED: file:E:/org/图片/Snipaste_2021-11-22_09-41-04.png @ 2021-11-22 09:41:09
[[file:查看GPU使用情况/2021-11-22_09-41-09_Snipaste_2021-11-22_09-41-04.png]]

#+DOWNLOADED: file:E:/org/图片/Snipaste_2021-11-22_09-41-31.png @ 2021-11-22 09:41:36
[[file:查看GPU使用情况/2021-11-22_09-41-36_Snipaste_2021-11-22_09-41-31.png]]

通过nvidia-smi -q 我们可以获取以下有用的信息：
- 系统中的GPU的基本信息
- GPU的SN号、VBIOS、PN号等信息：
- GPU的总线、PCI-E总线倍速、风扇转速等信息：
- 补充： PCI是Peripheral Component Interconnect(外设部件互连标准)的缩写，它是目前个人电脑中使用最为广泛的接口，几乎所有的主板产品上都带有这种插槽。


#+DOWNLOADED: file:E:/org/图片/Snipaste_2021-11-22_09-42-08.png @ 2021-11-22 09:42:13
[[file:查看GPU使用情况/2021-11-22_09-42-13_Snipaste_2021-11-22_09-42-08.png]]

GPU的显存、BAR1、所有资源利用率、ECC模式等信息：

#+DOWNLOADED: file:E:/org/图片/Snipaste_2021-11-22_09-42-27.png @ 2021-11-22 09:42:32
[[file:查看GPU使用情况/2021-11-22_09-42-32_Snipaste_2021-11-22_09-42-27.png]]
*** 参考文章
[[https://blog.csdn.net/C_chuxin/article/details/82993350][Nvidia-smi简介及常用指令及其参数说明]]
* 解压缩命令
#+BEGIN_SRC bash
#压缩
tar -jcv -f filename.tar.bz2 要被压缩的文件或目录名称
#查询
tar -jtv -f filename.tar.bz2
#解压缩
tar -jxv -f filename.tar.bz2 -C 欲解压缩的目录
#+END_SRC

* 搭建c语言环境
** gcc和g++的区别
gcc 最开始的时候是 GNU C Compiler, 如你所知，就是一个c编译器。但是后来因为这个项目里边集成了更多其他不同语言的编译器，GCC就代表 the GNU Compiler Collection，所以表示一堆编译器的合集。

g++则是GCC的c++编译器。现在你在编译代码时调用的gcc，已经不是当初那个c语言编译器了，更确切的说他是一个驱动程序，根据代码的后缀名来判断调用c编译器还是c++编译器 (g++)。比如你的代码后缀是*.c，他会调用c编译器还有linker去链接c的library。如果你的代码后缀是cpp, 他会调用g++编译器，当然library call也是c++版本的。
** 安装gcc和g++
#+BEGIN_SRC bash
sudo apt-get install gcc
sudo apt-get install gcc
#+END_SRC
* 设置合上笔记本盖子不休眠的方法
编辑下列文件：sudo gedit /etc/systemd/logind.conf
#+BEGIN_EXAMPLE
#HandlePowerKey按下电源键后的行为，默认power off
#HandleSleepKey 按下挂起键后的行为，默认suspend
#HandleHibernateKey按下休眠键后的行为，默认hibernate
#HandleLidSwitch合上笔记本盖后的行为，默认suspend（改为ignore；即合盖不休眠）在原文件中，还要去掉前面的#
#+END_EXAMPLE
最后重启服务

service systemd-logind restart
* 设置默认启动方式（图形界面或命令行界面）
在root用户权限下：

查看当前启动模式

systemctl get-default

更改模式命令：

systemctl set-default graphical.target由命令行模式更改为图形界面模式

systemctl set-default multi-user.target由图形界面模式更改为命令行模式

跟以前使用的linux版本一样，编辑 vi /etc/inittab 文件，修改系统初始化方式
* 设置Linux在未登录账号情况下自动连接wifi
期望机器能在通电进入系统后，即使没有登录账号也能自动连接wifi。可以使用Linux的网络管理工具的命令：

nmctl device wifi connect [ssid wifi名字] password [wifi密码]

* 查看Linux系统架构类型的方法
** uname 命令
uname -a 命令可以直接显示 Linux 系统架构的命令，安几乎可以工作在所有 Linux/Unix 系统当中。

#+DOWNLOADED: file:E:/org/图片/Snipaste_2021-11-22_16-26-12.png @ 2021-11-22 16:26:17
[[file:查看Linux系统架构类型的方法/2021-11-22_16-26-17_Snipaste_2021-11-22_16-26-12.png]]
** dpkg 命令
dpkg 的命令可用于查看 Debian/ Ubuntu 操作系统是 32 位还是 64 位，此命令只适用于基于 Debian 和 Ubuntu 的 Linux 发行版。

在终端中执行如下命令：
#+begin_src bash
dpkg --print-architecture
#+END_SRC

如果当前 Linux 是 64 位则输出 amd64，是 32 位则会输出 i386。
** getconf 命令
getconf 命令主要用于显示系统变量配置，我们也可使用如下参数来查看 Linux 系统架构：
#+begin_src bash
getconf LONG_BIT
#+END_SRC
** arch 命令
arch 命令主要用于显示操作系统架构类型，与 uname -m 命令非常类似。如果输出 x86_64 则表示为 64 位系统，如果输出 i686 或 i386 则表示为 32 位系统。

#+DOWNLOADED: file:E:/org/图片/Snipaste_2021-11-22_16-27-10.png @ 2021-11-22 16:27:15
[[file:查看Linux系统架构类型的方法/2021-11-22_16-27-14_Snipaste_2021-11-22_16-27-10.png]]
** file 命令
file 命令可以配合 /sbin/init 这个特殊参数来查看系统架构类型（/sbin/init 在 Ubuntu 15.10 里面是链接到 /lib/systemd/systemd 的）：
#+begin_src bash
file /sbin/init
#+END_SRC

#+DOWNLOADED: file:E:/org/图片/Snipaste_2021-11-22_16-27-37.png @ 2021-11-22 16:27:42
[[file:查看Linux系统架构类型的方法/2021-11-22_16-27-42_Snipaste_2021-11-22_16-27-37.png]]

** 参考文章
[[https://www.sysgeek.cn/find-out-linux-system-32-or-64-bit/][查看Linux系统架构类型的5条常用命令]]
* 启动文件
** bash
bash检查的启动文件取决于你启动bash shell的方式。启动bash shell有3种方式：
- 登录时作为默认登录shell
- 作为非登录shell的交互式shell
- 作为运行脚本的非交互shell

对于Bash，它们的工作方式如下。读取适当的列。执行A，然后执行B，然后执行C，依此类推。B1，B2，B3表示仅执行找到的那些文件中的第一个。

#+DOWNLOADED: screenshot @ 2021-12-11 10:03:53
[[file:images/linux笔记/启动文件/2021-12-11_10-03-53_screenshot.png]]

*** 登录shell
 当你登录Linux系统时，bash shell会作为登录shell启动。登录shell会从5个不同的启动文件里读取命令：
 - /etc/profile
 - $HOME/.bash_profile
 - $HOME/.bashrc
 - $HOME/.bash_login
 - $HOME/.profile

 /etc/profile文件是系统上默认的bash shell的主启动文件。系统上的每个用户登录时都会执行这个启动文件

 /etc/profile里的for循环会迭代/etc/profile.d目录下的所有文件。

 $HOME目录下的启动文件都起着同一个作用：提供一个用户专属的启动文件来定义该用户所用到的环境变量。大多数Linux发行版只用这四个启动文件中的一到两个：
 - $HOME/.bash_profile
 - $HOME/.bashrc
 - $HOME/.bash_login
 - $HOME/.profile

 shell会按照按照下列顺序，运行第一个被找到的文件，余下的则被忽略：
 - $HOME/.bash_profile
 - $HOME/.bash_login
 - $HOME/.profile

 注意，这个列表中并没有$HOME/.bashrc文件。这是因为该文件通常通过其他文件运行的。
*** 交互式 shell 进程
 如果你的bash shell不是登录系统时启动的（比如是在命令行提示符下敲入bash时启动），那么你启动的shell叫作交互式shell。

 如果bash是作为交互式shell启动的，它就不会访问/etc/profile文件，只会检查用户HOME目录中的.bashrc文件。
*** 非交互式 shell
 系统执行shell脚本时用的就是非交互式shell。它没有命令行提示符。

 当shell启动一个非交互式shell进程时，它会检查环境变量BASH_ENV来查看要执行的启动文件。如果有指定的文件，shell会执行该文件里的命令，这通常包括shell脚本变量设置
** zsh 
对于Zsh，其不同方式的执行顺序如下所示。【请注意，如果不存在〜/.zshrc，则zsh似乎也会读取〜/.profile】

#+DOWNLOADED: screenshot @ 2021-12-11 10:04:54
[[file:images/linux笔记/启动文件/2021-12-11_10-04-54_screenshot.png]]

** 参考文章
[[https://www.xth8013.com/website/blogArticle/detail/163][Bash/Zsh启动文件加载顺序]]

* 修改某用户默认shell
** 临时修改shell
我们可以对当前使用的shell进行改变，直接调用不同sheel名称进入到shell环境中去。

使用命令cat /etc/shells得到当前系统支持的shell环境。

使用echo $SHELL可得到当前的shell环境。
** 修改用户默认的shel
在linux系统的/etc/passwd文件内是保存系统内所有用户和用户的设置。

对某用户的默认设置也在这里。

可以使用chsh命令修改某用户的默认shell：
#+begin_src bash
merle@bogon ~ $ chsh                                                                                                                
Changing shell for merle.
New shell [/bin/bash]: /bin/zsh
密码：
Shell changed.

# 再次查看该用户设置
merle@bogon ~ $ grep merle /etc/passwd                                                                                               
merle:x:1000:1000:merle:/home/merle:/bin/zsh    
#+END_SRC
也可以使用usermod命令：
#+begin_src bash
usermod -s /bin/zsh merle

# 再次查看该用户设置
merle@bogon ~ $ grep merle /etc/passwd                                                                                               
merle:x:1000:1000:merle:/home/merle:/bin/zsh    
#+END_SRC
* 解决 Windows 传入 linux 出现的 ^M 问题
通过查询得知，其问题根源是windows和linux换行符不同造成，二者区别如下表（外加了mac book）

|        | windows | linux | MacBook |
|--------+---------+-------+---------|
| 换行符 | \r\n    | \n    | \r      |
| ASCII  | 0x0d0a  | 0x0a  | 0x0d    |

其中：
- "\r"在ASCII中表示“换行（LF）”
- "\n"在ASCII中表示“回车（CR）”

Dos、Windows 格式的文件，用 0D 0A (CR+LF)作为换行符，而Unix 的则是以0A(LF) 作为换行符，所以dos 底下的文本文件到了unix的话，换行符就会多出来一个 0D(CR) 显示为 ^M

解决方法如下：

1. 使用命令dos2unix对文件进行转换

2. 使用vi的替换功能。启动vi，进入命令模式，输入以下命令:
#+BEGIN_EXAMPLE
:%s/^M$//g         # 去掉行尾的^M,注意^M 不是shift ^ +M 而是ctrl+v 加上ctrl+m,此命令必须是手动打上，不可复制
:%s/^M//g          # 去掉所有的^M
:%s/^M/[ctrl-v]+[enter]/g        # 将^M替换成回车
:%s/^M/\r/g                      # 将^M替换成回车
#+END_EXAMPLE

3. 使用sed命令：
#+begin_src bash
$ sed -e‘s/^M/\n/g’upgrade.sh
#+END_SRC
* X11转发
** X 协议原理简介
#+DOWNLOADED: screenshot @ 2022-03-05 12:48:01
[[file:images/linux笔记/X11转发/2022-03-05_12-48-01_screenshot.png]]

Linux 本身是没有图形化界面的，所谓的图形化界面系统只不过中 Linux 下的应用程序。这一点和 Windows 不一样。Windows 从 Windows 95 开始，图形界面就直接在系统内核中实现了，是操作系统不可或缺的一部分。Linux 的图形化界面，底层都是基于 X 协议。

X 协议由 X server 和 X client 组成：

X server 管理主机上与显示相关的硬件设置（如显卡、硬盘、鼠标等），它负责屏幕画面的绘制与显示，以及将输入设置（如键盘、鼠标）的动作告知 X client。

X client (即 X 应用程序) 则主要负责事件的处理（即程序的逻辑）。

举个例子，如果用户点击了鼠标左键，因为鼠标归 X server 管理，于是 X server 就捕捉到了鼠标点击这个动作，然后它将这个动作告诉 X client，因为 X client 负责程序逻辑，于是 X client 就根据程序预先设定的逻辑（例如画一个圆），告诉 X server 说：“请在鼠标点击的位置，画一个圆”。最后，X server 就响应 X client 的请求，在鼠标点击的位置，绘制并显示出一个圆。

** 服务器x（X client）设置
首先要确保服务器的sshd打开X11转发功能

打开 /etc/sshd_config 确保下面的配置设置正确：
#+begin_src bash
X11Forwarding yes
X11DisplayOffset 10
X11UseLocalhost no
#+END_SRC
然后重启ssh服务：
#+begin_src bash
# If you are using CentOS 7, you should use
systemctl restart sshd.service
# If you are on CentOS 6, you should use the following command instead:
service sshd restart
#+END_SRC
** X server设置
*** widows下git bash的设置
**** 安装X server
***** windows
 安装vcxsrv
 #+BEGIN_EXAMPLE
 In order to use X11 forwarding, you also need to install a X server on your Windows computer. You can choose to install xming or vcxsrv. Vcxsrv is better since it is updated frequently and is free, while latest version of xming requires a license. 
 #+END_EXAMPLE
 之后打开xlaunch启动vcxsrv

 #+DOWNLOADED: screenshot @ 2021-12-12 23:00:43
 [[file:images/linux%E7%AC%94%E8%AE%B0/%E8%AE%BE%E7%BD%AEX11%E8%BD%AC%E5%8F%91/2021-12-12_23-00-43_screenshot.png]]
**** 配置ssh
 在git bash上设置变量DISPLAY：
 #+begin_src bash
 export DISPLAY=localhost:0.0
 #+END_SRC
 可以将该设置添加到用户目录下的.bash_profile文件里，这样以后每次连接服务器就会自动设置好该变量。

 使用带-X选项的ssh连接：
 #+begin_src bash
 # -v选项可以显示连接的详细信息
 ssh -X -v <user>@<server_addresss>
 #+END_SRC
 这里可能会出现下面的警告：
 #+BEGIN_EXAMPLE
 Warning: untrusted X11 forwarding setup failed: xauth key data not generated
 #+END_EXAMPLE
 如果这时候打开GUI程序，比如xclock，将会出现下面的报错：
 #+BEGIN_EXAMPLE
 Error: Can’t open display:
 #+END_EXAMPLE
 如果出现该错误，则选择用带-Y选项的ssh连接：
 #+begin_src bash
 ssh -Y -v <user>@<server_addresss>
 #+END_SRC
 运行下面的命令：
 #+begin_src bash
 xclock &
 #+END_SRC
 可以看到下面的图像：
 #+DOWNLOADED: screenshot @ 2021-12-12 23:07:10
 [[file:images/linux%E7%AC%94%E8%AE%B0/%E8%AE%BE%E7%BD%AEX11%E8%BD%AC%E5%8F%91/2021-12-12_23-07-10_screenshot.png]]

*** linux的设置
sudo vim /etc/ssh/ssh_config  修改以下配置，保存退出。
#+begin_src bash
ForwardAgent yes
ForwardX11 yes
ForwardX11Trusted yes
#+END_SRC
客服端修改完成后也需要执行对应的命令重启ssh服务
#+begin_src bash
sudo systemctl restart ssh.service
#+END_SRC
在客服端C 上执行命令
#+begin_src bash
xhost +　　//允许服务器的的x11界面连接过来
ssh -X tsfh@192.168.0.200　　　　　　//-X参数表示转发X11数据， 把用户名称tsfh 以及服务器S的ip地址替换为你自己的
#+END_SRC
现在你已经登陆了服务器，而且还有一个终端是连接的状态，和平时ssh连接没有什么区别，除了会转发X11的数据，你可以在终端里面用命令运行你想要运行的gui程序比如：firefox , google-chrome , xclock

现在我以xclock为例演示一下, xclock程序会显示一个图形时钟
#+begin_src bash
xclock
#+END_SRC
等待一小会儿 你就可以在客服端C 的桌面上看到服务器S 的xclock了

** termux设置方法
先安装VNC Viewer
*** Enabling the X11 Repository
X11 packages are available in a separate APT repository. You can enable it by running the following command:
#+begin_src bash
pkg install x11-repo
#+END_SRC
It will automatically add appropriate sources.list file and PGP key.

To disable this repository, you need to uninstall package x11-repo.
*** Setting up VNC
Server
If you decided to use VNC for graphical output, follow these instructions for properly setting up VNC server.

1. Install package `tigervnc`:
#+begin_src bash
pkg install tigervnc
#+END_SRC
2. After installation, execute this:
#+begin_src bash
vncserver -localhost
#+END_SRC
At first time, you will be prompted for setting up passwords:

You will require a password to access your desktops.
#+begin_src bash
Password:
Verify:
Would you like to enter a view-only password (y/n)? n
#+END_SRC
Note that passwords are not visible when you are typing them and maximal password length is 8 characters.

3. If everything is okay, you will see this message:
#+begin_src bash
New 'localhost:1 ()' desktop is localhost:1

Creating default startup script /data/data/com.termux/files/home/.vnc/xstartup
Creating default config /data/data/com.termux/files/home/.vnc/config
Starting applications specified in /data/data/com.termux/files/home/.vnc/xstartup
Log file is /data/data/com.termux/files/home/.vnc/localhost:1.log
#+END_SRC
It means that X (vnc) server is available on display 'localhost:1'.

4. Finally, to make programs do graphical output to the display 'localhost:1', set environment variable like shown here (yes, without specifying 'localhost'):
#+begin_src bash
export DISPLAY=":1"
#+END_SRC
You may even put this variable to your bashrc or profile so you don't have to always set it manually unless display address will be changed.
*** Client
Here will be assumed that you use this Android VNC client: VNC Viewer (developed by RealVNC Limited).

1. Determine port number on which VNC server listens. It can be calculated like this: 5900 + {display number}. So for display 'localhost:1' the port will be 5901.

2. Now open the VNC Viewer application and create a new connection with the following information (assuming that VNC port is 5901):
#+BEGIN_EXAMPLE
Address:
127.0.0.1:5901

Name:
Termux
#+END_EXAMPLE

#+DOWNLOADED: screenshot @ 2021-12-12 23:11:40
[[file:images/linux笔记/设置X11转发/2021-12-12_23-11-40_screenshot.png]]

If you are using VNC client on a computer using the same network as the phone does, make sure you correctly start a VNC session and know the IP address of the device.

3. Now launch it. You will be prompted for password that you entered on first launch of 'vncserver'. Depending on packages you installed, you may see either entirely black screen or terminal prompt (only if 'aterm' is installed).
*** 参考文章
[[https://wiki.termux.com/wiki/Graphical_Environment#Enabling_the_X11_Repository][Graphical Environment]]
** 参考文章
[[https://jdhao.github.io/2018/03/02/Windows-connect-server-x11-with-gitbash/][Set up X11 Forwarding with Git for Windows (git-bash)]]
[[https://www.cnblogs.com/tsfh/p/9022170.html][通过ssh X11转发使用远程gui程序]]
[[https://www.jianshu.com/p/1a296191a122][什么是X11-forwarding？怎么使用？]]
* 端口
** 介绍
传输层协议，如传输控制协议（TCP）与用户资料包协议（UDP），在分组表头中，定义了来源端口号与目的端口号。

一个端口号使用16位无符号整数（unsigned integer）来表示，其范围介于0与65535之间：
- 在TCP协议中，端口号0是被保留的，不可使用。
- 1--1023 系统保留，只能由root用户使用。
- 1024---4999 由客户端程序自由分配。
- 5000---65535 由服务器端程序自由分配在UDP协议中，来源端口号是可以选择要不要填上，如果设为0，则代表没有来源端口号。

在操作系统中，一个行程可以通过网络套接字将它的输入与输出与一个特定的传输协议、一个端口、一个IP地址关系起来。这个关系动作，称为綁定（binding），在这之后，就可以通过网络提交与接收资料。

在操作系统上运行的网络软件，可以透过操作系统，利用各个不同的端口，将资料发送到网络上；操作系统也可以根据数据包的IP地址以及端口号，将这些数据包转送到符合的行程去。

虽然使用同样传输协议，但是特定的IP地址以及端口的组合，只会被綁定到单一的特定行程上。当使用同样协议的多个程序，尝试着綁定在同一个IP地址下的相同端口，就会产生一个常见的应用程序错误，这个错误有时候被称为端口冲突（port conflicts）。
** Linux 查看端口占用情况
 Linux 查看端口占用情况可以使用 lsof 和 netstat 命令。
*** lsof
 lsof(list open files)是一个列出当前系统打开文件的工具。

 lsof 查看端口占用语法格式：
 #+BEGIN_EXAMPLE
 lsof -i:端口号
 #+END_EXAMPLE

**** 实例
 查看服务器 8000 端口的占用情况：
 #+begin_src bash
 /:lsof -i:8000

 COMMAND   PID USER   FD   TYPE   DEVICE SIZE/OFF NODE NAME
 nodejs  26993 root   10u  IPv4 37999514      0t0  TCP *:8000 (LISTEN)
 #+END_SRC
 可以看到 8000 端口已经被轻 nodejs 服务占用。

 lsof -i 需要 root 用户的权限来执行，如下图：
 #+DOWNLOADED: file:E%3A/org/%E5%9B%BE%E7%89%87/Snipaste_2021-09-03_15-42-19.png @ 2021-09-03 16:14:42
 [[file:Linux_%E6%9F%A5%E7%9C%8B%E7%AB%AF%E5%8F%A3%E5%8D%A0%E7%94%A8%E6%83%85%E5%86%B5/2021-09-03_16-14-42_Snipaste_2021-09-03_15-42-19.png]]
 更多 lsof 的命令如下：
 #+begin_src bash
 lsof -i:8080：查看8080端口占用
 lsof abc.txt：显示开启文件abc.txt的进程
 lsof -c abc：显示abc进程现在打开的文件
 lsof -c -p 1234：列出进程号为1234的进程所打开的文件
 lsof -g gid：显示归属gid的进程情况
 lsof +d /usr/local/：显示目录下被进程开启的文件
 lsof +D /usr/local/：同上，但是会搜索目录下的目录，时间较长
 lsof -d 4：显示使用fd为4的进程
 lsof -i -U：显示所有打开的端口和UNIX domain文件
 #+END_SRC

*** netstat
 netstat -tunlp 用于显示 tcp，udp 的端口和进程等相关情况。

 netstat 查看端口占用语法格式：
 #+begin_src bash
 netstat -tunlp | grep 端口号
 #+END_SRC
 -t (tcp) 仅显示tcp相关选项
 -u (udp)仅显示udp相关选项
 -n 拒绝显示别名，能显示数字的全部转化为数字
 -l 仅列出在Listen(监听)的服务状态
 -p 显示建立相关链接的程序名

 例如查看 8000 端口的情况，使用以下命令：
 #+begin_src bash
 /:netstat -tunlp | grep 8000
 tcp        0      0 0.0.0.0:8000            0.0.0.0:*               LISTEN      26993/nodejs   
 #+END_SRC
 更多命令：
 #+begin_src bash
 netstat -ntlp   //查看当前所有tcp端口
 netstat -ntulp | grep 80   //查看所有80端口使用情况
 netstat -ntulp | grep 3306   //查看所有3306端口使用情况
 #+END_SRC
* 挂载iso
mount命令允许你将 ISO 文件挂载到文件夹中的某个指定的挂载点。

本节内容的指定，应该可以在任何 Linux 发行版上正常运行，包括 Ubuntu, Debian, 和 CentOS。

01.开始创建挂载点，它可以是你想要的任何位置：
#+begin_src bash
sudo mkdir /media/iso
#+END_SRC

02.通过mount命令将 ISO 文件挂载到挂载点。
#+begin_src bash
sudo mount /path/to/image.iso /media/iso -o loop
#+END_SRC

这里很重要的一点是-o loop选项。它告诉命令将指定 ISO 文件映射成一个回环设备，并且将这个设备挂载到指定的挂载点。

不要忘记将/path/to/image.iso替换成你自己的 ISO 文件路径。

03.查看 ISO 镜像内容，请使用ls命令
#+begin_src bash
ls /media/iso
#+END_SRC

你也可以在一个文件管理器中，直接打开并浏览 ISO 镜像里面的具体内容。

04.当镜像挂载后，通过umount命令后面加上挂载目录，就可以卸载 ISO 文件。
#+begin_src bash
sudo umount /media/iso
#+END_SRC

如果此时文件系统正在使用中，那么umount将会卸载失败。
* loop设备
什么是loop设备？
loop设备是一种伪设备，是使用文件来模拟块设备的一种技术，文件模拟成块设备后, 就像一个磁盘或光盘一样使用。在使用之前，一个 loop 设备必须要和一个文件进行连接。这种结合方式给用户提供了一个替代块特殊文件的接口。因此，如果这个文件包含有一个完整的文件系统，那么这个文件就可以像一个磁盘设备一样被 mount 起来。之所以叫loop设备（回环），其实是从文件系统这一层来考虑的，因为这种被 mount 起来的镜像文件它本身也包含有文件系统，通过loop设备把它mount起来，它就像是文件系统之上再绕了一圈的文件系统，所以称为 loop。

loop设备的使用
一般在linux中会有8个loop设备，一般是/dev/loop0~loop7，可用通过losetup -a查看所有的loop设备，如果命令没有输出就说明所有的loop设备都没有被占用，你可以按照以下步骤创建自己的loop设备。

1）创建一个文件
dd if=/dev/zero of=/var/loop.img bs=1M count=10240

2）使用losetup将文件转化为块设备
losetup /dev/loop0 /var/loop.img

3）通过lsblk查看刚刚创建的块设备
lsblk |grep loop0
losetup -a

4）当然，你也可以将这个块设备格式化并创建其他的文件系统，然后再mount到某个目录，有点多余啊，一般人不这么干。

5）要删除这个loop设备可以执行以下命令
losetup -d /dev/loop0

作者：ppdjs
链接：https://www.jianshu.com/p/add423a1f01f
来源：简书
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。
* TexLive安装
这里以 Ubunt 18.04 LTS 版为例子进行讲解，首先下载镜像文件。然后挂载镜像，或者解压之后进入文件夹。

以root用户执行下面的命令：
#+begin_src bash
./install-tl
#+END_SRC
这会启动安装进程，如果是 GUI 模式，可以用鼠标点，如果是命令行，命令行会询问你是否安装，根据提示，输入大写的 I 就可以进行自动安装了。

安装过程大概有 12 到 30 分钟，具体的时间视情况而定，带有固态硬盘的电脑可能会快一点。整个过程中，有 3700 左右个包需要安装，请耐心等待。

配置环境变量。 安装完成之后，你需要配置一下环境变量，具体操作(注意，现在还是 root 用户)：
#+begin_src bash
echo "export MANPATH=${MANPATH}:/usr/local/texlive/2019/texmf-dist/doc/man" >> ~/.bashrc
echo "export INFOPATH=${INFOPATH}:/usr/local/texlive/2019/texmf-dist/doc/info" >> ~/.bashrc
echo "export PATH=${PATH}:/usr/local/texlive/2019/bin/x86_64-linux" >> ~/.bashrc
#+END_SRC
以上三句命令就是让系统识别 manual 手册、info 手册以及最最重要的 tex 的编译器所在位置。如果不配置上述三句话，那么你将无法使用texlive。

因为你一般是在普通用户下使用 TeX Live，所以还需要切换到普通用户下，配置一下环境变量。运行以下命令。

在当前终端中，输入 Ctrl + D，退出 root 身份。

在当前终端下，输入以下命令 (这几个命令和上面是一模一样的)：
#+begin_src bash
echo "export MANPATH=${MANPATH}:/usr/local/texlive/2019/texmf-dist/doc/man" >> ~/.bashrc
echo "export INFOPATH=${INFOPATH}:/usr/local/texlive/2019/texmf-dist/doc/info" >> ~/.bashrc
echo "export PATH=${PATH}:/usr/local/texlive/2019/bin/x86_64-linux" >> ~/.bashrc
source ~/.bashrc # 令 bashrc 生效
#+END_SRC
到此就结束了。
* 修改主机名
使用hostname命令就可以查看Linux的主机名

可以使用如下命令来修改主机名

hostnamectl set-hostname eaglezsx

也可以修改其配置文件/etc/hostname里边的内容
* 设置本地域名解析
在/etc/hosts文件中添加一句话
#+BEGIN_EXAMPLE
192.168.188.1 www.baidu.com
#+END_EXAMPLE

保存文件后再ping一下www.baidu.com就会连接到192.168.188.1了

每一行为一条记录，分成两部分，第一部分是IP，第二部分是域名。
- 一个IP后面可以跟多个域名，可以是几十个甚至上百个
- 每一行只能有一个IP，也就是说一个域名不能对应多个IP
- 如果有多行中出现相同的域名（对应的ip不一样），会按最前面的记录来解析
* gitee.com无法访问的临时解决方案
首先是否ping通: ping gitee.com

如果无法ping，则用临时解决方案：

修改/etc/hosts，添加 153.3.137.123 gitee.com

这个原因大概率是停止域名解析了。所以可以写死ip地址来进行访问
* 静态库和动态库
** 什么是库
库是写好的现有的，成熟的，可以复用的代码。现实中每个程序都要依赖很多基础的底层库，不可能每个人的代码都从零开始，因此库的存在意义非同寻常。

本质上来说库是一种可执行代码的二进制形式，可以被操作系统载入内存执行。

库有两种：静态库（.a、.lib）和动态库（.so、.dll）。

所谓静态、动态是指链接。回顾一下，将一个程序编译成可执行程序的步骤：

#+DOWNLOADED: screenshot @ 2022-05-16 16:39:28
[[file:images/linux笔记/静态库和动态库/2022-05-16_16-39-28_screenshot.png]]
** 静态库
之所以成为【静态库】，是因为在链接阶段，会将汇编生成的目标文件.o与引用到的库一起链接打包到可执行文件中。
因此对应的链接方式称为静态链接。

试想一下，静态库与汇编生成的目标文件一起链接为可执行文件，那么静态库必定跟.o文件格式相似。
其实一个静态库可以简单看成是一组目标文件（.o/.obj文件）的集合，即很多目标文件经过压缩打包后形成的一个文件。
静态库特点总结：
1. 静态库对函数库的链接是放在编译时期完成的。
2. 程序在运行时与函数库再无瓜葛，移植方便。
3. 浪费空间和资源，因为所有相关的目标文件与牵涉到的函数库被链接合成一个可执行文件。

Linux下使用ar工具、Windows下vs使用lib.exe，将目标文件压缩到一起，并且对其进行编号和索引，以便于查找和检索。

一般创建静态库的步骤如图所示：

#+DOWNLOADED: screenshot @ 2022-05-16 16:41:13
[[file:images/linux笔记/静态库和动态库/2022-05-16_16-41-13_screenshot.png]]
*** Linux下创建与使用静态库
下面编写一些简单的四则运算C++类，将其编译成静态库给他人用，头文件如下所示：

StaticMath.h头文件
#+begin_src bash
#pragma once
class StaticMath
{
public:
    StaticMath(void);
    ~StaticMath(void);
 
    static double add(double a, double b);//加法
    static double sub(double a, double b);//减法
    static double mul(double a, double b);//乘法
    static double div(double a, double b);//除法
    void print();
};
#+END_SRC

**** Linux静态库命名规则
Linux静态库命名规范，必须是"lib[your_library_name].a"：lib为前缀，中间是静态库名，扩展名为.a。
**** 创建静态库（.a）
Linux创建静态库过程如下：

首先，将代码文件编译成目标文件.o（StaticMath.o）
#+begin_src bash
g++ -c StaticMath.cpp
#+END_SRC
注意带参数-c，否则直接编译为可执行文件

然后，通过ar工具将目标文件打包成.a静态库文件
#+begin_src bash
ar -crv libstaticmath.a StaticMath.o
#+END_SRC
生成静态库libstaticmath.a。

#+DOWNLOADED: screenshot @ 2022-05-16 17:07:02
[[file:images/linux笔记/静态库和动态库/2022-05-16_17-07-02_screenshot.png]]
大一点的项目会编写makefile文件（CMake等等工程管理工具）来生成静态库，输入多个命令太麻烦了。
**** 使用静态库
编写使用上面创建的静态库的测试代码：
#+begin_src bash
#include "StaticMath.h"
#include <iostream>
using namespace std;

int main(int argc, char* argv[])
{
    double a = 10;
    double b = 2;

    cout << "a + b = " << StaticMath::add(a, b) << endl;
    cout << "a - b = " << StaticMath::sub(a, b) << endl;
    cout << "a * b = " << StaticMath::mul(a, b) << endl;
    cout << "a / b = " << StaticMath::div(a, b) << endl;

    StaticMath sm;
    sm.print();

    system("pause");
    return 0;
}
#+END_SRC
Linux下使用静态库，只需要在编译的时候，指定静态库的搜索路径（-L选项）、指定静态库名（不需要lib前缀和.a后缀，-l选项）。
#+begin_src bash
g++ TestStaticLibrary.cpp -L../StaticLibrary -lstaticmath
#+END_SRC
- -L：表示要连接的库所在目录
- -l：指定链接时需要的动态库，编译器查找动态连接库时有隐含的命名规则，即在给出的名字前面加上lib，后面加上.a或.so来确定库的名称。

#+DOWNLOADED: screenshot @ 2022-05-16 17:09:14
[[file:images/linux笔记/静态库和动态库/2022-05-16_17-09-14_screenshot.png]]
*** Windows下创建与使用静态库
**** 创建静态库（.lib）
如果是使用VS命令行生成静态库，也是分两个步骤来生成程序：

首先，通过使用带编译器选项 /c 的 Cl.exe 编译代码 (cl /c StaticMath.cpp)，创建名为“StaticMath.obj”的目标文件。

然后，使用库管理器 Lib.exe 链接代码 (lib StaticMath.obj)，创建静态库StaticMath.lib。

当然，我们一般不这么用，使用VS工程设置更方便。创建win32控制台程序时，勾选静态库类型；打开工程“属性面板”è”配置属性”è”常规”，配置类型选择静态库。

#+DOWNLOADED: screenshot @ 2022-05-16 17:14:22
[[file:images/linux笔记/静态库和动态库/2022-05-16_17-14-22_screenshot.png]]
Build项目即可生成静态库。
**** 使用静态库
测试代码Linux下面的一样。有3种使用方法：

方法一：
在VS中使用静态库方法：

工程“属性面板”è“通用属性”è “框架和引用”è”添加引用”，将显示“添加引用”对话框。 “项目”选项卡列出了当前解决方案中的各个项目以及可以引用的所有库。 在“项目”选项卡中，选择 StaticLibrary。 单击“确定”。

#+DOWNLOADED: screenshot @ 2022-05-16 17:15:04
[[file:images/linux笔记/静态库和动态库/2022-05-16_17-15-04_screenshot.png]]
添加StaticMath.h 头文件目录，必须修改包含目录路径。打开工程“属性面板”è”配置属性”è “C/C++”è” 常规”，在“附加包含目录”属性值中，键入StaticMath.h 头文件所在目录的路径或浏览至该目录。

#+DOWNLOADED: screenshot @ 2022-05-16 17:15:25
[[file:images/linux笔记/静态库和动态库/2022-05-16_17-15-25_screenshot.png]]
编译运行OK。

#+DOWNLOADED: screenshot @ 2022-05-16 17:16:47
[[file:images/linux笔记/静态库和动态库/2022-05-16_17-16-47_screenshot.png]]
如果引用的静态库不是在同一解决方案下的子工程，而是使用第三方提供的静态库lib和头文件，上面的方法设置不了。还有2中方法设置都可行。

方法二：
打开工程“属性面板”è”配置属性”è “链接器”è”命令行”，输入静态库的完整路径即可。


#+DOWNLOADED: screenshot @ 2022-05-16 17:17:36
[[file:images/linux笔记/静态库和动态库/2022-05-16_17-17-36_screenshot.png]]
方法三：
- “属性面板”è”配置属性”è “链接器”è”常规”，附加依赖库目录中输入，静态库所在目录；
- “属性面板”è”配置属性”è “链接器”è”输入”，附加依赖库中输入静态库名StaticLibrary.lib。


#+DOWNLOADED: screenshot @ 2022-05-16 17:18:07
[[file:images/linux笔记/静态库和动态库/2022-05-16_17-18-07_screenshot.png]]

** 动态库
为什么需要动态库，其实也是静态库的特点导致。

空间浪费是静态库的一个问题。

#+DOWNLOADED: screenshot @ 2022-05-16 16:41:30
[[file:images/linux笔记/静态库和动态库/2022-05-16_16-41-30_screenshot.png]]

另一个问题是静态库对程序的更新、部署和发布页会带来麻烦。
如果静态库liba.lib更新了，所以使用它的应用程序都需要重新编译、发布给用户（对于玩家来说，可能是一个很小的改动，却导致整个程序重新下载，全量更新）。

动态库在程序编译时并不会被连接到目标代码中，而是在程序运行是才被载入。
不同的应用程序如果调用相同的库，那么在内存里只需要有一份该共享库的实例，规避了空间浪费问题。
动态库在程序运行是才被载入，也解决了静态库对程序的更新、部署和发布页会带来麻烦。用户只需要更新动态库即可，增量更新。

#+DOWNLOADED: screenshot @ 2022-05-16 16:41:52
[[file:images/linux笔记/静态库和动态库/2022-05-16_16-41-52_screenshot.png]]
动态库特点总结：
1. 动态库把对一些库函数的链接载入推迟到程序运行的时期。
2. 可以实现进程之间的资源共享。（因此动态库也称为共享库）
3. 将一些程序升级变得简单。
4. 甚至可以真正做到链接载入完全由程序员在程序代码中控制（显示调用）。

Window与Linux执行文件格式不同，在创建动态库的时候有一些差异。

- 在Windows系统下的执行文件格式是PE格式，动态库需要一个DllMain函数做出初始化的入口，通常在导出函数的声明时需要有_declspec(dllexport)关键字。
- Linux下gcc编译的执行文件默认是ELF格式，不需要初始化入口，亦不需要函数做特别的声明，编写比较方便。

与创建静态库不同的是，不需要打包工具（ar、lib.exe），直接使用编译器即可创建动态库。

*** Linux下创建与使用动态库
**** linux动态库的命名规则
动态链接库的名字形式为 libxxx.so，前缀是lib，后缀名为“.so”。

针对于实际库文件，每个共享库都有个特殊的名字“soname”。在程序启动后，程序通过这个名字来告诉动态加载器该载入哪个共享库。

在文件系统中，soname仅是一个链接到实际动态库的链接。对于动态库而言，每个库实际上都有另一个名字给编译器来用。它是一个指向实际库镜像文件的链接文件（lib+soname+.so）。
**** 创建动态库（.so）
编写四则运算动态库代码：
DynamicMath.h头文件
#+begin_src bash
#pragma once

class DynamicMath
{
public:
        DynamicMath(void);
        ~DynamicMath(void);

        static double add(double a, double b);//¼Ó·¨
        static double sub(double a, double b);//¼õ·¨
        static double mul(double a, double b);//³Ë·¨
        static double div(double a, double b);//³ý·¨

        void print();
};
#+END_SRC
首先，生成目标文件，此时要加编译器选项-fpic
#+begin_src bash
g++ -fPIC -c DynamicMath.cpp
#+END_SRC
-fPIC 创建与地址无关的编译程序（pic，position independent code），是为了能够在多个应用程序间共享。
然后，生成动态库，此时要加链接器选项-shared
#+begin_src bash
g++ -shared -o libdynmath.so DynamicMath.o
#+END_SRC
-shared指定生成动态链接库。

#+DOWNLOADED: screenshot @ 2022-05-16 19:19:24
[[file:images/linux笔记/静态库和动态库/2022-05-16_19-19-24_screenshot.png]]
其实上面两个步骤可以合并为一个命令：
#+begin_src bash
g++ -fPIC -shared -o libdynmath.so DynamicMath.cpp
#+END_SRC 
**** 使用动态库
编写使用动态库的测试代码：
#+begin_src bash
#include "../DynamicLibrary/DynamicMath.h"
#include <iostream>

using namespace std;
int main(int argc, char* argv[])
{
    double a = 10;
    double b = 2;

    cout << "a + b = " << DynamicMath::add(a, b) << endl;
    cout << "a - b = " << DynamicMath::sub(a, b) << endl;
    cout << "a * b = " << DynamicMath::mul(a, b) << endl;
    cout << "a / b = " << DynamicMath::div(a, b) << endl;

    DynamicMath dyn;
    dyn.print();
    return 0;
}
#+END_SRC
引用动态库编译成可执行文件（跟静态库方式一样）：
#+begin_src bash
g++ TestDynamicLibrary.cpp -L../DynamicLibrary -ldynmath
#+END_SRC

在执行的时候是如何定位共享库文件的呢？
- 当系统加载可执行代码时候，能够知道其所依赖的库的名字，但是还需要知道绝对路径。此时就需要系统动态载入器(dynamic linker/loader)。
- 对于elf格式的可执行程序，是由ld-linux.so*来完成的，它先后搜索elf文件的 DT_RPATH段—环境变量LD_LIBRARY_PATH—/etc/ld.so.cache文件列表—/lib/,/usr/lib 目录找到库文件后将其载入内存。

如何让系统能够找到它：
- 如果安装在/lib或者/usr/lib下，那么ld默认能够找到，无需其他操作。
- 如果安装在其他目录，需要将其添加到/etc/ld.so.cache文件中，步骤如下：
    - 编辑/etc/ld.so.conf文件，加入库文件所在目录的路径
    - 运行ldconfig ，该命令会重建/etc/ld.so.cache文件

我们将创建的动态库复制到/usr/lib下面，然后运行测试程序。
#+DOWNLOADED: screenshot @ 2022-05-16 19:23:15
[[file:images/linux笔记/静态库和动态库/2022-05-16_19-23-15_screenshot.png]]
*** Windows下创建与使用动态库
**** 创建动态库（.dll）
与Linux相比，在Windows系统下创建动态库要稍微麻烦一些。首先，需要一个DllMain函数做出初始化的入口（创建win32控制台程序时，勾选DLL类型会自动生成这个文件）：

dllmain.cpp入口文件
#+begin_src c++
// dllmain.cpp : Defines the entry point for the DLL application.

#include "stdafx.h"
BOOL APIENTRY DllMain( HMODULE hModule,
                       DWORD  ul_reason_for_call,
                       LPVOID lpReserved
                     )
{
    switch (ul_reason_for_call)
    {
    case DLL_PROCESS_ATTACH:
    case DLL_THREAD_ATTACH:
    case DLL_THREAD_DETACH:
    case DLL_PROCESS_DETACH:
        break;
    }
    return TRUE;
}
#+END_SRC
通常在导出函数的声明时需要有_declspec(dllexport)关键字：

DynamicMath.h头文件
#+BEGIN_SRC c++
#pragma once

class DynamicMath
{
public:
    __declspec(dllexport) DynamicMath(void);
    __declspec(dllexport) ~DynamicMath(void);

    static __declspec(dllexport) double add(double a, double b);//加法
    static __declspec(dllexport) double sub(double a, double b);//减法
    static __declspec(dllexport) double mul(double a, double b);//乘法
    static __declspec(dllexport) double div(double a, double b);//除法

    __declspec(dllexport) void print();
};
#+END_SRC
生成动态库需要设置工程属性，打开工程“属性面板”è”配置属性”è”常规”，配置类型选择动态库。

#+DOWNLOADED: screenshot @ 2022-05-16 19:25:49
[[file:images/linux笔记/静态库和动态库/2022-05-16_19-25-49_screenshot.png]]
Build项目即可生成动态库。
**** 使用动态库
创建win32控制台测试程序：
TestDynamicLibrary.cpp测试程序
#+BEGIN_SRC c++
#include "stdafx.h"
#include "DynamicMath.h"

#include <iostream>
using namespace std;

int _tmain(int argc, _TCHAR* argv[])
{
    double a = 10;
    double b = 2;

    cout << "a + b = " << DynamicMath::add(a, b) << endl;

    cout << "a - b = " << DynamicMath::sub(a, b) << endl;

    cout << "a * b = " << DynamicMath::mul(a, b) << endl;

    cout << "a / b = " << DynamicMath::div(a, b) << endl;
 
    DynamicMath dyn;
    dyn.print();

    system("pause");
    return 0;
}
#+END_SRC
方法一：
工程“属性面板”è“通用属性”è “框架和引用”è”添加引用”，将显示“添加引用”对话框。“项目”选项卡列出了当前解决方案中的各个项目以及可以引用的所有库。 在“项目”选项卡中，选择 DynamicLibrary。 单击“确定”。

#+DOWNLOADED: screenshot @ 2022-05-16 19:27:07
[[file:images/linux笔记/静态库和动态库/2022-05-16_19-27-07_screenshot.png]]
添加DynamicMath.h 头文件目录，必须修改包含目录路径。打开工程“属性面板”è”配置属性”è “C/C++”è” 常规”，在“附加包含目录”属性值中，键入DynamicMath.h 头文件所在目录的路径或浏览至该目录。

#+DOWNLOADED: screenshot @ 2022-05-16 19:27:20
[[file:images/linux笔记/静态库和动态库/2022-05-16_19-27-20_screenshot.png]]
编译运行OK。

#+DOWNLOADED: screenshot @ 2022-05-16 19:27:29
[[file:images/linux笔记/静态库和动态库/2022-05-16_19-27-29_screenshot.png]]
方法二：
“属性面板”è”配置属性”è “链接器”è”常规”，附加依赖库目录中输入，动态库所在目录；

#+DOWNLOADED: screenshot @ 2022-05-16 19:27:45
[[file:images/linux笔记/静态库和动态库/2022-05-16_19-27-45_screenshot.png]]
“属性面板”è”配置属性”è “链接器”è”输入”，附加依赖库中输入动态库编译出来的DynamicLibrary.lib。

#+DOWNLOADED: screenshot @ 2022-05-16 19:27:55
[[file:images/linux笔记/静态库和动态库/2022-05-16_19-27-55_screenshot.png]]
这里可能大家有个疑问，动态库怎么还有一个DynamicLibrary.lib文件？即无论是静态链接库还是动态链接库，最后都有lib文件，那么两者区别是什么呢？其实，两个是完全不一样的东西。

#+DOWNLOADED: screenshot @ 2022-05-16 19:28:06
[[file:images/linux笔记/静态库和动态库/2022-05-16_19-28-06_screenshot.png]]
StaticLibrary.lib的大小为190KB，DynamicLibrary.lib的大小为3KB，静态库对应的lib文件叫静态库，动态库对应的lib文件叫【导入库】。实际上静态库本身就包含了实际执行代码、符号表等等，而对于导入库而言，其实际的执行代码位于动态库中，导入库只包含了地址符号表等，确保程序找到对应函数的一些基本地址信息。

** 动态库的显式调用
上面介绍的动态库使用方法和静态库类似属于隐式调用，编译的时候指定相应的库和查找路径。其实，动态库还可以显式调用。【在C语言中】，显示调用一个动态库轻而易举！

*** 在Linux下显式调用动态库
#include <dlfcn.h>，提供了下面几个接口：
- void * dlopen( const char * pathname, int mode )：函数以指定模式打开指定的动态连接库文件，并返回一个句柄给调用进程。
- void* dlsym(void* handle,const char* symbol)：dlsym根据动态链接库操作句柄(pHandle)与符号(symbol)，返回符号对应的地址。使用这个函数不但可以获取函数地址，也可以获取变量地址。
- int dlclose (void *handle)：dlclose用于关闭指定句柄的动态链接库，只有当此动态链接库的使用计数为0时,才会真正被系统卸载。
- const char *dlerror(void)：当动态链接库操作函数执行失败时，dlerror可以返回出错信息，返回值为NULL时表示操作函数执行成功。

*** 在Windows下显式调用动态库
应用程序必须进行函数调用以在运行时显式加载 DLL。为显式链接到 DLL，应用程序必须：
- 调用 LoadLibrary（或相似的函数）以加载 DLL 和获取模块句柄。
- 调用 GetProcAddress，以获取指向应用程序要调用的每个导出函数的函数指针。由于应用程序是通过指针调用 DLL 的函数，编译器不生成外部引用，故无需与导入库链接。
- 使用完 DLL 后调用 FreeLibrary。

*** 显式调用C++动态库注意点
对C++来说，情况稍微复杂。显式加载一个C++动态库的困难一部分是因为C++的name mangling；另一部分是因为没有提供一个合适的API来装载类，在C++中，您可能要用到库中的一个类，而这需要创建该类的一个实例，这不容易做到。

name mangling可以通过extern "C"解决。C++有个特定的关键字用来声明采用C binding的函数：extern "C" 。用 extern "C"声明的函数将使用函数名作符号名，就像C函数一样。因此，只有非成员函数才能被声明为extern "C"，并且不能被重载。尽管限制多多，extern "C"函数还是非常有用，因为它们可以象C函数一样被dlopen动态加载。冠以extern "C"限定符后，并不意味着函数中无法使用C++代码了，相反，它仍然是一个完全的C++函数，可以使用任何C++特性和各种类型的参数。
** 区别与联系
二者的不同点在于代码被载入的时刻不同。

静态库的代码在编译过程中已经被载入可执行程序,因此体积比较大。

动态库(共享库)的代码在可执行程序运行时才载入内存，在编译过程中仅简单的引用，因此代码体积比较小。

不同的应用程序如果调用相同的库,那么在内存中只需要有一份该动态库(共享库)的实例。

静态库和动态库的最大区别,静态情况下,把库直接加载到程序中,而动态库链接的时候,它只是保留接口,将动态库与程序代码独立,这样就可以提高代码的可复用度，和降低程序的耦合度。

静态库在程序编译时会被连接到目标代码中，程序运行时将不再需要该静态库。

动态库在程序编译时并不会被连接到目标代码中，而是在程序运行是才被载入，因此在程序运行时还需要动态库存在
** 参考文章
[[https://blog.nowcoder.net/n/8e07e78a703c413c916d0f830b8ceda7][浅析静态库和动态库的区别]]
[[https://www.cnblogs.com/skynet/p/3372855.html][C++静态库与动态库]]
* 创建用户
下面将创建用户 zyq01
1. 输入命令：sudo useradd zyq01，回车，创建用户；
2. 输入命令：ls，回车，查看用户是否创建成功（可以看到用户已经创建成功了）；
3. 输入命令：sudo passwd zyq01，回车，设置登录用户密码；
4. 输入命令：su zyq01，切换到新用户

* 未分类
如何在 QEMU 中使用 gdb：

修改自己 home 目录下的 .gdbinit 文件，允许 gdb 在xv6-labs-2020这个目录启动的时候，加载该文件夹下的 .gdbinit 文件。
#+begin_src bash
echo "add-auto-load-safe-path $(pwd)/.gdbinit " >> ~/.gdbinit
#+END_SRC
